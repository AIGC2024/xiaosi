[{"categories":["eks"],"content":" 运行环境： eks: 1.29 设置默认存储类如果已有默认的存储类，则可跳过这部分。以下是使用gp3做为默认存储类 查找集群是否有OIDC ID # https://docs.aws.amazon.com/zh_cn/eks/latest/userguide/enable-iam-roles-for-service-accounts.html ## 搜索 OIDC ID ，确定集群是否拥有现有 IAM OIDC 提供商。 [root@localhost ~]# aws eks describe-cluster \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --name \"eks01\" \\ --query \"cluster.identity.oidc.issuer\" \\ --output text | cut -d '/' -f 5 363BFA878EE4DF9B3569DE2E5010DAA5 确定账户中是否已存在集群IAM OIDC ID商。下面表示没有 [root@localhost ~]# aws iam list-open-id-connect-providers \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" { \"OpenIDConnectProviderList\": [] } 创建 IAM OIDC [root@localhost ~]# eksctl utils associate-iam-oidc-provider \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --cluster \"eks01\" \\ --approve 再次验证 [root@localhost ~]# aws iam --profile \"zjc-yuhai\" --region \"ap-southeast-1\" list-open-id-connect-providers { \"OpenIDConnectProviderList\": [ { \"Arn\": \"arn:aws:iam::968767926216:oidc-provider/oidc.eks.ap-southeast-1.amazonaws.com/id/363BFA878EE4DF9B3569DE2E5010DAA5\" } ] } 创建拥有使用EBS的IAM角色附加给EKS # https://docs.aws.amazon.com/zh_cn/eks/latest/userguide/csi-iam-role.html # 如果集群位于 AWS GovCloud（美国东部）或 AWS GovCloud（美国西部）AWS 区域，则将 arn:aws: 替换为 arn:aws-us-gov:。 [root@localhost singapore]# eksctl create iamserviceaccount \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --cluster \"eks01\" \\ --name ebs-csi-controller-sa \\ --namespace kube-system \\ --role-name AmazonEKS_EBS_CSI_DriverRole \\ --role-only \\ --attach-policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy \\ --approve [root@localhost ~]# eksctl get iamserviceaccount \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --cluster \"eks01\" \\ --name ebs-csi-controller-sa \\ --output json | jq 添加 EBS CSI 组件 [root@localhost singapore]# eksctl create addon \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --name \"aws-ebs-csi-driver\" \\ --cluster \"eks01\" \\ --service-account-role-arn arn:aws:iam::968767926216:role/AmazonEKS_EBS_CSI_DriverRole \\ --force 查看 EBS 插件状态 [root@localhost yh-eks]# eksctl get addon \\ \u003e --profile \"zjc-yuhai\" \\ \u003e --region \"ap-southeast-1\" \\ \u003e --cluster \"yh-eks\" \\ \u003e --name \"aws-ebs-csi-driver\" \\ \u003e --output json | jq 2023-07-27 15:56:02 [ℹ] Kubernetes version \"1.27\" in use by cluster \"yh-eks\" 2023-07-27 15:56:03 [ℹ] to see issues for an addon run `eksctl get addon --name \u003caddon-name\u003e --cluster \u003ccluster-name\u003e` [ { \"Name\": \"aws-ebs-csi-driver\", \"Version\": \"v1.21.0-eksbuild.1\", \"NewerVersion\": \"\", \"IAMRole\": \"arn:aws:iam::968767926216:role/AmazonEKS_EBS_CSI_DriverRole\", \"Status\": \"ACTIVE\", \"ConfigurationValues\": \"\", \"Issues\": null } ] EKS 不会自动为集群更新 Amazon EBS CSI。使用下面命令更新 EBS 驱动插件(如果需要) [root@localhost ~]# eksctl update addon \\ --name \"aws-ebs-csi-driver\" \\ --version \"v1.11.4-eksbuild.1\" \\ --cluster \"my-cluster\" \\ --force 删除默认的GP2存储类，后续创建 GP3 做为默认的存储类 [root@localhost ~]# kubectl delete storageclass gp2 \\ --kubeconfig .kube/singapore-eks01-config 创建gp3 为默认存储类 [root@localhost ~]# cat aws-ebs.yaml apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: annotations: storageclass.kubernetes.io/is-default-class: \"true\" name: aws-ebs provisioner: ebs.csi.aws.com reclaimPolicy: Delete volumeBindingMode: WaitForFirstConsumer [root@localhost ~]# kubectl apply -f aws-ebs.yaml --kubeconfig /root/.kube/singapore-eks01-config 使用 AWS Load Balancer 做为Ingress如果不使用aws负载均衡器可跳过这部分，以下是使用AWS Load Balancer Ingress 控制器步骤 创建 iam 策略 ## github: https://github.com/kubernetes-sigs/aws-load-balancer-controller ## 美国地区使用：https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.4.7/docs/install/iam_policy_us-gov.json [root@localhost ~]# mkdir AwsLoadBalancerController ; cd AwsLoadBalancerController # 下载 IAM 策略文件 [root@localhost AwsLoadBalancerController]# curl -Os https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.5.3/docs/install/iam_policy.json [root@localhost AwsLoadBalancerController]# ls iam_policy.json # 创建策略 [root@localhost AwsLoadBalancerController]# aw","date":"2024-03-01","objectID":"/eksPrometheus/:0:0","tags":[null],"title":"eks中部署prometheus","uri":"/eksPrometheus/"},{"categories":["aws"],"content":" 运行环境： 内容来自以下文档： Amazon CloudWatch 用户指南：使用 CloudWatch 代理收集指标、日志和跟踪信息 Amazon CloudWatch 用户指南：发布 CloudWatch 指标的 AWS 服务 Amazon EC2用户指南（适用于 Linux 实例）：列出实例的可用 CloudWatch 指标 指标指标仅存在于创建它们的区域中。指标无法删除，但如果在 15 个月后没有向指标发布新数据，这些指标将自动过期。依据滚动机制，15 个月之前的数据点将过期；当新的数据点进入时，15 个月之前的数据将被丢弃。指标是通过一个名称、一个命名空间以及零个或多个维度进行唯一定义的。指标中的每个数据点都有一个时间戳和一个度量单位（可选）。您可以从 CloudWatch 中检索任何指标的统计数据。 CloudWatch 将保留指标数据，如下所示： 时间段短于 60 秒的数据点的可用时间为 3 小时。这些数据点是高精度自定义指标。 时间段为 60 秒 (1 分钟) 的数据点可用 15 天 时间段为 300 秒（5 分钟）的数据点可用 63 天 时间段为 3600 秒 (1 小时) 的数据点可用 455 天 (15 个月) 最初以较短时间段发布的数据点汇总在一起，可实现长期存储。例如，如果您使用 1 分钟的时间段收集数据，数据以 1 分钟的精度保持 15 天可用。15 天之后，此数据仍可用，但汇总在一起，只能以 5 分钟的精度检索。63 天之后，数据进一步汇总，以 1 小时的精度提供。 控制台中不会显示在过去两周内没有任何新数据点的指标。当您在控制台的 All metrics（全部指标）选项卡的搜索框中键入指标名称或维度名称时，它们也不会显示，并且 list-metrics 命令的结果中不会返回它们。检索这些指标的最佳方法是使用 AWS CLI 中的 get-metric-data 或者 get-metric-statistics 命令。 使用 CloudWatch Metrics Insights 查询指标CloudWatch Metrics Insights 是一个功能强大的高性能 SQL 查询引擎，可以使用它来大规模查询指标，有以下限制： 只能查询最近三个小时的数据 单个查询可处理的指标不超过 10,000 个。这意味着，如果 SELECT、FROM 和 WHERE 子句匹配 10,000 个以上的指标，查询只处理找到的前 10,000 个指标。 单个查询可返回的时间序列不超过 500 个。这意味着，如果查询返回 500 个以上的指标，则查询结果中并非所有指标都将返回。如果您使用的是 ORDER BY 子句，则将对正在处理的所有指标进行排序，并根据您的 ORDER BY 子句，具有前 500 个最高值或最低值的指标将返回。 每个区域最多可以有 75 个 Metrics Insights 告警。 Metrics Insights 不支持低于一分钟的指标，低于一分钟的指标会以一分钟聚合 每个 GetMetricData 操作只能有一个查询，但是您可以在控制面板中有多个小组件，每个小组件都包含一个查询 CloudWatch Metrics Insights 语法如下 SELECT FUNCTION(metricName) FROM namespace | SCHEMA(...) [ WHERE labelKey OPERATOR labelValue [AND ... ] ] [ GROUP BY labelKey [ , ... ] ] [ ORDER BY FUNCTION() [ DESC | ASC ] ] [ LIMIT number ] FUNCTION 的有效值为: AVG 计算查询匹配的观测值的平均值。 COUNT 返回查询匹配的观测值的计数。 MAX 返回查询匹配的观测值的最大值。 MIN 返回查询匹配的观测值的最小值。 SUM 计算查询匹配的观测值的总和。 FROM 是必选的，有以下用法 FROM 指标命名空间: 该方式返回所有指标 FROM SCHEMA(\"指标命名空间\",[指标维度1,指标维度2,...): 通过指标维度筛选 WHERE 可通过指标值筛选，标签值必须始终放在单引号中。支持以下运算符： = 值相等 != 值不相等 AND 前后条件相等，可以使用多个AND GROUP BY: 结果分组依据 ORDER BY子句可以根据使用的有效函数 AVG()、COUNT()、MAX()、MIN() 和 SUM()返回什值进行升序（ASC也是默认值） 或降序（DESC） LIMIT 将限制返回序列最大数量 SEARCH('{AWS/EC2,InstanceId} MetricName=\"CPUUtilization\"', 'Average', 300) 搜索表达式搜索表达式可让您快速向图表添加多个相关指标。它们还使您能够创建动态图表，从而自动将相应的指标添加到其显示中，即使您在第一次创建图表时不存在这些指标也是如此。例如，您可以创建一个搜索表达式来显示区域中所有实例的 AWS/EC2 CPUUtilization 指标。如果您稍后启动新实例，则新实例的 CPUUtilization 会自动添加到图表中。 被搜索对象有：命名空间、指标名名称、指标值、指标维度 搜索表达式有以下限制： 只能找到在过去两周内的指标 由于搜索表达式可返回多个时间序列，因此无法根据创建告警 最大搜索表达式查询大小为 1024 个字符。一个图表上最多可以包含 100 个搜索表达式。一个图表可以显示多达 500 个时间序列。 语法如下： SEARCH(' {Namespace, DimensionName1, DimensionName2, ...} SearchTerm', 'Statistic') DimensionName: 是指标维度 SearchTerm: 代指搜索条件的表达式 Statistic: 代指统计方式名称，如Average（平均值） 以下是一个示例： # 搜索 AWS/EC2 带有 InstanceId 维度的指标，如果指标名称是CPUUtilization，则返回平均值 SEARCH('{AWS/EC2,InstanceId} MetricName=\"CPUUtilization\"', 'Average') ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:0:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" 指标架构指标架构即大括号部分是可以缺省的，缺省情况下表示所有命名空间中的搜索 # 搜索名称为 CPUUtilization 的命名空间、指标名称、维度名称、维度值 SEARCH(' \"CPUUtilization\" ', 'Average') # 添加条件，缩小范围 SEARCH(' \"AWS/EC2\" AND MetricName=\"CPUUtilization\" ', 'Average') ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:1:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" 搜索字符串以下搜索表达示中\"Errors\" 中有双引号，表示精确匹配搜索对象 # 只匹配为Errors的对象 SEARCH(' \"Errors\" ', 'Average') 如果 SearchTerm 部分指定的字符串没有双引号时，搜索词会被令牌化。CloudWatch 根据部分匹配项查找指标，部分匹配项是根据搜索词生成的单个令牌与根据指标名称、命名空间、维度名称或维度值生成的单个令牌的匹配项。如 # 匹配对象中含有Errors的对象，如名为 ConnectionErrors 或 errors 的指标 SEARCH('Errors', 'Average') 搜索词令牌化即拆分搜索单词生成的字符串，大致原则如下： 以驼峰式大小写区分 数字字符也可用作新令牌的开头 非字母数字字符用作分隔符 从而在非字母数字字符之前和之后创建令牌 相同类型的令牌分隔符字符的连续字符串会生成一个令牌 单个搜索词生成的令牌都是小写的 原始字符串（匹配的搜索对象） 生成的令牌（可用于SearchTerm 部分指定的单词） CustomCount1 customcount1, custom, count, 1, COUNT SDBFailure sdbfailure, sdb, failure Project2-trial333 project2trial333, project, 2, trial, 333 如果搜索词是复合对象，那么搜索是区分大小写的，如下面示例 # 能匹配 CustomCount1 SEARCH('CustomCount', 'Average') # 能匹配 CustomCount1 SEARCH('Count1', 'Average') # 不能匹配 CustomCount1 SEARCH('customcount', 'Average') # 不能匹配 CustomCount1 SEARCH('count1', 'Average') ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:2:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" 限制搜索对象 指定指标名示例 SEARCH(' MetricName=\"CustomCount1\" ', 'Maximum') 指定命名空间与指标维度及其值 SEARCH(' InstanceType=\"t2.micro\" Namespace=\"AWS/EC2\" ', 'Average') ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:3:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" 布尔运算符搜索支持在 SearchTerm 中使用布尔运算符 AND、OR 和 NOT。布尔运算符被括在用于将整个搜索词引起来的单引号中。布尔运算符必须是大写。 AND示例 # AND 可以缺省 SEARCH('{AWS/EC2,InstanceId} network AND packets', 'Average') NOT示例 # 排除名为 i-1234567890123456 的对象 SEARCH(' {AWS/EC2,InstanceId} MetricName=\"CPUUtilization\" NOT i-1234567890123456 ', 'Average') # 排除AWS命名空间 SEARCH( 'NOT Namespace=AWS ', 'Maximum') # 排除名为 ProjectA 与 ProjectB 的对象 SEARCH(' {AWS/EC2,InstanceId} MetricName=\"CPUUtilization\" NOT \"ProjectA\" NOT \"ProjectB\" ', 'Average') 布尔运算符支持使用括号进行分组 SEARCH(' (EC2 OR EBS) AND MetricName=ReadOps ', 'Maximum') SEARCH(' (EC2 OR EBS) AND ReadOps AND ProjectA ', 'Maximum') SEARCH(' {AWS/Lambda,FunctionName} MetricName=\"Errors\" OR (MetricName=\"Invocations\" AND (ProjectA OR ProjectB)) ', 'Average') 仪表盘Dashboards 被翻译为控制面板，创建仪表盘后可以通前端提示或修改json内容创建/修改仪表盘 通过修改json文本内容步骤如下： 创建或打开仪表盘 点击右上角操作下拉按妞，选择查看/编辑来源 在窗口中修改json内容后点击更新 面板josn内容可查看Dashboard Body Structure and Syntax，以下是部分注释 { // 仪表盘使用的变量，可选 \"values\": [ ], // 定义仪表盘的字段，是必须的 \"widgets\": [ { // 小仪表盘类型，必须字段 // 值为之一：metric , text , log , alarm , explorer \"type\": // 仪表盘窗口高度 // 值为：1~100 \"height\": // 仪表盘窗口宽度 // 值为：1~24 \"width\": // 仪表盘水平位置，必须字段 // 值为：0~23整数 \"y\": // 仪表盘垂直位置，必须字段 // 值为：大于或等于0的整数 \"x\": // 小仪表盘定义字段 \"properties\": { // aws 区域，必须字段 \"region\": // 指标表达式 // [ {\"expression\" : \"expression\", [\"label\" : \"label\"] , [\"id\" : \"id\"] } ] // [ Namespace, MetricName, [{DimensionName,DimensionValue}...] {Rendering Properties Object} ] \"metrics\": [ [....] ], // 数据点时间周期，单位为秒 // 值为：60或60的倍数 \"period\": // 指标统计信息 // 值为：SampleCount , Average , Sum , Minimum , Maximum \"stat\": // 仪表盘标题 \"title\": // 是否显示实时数据，立即显示最新数据点 // 值为：true 或 false \"liveData\": // 图像出现位置 \"legend\": { // 值为：right, bottom, hidden \"position\": }, // 图形形状： // 值为之一：timeSeries(线形图或) , singleValue(数字) , gauge , bar , pie , taule \"view\": // 是否将线形图改为堆叠面积图 // 值为：true 或 false \"stacked\": } }, ] } 其中@.widgets.properties.metrics 字段说明： # 指标命名空间,指标名称, 可选的指标维度与值，{度量属性} [ Namespace, MetricName, [{DimensionName,DimensionValue}...] {Rendering Properties Object} ] Rendering Properties Object: 是度量（每条查询）属性，即当前指标展示属性，会覆盖小仪表盘的值（@.widgets.properties）。如： stat: 统计方式 yAxis: 图表单位展示位置，默认为left（左），可以指定为right（右） clolr: html图表展示的颜色 label: html图表展示该指标显示的标签名，用于区分查询语句 period: 时间颗粒度，为60或60的倍数，单位为秒 visible: 是否在html图表中展示 id: 此查询语句ID # expression 为表达示：数学表达式、Metrics Insights，搜索表达式 [ {\"expression\" : \"expression\", [\"label\" : \"label\"] , [\"id\" : \"id\"] } ] 示例： # 命名空间：CWAgent, 指标：cpu_usage_idle, 后面是维度与值, {...} [ \"CWAgent\", \"cpu_usage_idle\", \"InstanceId\", \"i-0cdd956cd0af2408e\", \"ImageId\", \"ami-08a2628fc1b0020bf\", \"cpu\", \"cpu3\", \"InstanceType\", \"c5a.xlarge\", { \"region\": \"ap-southeast-1\", \"id\": \"m1\", \"visible\": false } ], # 一个点.表示引用上层，但不含展示属性部分 # 三个点.表示引用上层，但为贪婪匹配 [ \"...\", \"cpu0\", \".\", \".\", { \"region\": \"ap-southeast-1\", \"id\": \"m2\", \"visible\": false } ], [ \"...\", \"cpu2\", \".\", \".\", { \"region\": \"ap-southeast-1\", \"id\": \"m3\", \"visible\": false } ], [ \"...\", \"cpu1\", \".\", \".\", { \"region\": \"ap-southeast-1\", \"id\": \"m4\", \"visible\": false } ], # expression 后面接的是表达示 [ { \"expression\": \"100-(m1+m2+m3+m4)/4\", \"label\": \"表达式1\", \"id\": \"e1\", \"region\": \"ap-southeast-1\", \"stat\": \"Maximum\", \"color\": \"#8c564b\" } ] EC2 linux实例指标 指标名称 单位 说明 CPUUtilization 百分比 用于运行 EC2 实例的物理 CPU 时间的百分比，包括运行用户代码和 Amazon EC2 代码所花费的时间。 DiskReadOps 计数 在指定时间段内从可供实例使用的所有实例存储卷完成的读取操作次数。 DiskWriteOps 计数 在指定时间段内向可供实例使用的所有实例存储卷完成的写入操作次数。 DiskWriteBytes 字节 向可供实例使用的所有实例存储卷写入的字节数。 NetworkIn 字节 实例在所有网络接口上收到的字节数。 NetworkOut 字节 实例在所有网络接口上发送的字节数 NetworkPacketsIn 计数 实例在所有网络接口上收到的数据包数 NetworkPacketsOut 计数 实例在所有网络接口上发送的数据包数。 CPUCreditUsage 计数 实例为保持 CPU 使用率而花费的 CPU 积分数。CPU 信用指标仅每 5 分钟提供一次。如果您指定一个大于五分钟的时间段，请使用Sum 统计数据，而非 Average 统计数据。 CPUCreditBalance 计数 实例自启动后已累积获得的 CPU 积分数。 CPUSurplusCreditBalance 计数 实例花费的超额积分数。 CPUSurplusCreditsCharged 计数 未由获得的 CPU 积分支付并且会产生额外费用的已花费超额积分数。 StatusCheckFailed 计数 报告实例在上一分钟是否通过了实例状态检查和系统状态检查。此指标可以是 0（通过）或 1（失败）。 StatusCheckFailed_Instance 计数 报告实例在上个 1 分钟内是否通过了 实例状况检查。 StatusCheckFailed_System 计数 报告实例在上一分钟内是否通过了 系统状况检查。 StatusCheckFailed_AttachedEBS 计数 报告实例在上一分钟内是否通过了附加的 EBS 卷状态检查。 EC2 指标都有以下维度","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:4:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" CloudWatch agentCloudWatch 代理执行以下操作： 跨操作系统从 Amazon EC2 实例中收集内部系统级指标。 从本地服务器中收集系统级别指标 使用 StatsD 和 collectd 协议从应用程序或服务中检索自定义指标 由统一 CloudWatch代理收集的日志在 Amazon CloudWatch Logs中处理和存储 ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:5:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" 在EC2中运行 CloudWatch agent 创建CloudWatch 代理将指标写入 CloudWatch 所需的权限 登录到AWS IAM 控制台 在左侧的导航窗格中选择：访问管理（Access management）-\u003e Roles (角色) -\u003e Create role (创建角色) 在受信任实体的类型（Trusted entity type）中选择服务（AWS service） 在使用案例(Use case)中搜索与指定ec2后选择下一步 在权限策略(Permissions policies)中搜索并指定CloudWatchAgentServerPolicy。然后下一步 指定角色名称，并创建 对于创建中的EC2，在高级详细信息中指定IAM 实例配置文件值为上一步创建的角色 在系统中安装amazon-cloudwatch-agent Amazon Linux 2 系统可以直接使用以下命令安装 sudo yum install amazon-cloudwatch-agent centos 系列： [root@ip-172-31-3-132 ~]# dnf -y install https://amazoncloudwatch-agent.s3.amazonaws.com/centos/amd64/latest/amazon-cloudwatch-agent.rpm ... Installed: amazon-cloudwatch-agent-1.300033.0b462-1.x86_64 Complete! ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:6:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" CloudWatch 代理配置文件代理配置文件是一个 JSON 文件，它指定了该代理要收集的指标(包括自定义指标)、日志和跟踪信息，每次更改代理配置文件时，您必须重新启动该代理以使更改生效。 配置文件json文件分为以下几部分： agent: 默认配置值，会被其它部分覆盖 metrics: 收集指标并发布到 CloudWatch logs: 将日志文件发布到 CloudWatch Logs traces: 部分指定收集并发送到 AWS X-Ray ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:7:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" 使用二进制文件生成配置文件运行该二进制文件可通过选项生成配置文件，文件将保存到/opt/aws/amazon-cloudwatch-agent/bin/config.json # 执行后为交互式选项 [root@ip-172-31-3-132 ~]# sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-config-wizard ================================================================ = Welcome to the Amazon CloudWatch Agent Configuration Manager = = = = CloudWatch Agent allows you to collect metrics and logs from = = your host and send them to CloudWatch. Additional CloudWatch = = charges may apply. = ================================================================ On which OS are you planning to use the agent? 1. linux 2. windows 3. darwin default choice: [1]: 1 。。。。。。 Please check the above content of the config. The config file is also located at /opt/aws/amazon-cloudwatch-agent/bin/config.json. Edit it manually if needed. Do you want to store the config in the SSM parameter store? 1. yes 2. no default choice: [1]: 2 Program exits now. ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:7:1","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" 运行 CloudWatch 代理amazon-cloudwatch-agent-ctl 查找帮助选项 [root@ip-172-31-3-132 ~]# amazon-cloudwatch-agent-ctl --help Invalid option: -- -a: action stop: stop the agent process. start: start the agent process. status: get the status of the agent process. fetch-config: # 应用配置文件（并不会重启进程） append-config: # 添加json字段与值到配置文件 remove-config: # 从配置文件移除json字段与值 set-log-level: # 日本级别 -m: mode ec2: # ec2实例运行 onPremise, onPrem: # indicate this is on onPremise host. auto: # 自动判断 -s # 执行 'fetch-config', 'append-config', 'remove-config' 动作时重启进程 -c # 指定运行时配置文件。有以下方式 # default: 默认配置 # ssm:\u003cparameter-store-name\u003e: AWS Systems Manager 地址 # file:\u003cfile-path\u003e: 本地主机地址 示例 [root@ip-172-31-3-132 ~]# amazon-cloudwatch-agent-ctl \\ -a fetch-config -s \\ -m ec2 \\ -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json ****** processing amazon-cloudwatch-agent ****** ... amazon-cloudwatch-agent has already been stopped Created symlink /etc/systemd/system/multi-user.target.wants/amazon-cloudwatch-agent.service → /etc/systemd/system/amazon-cloudwatch-agent.service. [root@ip-172-31-3-132 ~]# [root@ip-172-31-3-132 ~]# systemctl status amazon-cloudwatch-agent.service ● amazon-cloudwatch-agent.service - Amazon CloudWatch Agent Loaded: loaded (/etc/systemd/system/amazon-cloudwatch-agent.service; enabled; preset: disabled) Active: active (running) since Thu 2024-02-22 08:59:06 UTC; 26s ago Main PID: 4260 (amazon-cloudwat) Tasks: 9 (limit: 47887) Memory: 22.8M CPU: 217ms CGroup: /system.slice/amazon-cloudwatch-agent.service ... ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:7:2","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["aws"],"content":" CloudWatch agent 收集的指标CloudWatch 代理收集的指标 ","date":"2024-02-22","objectID":"/awsCloudWatchMetric/:8:0","tags":["aws","CloudWatch"],"title":"Amazon CloudWatch - Amazon CloudWatch 可实时监控您的亚马逊云科技 (AWS) 资源以及您在 AWS 上运行的应用程序。","uri":"/awsCloudWatchMetric/"},{"categories":["linux"],"content":" 运行环境： 内容来自以下文档： 大魔王：CentOS7 配置Mailx使用SMTP发送邮件 802.11：解决mailx发邮件报错 mail、mailx和sendmail介绍　mail是mailx的别名，最初叫nail（与arch linux目前用的S-nail基因相同）；mail是Heirloom的一个子项目。sendmail是Eric Allman的作品，都是开源项目；mail是用户代理（客户端），sendmail是邮件传输代理（服务器）；mail默认使用sendmail对外发送邮件。 总结：mail和mailx是同一个东西，大约类似于发信用的foxmail、outlook等工具，sendmail大约相当于163/qq邮箱的服务器软件。 SSL、TLS和STARTTLS介绍我们知道云服务器基本上不允许25端口对外通信，要对外发邮件只能考虑465和587端口。那么465和587端口有什么区别？这要先从SSL、TLS和STARTTLS的区别开始说。 SSL（Secure Socket Layer）是加密传输层，TLS(Transport Layer Security)是SSL的继承者和升级版，提供更好的安全性和性能。SSL有SSL v2、SSL v3两个版本，目前都不建议使用。TLS有TSL v1.0-v1.3，建议至少使用TLS v1.2。 TLS和STARTTLS两者关系不大，但更让人容易产生误解，原因是名字中都带有TLS。STARTTLS是升级非安全连接为安全连接的协议，并没有强制使用加密。当服务端支持时，客户端和服务端才协商将已经建立的连接升级到SSL或者TLS加密。 接着看465端口和587端口。我们知道25端口刚被设计出来时是用于转发邮件的，没有考虑认证、加密等问题。随着垃圾邮件泛滥、网络安全问题严重，MSA、ESMTP/SMTPS等概念和协议被设计出来。1997年465端口被注册用于加密方式（SMTPS）提交邮件，那时还没有STARTTLS。1998年STARTLS标准出炉，规定用587端口以STARTTLS方式提交邮件，465端口被吊销。然而许多客户端不支持STARTTLS，加上非常多邮件服务提供商都在使用465端口作为加密提交端口，于是465就一直这么被用到今天。 简单来说，465端口只支持加密传输，不符合互联网号码分配结构（The Internet Assigned Numbers Authority，IANA）的标准，但一直被使用和支持；587端口专门被设计用来提交邮件，传输可以加密也可以不加密。 配置mail明白了基本概念，接下来配置mail使用SMTP对外发送邮件。mail命令的系统级配置文件是/etc/mail.rc，用户级别的默认配置文件是~/.mailrc，也可以通过MAILRC环境变量设置配置文件路径。作为普通用户，我们在本地的~/.mailrc文件进行配置，SMTP的主要配置如下： set smtp=smtps://smtp.xxx.com:465 # 这里填入smtp地址 set smtp-auth=login # 认证方式 set smtp-auth-user=user@xxx.com # 这里输入邮箱账号 set smtp-auth-password=password # 这里填入密码 set ssl-verify=ignore # 忽略证书警告 set nss-config-dir=/etc/pki/nssdb # 证书所在目录 set from=user@xxx.com # 设置发信人邮箱和昵称 #set smtp-use-starttls=yes # STARTTLS时使用 注意事项： 如果是465端口，需要加上smtps://协议；如果是587端口 如果使用587端口通讯，应当显示设置smtp-use-starttls,不需要加smtps://或者写smtp:// 邮件的来源应当与邮箱相同，或者将发信人姓名写在邮箱后的括号中。例如：set from=user@xxxx.com或set from=user@xxx.com；如果邮箱与认证的不一致，将出现smtp-server: 553 Mail from must equal authorized user的错误 有些邮件服务器的587端口不是使用STARTTLS而是SMTPS，此时仍需加上smtps://协议，例如126邮箱。 ","date":"2024-02-10","objectID":"/mailx/:0:0","tags":["mail","mailx"],"title":"mailx - 发送和接收网络邮件","uri":"/mailx/"},{"categories":["linux"],"content":" 多账户配置文件的account指令或在命令行中指定配置。先看配置文件中指定，在~/.mailrc中将配置改成如下： # 126不支持STARTTLS，使用465端口 account 126 { set smtp=smtps://smtp.126.com:465 set smtp-auth=login set smtp-auth-user=user@126.com set smtp-auth-password=password set ssl-verify=ignore set nss-config-dir=/etc/pki/nssdb set from=password@126.com } # QQ邮箱支持STARTTLS，使用587端口 account qq { set smtp=smtp://smtp.qq.com:587 set smtp-auth=login set smtp-auth-user=user@qq.com set smtp-auth-password=password set ssl-verify=ignore set nss-config-dir=/etc/pki/nssdb set from=\"user@qq.com\" set smtp-use-starttls=yes } 配置文件中定义了两个账户，发送邮件时可用-A参数指定发信账户： echo 'mail test for 126' | mail -A 126 -s 'mail test' user@xxx.com echo 'mail test for qq' | mail -A qq -s 'mail test' user@xxx.com 除了配置文件，也可以在命令行中用-S参数进行设置。例如： echo 'mail test for command line option' | mail -s 'mail test' -S smtp=smtp://smtp.qq.com:587 -S smtp-auth=login -S smtp-auth-user=user@qq.com -S smtp-auth-password=password -S ssl-verify=ignore -S nss-config-dir=/etc/pki/nssdb -S from=\"user@qq.com(nickname)\" -S smtp-use-starttls=yes user@xxx.com 这种方法比较繁琐，就是将配置文件的每一行都作为选项写在命令中。在程序中调用mail命令发送邮件时可以采取这种方法。 解决警告　虽然邮件能顺利发送，但每次运行都会出现一行警告：Error in certificate: Peer's certificate issuer is not recognized.。这是由于使用加密通信，但客户端不能确认证书是否真实。如果我们将配置中的set ssl-verify=ignore改成set ssl-verify=strict，连接将直接中断而不会继续发邮件。 获取邮件服务器证书： 要解决这个警告，需要将邮件服务器的证书加入到信任列表。操作步骤如下： 465端口： echo -n \"\" | openssl s_client -connect smtp.xxx.com:465 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \u003e xxx.crt 587端口 echo -n | openssl s_client -starttls smtp -connect smtp.xxx.com:587 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \u003e xxx.crt 将证书添加到受信任列表： certutil -A -n 'xxxx' -t \"P,P,P\" -d . -i ./xxx.crt 上述命令中-A表示添加，-n是nickname，可以随意取，例如126或qq；-t表示受信任的标签，可取值是t/c/p三种或者其组合（许多-t标签都是C,,，实践中发现使用该标签仍会报错，使用P标签完美解决，再发邮件就没有报错了。）；-d表示证书所在目录，-i指示证书文件的位置。在配置文件中更改证书目录： # 指向证书文件目录 set nss-config-dir=/path/to/cert-dir 示例 [root@localhost ~]# mkdir -p ~/.mailx/tls/ [root@localhost ~]# echo -n \"\" | openssl s_client -connect alertmanager.xiaosi.host:465 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \u003e ~/.mailx/tls/alertmanager.crt depth=0 C = DE, ST = NRW, L = Willich, O = mailcow, OU = mailcow, CN = mail.xiaosi.host verify error:num=18:self signed certificate verify return:1 depth=0 C = DE, ST = NRW, L = Willich, O = mailcow, OU = mailcow, CN = mail.xiaosi.host verify return:1 DONE error","date":"2024-02-10","objectID":"/mailx/:1:0","tags":["mail","mailx"],"title":"mailx - 发送和接收网络邮件","uri":"/mailx/"},{"categories":["linux"],"content":" Error initializing NSS: Unknown error -8015. 信息： [root@localhost tls]# echo 'test' | mailx -A alertmanager -s 'test 2' 3131516796@qq.com [root@localhost tls]# Error initializing NSS: Unknown error -8015. \"/root/dead.letter\" 11/322 . . . message not sent. ^C 解决 #创建目录，用来存放证书 mkdir -p /etc/mail/tls/ cd /etc/mail/tls/ # 生成证书 [root@localhost tls]# echo -n | openssl s_client -connect alertmanager.xiaosi.host:465 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \u003e ./alertmanager.crt depth=0 C = DE, ST = NRW, L = Willich, O = mailcow, OU = mailcow, CN = mail.xiaosi.host verify error:num=18:self signed certificate verify return:1 depth=0 C = DE, ST = NRW, L = Willich, O = mailcow, OU = mailcow, CN = mail.xiaosi.host verify return:1 DONE # 添加一个ssl证书到证书数据库中 [root@localhost tls]# certutil -A -n \"GeoTrust SSL CA\" -t \"P,P,P\" -d ./ -i alertmanager.crt # [root@localhost tls]# certutil -A -n \"GeoTrust Global CA\" -t \"P,P,P\" -d ./ -i alertmanager.crt ","date":"2024-02-10","objectID":"/mailx/:2:0","tags":["mail","mailx"],"title":"mailx - 发送和接收网络邮件","uri":"/mailx/"},{"categories":["linux"],"content":" host certificate does not match [root@localhost ~]# host certificate does not match \"alertmanager.xiaosi.host\" smtp-server: 553 5.7.1 \u003chkvps@alertmanager.xiaosi.host\u003e: Sender address rejected: not owned by user mail@alertmanager.xiaosi.host \"/root/dead.letter\" 11/322 . . . message not sent. ^C ","date":"2024-02-10","objectID":"/mailx/:3:0","tags":["mail","mailx"],"title":"mailx - 发送和接收网络邮件","uri":"/mailx/"},{"categories":["grafana"],"content":" 运行环境： 内容来自以下文档： docker 安装 [root@localhost grafana]# cat docker-grafana.sh #!/bin/bash # start grafana docker container rm -f grafana docker run -d -p 103.106.246.103:3000:3000 --name=grafana \\ --volume /data/grafana/etc/grafana.ini:/etc/grafan/grafana.ini \\ --volume /data/grafana/data/:/var/lib/grafana \\ --user $(id -u) \\ grafana/grafana-oss 创建后默认密码都是admin ","date":"2024-02-09","objectID":"/grafana/:0:0","tags":["grafana"],"title":"grafana","uri":"/grafana/"},{"categories":["prometheus"],"content":" 运行环境： 内容来自以下文档： prometheus官方文档：ALERTMANAGER prometheus官方文档：ALERTING OVERVIEW 周plus：Prometheus：告警特性、配置与绑定Alertmanager详解（1） 周plus：Prometheus：告警规则集、告警接收器、Alertmanager启动参数详解（2） 简介Alertmanager 是独立与Prometheus项目的，Prometheus会根据配置的参数周期性的对警报规则进行计算，如果满足警报条件，生产一条警报信息，将其推送到 Alertmanager 组件，Alertmanager 收到警报信息之后，会对警告信息先进行处理再发送通知。大致流程如下： 定期执行PromQL语句，满足条件时发送警报到Alertmanager Alertmanager 收到警报后对信息进入以下方式处理： Grouping: 分组，同类型的警报进行分组，合并多条警报到一个通知中，从而避免瞬间突发性的接受大量警报通知，使得管理员无法对问题进行快速定位。 Inhibition: 抑制，当某条警报已经发送，停止重复发送由此警报引发的其他异常或故障的警报机制。 Silences: 忽略错误警报信息，不发送通知 如果有必要，发送通知到目标 安装","date":"2024-02-07","objectID":"/prometheusAlertmanager/:0:0","tags":["prometheus","Alertmanager"],"title":"Alertmanager - 处理由Prometheus服务器等客户端应用程序发送的警报","uri":"/prometheusAlertmanager/"},{"categories":["prometheus"],"content":" 命令行参数 --config.file=\"alertmanager.yml\" # 指定Alertmanager配置文件路径 --storage.path=\"data/\" # Alertmanager的数据存放目录 --data.retention=120h # 历史数据保留时间，默认为120h --alerts.gc-interval=30m # 警报gc之间的间隔 --web.external-url=WEB.EXTERNAL-URL # 外部可访问的Alertmanager的URL(例如Alertmanager是通过nginx反向代理) --web.route-prefix=WEB.ROUTE-PREFIX # wen访问内部路由路径，默认是 --web.external-url --web.listen-address=\":9093\" # 监听端口，可以随意修改 --web.get-concurrency=0 # 并发处理的最大GET请求数，默认为0 --web.timeout=0 # web请求超时时间 --cluster.listen-address=\"0.0.0.0:9094\" # 集群的监听端口地址。设置为空字符串禁用HA模式 --cluster.advertise-address=CLUSTER.ADVERTISE-ADDRESS # 配置集群通知地址 --cluster.gossip-interval=200ms # 发送条消息之间的间隔，可以以增加带宽为代价更快地跨集群传播。 --cluster.peer-timeout=15s # 在同级之间等待发送通知的时间 --log.level=info # 自定义消息格式 [debug, info, warn, error] --log.format=logfmt # 日志消息的输出格式: [logfmt, json] --version # 显示版本号 ","date":"2024-02-07","objectID":"/prometheusAlertmanager/:1:0","tags":["prometheus","Alertmanager"],"title":"Alertmanager - 处理由Prometheus服务器等客户端应用程序发送的警报","uri":"/prometheusAlertmanager/"},{"categories":["prometheus"],"content":" docker 安装 Alertmanager 配置文件alertname --config.file 指定启动配置文件，默认的alertmanager.yml配置文件，内容如下所示： global: # resolve_timeout：解析超时时间 resolve_timeout: 5m # smtp_smarthost: 使用email打开服务配置 smtp_smarthost: smtp.126.com:25 # smtp_from：指定通知报警的邮箱 smtp_from: rocket_2014@126.com # smtp_auth_username：邮箱用户名 smtp_auth_username: rocket_2014@126.com smtp_auth_identity: rocket_2014@126.com # smtp_auth_password：授权密码 smtp_auth_password: **************** # route标记：告警如何发送分配 route: # group_by：采用哪个标签作为分组的依据 group_by: ['alertname'] # group_wait：分组等待的时间 group_wait: 30s # group_interval：上下两组发送告警的间隔时间 group_interval: 5m # repeat_interval：重复发送告警时间。默认1h repeat_interval: 1h # receiver 定义谁来通知报警 # receiver: 'web.hook' receiver: 'default-receiver' # error use # receiver: ['web.hook','default-receiver'] # receiver标记：告警接受者 receivers: # - name: 'web.hook' # webhook_configs: # - url: 'http://127.0.0.1:5001/web_hook' # python webhook server # name：报警来源自定义名称 - name: 'default-receiver' # email_configs：通过邮箱发送报警 email_configs: # error use ['rocket_2014@126.com', 'gc_zhouruifu@ieggtc.com'] # to：指定接收端email - to: 'rocket_2014@126.com' # error use ['rocket_2014@126.com', 'gc_zhouruifu@ieggtc.com'] send_resolved: true webhook_configs: #- url: 'http://127.0.0.1:5001/' - url: 'http://127.0.0.1:5001/web_hook' # python webhook server #send_resolved: true # inhibit_rules标记：降低告警收敛，减少报警，发送关键报警 inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 配置 # 推送警报时每个目标Alertmanager超时时间 [ timeout: \u003cduration\u003e | default = 10s ] # Alertmanager的api版本 [ api_version: \u003cstring\u003e | default = v2 ] # 被推送HTTP路径警报的前缀 [ path_prefix: \u003cpath\u003e | default = / ] # 配置用于请求的协议方案。 [ scheme: \u003cscheme\u003e | default = http ] # 配置认证信息 basic_auth: [ username: \u003cstring\u003e ] [ password: \u003csecret\u003e ] [ password_file: \u003cstring\u003e ] authorization: [ type: \u003cstring\u003e | default: Bearer ] [ credentials: \u003csecret\u003e ] [ credentials_file: \u003cfilename\u003e ] oauth2: [ \u003coauth2\u003e ] tls_config: [ \u003ctls_config\u003e ] [ proxy_url: \u003cstring\u003e ] [ follow_redirects: \u003cbool\u003e | default = true ] # List of Azure service discovery configurations. azure_sd_configs: [ - \u003cazure_sd_config\u003e ... ] # 省略其他服务发现配置 # Alertmanagers的static_config集合 static_configs: [ - \u003cstatic_config\u003e ... ] # Alertmanager 的relabel_configs配置集合 relabel_configs: [ - \u003crelabel_config\u003e ... ] ","date":"2024-02-07","objectID":"/prometheusAlertmanager/:2:0","tags":["prometheus","Alertmanager"],"title":"Alertmanager - 处理由Prometheus服务器等客户端应用程序发送的警报","uri":"/prometheusAlertmanager/"},{"categories":["prometheus"],"content":" 运行环境： 内容来自以下文档： github：prometheus-operator PrometheusOperator 简介Prometheus Operator 在Kubernetes中引入 CRD 实现以下自定义资源 Prometheus: 定义prometheus集群状态 ServiceMonitor: 定义被监控的目标 PodMonitor 架构图如下： ServiceMonitor 资源通过service 资源发现服务 apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: ... spec: attachMetadata: # 是否附加元数据到标签 node: \u003cbool\u003e # 附加节点元数据 jobLabel: # prometheus job 标签 targetLabels: []string # 指标标签列表 podTargetLabels: []string endpoints: # prometheus 采集的端点列表 - honorLabels: \u003cbool\u003e # 度量与目标冲突时，是否保留冲突的标签 honorTimestamps: \u003cbool\u003e # 是否保留时间时间戳 relabelings: # 重写规则，参考 参考 prometheus \u003crelabel_config\u003e path: \u003cstring\u003e # http 路径，缺省时为 /metrics port: \u003cstring\u003e # 采集的端口名称，优先级比 targetPort 字段高 scheme: \u003cstring\u003e # http 方案，缺省时为 http scrapeTimeout: # 时间单位，采集超时时间 bearerTokenFile: # 已弃用，使用 authorization 字段替代 metricRelabelings: # 在采集前重写标签，参考 prometheus \u003crelabel_config\u003e tlsConfig: # HTTP TLS 配置 ca: # CA 证书 secret: # secret 资源选择 name: # secret 资源 名称 key: # secret 资源 key optional: \u003cbool\u003e # 是否强制使用 secret serverName: # 用于验证目标的主机名 namespaceSelector: # 目标命名空间选择器 any: \u003cbool\u003e # 是否选择所以命名空间 # 如果为 true : 优先级高于matchNames字段 # 如果为 false 且 matchNames 字段为空时，表示当前命名空间 matchNames: \u003c[]string\u003e # 命名空间列表 selector: # 标签选择器 Prometheus 资源Prometheus部署字段如下 apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: ... spec: serviceAccountName: \u003cstring\u003e # 运行 prometheus POD的k8s服务账号 version: \u003cstring\u003e # 告知 prometheus operator 使用的prometheus版本 image: \u003cstring\u003e # prometheus 镜像地址，缺省时为最新版本 imagePullPolicy: \u003cstring\u003e # 镜像拉取策略 imagePullSecrets: \u003cstring\u003e # 从私有仓库拉取镜像使用的secrets凭证 shards: \u003cint32\u003e # 分片数量，缺省时为1，POD数量=分片x副本数量 replicas: \u003cint32\u003e # 每个分片 缺省时为，prometheus 副本数量 listenLocal: \u003cstring\u003e # prometheus 是否监听 local 地址，而不是 pod ip securityContext: \u003c\u003e # pod 安全上下文，即k8s Pod.sepc.SecurityContext 字段 hostNetwork: \u003cbool\u003e # 是否使用主机网络命名空间 logFormat: \u003cstring\u003e # 日志格式 logLevel: \u003cstring\u003e # 日志级别 alerting: # 可选，定义与Alertmanager相关的设置 alertmanagers: [] # AlertmanagerEndpoints 端口 - namespace: # Endpoints 对象所在的命名空间 name: # 端点名称 port: # Alertmanager API 端口名称 scheme: # 请求方式 pathPrefix: # 路径前缀 serviceMonitorSelector: # ServiceMonitor 资源对象标签选择器 enableAdminAPI: \u003cbool\u003e # 是否启用 prometheus web API evaluationInterval: \u003ctime\u003e # 采集数据间隔时间 externalUrl: \u003curl\u003e # prometheus 对外提供服务的URL paused: \u003cbool\u003e podMonitorNamespaceSelector: # podMonitors 资源所在命名空间标签选择器，缺省时选择所有命名空间。为空时选择当前命名空间 podMonitorSelector: # 选择 podMonitors 资源标签 retention: \u003ctime\u003e # Alertmanager 保留时间，缺省时为 120h，必须满足正则表达式：[0-9]+(ms|s|m|h) routePrefix: HTTP路径前缀 ruleNamespaceSelector: \u003cstring\u003e # 发现 Rules 规则的命名空间，缺省时为 ThanosRuler 相同的命名空间 ruleSelector: # 标签选择器，用于选择要挂载的prometheus rules scrapeConfigNamespaceSelector: # 发现 ScrapeConfig 资源的命名空间 scrapeConfigSelector: # 标签选择器，用于选择 scrapeConfig 资源 scrapeInterval: \u003ctime\u003e # scrapes间隔时间，缺省有 30s serviceMonitorNamespaceSelector: # 发现ServicedMonitors资源的命名空间 serviceMonitorSelector: # 标签选择器，用于选择 ServiceMonitor 资源 tsdb: # 定义时序数据库 outOfOrderTimeWindow: \u003ctime\u003e # prometheus out_of_order_time_window 特性 walCompression: \u003cbool\u003e # 使用Snappy配置预写日志(WAL)的压缩 kube-prometheus-stack默认的Prometheus资源 [root@localhost karpenter]# kubectl get Prometheus prometheus-kube-prometheus-prometheus -n prometheus-stack -o yaml apiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: annotations: meta.helm.sh/release-name: prometheus meta.helm.sh/release-namespace: prometheus-stack creationTimestamp: \"2024-02-01T04:20:59Z\" generation: 1 labels: app: kube-prometheus-stack-prometheus app.kubernetes.io/instance: prometheus app.kubernetes.io/managed-by: Helm app.kubernetes.io/part-of: kube-prometheus-stack app.kubernetes.io/version: 56.3.0 chart: kube-prometheus-stack-56.3.0 heritage: Helm release: prometheus name: prometheus-kube-prometheus-prometheus namespace: prometheus-stack resourceVersion: \"21065956\" uid: d429ad14-57f9-49a2-a4a0-d25047398039 spec: alerting: alertmanagers: - apiVersion: v2 name: prometheus-kube-prometheus-alertmanager namespace: prometheus-stack pathPrefix: / port: http-web enableAdminAPI: false evaluationInterval: 30s externalUrl: http://prometheus-k","date":"2024-02-02","objectID":"/prometheusOperator/:0:0","tags":["prometheus"],"title":"Prometheus Operator -为 Kubernetes 提供 Prometheus 和相关监控组件的本地部署和管理。","uri":"/prometheusOperator/"},{"categories":["k8s","prometheus"],"content":" 运行环境： prometheus: 25.8.2 内容来自以下文档： yunlzheng：Kubernetes下的服务发现 prometheus 官方文档：kubernetes_sd_config kube-prometheus-stack How to reset grafana’s admin password (installed by helm) 监控KubernetesPrometheus可以通过与Kubernetes的API进行交互，从而能够动态的发现Kubernetes中部署的所有可监控的目标资源。 ","date":"2024-01-29","objectID":"/k8sMonitorKubernetes/:0:0","tags":["k8s","prometheus","kubernetes_sd_configs"],"title":"promtheus监控k8s","uri":"/k8sMonitorKubernetes/"},{"categories":["k8s","prometheus"],"content":" 使用kube-prometheus-stack搭建prometheus 添加 helm 源 [root@localhost kube-prometheus-stack]# helm repo add prometheus-community https://prometheus-community.github.io/helm-charts [root@localhost kube-prometheus-stack]# [root@localhost kube-prometheus-stack]# helm repo update 安装前可查找默认参数或查看可修改的参数使用以下命令 [root@localhost ~]# helm show values prometheus-community/kube-prometheus-stack 安装 # 安装 [root@localhost kube-prometheus-stack]# helm install prometheus prometheus-community/kube-prometheus-stack -n prometheus-stack --create-namespace NAME: prometheus LAST DEPLOYED: Thu Feb 1 12:20:31 2024 NAMESPACE: prometheus-stack STATUS: deployed REVISION: 1 NOTES: kube-prometheus-stack has been installed. Check its status by running: kubectl --namespace prometheus-stack get pods -l \"release=prometheus\" Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create \u0026 configure Alertmanager and Prometheus instances using the Operator. [root@localhost kube-prometheus-stack]# [root@localhost kube-prometheus-stack]# kubectl get all -A -l \"app.kubernetes.io/instance=prometheus\" NAMESPACE NAME READY STATUS RESTARTS AGE prometheus-stack pod/prometheus-grafana-77c588fccf-z5p5b 3/3 Running 0 10m prometheus-stack pod/prometheus-kube-prometheus-operator-5987fcd6bf-znxwj 1/1 Running 0 10m prometheus-stack pod/prometheus-kube-state-metrics-6db866c85b-xjscc 1/1 Running 0 10m prometheus-stack pod/prometheus-prometheus-node-exporter-6wpkz 1/1 Running 0 10m prometheus-stack pod/prometheus-prometheus-node-exporter-fcv8c 1/1 Running 0 10m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-system service/prometheus-kube-prometheus-coredns ClusterIP None \u003cnone\u003e 9153/TCP 10m kube-system service/prometheus-kube-prometheus-kube-controller-manager ClusterIP None \u003cnone\u003e 10257/TCP 10m kube-system service/prometheus-kube-prometheus-kube-etcd ClusterIP None \u003cnone\u003e 2381/TCP 10m kube-system service/prometheus-kube-prometheus-kube-proxy ClusterIP None \u003cnone\u003e 10249/TCP 10m kube-system service/prometheus-kube-prometheus-kube-scheduler ClusterIP None \u003cnone\u003e 10259/TCP 10m prometheus-stack service/prometheus-grafana ClusterIP 172.20.6.178 \u003cnone\u003e 80/TCP 10m prometheus-stack service/prometheus-kube-prometheus-alertmanager ClusterIP 172.20.76.166 \u003cnone\u003e 9093/TCP,8080/TCP 10m prometheus-stack service/prometheus-kube-prometheus-operator ClusterIP 172.20.21.42 \u003cnone\u003e 443/TCP 10m prometheus-stack service/prometheus-kube-prometheus-prometheus ClusterIP 172.20.190.147 \u003cnone\u003e 9090/TCP,8080/TCP 10m prometheus-stack service/prometheus-kube-state-metrics ClusterIP 172.20.171.127 \u003cnone\u003e 8080/TCP 10m prometheus-stack service/prometheus-prometheus-node-exporter ClusterIP 172.20.29.184 \u003cnone\u003e 9100/TCP 10m NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE prometheus-stack daemonset.apps/prometheus-prometheus-node-exporter 2 2 2 2 2 kubernetes.io/os=linux 10m NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE prometheus-stack deployment.apps/prometheus-grafana 1/1 1 1 10m prometheus-stack deployment.apps/prometheus-kube-prometheus-operator 1/1 1 1 10m prometheus-stack deployment.apps/prometheus-kube-state-metrics 1/1 1 1 10m NAMESPACE NAME DESIRED CURRENT READY AGE prometheus-stack replicaset.apps/prometheus-grafana-77c588fccf 1 1 1 10m prometheus-stack replicaset.apps/prometheus-kube-prometheus-operator-5987fcd6bf 1 1 1 10m prometheus-stack replicaset.apps/prometheus-kube-state-metrics-6db866c85b 1 1 1 10m NAMESPACE NAME READY AGE prometheus-stack statefulset.apps/alertmanager-prometheus-kube-prometheus-alertmanager 1/1 10m prometheus-stack statefulset.apps/prometheus-prometheus-kube-prometheus-prometheus 1/1 10m grafana 用户名与密码保存在secret资源中 # 用户名 [root@localhost kube-prometheus-stack]# kubectl get secret prometheus-grafana \\ -n prometheus-stack \\ -o jsonpath=\"{.data.admin-user}\" | base64 --decode ; echo admin # 密码 [root@localhost kube-prometheus-stack]# kubectl get secret prometheus-grafana \\ -n prometheus-stack \\ -o jsonpath=\"{.data.admin-pass","date":"2024-01-29","objectID":"/k8sMonitorKubernetes/:1:0","tags":["k8s","prometheus","kubernetes_sd_configs"],"title":"promtheus监控k8s","uri":"/k8sMonitorKubernetes/"},{"categories":["k8s","prometheus"],"content":" role 值role 有以下值： node: 节点目标地址，依次获取：NodeInternalIP, NodeExternalIP, NodeLegacyHostIP, NodeHostName __meta_kubernetes_node_name: node 对象名称 __meta_kubernetes_node_provider_id: 云厂商对node的名称 __meta_kubernetes_node_label_\u003clabelname\u003e: node对象的标签 __meta_kubernetes_node_labelpresent_\u003clabelname\u003e: 如果为true __meta_kubernetes_node_annotation_\u003cannotationname\u003e: node对象的annotation __meta_kubernetes_node_address_\u003caddress_type\u003e: 如果存在，则为node地址类型 service: service对象目标，地址为DNS与端口，有以下标签 __meta_kubernetes_namespace: service 对象所在的命名空间 __meta_kubernetes_service_annotation_\u003cannotationname\u003e __meta_kubernetes_service_annotationpresent_\u003cannotationname\u003e __meta_kubernetes_service_cluster_ip: 分配组 service 对象的集群IP地址，不适用ExternalName Service __meta_kubernetes_service_loadbalancer_ip: 分配给外部负载均衡器IP地址 __meta_kubernetes_service_external_name: 分配给外部ExternalName Service 的DNS __meta_kubernetes_service_label_\u003clabelname\u003e __meta_kubernetes_service_labelpresent_\u003clabelname\u003e __meta_kubernetes_service_name __meta_kubernetes_service_port_name __meta_kubernetes_service_port_number __meta_kubernetes_service_port_protocol __meta_kubernetes_service_type: service对象类型 pod: 目标为pod及其容器 __meta_kubernetes_namespace: __meta_kubernetes_pod_name: __meta_kubernetes_pod_ip: __meta_kubernetes_pod_label_\u003clabelname\u003e: __meta_kubernetes_pod_labelpresent_\u003clabelname\u003e: __meta_kubernetes_pod_annotation_\u003cannotationname\u003e: __meta_kubernetes_pod_annotationpresent_\u003cannotationname\u003e: __meta_kubernetes_pod_container_init: 是否为init容器 __meta_kubernetes_pod_container_name: __meta_kubernetes_pod_container_id: __meta_kubernetes_pod_container_image: __meta_kubernetes_pod_container_port_name: __meta_kubernetes_pod_container_port_number: __meta_kubernetes_pod_container_port_protocol: __meta_kubernetes_pod_ready: pod 对象是否就绪 __meta_kubernetes_pod_phase: pod 对象生命周期状态 __meta_kubernetes_pod_node_name: pod 对象所在node名称 __meta_kubernetes_pod_host_ip: 分配给pod 对象的IP地址 __meta_kubernetes_pod_uid: pod 对象UID __meta_kubernetes_pod_controller_kind: __meta_kubernetes_pod_controller_name: pod对象中的容器名称 endpoints: 通过endpoints服务列出的列表中发现目标，有以下标签 __meta_kubernetes_namespace: endpoints 对象所在的命名空间 __meta_kubernetes_endpoints_name: endpoints 对象名称 __meta_kubernetes_endpoints_label_\u003clabelname\u003e: endpoints 对象标签，\u003clabelname\u003e需要替换为具体的endpoints对象标签 __meta_kubernetes_endpoints_labelpresent_\u003clabelname\u003e: 如果值为true __meta_kubernetes_endpoints_annotation_\u003cannotationname\u003e: endpoints 对象中的annotation __meta_kubernetes_endpoints_annotationpresent_\u003cannotationname\u003e: 如果为true 对于没有与pod关联的endpoints对象附加以上标签 __meta_kubernetes_endpoint_hostname: endpoints 对象主机名 __meta_kubernetes_endpoint_node_name: endpoints 对象所在节点名 __meta_kubernetes_endpoint_ready: endpoints对象是否就绪 __meta_kubernetes_endpoint_port_name: endpoints 对象端口名称 __meta_kubernetes_endpoint_port_protocol: endpoints 对象网络协议 __meta_kubernetes_endpoint_address_target_kind: endpoints 对象目标地址 __meta_kubernetes_endpoint_address_target_name: endpoints 对象目标名称 如果endpoints属于service，则附加role值为service的所有标签 如果endpoints对象与pod，则附加role值为pod的所有标签 endpointslice __meta_kubernetes_namespace: __meta_kubernetes_endpointslice_name: __meta_kubernetes_endpointslice_label_\u003clabelname\u003e: __meta_kubernetes_endpointslice_labelpresent_\u003clabelname\u003e: __meta_kubernetes_endpointslice_annotation_\u003cannotationname\u003e: __meta_kubernetes_endpointslice_annotationpresent_\u003cannotationname\u003e: 对于没有与pod关联的endpoints对象附加以上标签 __meta_kubernetes_endpointslice_address_target_kind: __meta_kubernetes_endpointslice_address_target_name: __meta_kubernetes_endpointslice_address_type: __meta_kubernetes_endpointslice_endpoint_conditions_ready: __meta_kubernetes_endpointslice_endpoint_conditions_serving: __meta_kubernetes_endpointslice_endpoint_conditions_terminating: __meta_kubernetes_endpointslice_endpoint_topology_kubernetes_io_hostname: __meta_kubernetes_endpointslice_endpoint_topology_present_kubernetes_io_hostname: __meta_kubernetes_endpointslice_port: __meta_kubernetes_endpointslice_port_name: __meta_kubernetes_endpointslice_port_protocol: 如果endpoints属于service，则附加role值为service的所有标签 如果end","date":"2024-01-29","objectID":"/k8sMonitorKubernetes/:2:0","tags":["k8s","prometheus","kubernetes_sd_configs"],"title":"promtheus监控k8s","uri":"/k8sMonitorKubernetes/"},{"categories":["hugo"],"content":" 运行环境： 内容来自以下文档： [name][name] [name]: ","date":"2024-01-29","objectID":"/hugoImage/:0:0","tags":["hugo"],"title":"note网站图片","uri":"/hugoImage/"},{"categories":["linux"],"content":" 运行环境： docker: 24.0.4 内容来自以下文档： docker hub freshrss 概述 FreshRSS 官方文档：用户文档 FreshRSS 官方文档：管理员文档 docker 安装FreshRSS 镜像自带了SQLite 数据库，也可使用PostgreSQL、MySQL、MariaDB 运行 docker [root@localhost freshRSS]# cat dockerFreshRSS.sh # PostgreSQL 实例数据库名 postgresDB=freshrss # PostgreSQL 实例用户名 postgresUser=freshrss # PostgreSQL 实例用户密码 postgresPasswd=nbqAEsbQziOGmUcW0frdKy # PostgreSQL 实例目录 postgresData=/data/freshRSS/postgresql/data # FreshRSS 数据目录 freshrssData=/data/freshRSS/freshrssData freshrssExtensions=/data/freshRSS/freshrssExtensions mkdir -p ${postgresData} mkdir -p ${freshrssData} mkidr -p ${freshrssExtensions} docker network create freshrss-network #docker network connect freshrss-network freshrss #docker network connect freshrss-network postgres docker container run -d \\ -p 5432:5432 \\ --net freshrss-network \\ -e POSTGRES_DB=${postgresDB} \\ -e POSTGRES_USER=${postgresUser} \\ -e POSTGRES_PASSWORD=${postgresPasswd} \\ -v ${postgresData}:/var/lib/postgresql/data \\ --name freshrss-db postgres:latest docker container run -d \\ -p 8020:80 \\ --net freshrss-network \\ -e TZ=Asia/Shanghai \\ -e 'CRON_MIN=60,30' \\ -v ${freshrssData}:/var/www/FreshRSS/data \\ -v ${freshrssExtensions}:/var/www/FreshRSS/extensions \\ --name freshrss-app freshrss/freshrss:latest 使用nginx创建前端代理，使用支持HTTPS [root@localhost freshRSS]# cat /usr/local/nginx/conf/conf.d/freshrss.xiaosi.host.nginx.conf upstream freshrss { server 127.0.0.1:8020; keepalive 64; } # server { # listen 80; # location / { # return 301 https://$host$request_uri; # } # } server { server_name freshrss.xiaosi.host; listen 103.106.246.103:443 ssl; listen 103.106.246.103:80 ; # Other SSL stuff goes here # 证书公钥路径 ssl_certificate /usr/local/nginx/ssl/fullchain.pem; # 证书私钥路径 ssl_certificate_key /usr/local/nginx/ssl/privkey.pem; # 把 http 协议通过 301 跳转到 https 协议 if ($scheme != \"https\"){ return 301 https://$host$request_uri; } location / { # The final `/` is important. proxy_pass http://freshrss/; add_header X-Frame-Options SAMEORIGIN; add_header X-XSS-Protection \"1; mode=block\"; proxy_redirect off; proxy_buffering off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Port $server_port; proxy_read_timeout 90; # Forward the Authorization header for the Google Reader API. proxy_set_header Authorization $http_authorization; proxy_pass_header Authorization; } } 运行后在浏览器打开web地址，按指引操作 备份","date":"2024-01-26","objectID":"/freshRSS/:0:0","tags":["RSS","FreshRSS"],"title":"FreshRSS - 轻量、易于使用的 RSS 聚合器","uri":"/freshRSS/"},{"categories":["linux"],"content":" 备份FreshRSS 备份脚本 [root@localhost freshRSS]# cat freshRssBackup.sh #!/bin/bash #freshRSSContainerID=$(docker container ls \\ # --format \"table {{.ID}}\\t{{.Names}}\" | \\ # grep ${freshRSSContainerName} | awk '{print $1}') # #echo ${freshRSSContainerID} # 数据库容器名 dbContainerName=freshrss-db # 数据库类型 dbType=postgres # 数据库名 dbName=freshrss # 数据 用户名 dbUser=freshrss # 数据库 用户密码 dbPasswd=nbqAEsbQziOGmUcW0frdKy # 数据库 备份文件 dbBackupDir=/data/freshRSS/backup/ # freshRSS 数据目录 freshRssDataDir=/data/freshRSS/freshrssData date=$(date '+%Y%m%d%H') awsProfile=yh-xiaosi mkdir -p ${dbBackupDir} # 创建 PostgreSQL 备份 docker container exec -it ${dbContainerName} \\ /usr/bin/pg_dump -U ${dbUser} ${dbName} \\ \u003e ${dbBackupDir}/${date}${dbType}Backup.sql # 创建压缩文件 tar -czf ${dbBackupDir}${date}FreshRssBackup.tar.gz \\ ${freshRssDataDir} ${dbBackupDir}${date}${dbType}Backup.sql # 删除多余的数据库备份 rm -rf ${dbBackupDir}/${date}${dbType}Backup.sql # 备份文件复制到aws s3 aws s3 cp ${dbBackupDir}${date}FreshRssBackup.tar.gz \\ s3://xiaosi-backup/FreshRSS/ \\ --profile ${awsProfile} 定时执行脚本 [root@localhost system]# cat freshRssBackup.service [Unit] Description=FreshRSS 备份脚本 [Service] Type=simple ExecStart=/bin/bash /data/freshRSS/freshRssBackup.sh [Install] WantedBy=default.target [root@localhost system]# cat freshRssBackup.timer [Unit] Description=定时执行 FreshRSS 备份单元 After=network.target [Timer] Unit=freshRssBackup.service OnCalendar=*-*-* 02:59:59 Persistent=true AccuracySec=3600s ","date":"2024-01-26","objectID":"/freshRSS/:1:0","tags":["RSS","FreshRSS"],"title":"FreshRSS - 轻量、易于使用的 RSS 聚合器","uri":"/freshRSS/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： MailCow：Docker 化文档 雨き声残響：使用 Mailcow 搭建自己的域名邮箱 先决条件","date":"2024-01-09","objectID":"/MailCow/:0:0","tags":["mail","MailCow"],"title":"MialCow - 一个基于 Docker 的开源群件/电子邮件套件","uri":"/MailCow/"},{"categories":["linux"],"content":" 系统要求 CPU: 1 GHz 内存：7GiB(6G物理内存与1G交换分区) 磁盘：20GiB以上 CPU架构：x86_64 支持系统：centos 7、Debian 10/11/12、Ubuntu 18.04/20.04/22.04、Alma Linux 8、Rocky Linux 9 放行端口：默认端口： 25/TCP: postfix-mailcow,可修改变量：${SMTP_PORT} 80/TCP: nginx-mailcow 110/TCP: dovecot-mailcow 143/TCP: dovecot-mailcow 443/TCP: nginx-mailcow 465/TCP: postfix-mailcow 587/TCP: postfix-mailcow 993/TCP: dovecot-mailcow 995/TCP: dovecot-mailcow 4190/TCP: dovecot-mailcow 如果对出口有限制，还需要放行以下端口 tcp SRC-IP: --- DST IP: --- SRC Port: --- DST Port: 1024-65535 Protocol: tcp TCP flags: ack Action: Accept udp SRC-IP: --- DST IP: --- SRC Port: --- DST Port: 1024-65535 Protocol: udp Action: Accept ","date":"2024-01-09","objectID":"/MailCow/:1:0","tags":["mail","MailCow"],"title":"MialCow - 一个基于 Docker 的开源群件/电子邮件套件","uri":"/MailCow/"},{"categories":["linux"],"content":" DNS记录 # Name Type Value mail IN A 1.2.3.4 (服务器IP) autodiscover IN CNAME mail.example.org. (your ${MAILCOW_HOSTNAME}) autoconfig IN CNAME mail.example.org. (your ${MAILCOW_HOSTNAME}) @ IN MX 10 mail.example.org. (your ${MAILCOW_HOSTNAME}) 安装 安装doker如果已安装则跳过 curl -sSL https://get.docker.com/ | CHANNEL=stable sh # After the installation process is finished, you may need to enable the service and make sure it is started (e.g. CentOS 7) systemctl enable --now docker 查看系统是否安装了selinux [root@localhost ~]# rpm -qa | grep container-selinux container-selinux-2.119.2-1.911c772.el7_8.noarch 查看docker是否启用selinux [root@localhost ~]# docker info | grep selinux 如果输出为空，则修改/etc/docker/daemon.json文件，启用selinux验证 [root@localhost ~]# cat /etc/docker/daemon.json { ... \"selinux-enabled\": true } 修改后重启docker进程 [root@localhost ~]# systemctl daemon-reload [root@localhost ~]# [root@localhost ~]# systemctl stop docker Warning: Stopping docker.service, but it can still be activated by: docker.socket [root@localhost ~]# [root@localhost ~]# systemctl start docker [root@localhost ~]# [root@localhost ~]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: active (running) since Tue 2024-01-09 13:31:08 CST; 4s ago 下载 MailCow [root@localhost ~]# cd /data/ [root@localhost data]# [root@localhost data]# git clone https://github.com/mailcow/mailcow-dockerized Cloning into 'mailcow-dockerized'... remote: Enumerating objects: 51120, done. remote: Counting objects: 100% (1366/1366), done. remote: Compressing objects: 100% (630/630), done. remote: Total 51120 (delta 813), reused 1171 (delta 734), pack-reused 49754 Receiving objects: 100% (51120/51120), 45.16 MiB | 3.64 MiB/s, done. Resolving deltas: 100% (33576/33576), done. [root@localhost data]# [root@localhost data]# cd mailcow-dockerized/ [root@localhost mailcow-dockerized]# 生成MailCow 配置文件 [root@localhost mailcow-dockerized]# ./generate_config.sh Found Docker Compose Plugin (native). Setting the DOCKER_COMPOSE_VERSION Variable to native Notice: You´ll have to update this Compose Version via your Package Manager manually! Press enter to confirm the detected value '[value]' where applicable or enter a custom value. # 输入之前解析的域名 Mail server hostname (FQDN) - this is not your mail domain, but your mail servers hostname: mail.xiaosi.host # 选择时区 Timezone [Asia/Shanghai]: Which branch of mailcow do you want to use? Available Branches: # 主线版本 - master branch (stable updates) | default, recommended [1] # 开发版本 - nightly branch (unstable updates, testing) | not-production ready [2] Choose the Branch with it´s number [1/2] 1 Fetching origin Already on 'master' Generating snake-oil certificate... Generating a 4096 bit RSA private key .........................................++ ...........................++ writing new private key to 'data/assets/ssl-example/key.pem' ----- Copying snake-oil certificate... Detecting if your IP is listed on Spamhaus Bad ASN List... Check completed! Your IP is clean 修改配置文件（这里只修改了nginx端口）。如果服务器禁止了ipv6则参考禁用 IPv6修改配置 [root@localhost mailcow-dockerized]# cat mailcow.conf ... HTTP_PORT=8025 ... HTTPS_PORT=8026 ... 确认端口被占用情况，没有任何输出则正常 [root@localhost mailcow-dockerized]# ss -tlpn | grep -E -w '25|8025|8026|110|143|465|587|993|995|4190' 确定docker网卡MUT值是否为1500,如果不是，则修改docker-compose.yml文件中com.docker.network.driver.mtu值 [root@localhost mailcow-dockerized]# ip a | grep mtu 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 2: eth0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc mq state UP group default qlen 1000 4: docker0: \u003cNO-CARRIER,BROADCAST,MULTICAST,UP\u003e mtu 1500 qdisc noqueue state DOWN group default 5: br-3fcd0a85ece9: \u003cNO-CARRIER,BROADCAST,MULTICAST,UP\u003e mtu 1500 qdisc noqueue state DOWN group default 6: br-7060f1072379: \u003cNO-CARRIER,BROADCAST,MULTICAST,UP\u003e mtu 1500 qdisc noqueue state DOWN group default 90: br-31da319d3a54: \u003cBROADCAST,MULT","date":"2024-01-09","objectID":"/MailCow/:2:0","tags":["mail","MailCow"],"title":"MialCow - 一个基于 Docker 的开源群件/电子邮件套件","uri":"/MailCow/"},{"categories":["k8s"],"content":" 运行环境： helm: 3 内容来自以下文档： heml官方文档：使用Helm 相关命令","date":"2023-12-12","objectID":"/helm/:0:0","tags":["k8s","helm"],"title":"helm - Kubernetes 的包管理器","uri":"/helm/"},{"categories":["k8s"],"content":" 登录或登出注册表 登录到 aws ecr helm registry logout public.ecr.aws ","date":"2023-12-12","objectID":"/helm/:1:0","tags":["k8s","helm"],"title":"helm - Kubernetes 的包管理器","uri":"/helm/"},{"categories":["k8s"],"content":" 安装 chart # https://helm.sh/zh/docs/helm/helm_install/ helm install [NAME] [CHART] [flags] # flags --create-namespace # 如果命名空间不存在，则创建它 -n, --namespace # 指定命名空间 --set stringArray # 指定配置项与值，这些选项与值可使用 helm show values 命令查看 # 可以使用多次，如果一个配置项被 -set 设置值，则最后一个 --set 生效 ","date":"2023-12-12","objectID":"/helm/:2:0","tags":["k8s","helm"],"title":"helm - Kubernetes 的包管理器","uri":"/helm/"},{"categories":["k8s"],"content":" 查看chart可指定参数该命令检查chart(目录、文件或URL)并显示values.yaml文件的内容 helm show values [CHART] [flags] ","date":"2023-12-12","objectID":"/helm/:3:0","tags":["k8s","helm"],"title":"helm - Kubernetes 的包管理器","uri":"/helm/"},{"categories":["k8s"],"content":" 生成yaml文件该命令只生成yaml文件，并未对服务器进行有效测试 helm template [NAME] [CHART] [flags] # flags -n, --namespace # 指定命名空间 ","date":"2023-12-12","objectID":"/helm/:4:0","tags":["k8s","helm"],"title":"helm - Kubernetes 的包管理器","uri":"/helm/"},{"categories":["aws"],"content":" 运行环境： eks:1.28 内容来自以下文档： Karpenter文档 如何在我的 Amazon EKS 集群中安装 Karpenter？ k8s官方文档：将 Pod 指派给节点 karpenter 官方文档：调度 KarpenterKarpenter 会自动配置新节点以响应不可调度的 pod。Karpenter 通过观察 Kubernetes 集群内的事件，然后向底层云提供商发送命令来实现。大致过程如下： 监控调度失败的 pod 评估 pod 调度条件 配置满足 pod 的ec2节点 缩减过多ec2节点 安装 karpenter 使用模板文件部署karpenter相关iam、sqa等资源 [root@localhost karpenter]# cat karpenterCloudformation.sh #!/bin/bash # karpenter 版本 karpenterVersion=v0.33.0 # karpenter 安装的命令空间 karpenterNamespace=karpenter # eks 集群名称 eksClusterName=xiaosi # 模板文件名称 cloudformationFile=cloudformation.yaml # aws config 名称 awsProfile=yh-xiaosi # aws 区域 awsRegion=ap-southeast-1 # aws 账户ID awsAccountID=$(aws sts get-caller-identity \\ --query 'Account' \\ --output text \\ --profile \"${awsProfile}\") # 下载模板文件 curl https://raw.githubusercontent.com/aws/karpenter-provider-aws/\"${karpenterVersion}\"/website/content/en/preview/getting-started/getting-started-with-karpenter/cloudformation.yaml \u003e cloudformation.yaml # 使用模板文件部署 aws cloudformation deploy \\ --stack-name \"karpenter-${eksClusterName}\" \\ --template-file \"${cloudformationFile}\" \\ --capabilities CAPABILITY_NAMED_IAM \\ --parameter-overrides \"ClusterName=${eksClusterName}\" \\ --profile \"${awsProfile}\" \\ --region \"${awsRegion}\" # 创建服务账号 eksctl create iamserviceaccount \\ --cluster \"${eksClusterName}\" \\ --name karpenter \\ --namespace \"${karpenterNamespace}\" \\ --role-name \"${eksClusterName}-karpenter\" \\ --attach-policy-arn \"arn:aws:iam::${awsAccountID}:policy/KarpenterControllerPolicy-${eksClusterName}\" \\ --role-only \\ --approve \\ --profile \"${awsProfile}\" \\ --region \"${awsRegion}\" 创建 iam账号，并与karpenter服务账号关联 [root@localhost karpenter]# cat eksctl-iam.yaml --- apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: xiaosi region: ap-southeast-1 iamIdentityMappings: - arn: \"arn:aws:iam::223665515173:role/KarpenterNodeRole-xiaosi\" username: system:node:{{EC2PrivateDNSName}} groups: - system:bootstrappers - system:nodes [root@localhost karpenter]# eksctl create iamidentitymapping -f eksctl-iam.yaml --profile yh-xiaosi 使用模板创建的节点角色创建新的节点组，新的节点组启用后删除之前的节点组 [root@localhost karpenter]# cat node.sh #!/bin/bash eksClusterName=xiaosi awsProfile=yh-xiaosi awsRegion=ap-southeast-1 vpcSubnetsPrivateA=subnet-0921ac14d1573d55f vpcSubnetsPrivateB=subnet-0821ddb76fdf30d03 vpcSubnets=\"${vpcSubnetsPrivateA}\"\\ \"${vpcSubnetsPrivateB}\" eksNodeGroupName=work01 eskNodeRoleArn=\"arn:aws:iam::223665515173:role/KarpenterNodeRole-xiaosi\" ec2IamType=\"AL2_ARM_64\" ec2Type=\"c6g.xlarge\" ec2CapacityType=\"SPOT\" aws eks create-addon \\ --cluster \"${eksClusterName}\" \\ --addon-name eks-pod-identity-agent \\ --profile \"${awsProfile}\" \\ --region \"${awsRegion}\" aws eks create-nodegroup \\ --cluster \"${eksClusterName}\" \\ --nodegroup-name \"${eksNodeGroupName}\" \\ --subnets ${vpcSubnets} \\ --node-role \"${eskNodeRoleArn}\" \\ --scaling-config \"minSize=1,maxSize=6,desiredSize=1\" \\ --ami-type \"${ec2IamType}\" \\ --instance-types \"${ec2Type}\" \\ --capacity-type \"${ec2CapacityType}\" \\ --profile \"${awsProfile}\" \\ --region \"${awsRegion}\" 修改 kube-system 命名空间中名为aws-auth 的configmap 资源，将arn路径替换为模板创建的节点角色 kubectl edit configmap aws-auth -n kube-system 部署karpenter [root@localhost karpenter]# cat helm-karpenter.sh #!/bin/bash # 在eks中安装karpenter karpenterVersion=v0.33.0 karpenterNamespace=karpenter eksClusterName=xiaosi helm upgrade \\ --install karpenter oci://public.ecr.aws/karpenter/karpenter \\ --version \"${karpenterVersion}\" \\ --namespace \"${karpenterNamespace}\" \\ --create-namespace \\ --set \"settings.clusterName=${eksClusterName}\" \\ --set \"settings.interruptionQueue=${eksClusterName}\" \\ --set controller.resources.requests.cpu=1 \\ --set controller.resources.requests.memory=1Gi \\ --set controller.resources.limits.cpu=1 \\ --set controller.resources.limits.memory=1Gi \\ --set serviceAccount.annotations.\"eks\\.amazonaws\\.com/role-arn\"=\"arn:aws:iam::223665515173:role/xiaosi-karpenter\" 安装完成后 [root@localhost karpenter]# kubectl api-resources | grep karpenter ec2nodeclasses ec2nc,ec2ncs karpenter.k8s.aws/v1beta1 false EC2NodeC","date":"2023-12-12","objectID":"/awsKarpenter/:0:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 节点污点spec.template.spec.taints key effect 值为：\"NoSchedule\"、\"PreferNoSchedule\"、\"NoExecute\" 之一 taints: - key: work value: \"karpenter\" effect: NoSchedule # 节点临时污点，在节点初始化完成后会被删除 startupTaints: - key: example.com/another-taint effect: NoSchedule ","date":"2023-12-12","objectID":"/awsKarpenter/:1:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 节点标签NodePool.spec.template.spec.requirements可以指定节点标签(k8s)，下面是官方文档中的示例 ... spec: template: spec: requirements: - key: kubernetes.io/arch operator: In values: [\"amd64\"] - key: kubernetes.io/os operator: In values: [\"linux\"] - key: karpenter.sh/capacity-type operator: In values: [\"on-demand\"] - key: karpenter.k8s.aws/instance-category operator: In values: [\"c\", \"m\", \"r\"] - key: karpenter.k8s.aws/instance-generation operator: Gt values: [\"2\"] 以下标签可被karpenter用于选择ec2实例 key 说明 values 示例 topology.kubernetes.io/zone 可用区 [\"us-west-2a\", \"us-west-2b\"] node.kubernetes.io/instance-type 实例类型 [\"t4g.micro\"] karpenter.k8s.aws/instance-category 实例类型系列 [\"c\", \"m\", \"t\"] karpenter.k8s.aws/instance-cpu 实例 cpu 数量 [\"1\"] karpenter.k8s.aws/instance-memory 实例内存大小，单位MB [\"2050\"] node.kubernetes.io/instance-type 实例规格 [\"c6g.medium\", \"t4g.micro\"] kubernetes.io/arch 实例 cpu 架构，可用值：点击查看支持的架构列表 [\"arm64\", \"amd64\"] karpenter.sh/capacity-type 实例付费类型，可用值：spot、on-demand [\"spot\", \"on-demand\"] kubernetes.io/os 操作系统，可用值：点击查看支持的系统列表 [\"linux\"] karpenter.k8s.aws/instance-family 实例类型迭代版本 [\"c6g\", \"c7g\"] … … … operator 指定key与valuse的操作符，有以下值： In: 匹配列表中的值 NotIn: 匹配列表以外的值 Exists: 只匹配key DoesNotExist: 不匹配 key Gt: 小于values的整数值（字符串必须为整数） Lt: 大于values的整数值（字符串必须为整数） ","date":"2023-12-12","objectID":"/awsKarpenter/:2:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" kubelet 配置NodePool.spec.template.spec.kubelet字段指定kubelet进程选项，其字段值参考Kubelet 配置。以下是官方示例 kubelet: clusterDNS: [\"10.0.1.100\"] systemReserved: cpu: 100m memory: 100Mi ephemeral-storage: 1Gi kubeReserved: cpu: 200m memory: 100Mi ephemeral-storage: 3Gi evictionHard: memory.available: 5% nodefs.available: 10% nodefs.inodesFree: 10% evictionSoft: memory.available: 500Mi nodefs.available: 15% nodefs.inodesFree: 15% evictionSoftGracePeriod: memory.available: 1m nodefs.available: 1m30s nodefs.inodesFree: 2m evictionMaxPodGracePeriod: 60 imageGCHighThresholdPercent: 85 imageGCLowThresholdPercent: 80 cpuCFSQuota: true podsPerCore: 2 maxPods: 20 ","date":"2023-12-12","objectID":"/awsKarpenter/:3:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 引用节点类配置NodePool.spec.template.spec.nodeClassRef 引用节点类（EC2NodeClass）资源。节点类指定了ec2指定子网、安全组、ami等相关配置 # 引用默认命名空间中名为 default 的 EC2NodeClass 资源 apiVersion: karpenter.sh/v1beta1 kind: NodePool metadata: name: default spec: template: spec: nodeClassRef: apiVersion: karpenter.k8s.aws/v1beta1 kind: EC2NodeClass name: default ","date":"2023-12-12","objectID":"/awsKarpenter/:4:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 节点整合NodePool.spec.disruption 指定karpenter删除节点方式。karpenter会在每个节点上设置一个终结器资源（Finalizers）。当条件满足时，karpenter 每次使用一种方法中断节点。虽然中断方法不一样，但都遵循以下标准中断过程： 按方法顺序筛选可中段节点：Expiration、Drift、Consolidation 如果节点存在无法驱逐的 pod 则放弃中断该节点 模拟 pod 调度，确定可调度的节点 为即将被中断的节点添加 karpenter.sh/disruption:NoSchedule 污点防止新的pod调度到节点 执行调度： 如果调度失败。取消上一步添加的节点污点，并返回第一步，从头开始 如果调度成功。删除节点，等待终结器正常关闭节点 终结器关闭节点后，再次从头开始 Expiration 方法是为节点标记一个运行时长（秒），过期的节点将尝试回收 Drift 方法通过以下条件判断尝试回收节点来节约实例成本 删除空节点 pod可被调度到其它节点，删除该多余的节点 节点可以更换为更便宜的实例，如删除一个贵的节点，启动一个便宜的节点；删除多少个节点，启动一个比总价更便宜的节点。 为了减少整合多个节点过程中减少工作干扰，从以下方面考虑： 删除运行较少的pod节点 删除即将过期的节点 删除pod优先级低的节点 定义整合节点 disruption: # WhenUnderutilized: 以成本维护尽量整合节点 # WhenEmpty: 只删除空节点 consolidationPolicy: WhenEmpty # consolidationPolicy 值为 WhenEmpty 时，指定时间，删除节点前的等待时间 # 可以指定为 Never，将禁止整合节点 consolidateAfter: 30s # 节点生存有效期，长时间运行的节点可能会导致内存泄露或过多碎片文件 # 可以指定为 Never，节点将永不过期 expireAfter: 720h ","date":"2023-12-12","objectID":"/awsKarpenter/:5:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 扩展资源上限NodePool.spec.limits 字段 limits: # cpu 上限核心数， cpu: \"1000\" # 内存上限，单位建议用BinarySI memory: 1000Gi # GPU 上限 nvidia.com/gpu: 2 可以使用以下命令查看资源消耗情况 kubectl get nodepool -o=jsonpath='{.items[0].status}' ","date":"2023-12-12","objectID":"/awsKarpenter/:6:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 权重NodePool.spec.weight 指定NodePool资源权重，数值越大，权限越高 weight: 10 节点类节点类指定了ec2指定子网、安全组、ami等相关配置。每个 NodePool 必须引用 EC2NodeClass。 多个 NodePool 可能指向同一个 EC2NodeClass apiVersion: karpenter.sh/v1beta1 kind: NodePool metadata: name: default spec: template: spec: nodeClassRef: apiVersion: karpenter.k8s.aws/v1beta1 kind: EC2NodeClass name: default --- apiVersion: karpenter.k8s.aws/v1beta1 kind: EC2NodeClass metadata: name: default spec: .... ","date":"2023-12-12","objectID":"/awsKarpenter/:7:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" ami模板EC2NodeClass.spec.amiFamily 是必须指定的字段，它指定节点启动使用的AMI。有以下值 AL2: 支持GPU，但不支持ARM64 GPU Bottlerocket: 支持GPU Ubuntu Windows2019 Windows2022 Custom: 不指定AMI，使用该值时必须指定EC2NodeClass.spec.amiSelectorTerms字段 ","date":"2023-12-12","objectID":"/awsKarpenter/:8:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 指定子网EC2NodeClass.spec.subnetSelectorTerms 可以通过子网id或tag选择节点所在子网，如果同一个可用区有多个可用子网，则选择ip数量最多的子网 如果是通过标签选择，值可以使用*表示通配符 spec: subnetSelectorTerms: - tags: Name: \"*Public*\" 通过子网id选择 spec: subnetSelectorTerms: - id: \"subnet-09fa4a0a8f233a921\" - id: \"subnet-0471ca205b8a129ae\" ","date":"2023-12-12","objectID":"/awsKarpenter/:9:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 安全组EC2NodeClass.spec.securityGroupSelectorTerms 可以通过安全组id或tag选择节点使用的安全组。当自建安全组限制流量时必须允许集群安全组能访问节点安全组 查看kes使用的安全组： [root@localhost ~]# aws eks describe-cluster \\ --name xiaosi \\ --query cluster.resourcesVpcConfig.clusterSecurityGroupId \\ --profile yh-xiaosi \\ --region ap-southeast-1 \"sg-0119f1221cdd404d9\" 如果是通过标签选择，值可以使用*表示通配符 spec: securityGroupSelectorTerms: - name: \"*Public*\" securityGroupSelectorTerms: - tags: Name: \"my-security-group-1\" - tags: Name: \"my-security-group-2\" 通过安全组ID选择 spec: securityGroupSelectorTerms: - id: \"sg-063d7acfb4b06c82c\" - id: \"sg-06e0cf9c198874591\" ","date":"2023-12-12","objectID":"/awsKarpenter/:10:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 节点运行身份必须指定节点角色或IAM 实例配置文件： EC2NodeClass.spec.role: 指定角色名称 EC2NodeClass.spec.instanceProfile: karpenter 是使用IAM端点管理实例配置文件，由于IAM不支持私有端点在不访问公共互联网的情况下访问服务，因此在私有集群中，必须使用该值 ","date":"2023-12-12","objectID":"/awsKarpenter/:11:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 节点标签EC2NodeClass.spec.tags 指定节点标签，karpenter会为节点加入以下标签 Name: \u003cnode-name\u003e karpenter.sh/nodeclaim: \u003cnodeclaim-name\u003e karpenter.sh/nodepool: \u003cnodepool-name\u003e kubernetes.io/cluster/\u003ccluster-name\u003e: owned spec: tags: InternalAccountingTag: 1234 dev.corp.net/app: Calculator dev.corp.net/team: MyTeam ","date":"2023-12-12","objectID":"/awsKarpenter/:12:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 指定实例元数据EC2NodeClass.spec.metadataOptions 指定EC2 实例元数据，如果不指定 karpenter 会指定以下元数据 spec: metadataOptions: httpEndpoint: enabled httpProtocolIPv6: disabled httpPutResponseHopLimit: 2 httpTokens: required ","date":"2023-12-12","objectID":"/awsKarpenter/:13:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" EBS挂载EC2NodeClass.spec.blockDeviceMappings 指定节点挂载的EBS卷。如下面是Bottlerocket AMI默认挂载 spec: blockDeviceMappings: # Root device - deviceName: /dev/xvda ebs: volumeSize: 4Gi volumeType: gp3 encrypted: true # Data device: Container resources such as images and logs - deviceName: /dev/xvdb ebs: volumeSize: 20Gi volumeType: gp3 encrypted: true ","date":"2023-12-12","objectID":"/awsKarpenter/:14:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 用户数据EC2NodeClass.spec.userData 指定ec2初始化启动后执行的脚本 ","date":"2023-12-12","objectID":"/awsKarpenter/:15:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 启用EC2详细监控EC2NodeClass.spec.detailedMonitoring 当值为true时启用详细指标收集，采集频率为1m 示例NodePool资源 --- apiVersion: karpenter.sh/v1beta1 kind: NodePool metadata: name: karpenter-c6g-c7g spec: weight: 50 disruption: consolidationPolicy: WhenUnderutilized expireAfter: 720h limits: cpu: \"8\" memory: \"16Gi\" nvidia.com/gpu: 0 template: metadata: labels: work: karpenter annotations: work: karpenter spec: nodeClassRef: name: karpenter taints: - key: \"work\" value: \"karpenter\" effect: \"NoSchedule\" # startupTaints: # - key: example.com/another-taint # effect: NoSchedule requirements: - key: karpenter.sh/capacity-type operator: In values: [\"on-demand\"] - key: topology.kubernetes.io/zone operator: In values: [\"ap-southeast-1a\", \"ap-southeast-1b\"] - key: kubernetes.io/os operator: In values: [\"linux\"] - key: karpenter.k8s.aws/instance-family operator: In values: [\"c6g\", \"c7g\"] nodeClassRef: apiVersion: karpenter.k8s.aws/v1beta1 kind: EC2NodeClass name: karpenter EC2NodeClass 资源 [root@localhost karpenter]# cat karpenterEC2NodeClass.yaml --- apiVersion: karpenter.k8s.aws/v1beta1 kind: EC2NodeClass metadata: name: karpenter spec: amiFamily: AL2 subnetSelectorTerms: - id: \"subnet-0921ac14d1573d55f\" - id: \"subnet-0821ddb76fdf30d03\" securityGroupSelectorTerms: - id: \"sg-0119f1221cdd404d9\" role: \"KarpenterNodeRole-xiaosi\" 部署 [root@localhost karpenter]# kubectl apply -f karpenterNodePool.yaml nodepool.karpenter.sh/t4g created [root@localhost karpenter]# kubectl apply -f karpenterEC2NodeClass.yaml ec2nodeclass.karpenter.k8s.aws/karpenter created 创建新的karpenter Deployment apiVersion: apps/v1 kind: Deployment metadata: labels: app.kubernetes.io/instance: karpenter app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: karpenter app.kubernetes.io/version: 0.33.0 helm.sh/chart: karpenter-v0.33.0 name: karpenter2 namespace: karpenter spec: progressDeadlineSeconds: 600 replicas: 2 revisionHistoryLimit: 10 selector: matchLabels: app.kubernetes.io/instance: karpenter app.kubernetes.io/name: karpenter strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 1 type: RollingUpdate template: metadata: creationTimestamp: null labels: app.kubernetes.io/instance: karpenter app.kubernetes.io/name: karpenter spec: tolerations: - key: \"work\" value: \"karpenter\" operator: \"Equal\" effect: NoSchedule containers: - env: - name: KUBERNETES_MIN_VERSION value: 1.19.0-0 - name: KARPENTER_SERVICE value: karpenter - name: LOG_LEVEL value: info - name: METRICS_PORT value: \"8000\" - name: HEALTH_PROBE_PORT value: \"8081\" - name: SYSTEM_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: MEMORY_LIMIT valueFrom: resourceFieldRef: containerName: controller divisor: \"0\" resource: limits.memory - name: FEATURE_GATES value: Drift=true - name: BATCH_MAX_DURATION value: 10s - name: BATCH_IDLE_DURATION value: 1s - name: ASSUME_ROLE_DURATION value: 15m - name: CLUSTER_NAME value: xiaosi - name: VM_MEMORY_OVERHEAD_PERCENT value: \"0.075\" - name: INTERRUPTION_QUEUE value: xiaosi - name: RESERVED_ENIS value: \"0\" image: public.ecr.aws/karpenter/controller:v0.33.0@sha256:5e5f59f74d86ff7f13d7d80b89afff8c661cb4e3265f2fdda95b76dd9c838cc1 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 3 httpGet: path: /healthz port: http scheme: HTTP initialDelaySeconds: 30 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 30 name: controller ports: - containerPort: 8000 name: http-metrics protocol: TCP - containerPort: 8081 name: http protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /readyz port: http scheme: HTTP initialDelaySeconds: 5 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 30 resources: limits: cpu: \"1\" memory: 1Gi requests: cpu: \"1\" memory: 1Gi securityContext: allowPrivilegeEscalation: false capabilities: drop: - ALL readOnlyRootFilesystem: true runAsGroup: 65536 runAsNonRoot: true runAsUser: 65536 seccompProfile: type: RuntimeDefault terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: Default nodeSelector: kub","date":"2023-12-12","objectID":"/awsKarpenter/:16:0","tags":["eks","Karpenter"],"title":"Karpenter - 开源 EKS 工作节点生命周期管理","uri":"/awsKarpenter/"},{"categories":["aws"],"content":" 运行环境： k8s: 1.28 内容来自以下文档： aws 官方文档：使用 Helm 设置从新 Prometheus 服务器进行摄取 在 eks 集群中创建 prometheus 添加 Helm 存储库 [root@localhost ~]# helm repo add prometheus-community https://prometheus-community.github.io/helm-charts \"prometheus-community\" has been added to your repositories [root@localhost ~]# [root@localhost ~]# helm repo add kube-state-metrics https://kubernetes.github.io/kube-state-metrics \"kube-state-metrics\" has been added to your repositories [root@localhost ~]# [root@localhost ~]# helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"kube-state-metrics\" chart repository ...Successfully got an update from the \"eks\" chart repository ...Successfully got an update from the \"gitlab-jh\" chart repository ...Successfully got an update from the \"prometheus-community\" chart repository Update Complete. ⎈Happy Helming!⎈ 创建名称空间 [root@localhost ~]# kubectl create namespace prometheus namespace/prometheus created 创建 AWS 角色 [root@localhost prometheus]# cat createIRSA-AMPIngest.sh #!/bin/bash -e # CLUSTER_NAME=\u003cmy_amazon_eks_clustername\u003e # SERVICE_ACCOUNT_NAMESPACE=\u003cmy_prometheus_namespace\u003e CLUSTER_NAME=eks01 SERVICE_ACCOUNT_NAMESPACE=prometheus AWS_ACCOUNT_ID=$(aws sts get-caller-identity \\ --query \"Account\" \\ --output text \\ --profile yh-xiaosi \\ --region ap-southeast-1 ) OIDC_PROVIDER=$(aws eks describe-cluster \\ --name $CLUSTER_NAME \\ --query \"cluster.identity.oidc.issuer\" \\ --output text \\ --profile yh-xiaosi \\ --region ap-southeast-1 | sed -e \"s/^https:\\/\\///\") SERVICE_ACCOUNT_AMP_INGEST_NAME=amp-iamproxy-ingest-service-account SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE=amp-iamproxy-ingest-role SERVICE_ACCOUNT_IAM_AMP_INGEST_POLICY=AMPIngestPolicy # # Set up a trust policy designed for a specific combination of K8s service account and namespace to sign in from a Kubernetes cluster which hosts the OIDC Idp. # cat \u003c\u003cEOF \u003e TrustPolicy.json { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Federated\": \"arn:aws:iam::${AWS_ACCOUNT_ID}:oidc-provider/${OIDC_PROVIDER}\" }, \"Action\": \"sts:AssumeRoleWithWebIdentity\", \"Condition\": { \"StringEquals\": { \"${OIDC_PROVIDER}:sub\": \"system:serviceaccount:${SERVICE_ACCOUNT_NAMESPACE}:${SERVICE_ACCOUNT_AMP_INGEST_NAME}\" } } } ] } EOF # # Set up the permission policy that grants ingest (remote write) permissions for all AMP workspaces # cat \u003c\u003cEOF \u003e PermissionPolicyIngest.json { \"Version\": \"2012-10-17\", \"Statement\": [ {\"Effect\": \"Allow\", \"Action\": [ \"aps:RemoteWrite\", \"aps:GetSeries\", \"aps:GetLabels\", \"aps:GetMetricMetadata\" ], \"Resource\": \"*\" } ] } EOF function getRoleArn() { OUTPUT=$(aws iam get-role \\ --role-name $1 \\ --query 'Role.Arn' \\ --output text \\ --profile yh-xiaosi \\ --region ap-southeast-1 2\u003e\u00261) # Check for an expected exception if [[ $? -eq 0 ]]; then echo $OUTPUT elif [[ -n $(grep \"NoSuchEntity\" \u003c\u003c\u003c $OUTPUT) ]]; then echo \"\" else \u003e\u00262 echo $OUTPUT return 1 fi } # # Create the IAM Role for ingest with the above trust policy # SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN=$(getRoleArn $SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE) if [ \"$SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN\" = \"\" ]; then # # Create the IAM role for service account # SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN=$(aws iam create-role \\ --role-name $SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE \\ --assume-role-policy-document file://TrustPolicy.json \\ --query \"Role.Arn\" --output text \\ --profile yh-xiaosi \\ --region ap-southeast-1) # # Create an IAM permission policy # SERVICE_ACCOUNT_IAM_AMP_INGEST_ARN=$(aws iam create-policy \\ --policy-name $SERVICE_ACCOUNT_IAM_AMP_INGEST_POLICY \\ --policy-document file://PermissionPolicyIngest.json \\ --query 'Policy.Arn' \\ --profile yh-xiaosi \\ --region ap-southeast-1 \\ --output text) # # Attach the required IAM policies to the IAM role created above # aws iam attach-role-policy \\ --role-name $SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE \\ --policy-arn $SERVICE_ACCOUNT_IAM_AMP_INGEST_ARN \\ --profile yh-xiaosi \\ --region ap-southeast-1 else echo","date":"2023-12-11","objectID":"/awsPrometheusToAwsPrometheus/:0:0","tags":["prometheus"],"title":"prometheus推送指标到aws prometheus","uri":"/awsPrometheusToAwsPrometheus/"},{"categories":["aws"],"content":" PVC 因为没有 PV 导致无法绑定 解决存储问题 [root@localhost ~]# kubectl get pod -n prometheus NAME READY STATUS RESTARTS AGE prometheus-alertmanager-0 0/1 Pending 0 6m49s prometheus-kube-state-metrics-6b464f5b88-l2kbl 1/1 Running 0 6m49s prometheus-prometheus-node-exporter-8b4xc 1/1 Running 0 6m50s prometheus-prometheus-pushgateway-7857c44f49-p4qqs 1/1 Running 0 6m49s prometheus-server-74f95f965c-hp7zx 0/2 Pending 0 6m49s [root@localhost ~]# kubectl -n prometheus describe pod prometheus-alertmanager-0 Name: prometheus-alertmanager-0 Namespace: prometheus .... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 85s (x3 over 11m) default-scheduler 0/2 nodes are available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.. [root@localhost ~]# kubectl -n prometheus describe pod prometheus-server-74f95f965c-hp7zx Name: prometheus-server-74f95f965c-hp7zx Namespace: prometheus ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 2m14s (x4 over 12m) default-scheduler 0/2 nodes are available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.. 创建EBS存储类 [root@localhost ~]# cat eks-ebs.yaml --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: ebs provisioner: ebs.csi.aws.com volumeBindingMode: WaitForFirstConsumer [root@localhost ~]# [root@localhost ~]# kubectl apply -f eks-ebs.yaml storageclass.storage.k8s.io/ebs created [root@localhost ~]# [root@localhost ~]# kubectl get StorageClass NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE ebs ebs.csi.aws.com Delete WaitForFirstConsumer false 5s 更新pvc资源 [root@localhost ~]# kubectl -n prometheus get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE prometheus-server Pending 35m storage-prometheus-alertmanager-0 Pending 35m [root@localhost ~]# kubectl -n prometheus patch pvc storage-prometheus-alertmanager-0 -p '{\"spec\":{\"storageClassName\": \"ebs\"}}' persistentvolumeclaim/storage-prometheus-alertmanager-0 patched [root@localhost ~]# kubectl -n prometheus patch pvc prometheus-server -p '{\"spec\":{\"storageClassName\": \"ebs\"}}' persistentvolumeclaim/prometheus-server patched [root@localhost ~]# kubectl -n prometheus get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE prometheus-server Bound pvc-881187c8-1910-49c3-8b84-4c581486221d 8Gi RWO ebs 48m storage-prometheus-alertmanager-0 Bound pvc-a0cd71ff-f394-4649-b4e7-9663fbce5f37 2Gi RWO ebs 48m ","date":"2023-12-11","objectID":"/awsPrometheusToAwsPrometheus/:1:0","tags":["prometheus"],"title":"prometheus推送指标到aws prometheus","uri":"/awsPrometheusToAwsPrometheus/"},{"categories":["aws"],"content":" 无法连接 127.0.0.1:9090 导致 prometheus-server 退出 [root@localhost ~]# kubectl -n prometheus get pod NAME READY STATUS RESTARTS AGE prometheus-alertmanager-0 1/1 Running 0 53m prometheus-kube-state-metrics-6b464f5b88-l2kbl 1/1 Running 0 53m prometheus-prometheus-node-exporter-8b4xc 1/1 Running 0 53m prometheus-prometheus-pushgateway-7857c44f49-p4qqs 1/1 Running 0 53m prometheus-server-74f95f965c-rf94c 1/2 CrashLoopBackOff 1 (6s ago) 8s 查看容器状态 [root@localhost prometheus]# kubectl -n prometheus \\ get pod prometheus-server-74f95f965c-rf94c \\ -o jsonpath='{.status.containerStatuses}' | \\ jq '.[] | {(.name): .started}' { \"prometheus-server\": false } { \"prometheus-server-configmap-reload\": true } 查看容器错误日志 [root@localhost prometheus]# kubectl logs prometheus-server-74f95f965c-rf94c \\ -n prometheus \\ -c prometheus-server | grep 'err=' ts=2023-12-11T09:24:13.264Z caller=main.go:1255 level=error msg=\"Failed to apply configuration\" err=\"could not get SigV4 credentials: WebIdentityErr: failed to retrieve credentials\\ncaused by: AccessDenied: Not authorized to perform sts:AssumeRoleWithWebIdentity\\n\\tstatus code: 403, request id: 6a5e8f40-37f5-40fa-ab68-7e770356ee3d\" ts=2023-12-11T09:24:13.268Z caller=main.go:1164 level=error err=\"error loading config from \\\"/etc/config/prometheus.yml\\\": one or more errors occurred while applying the new configuration (--config.file=\\\"/etc/config/prometheus.yml\\\")\" 原因，角色受信任关系配置不对。删除角色重新执行脚本 ","date":"2023-12-11","objectID":"/awsPrometheusToAwsPrometheus/:2:0","tags":["prometheus"],"title":"prometheus推送指标到aws prometheus","uri":"/awsPrometheusToAwsPrometheus/"},{"categories":["aws"],"content":" 运行环境： 内容来自以下文档： aws 知识中心：如何使用 NGINX 代理通过 Amazon Cognito 身份验证从 VPC 外部访问 OpenSearch 控制面板？ eks 中搭建 nginx 代理 创建名称空间 [root@localhost nginx-proxy-opensearch]# kubectl create ns proxy namespace/proxy created 为 nginx pod 生成 tls证书 [root@localhost nginx-proxy-opensearch]# openssl req -x509 -nodes -days 365 \\ \u003e -newkey rsa:2048 -keyout nginx-proxy-opensearch.key \\ \u003e -out nginx-proxy-opensearch.crt \\ \u003e -subj \"/CN=opensearch.aws.xiaosi.host/O=my-nginx\" Generating a 2048 bit RSA private key .+++ .....+++ writing new private key to 'nginx-proxy-opensearch.key' ----- 为 TLS 文件生成secret 对象 [root@localhost nginx-proxy-opensearch]# kubectl create secret tls nginx-proxy-opensearch-tls \\ \u003e --cert=nginx-proxy-opensearch.crt \\ \u003e --key=nginx-proxy-opensearch.key \\ \u003e -n proxy secret/nginx-proxy-opensearch-tls created [root@localhost nginx-proxy-opensearch]# [root@localhost nginx-proxy-opensearch]# kubectl get secret -n proxy NAME TYPE DATA AGE nginx-proxy-opensearch-tls kubernetes.io/tls 2 23s 创建 nginx 配置文件 user nginx; worker_processes 1; error_log /var/log/nginx/error.log; pid /run/nginx.pid; events { worker_connections 1024; } http { log_format main escape=json '{ ' '\"Client IP\": \"$http_x_forwarded_for\",' '\"responseTime\": \"$time_iso8601\",' '\"requestIP\": \"$remote_addr\",' '\"requestPort\": \"$remote_port\",' '\"requestScheme\": \"$scheme\",' '\"requestProtocol\": \"$server_protocol\",' '\"requestMethod\": \"$request_method\",' '\"requestDomainName\": \"$host\",' '\"requestUri\": \"$request_uri\",' '\"responseUrl\": \"$uri\",' '\"responseIP\": \"$server_addr\",' '\"responseport\": \"$server_port\",' '\"responseStatus\": \"$status\",' \"\\\"responseSize\\\": \" \"\\\"$bytes_sent\" \"B\\\",\" \"\\\"responseBodySize\\\": \" \"\\\"$body_bytes_sent\" \"B\\\",\" \"\\\"processingConsumeTime\\\": \" \"\\\"$request_time\" \"s\\\",\" '\"processingStatus\": \"$request_completion\",' '\"User-Agent\": \"$http_user_agent\"' '}'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 4096; include /etc/nginx/mime.types; default_type application/octet-stream; server { listen 80; listen [::]:80; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. error_page 404 /404.html; location = /404.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } server { listen 443 ssl; server_name opensearch.aws.xiaosi.host; resolver 192.168.0.2 [::1]:5353 valid=30s; rewrite ^/$ https://opensearch.aws.xiaosi.host/_dashboards redirect; ssl_certificate /etc/nginx/cert.crt; ssl_certificate_key /etc/nginx/cert.key; ssl_session_cache builtin:1000 shared:SSL:10m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!eNULL:!EXPORT:!CAMELLIA:!DES:!MD5:!PSK:!RC4; ssl_prefer_server_ciphers on; set $es_endpoint vpc-xiaosi-totppbb2en4wkcvtgkwlxl773u.ap-southeast-1.es.amazonaws.com; set $cognito_endpoint vpc-xiaosi-totppbb2en4wkcvtgkwlxl773u.ap-southeast-1.es.amazonaws.com; location ^~ /_dashboards { # Forward requests to Kibana proxy_pass https://$es_endpoint; # Handle redirects to Amazon Cognito proxy_redirect https://$cognito_endpoint https://opensearch.aws.xiaosi.host; # Update cookie domain and path proxy_cookie_domain $es_endpoint opensearch.aws.xiaosi.host; # Response buffer settings proxy_buffer_size 128k; proxy_buffers 4 256k; proxy_busy_buffers_size 256k; # Ignore client disconnection proxy_ignore_client_abort on; } location ~ \\/(log|sign|error|fav|forgot|change|confirm|mfa) { # Forward requests to Cognito proxy_pass https://$cognito_endpoint; # Handle redirects to Kibana proxy_redirect https://$es_endpoint https://opensearch.aws.xiaosi.host; # Handle redirects to Amazon Cognito proxy_redirect https://$cognito_endpoint https://opensearch.aws.xiaosi.host; # Update cookie domain proxy_cookie_domain $cognito_endpoint opensearch.aws.xiaosi.host; # Ignore client disconnection proxy_ignore_client_abort on; internal; } } } 创建 ConfigMap 资源 [root@localhost nginx-proxy-opensearch]# kubectl create configmap nginx-proxy-opensearch-conf \\ \u003e --from","date":"2023-12-10","objectID":"/awsNginxToOpenSearchDashboard/:0:0","tags":["aws","OpenSearch"],"title":"使用nginx代理访问私有子网中的OpenSearch 控制面板","uri":"/awsNginxToOpenSearchDashboard/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.28 内容来自以下文档： k8s 官方文档：ConfigMap k8s 官方文档：配置 Pod 使用 ConfigMap ConfigMap 对象ConfigMap 是 k8s API 对象，用来将非机密性的数据保存到键值对中。 Pod 可以将其用作环境变量、命令行参数或者存储卷中的配置文件。通常存储应用程序配置信息，将环境配置信息和容器镜像解耦，便于应用配置的修改。 注意： ConfigMap 不会对内容加密 ConfigMap 中保存的数据不可超过 1 MiB 创建 ConfigMap","date":"2023-12-10","objectID":"/k8sConfigMap/:0:0","tags":["k8s","ConfigMap"],"title":"k8s ConfigMap 对象","uri":"/k8sConfigMap/"},{"categories":["k8s"],"content":" 基于文件创建 kubectl create configmap \u003cConfigMap名称\u003e --from-file[=\u003c我的键名\u003e]=\u003c文件路径\u003e [--from-file ...] [root@localhost nginx-proxy-opensearch]# kubectl create configmap nginx-proxy-opensearch-conf-http \\ --from-file=nginx-proxy-opensearch-http.conf \\ -n proxy configmap/nginx-proxy-opensearch-conf-http created 使用","date":"2023-12-10","objectID":"/k8sConfigMap/:1:0","tags":["k8s","ConfigMap"],"title":"k8s ConfigMap 对象","uri":"/k8sConfigMap/"},{"categories":["k8s"],"content":" 挂载为文件 [root@localhost nginx-proxy-opensearch]# cat deployment-nginx.yaml apiVersion: apps/v1 kind: Deployment metadata: namespace: proxy name: nginx-to-opensearch labels: app: nginx-to-opensearch spec: replicas: 1 selector: matchLabels: app: to-opensearch template: metadata: labels: app: to-opensearch spec: containers: - name: nginx image: nginx ports: - containerPort: 80 volumeMounts: - name: nginx-conf mountPath: /etc/nginx/nginx.conf subPath: nginx.conf volumes: - name: nginx-conf configMap: name: nginx-proxy-opensearch-conf-http items: - key: nginx-proxy-opensearch-http.conf path: nginx.conf ","date":"2023-12-10","objectID":"/k8sConfigMap/:2:0","tags":["k8s","ConfigMap"],"title":"k8s ConfigMap 对象","uri":"/k8sConfigMap/"},{"categories":["aws"],"content":"内容来自： AWS 官方文档：AWS计费指挥家的最佳实践 BD：bowei 组织成员账户账单中直接显示实际消费订单为了对成员账户屏蔽组织盈利情况，同时需要在成员账户中实际显示原始消费账单。可以使用 AWS Billing Conductor服务实现（成本：每个账号每月收费8.25美元/月）： 登录组织账号（具有添加 AWS Billing Conductor 权限） 进入 AWS Billing Conductor 账单组 页面，创建新的账号组 指定账单组信息，名称推荐格式为具有标识性的：“销售名-客户名-可选的其它备注” 。 选择账单组的成员，同个账单组的账号账单会整合，即成员中一个账号购买预留实例或Savings Plans，所有账号都会显示抵扣。同个账单组中的账号分为成员账户与一个主账户。主账户可以在账单中查看其它成员账号账单。因此按情况不同可以设置为： 账单组只有一个账号，即是成员也是主账号 主账号必须与成员账号具有逻辑关联。如销售（主账号）与客户（成员账号）；同个企业客户有多个账号 最终效果展示（主账号是自己账号） 注意事项 AWS Billing Conductor服务成本：每个账号每月收费8.25美元/月 同个账单组中的账号分为成员账户与一个主账户，主账户可以在账单中查看其它成员账号账单。 只有组织账号才有AWS Billing Conductor服务 每个自然月分用上半月（1 ~ 15）与下半月（16 ~ 31），下半月创建的账单组，不会显示包含上半月及其之前的实际账单 AWS Billing Conductor不会共享以下以下费用： Tax：税费 Credits: 服务抵扣金 AWS Support: 售后支持 只是账单显示，实际不影响组织中共享的预留实例或Savings Plans抵扣 账号如果有够买预留实例和 Savings Plans，无论有没有禁止共享，账单都会在同一账单组中显示 ","date":"2023-11-20","objectID":"/awsBillingConductorForMembersBilling/:0:0","tags":["aws","AWS Billing Conductor"],"title":"使用 AWS Billing Conductor 在组织成员账户中显示实际账单","uri":"/awsBillingConductorForMembersBilling/"},{"categories":["aws"],"content":" 运行环境： EKS: 1.28 内容来自以下文档： AWS 官方文档：在亚马逊 Elastic Kubernetes Service 集群上使用 AWS Distro 为开放遥测设置指标提取 AWS 官方文档：Prometheus 与 Grafana 之间授权和身份验证所需的角色 Prometheus 接收器 执行以下脚本内容，为从 Amazon EKS 集群提取指标设置服务角色 [root@localhost ADOT]# cat createIRSA-AMPIngest.sh #!/bin/bash -e CLUSTER_NAME=eks01 SERVICE_ACCOUNT_NAMESPACE=eks01 profile=yh-xiaosi region=ap-southeast-1 AWS_ACCOUNT_ID=$(aws sts get-caller-identity \\ --query \"Account\" \\ --output text \\ --profile $profile) OIDC_PROVIDER=$(aws eks describe-cluster \\ --name $CLUSTER_NAME \\ --query \"cluster.identity.oidc.issuer\" \\ --output text \\ --profile $profile \\ --region $region | sed -e \"s/^https:\\/\\///\") SERVICE_ACCOUNT_AMP_INGEST_NAME=amp-iamproxy-ingest-service-account SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE=amp-iamproxy-ingest-role SERVICE_ACCOUNT_IAM_AMP_INGEST_POLICY=AMPIngestPolicy # # Set up a trust policy designed for a specific combination of K8s service account and namespace to sign in from a Kubernetes cluster which hosts the OIDC Idp. # cat \u003c\u003cEOF \u003e TrustPolicy.json { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Federated\": \"arn:aws:iam::${AWS_ACCOUNT_ID}:oidc-provider/${OIDC_PROVIDER}\" }, \"Action\": \"sts:AssumeRoleWithWebIdentity\", \"Condition\": { \"StringEquals\": { \"${OIDC_PROVIDER}:sub\": \"system:serviceaccount:${SERVICE_ACCOUNT_NAMESPACE}:${SERVICE_ACCOUNT_AMP_INGEST_NAME}\" } } } ] } EOF # # Set up the permission policy that grants ingest (remote write) permissions for all AMP workspaces # cat \u003c\u003cEOF \u003e PermissionPolicyIngest.json { \"Version\": \"2012-10-17\", \"Statement\": [ {\"Effect\": \"Allow\", \"Action\": [ \"aps:RemoteWrite\", \"aps:GetSeries\", \"aps:GetLabels\", \"aps:GetMetricMetadata\" ], \"Resource\": \"*\" } ] } EOF function getRoleArn() { OUTPUT=$(aws iam get-role --role-name $1 \\ --query 'Role.Arn' \\ --output text \\ --profile $profile \\ --region $region 2\u003e\u00261) # Check for an expected exception if [[ $? -eq 0 ]]; then echo $OUTPUT elif [[ -n $(grep \"NoSuchEntity\" \u003c\u003c\u003c $OUTPUT) ]]; then echo \"\" else \u003e\u00262 echo $OUTPUT return 1 fi } # # Create the IAM Role for ingest with the above trust policy # SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN=$(getRoleArn $SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE) if [ \"$SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN\" = \"\" ]; then # # Create the IAM role for service account # SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN=$(aws iam create-role \\ --role-name $SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE \\ --assume-role-policy-document file://TrustPolicy.json \\ --query \"Role.Arn\" --output text \\ --profile $profile) \\ --region $region # # Create an IAM permission policy # SERVICE_ACCOUNT_IAM_AMP_INGEST_ARN=$(aws iam create-policy \\ --policy-name $SERVICE_ACCOUNT_IAM_AMP_INGEST_POLICY \\ --policy-document file://PermissionPolicyIngest.json \\ --query 'Policy.Arn' --output text \\ --region $region \\ --profile $profile) # # Attach the required IAM policies to the IAM role created above # aws iam attach-role-policy \\ --role-name $SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE \\ --policy-arn $SERVICE_ACCOUNT_IAM_AMP_INGEST_ARN \\ --region $region \\ --profile $profile else echo \"$SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN IAM role for ingest already exists\" fi echo $SERVICE_ACCOUNT_IAM_AMP_INGEST_ROLE_ARN # # EKS cluster hosts an OIDC provider with a public discovery endpoint. # Associate this IdP with AWS IAM so that the latter can validate and accept the OIDC tokens issued by Kubernetes to service accounts. # Doing this with eksctl is the easier and best approach. # eksctl utils associate-iam-oidc-provider \\ --cluster $CLUSTER_NAME \\ --approve \\ --region $region \\ --profile $profile 脚本输出 [root@localhost ADOT]# bash createIRSA-AMPIngest.sh arn:aws:iam::223665515173:role/amp-iamproxy-ingest-role 2023-11-16 16:59:15 [ℹ] IAM Open ID Connect provider is already associated with cluster \"eks01\" in \"ap-southeast-1\" 执行脚本，允许从 Prometheus 工作空间的亚马逊托管服务查询指标 [root@localhost ADOT]# cat createIRSA-AMPQuery.sh #!/bin/bash -e CLUSTER_NAME=eks01 SERVICE_ACCOUNT_NAMESPACE=eks01 profile=yh-xiaosi region=ap-southeast-1 AWS","date":"2023-11-16","objectID":"/awsADOT/:0:0","tags":["AWS Distro for OpenTelemetry","ADOT","Amazon Managed Service for Prometheus","EKS"],"title":"ADOT开放EKS指标给Prometheus抓取","uri":"/awsADOT/"},{"categories":["aws"],"content":" 构建镜像 下载开源库 [root@localhost ADOT]# git clone https://github.com/aws-observability/aws-otel-community.git Cloning into 'aws-otel-community'... remote: Enumerating objects: 2919, done. remote: Counting objects: 100% (1594/1594), done. remote: Compressing objects: 100% (599/599), done. remote: Total 2919 (delta 1242), reused 1223 (delta 978), pack-reused 1325 Receiving objects: 100% (2919/2919), 1.63 MiB | 1.96 MiB/s, done. Resolving deltas: 100% (1863/1863), done. 构建镜像 [root@localhost ADOT]# cd aws-otel-community/sample-apps/prometheus-sample-app/ [root@localhost prometheus-sample-app]# [root@localhost prometheus-sample-app]# docker build . -t prometheus-sample-app:latest [+] Building 853.3s (17/17) FINISHED docker:default =\u003e [internal] load build definition from Dockerfile 0.0s =\u003e =\u003e transferring dockerfile: 523B 0.0s =\u003e [internal] load .dockerignore 0.0s =\u003e =\u003e transferring context: 2B 0.0s =\u003e [internal] load metadata for docker.io/library/golang:1.17 2.8s =\u003e [internal] load build context 0.0s =\u003e =\u003e transferring context: 77.05kB 0.0s =\u003e [mod 1/5] FROM docker.io/library/golang:1.17@sha256:87262e4a4c7db56158a80a18fefdc4fee5accc41b59cde821e691d05541bbb18 66.5s =\u003e =\u003e resolve docker.io/library/golang:1.17@sha256:87262e4a4c7db56158a80a18fefdc4fee5accc41b59cde821e691d05541bbb18 0.0s =\u003e =\u003e sha256:d836772a1c1f9c4b1f280fb2a98ace30a4c4c87370f89aa092b35dfd9556278a 55.00MB / 55.00MB 17.4s =\u003e =\u003e sha256:66a9e63c657ad881997f5165c0826be395bfc064415876b9fbaae74bcb5dc721 5.16MB / 5.16MB 1.3s =\u003e =\u003e sha256:d1989b6e74cfdda1591b9dd23be47c5caeb002b7a151379361ec0c3f0e6d0e52 10.88MB / 10.88MB 3.5s =\u003e =\u003e sha256:87262e4a4c7db56158a80a18fefdc4fee5accc41b59cde821e691d05541bbb18 2.35kB / 2.35kB 0.0s =\u003e =\u003e sha256:55636cf1983628109e569690596b85077f45aca810a77904e8afad48b49aa500 1.80kB / 1.80kB 0.0s =\u003e =\u003e sha256:742df529b073e7d1e213702a6cca40c32f3f5068125988de249416ba0abee517 7.12kB / 7.12kB 0.0s =\u003e =\u003e sha256:c28818711e1ed38df107014a20127b41491b224d7aed8aa7066b55552d9600d2 54.58MB / 54.58MB 17.0s =\u003e =\u003e sha256:9d6246ba248cc80872dc2995f9080ef76305b540968dadb096b75f2e2146a38a 85.90MB / 85.90MB 24.1s =\u003e =\u003e sha256:21d43f0d73c2979514706af3d892f631b75d5c2d56aebfac0172e5a4e934b447 135.06MB / 135.06MB 38.5s =\u003e =\u003e extracting sha256:d836772a1c1f9c4b1f280fb2a98ace30a4c4c87370f89aa092b35dfd9556278a 8.3s =\u003e =\u003e sha256:d8a1c5873f408d3f5a8d8d73c6b9a3d77818bab0b26142a493909ea8c4d0c020 154B / 154B 18.0s =\u003e =\u003e extracting sha256:66a9e63c657ad881997f5165c0826be395bfc064415876b9fbaae74bcb5dc721 0.8s =\u003e =\u003e extracting sha256:d1989b6e74cfdda1591b9dd23be47c5caeb002b7a151379361ec0c3f0e6d0e52 0.8s =\u003e =\u003e extracting sha256:c28818711e1ed38df107014a20127b41491b224d7aed8aa7066b55552d9600d2 9.4s =\u003e =\u003e extracting sha256:9d6246ba248cc80872dc2995f9080ef76305b540968dadb096b75f2e2146a38a 10.1s =\u003e =\u003e extracting sha256:21d43f0d73c2979514706af3d892f631b75d5c2d56aebfac0172e5a4e934b447 18.3s =\u003e =\u003e extracting sha256:d8a1c5873f408d3f5a8d8d73c6b9a3d77818bab0b26142a493909ea8c4d0c020 0.0s =\u003e [mod 2/5] WORKDIR /go/main 2.1s =\u003e [mod 3/5] COPY go.mod . 0.0s =\u003e [mod 4/5] COPY go.sum . 0.0s =\u003e [mod 5/5] RUN GO111MODULE=on go mod download 494.6s =\u003e [build 2/6] COPY --from=mod 112.7s =\u003e [build 3/6] COPY --from=mod /go/pkg/mod /go/pkg/mod 82.3s =\u003e [build 4/6] WORKDIR /go/main 0.0s =\u003e [build 5/6] COPY . . 0.1s =\u003e [build 6/6] RUN GO111MODULE=on CGO_ENABLED=0 GOOS=linux go build -o=/bin/main . 26.0s =\u003e [stage-2 1/2] COPY --from=build /bin/main /bin/main 0.1s =\u003e [stage-2 2/2] COPY ./config.yaml / 0.0s =\u003e exporting to image 0.2s =\u003e =\u003e exporting layers 0.2s =\u003e =\u003e writing image sha256:233024893a82a8fd912d03736130ff7374c8d9da90312c48c3b81540f1379bc1 0.0s =\u003e =\u003e naming to docker.io/library/prometheus-sample-app:latest 0.0s 查看 [root@localhost prometheus-sample-app]# docker image ls prometheus-sample-app REPOSITORY TAG IMAGE ID CREATED SIZE prometheus-sample-app latest 233024893a82 2 minutes ago 12.3MB Prometheus 远程写入导出器 Sigv4 身份验证扩展。","date":"2023-11-16","objectID":"/awsADOT/:1:0","tags":["AWS Distro for OpenTelemetry","ADOT","Amazon Managed Service for Prometheus","EKS"],"title":"ADOT开放EKS指标给Prometheus抓取","uri":"/awsADOT/"},{"categories":["golang"],"content":" 运行环境： go: 1.21.3 内容来自以下文档： Go 系列教程 —— 17. 方法 方法Go 不是纯粹的面向对象编程语言，而且Go不支持类。因此，基于类型的方法是一种实现和类相似行为的途径。 一个对象其实也就是一个简单的值或者一个变量，在这个对象中会包含一些方法，而一个方法则是一个和特殊类型关联的函数。一个面向对象的程序会用方法来表达其属性和对应的操作，这样使用这个对象的用户就不需要直接去操作对象，而是借助方法来做这些事情。 在函数声明时，在其名字之前放上一个变量，即是一个方法。这个附加的参数会将该函数附加到这种类型上，即相当于为这种类型定义了一个独占的方法。 声明方法语句： // 变量名也称为方法的接收器 func (变量名 类型) 方法名(形参列表) (返回值列表) { 内容 } 下面是示例 package main import ( \"fmt\" ) type Employee struct { name string age int } /* 使用值接收器的方法。*/ func (e Employee) changeName(newName string) { e.name = newName } /* 使用指针接收器的方法。*/ func (e *Employee) changeAge(newAge int) { e.age = newAge } func main() { e := Employee{ name: \"Mark Andrew\", age: 50, } fmt.Printf(\"Employee name before change: %s\", e.name) // 修改名称 e.changeName(\"Michael Andrew\") fmt.Printf(\"\\nEmployee name after change: %s\", e.name) fmt.Printf(\"\\n\\nEmployee age before change: %d\", e.age) // 修改年龄，该语句会被GO自动解释为：(\u0026e).changeAge(51) e.changeAge(51) fmt.Printf(\"\\nEmployee age after change: %d\", e.age) } 输出 Employee name before change: Mark Andrew Employee name after change: Mark Andrew Employee age before change: 50 Employee age after change: 51 下面是示例 package main import \"fmt\" type BankAccount struct { accountHolder string balance float64 } // Deposit 存款方法，更新余额 func (b *BankAccount) Deposit(amount float64) { b.balance += amount fmt.Printf(\"%s 存入 %.2f 元，余额为 %.2f 元\\n\", b.accountHolder, amount, b.balance) } // Withdraw 取款方法，更新余额 func (b *BankAccount) Withdraw(amount float64) { if amount \u003e b.balance { fmt.Printf(\"%s 余额不足，无法取款 %.2f 元\\n\", b.accountHolder, amount) } else { b.balance -= amount fmt.Printf(\"%s 取款 %.2f 元，余额为 %.2f 元\\n\", b.accountHolder, amount, b.balance) } } func main() { account := BankAccount{accountHolder: \"Alice\", balance: 1000.0} account.Deposit(500.0) // 存款 account.Withdraw(300.0) // 取款 } 输出结果如下： Alice 存入 500.00 元，余额为 1500.00 元 Alice 取款 300.00 元，余额为 1200.00 元 匿名字段的方法属于结构体的匿名字段的方法可以被直接调用，就好像这些方法是属于定义了匿名字段的结构体一样 package main import ( \"fmt\" ) type address struct { city string state string } type person struct { firstName string lastName string address } func (a address) fullAddress() { fmt.Printf(\"Full address: %s, %s\", a.city, a.state) } func main() { p := person{ firstName: \"Elon\", lastName: \"Musk\", address: address{ city: \"Los Angeles\", state: \"California\", }, } // 访问 address 结构体的 fullAddress 方法 // 等效：p.address.fullAddress() p.fullAddress() } 输出 Full address: Los Angeles, California 方法中的接收器没有强制指定传递的是值还是指针当一个方法有值接收器或指针接收器。他对传入类型（值或指针）没有强制要求。这是方法与函数的差异（函数值参数只能接受值无法接受指针，反之指针参数无法接受值) package main import ( \"fmt\" ) type rectangle struct { length int width int } func (r rectangle) area() { fmt.Printf(\"Area Method result: %d\\n\", r.length*r.width) } func (r *rectangle) area1() { fmt.Printf(\"Area Method result: %d\\n\", r.length*r.width) } func main() { r := rectangle{ length: 10, width: 5, } p := \u0026r // 通过指针调用值接收器 // 为了方便，Go语言把 p.area() 解释为 (*p).area() p.area() // 通过值调用指针接收器 r.area1() } 接受器定义与方法定义不在同一个包为了在一个类型上定义一个方法，方法的接收器类型定义和方法的定义必须在同一个包中。如下面main包中add方法使用其它包(builtin)定义的int类型则会报错 package main func (a int) add(b int) { } func main() { a := int(2) b := int(3) c := a.add(b) print(c) } 输出 .\\man.go:3:7: cannot define new methods on non-local type int .\\man.go:9:9: a.add undefined (type int has no field or method add) 解决方式是创建类型别名作为方法接收器 package main import \"fmt\" type myInt int func (a myInt) add(b myInt) myInt { return a + b } func main() { num1 := myInt(5) num2 := myInt(10) sum := num1.add(num2) fmt.Println(\"Sum is\", sum) } ","date":"2023-10-27","objectID":"/goMethod/:0:0","tags":["golang","方法"],"title":"go 方法","uri":"/goMethod/"},{"categories":["aws"],"content":" 运行环境： 内容来自以下文档： AWS 官方文档：AWS Cost Explorer API Reference AWS Cost Explorer API Reference 创建异常监视器：GreateAnomalyMonitor 创建异常订阅：CreateAnomalySubscription 创建成本类别定义：CreateCostCategoryDefinition 删除异常监视器：DeleteAnomalyMonitor 删除异常订阅：DeleteAnomalySubscription 删除成本类别定义：DeleteCostCategoryDefinition 描述成本类别定义：DescribeCostCategoryDefinition 获取异常情况：GetAnomalies 获取异常监视器：GetAnomalyMonitors 获取异常订阅：GetAnomalySubscriptions 获取成本和使用情况：GetCostAndUsage 获取资源成本和使用情况：GetCostAndUsageWithResources 获取成本类别：GetCostCategories 获取成本预测：GetCostForecast 获取维度值","date":"2023-10-12","objectID":"/awsCostExplorer/:0:0","tags":["aws","成本管理"],"title":"aws 成本浏览器","uri":"/awsCostExplorer/"},{"categories":["aws"],"content":" web","date":"2023-10-12","objectID":"/awsCostExplorer/:1:0","tags":["aws","成本管理"],"title":"aws 成本浏览器","uri":"/awsCostExplorer/"},{"categories":["aws"],"content":" goGetDimensionValues https://docs.aws.amazon.com/zh_cn/aws-cost-management/latest/APIReference/API_GetDimensionValues.html 获取预订范围：GetReservationCoverage 获取预约购买推荐：GetReservationPurchaseRecommendation 获取预订利用率：GetReservationUtilization 获取规模调整建议：GetRightsizingRecommendation 获取储蓄计划购买建议详细信息：GetSavingsPlanPurchaseRecommendationDetails 获得储蓄计划承保范围：GetSavingsPlansCoverage 获取储蓄计划购买建议：GetSavingsPlansPurchaseRecommendation 获取储蓄计划利用率：GetSavingsPlansUtilization 获取储蓄计划使用详情：GetSavingsPlansUtilizationDetails 获取标签：GetTags 获取使用量预测：GetUsageForecast 列出成本分配标签：ListCostAllocationTags 列出成本类别定义：ListCostCategoryDefinitions 列出储蓄计划购买建议生成：ListSavingsPlansPurchaseRecommendationGeneration 列出资源标签：ListTagsForResource 提供异常反馈：ProvideAnomalyFeedback 启动储蓄计划购买建议生成：StartSavingsPlansPurchaseRecommendationGeneration 标签资源：TagResource 取消资源标签：UntagResource 更新异常监视器：UpdateAnomalyMonitor 更新异常订阅：UpdateAnomalySubscription 更新成本分配标签状态：UpdateCostAllocationTagsStatus 更新成本类别定义：UpdateCostCategoryDefinition ","date":"2023-10-12","objectID":"/awsCostExplorer/:2:0","tags":["aws","成本管理"],"title":"aws 成本浏览器","uri":"/awsCostExplorer/"},{"categories":["aws"],"content":" GetCostAndUsageInput package main import ( \"context\" \"encoding/json\" \"fmt\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/costexplorer\" \"github.com/aws/aws-sdk-go-v2/service/costexplorer/types\" \"log\" ) func main() { sdkConfig, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(\"ap-southeast-1\"), config.WithSharedConfigProfile(\"yh-xiaosi\")) if err != nil { log.Fatalf(\"failed to load configuration (~/.aws/config), %v\", err) } costexplorerClient := costexplorer.NewFromConfig(sdkConfig) startTime := \"2023-09-01\" endTime := \"2023-10-01\" getCostAndUsageInput := \u0026costexplorer.GetCostAndUsageInput{ Granularity: \"MONTHLY\", Metrics: []string{\"UnblendedCost\"}, TimePeriod: \u0026types.DateInterval{ Start: \u0026startTime, End: \u0026endTime, }, Filter: \u0026types.Expression{ CostCategories: \u0026types.CostCategoryValues{ Key: nil, MatchOptions: nil, Values: nil, }, Dimensions: \u0026types.DimensionValues{ Key: \"LINKED_ACCOUNT\", MatchOptions: []types.MatchOption{\"EQUALS\"}, Values: []string{\"223665515173\"}, }, }, } costExplorerOutput, err := costexplorerClient.GetCostAndUsage(context.TODO(), getCostAndUsageInput) costExplorerJson, _ := json.MarshalIndent(costExplorerOutput, \"\", \" \") fmt.Println(string(costExplorerJson)) } Granularity: 时间精细度，必须有 MONTHLY: 月 DAILY: 天 HOURLY: 时 Metrics: 字符串列表，必须有 AmortizedCost: 摊销成本 BlendedCost: 混合成本 NetAmortizedCost: 净摊销成本 NetUnblendedCost: 净未混合成本 NormalizedUsageAmount: 标准化使用量 UnblendedCost: 未混合成 UsageQuantity: 使用量，聚合数值，不考虑单位。 TimePeriod: 时间范围 Start: 起始时间，字符串格式，如：2023-09-01 End: 结束时间，字符串格式，结束时间具有排它性，实际日期要往前一天。如：2023-10-01，实际为 2023-09-30 Filter: 分组筛选 And: 逻辑和 Or: 逻辑或 Not: 排除 CostCategories: 成本类别 Dimensions: 按维度指标搜索 MatchOptions: 指标名与指标值的逻辑关系，有以下值，取决于指标是否支持 EQUALS: ABSENT: STARTS_WITH: ENDS_WITH: CONTAINS: CASE_SENSITIVE: CASE_INSENSITIVE: GREATER_THAN_OR_EQUAL: key: 指标名称，有以下值 AZ: INSTANCE_TYPE: LINKED_ACCOUNT: AWS 账户ID LINKED_ACCOUNT_NAME: AWS 账户名称 OPERATION: PURCHASE_TYPE: REGION: SERVICE: SERVICE_CODE: USAGE_TYPE: USAGE_TYPE_GROUP: RECORD_TYPE: 计费类型 OPERATING_SYSTEM: TENANCY: SCOPE: PLATFORM: SUBSCRIPTION_ID: LEGAL_ENTITY_NAME: DEPLOYMENT_OPTION: DATABASE_ENGINE: CACHE_ENGINE: INSTANCE_TYPE_FAMILY: BILLING_ENTITY: AWS 卖家，值有 AWS、AISPL、AWS Marketplace RESERVATION_ID: RESOURCE_ID: RIGHTSIZING_TYPE: SAVINGS_PLANS_TYPE: SAVINGS_PLAN_ARN: PAYMENT_OPTION: AGREEMENT_END_DATE_TIME_AFTER: AGREEMENT_END_DATE_TIME_BEFORE: INVOICING_ENTITY: ANOMALY_TOTAL_IMPACT_ABSOLUTE: ANOMALY_TOTAL_IMPACT_PERCENTAGE: Values: 指标指 成本汇总依据 未混合成本：现金基础会计方式，即各项实际成本分别计算且当天有效 摊销成本：够买SavingsPlans的折扣前成本分摊到使用账号中 摊销成本净值：够买SavingsPlans实际成本（去除折扣后实际支付的） 示例","date":"2023-10-12","objectID":"/awsCostExplorer/:3:0","tags":["aws","成本管理"],"title":"aws 成本浏览器","uri":"/awsCostExplorer/"},{"categories":["aws"],"content":" 查看组织Savings Plans分摊成本 计费类型选择： Savings Plan 覆盖的使用量 Savings Plan 经常性费用（在利用率没有100%的情况下能显示完整支出） 成本汇总依据选择摊销成本（这是去除折扣前的成本，实际成本应选摊销成本净值） ","date":"2023-10-12","objectID":"/awsCostExplorer/:4:0","tags":["aws","成本管理"],"title":"aws 成本浏览器","uri":"/awsCostExplorer/"},{"categories":["aws"],"content":" 运行环境： 内容来自以下文档： AWS SDK for Go V2 说明文档 sdk 路径aws sdk for go 在 github.com/aws/aws-sdk-go-v2 aws 客户端配置依赖 \"github.com/aws/aws-sdk-go-v2/config\" ","date":"2023-10-11","objectID":"/awsSdkGo/:0:0","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["aws"],"content":" 身份验证","date":"2023-10-11","objectID":"/awsSdkGo/:1:0","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["aws"],"content":" aws 凭证文件配置项aws 访问配置文件可以分为凭证文件(credentials)指定身份验证信息，如密钥；配置文件(conf)指定其它配置项如地区，它们没有实际差别。可以指定多个配置名称与文件。它们优先级： 相同profile时，凭证文件优先于配置文件 多个文件时，按加载顺序，后者覆盖前者 同个文件中，后者profile覆盖前者 以下示例加载 aws 凭证文件 import ( \"context\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"log\" ) // ... func main() { cfg, err := config.LoadDefaultConfig(context.TODO()) if err != nil { log.Fatalf(\"failed to load configuration (~/.aws/config), %v\", err) } } aws 凭证文件默认为 ~/.aws/config，它是 ini 格式文本，以下是常用配置项目 # 默认有配置名称 # 等效 [profile default] [default] # id aws_access_key_id=AKIAIOSFODNN7EXAMPLE # 密钥 aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY # 区域 region=us-west-2 # 输出格式 output=json # 指定配置名称 [profile yh-xiaosi] aws_access_key_id=AKIAIOSFODNN7EXAMPLE aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY ","date":"2023-10-11","objectID":"/awsSdkGo/:1:1","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["aws"],"content":" 指定 aws 访问配置文件指定多个配置文件时，加载顺序可添加config.LoadOptions 查看。 import ( \"context\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"log\" ) // ... func main() { cfg, err := config.LoadDefaultConfig(context.TODO(), // 加载凭证文件 config.WithSharedCredentialsFiles( []string{\"test/credentials\", \"data/credentials\"}, ), // 加载配置文件 config.WithSharedConfigFiles( []string{\"test/config\", \"data/config\"}, ), ) } ","date":"2023-10-11","objectID":"/awsSdkGo/:1:2","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["aws"],"content":" 指定 profileconfig.WithSharedConfigProfile(\"string\")) 指定profile func main() { cfg, err := config.LoadDefaultConfig(context.TODO(), config.WithSharedConfigProfile(\"yh-xiaosi\")) if err != nil { log.Fatalf(\"failed to load configuration (~/.aws/config), %v\", err) } } ","date":"2023-10-11","objectID":"/awsSdkGo/:1:3","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["aws"],"content":" 修改地区config.WithRegion 可指定aws区域，如下示例指定为新加坡 import ( \"context\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"log\" ) // ... func main() { cfg, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(\"ap-southeast-1\")) if err != nil { log.Fatalf(\"failed to load configuration (~/.aws/config), %v\", err) } } ","date":"2023-10-11","objectID":"/awsSdkGo/:1:4","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["aws"],"content":" 把访问凭证硬编码到代码中不推荐的做法 import ( \"context\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/credentials\" \"log\" ) // ... func main() { cfg, err := config.LoadDefaultConfig(context.TODO(), config.WithCredentialsProvider( credentials.NewStaticCredentialsProvider( \"AKID\", \"SECRET_KEY\", \"TOKEN\")), ) if err != nil { log.Fatalf(\"failed to load configuration (~/.aws/config), %v\", err) } } ","date":"2023-10-11","objectID":"/awsSdkGo/:1:5","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["aws"],"content":" 构建客户端 package main import ( \"context\" \"encoding/json\" \"fmt\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/iam\" \"github.com/aws/aws-sdk-go-v2/service/sts\" \"log\" \"strings\" ) func main() { sdkConfig, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(\"ap-southeast-1\"), config.WithSharedConfigProfile(\"yh-xiaosi\")) if err != nil { log.Fatalf(\"failed to load configuration (~/.aws/config), %v\", err) } // 创建 sts 服务客户端口 stsClient := sts.NewFromConfig(sdkConfig) userIdInfo, err := stsClient.GetCallerIdentity(context.TODO(), nil) if err != nil { fmt.Println(\"出错\") } userArn := *userIdInfo.Arn parts := strings.Split(userArn, \"/\") userName := parts[len(parts)-1] userInput := \u0026iam.GetUserInput{ UserName: aws.String(userName), } // 创建 iam 服务客户端 iamClient := iam.NewFromConfig(sdkConfig) userOutput, err := iamClient.GetUser(context.TODO(), userInput) if err != nil { fmt.Println(\"出错\") } userInfoJson, _ := json.MarshalIndent(userOutput, \"\", \" \") fmt.Println(string(userInfoJson)) } 示例 package main import ( \"context\" \"encoding/json\" \"fmt\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/iam\" \"github.com/aws/aws-sdk-go-v2/service/iam/types\" \"log\" ) func main() { sdkConfig, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(\"ap-southeast-1\"), config.WithSharedConfigProfile(\"yh-xiaosi\")) if err != nil { fmt.Println(\"Couldn't load default configuration. Have you set up your AWS account?\") fmt.Println(err) return } iamClient := iam.NewFromConfig(sdkConfig) // 获取 30 个用户信息 maxUsers := 30 userList, err := iamClient.ListUsers(context.TODO(), \u0026iam.ListUsersInput{ MaxItems: aws.Int32(int32(maxUsers)), }) var users []types.User if err != nil { log.Printf(\"Couldn't list users. Here's why: %v\\n\", err) } else { users = userList.Users } // 格式化输出 formattedJSON, _ := json.MarshalIndent(users, \"\", \" \") // 打印格式化后的JSON数据 fmt.Println(string(formattedJSON)) } ","date":"2023-10-11","objectID":"/awsSdkGo/:2:0","tags":["aws"],"title":"aws sdk golang","uri":"/awsSdkGo/"},{"categories":["golang"],"content":" 运行环境： 内容来自以下文档： download golang 从官网下载安装包 [root@localhost ~]# wget https://go.dev/dl/go1.21.3.linux-amd64.tar.gz 解压 [root@localhost ~]# tar -zxf go1.21.3.linux-amd64.tar.gz -C /usr/local/ 加入到 PATH 环境变量中 [root@localhost ~]# ln -s /usr/local/go/bin/go /usr/bin/go 查看版本 [root@localhost ~]# go version go version go1.21.3 linux/amd64 ","date":"2023-10-11","objectID":"/goInstallGolang/:0:0","tags":["go"],"title":"安装 golang","uri":"/goInstallGolang/"},{"categories":["aws"],"content":" 运行环境： centos 说明文章包含以下部分： 创建具有权限操作lightsail资源的IAM用户 创建lightsail 实例 创建lightsail 实例快照 通过脚本使用lightsail 实例快照批量创建实例 执行脚本前说明： 脚本目前只能在centos系统中执行 脚本目前只能使用root身份执行 脚本是使用aws cli 命令行工具，因此执行前需要准备有lightsail实例操作权限的访问密钥与Lightsail快照 准备工作该部分是创建 IAM 用户，只用于管理Lightsail资源。以生成及脚本所需的IAM用户访问密钥。如果之前操作过或对AWS IAM 用户权限相对了解则可以适当或完全跳过该部分 ","date":"2023-09-16","objectID":"/awsCreateLightsailInstancesFromSnapshot/:0:0","tags":["Lightsail"],"title":"基于Lightsail快照批量创建实例bash脚本使用手册","uri":"/awsCreateLightsailInstancesFromSnapshot/"},{"categories":["aws"],"content":" 创建 lightsail 用户所需权限 从 AWS 控制台进入IAM主页 进入创建IAM权限策略 在策略编辑器中，把下面文本替换掉默认内容 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"VisualEditor0\", \"Effect\": \"Allow\", \"Action\": [ \"iam:UpdateLoginProfile\", \"iam:DeleteAccessKey\", \"iam:GetAccessKeyLastUsed\", \"iam:UpdateAccessKey\", \"iam:ListUserPolicies\", \"iam:ListMFADevices\", \"iam:CreateAccessKey\", \"iam:ListGroupsForUser\", \"iam:ListAttachedUserPolicies\", \"iam:GetUser\", \"iam:GetLoginProfile\", \"iam:ChangePassword\", \"iam:ListAccessKeys\", \"iam:ListUserTags\" ], \"Resource\": \"arn:aws:iam::223665515173:user/${aws:username}\" }, { \"Sid\": \"VisualEditor1\", \"Effect\": \"Allow\", \"Action\": [ \"lightsail:*\", \"iam:ListUsers\", \"iam:GetPolicyVersion\", \"iam:GetPolicy\", \"iam:ListPolicies\" ], \"Resource\": \"*\" } ] } 注意：要修改账号ID，账号ID可以在右上角账号查看。修改后保存 输入策略名称，描述是可选的 在保存前可以添加标签，标签是可选的 ","date":"2023-09-16","objectID":"/awsCreateLightsailInstancesFromSnapshot/:1:0","tags":["Lightsail"],"title":"基于Lightsail快照批量创建实例bash脚本使用手册","uri":"/awsCreateLightsailInstancesFromSnapshot/"},{"categories":["aws"],"content":" 创建 IAM 用户用于管理 Lightsail 资源 在 AWS 控制台创建IAM用户 指定用户名，并为其提供控制台权限 指定控制台登录密码，自动生成受密码策略影响，可能过于简单，建议手动输入。可以取消登录时强制修改密码 把之前创建的策略附加给用户 检查没问题后，选择创建用户 妥善保管登录信息，建议使用该登录信息管理 lightsail 资源 ","date":"2023-09-16","objectID":"/awsCreateLightsailInstancesFromSnapshot/:2:0","tags":["Lightsail"],"title":"基于Lightsail快照批量创建实例bash脚本使用手册","uri":"/awsCreateLightsailInstancesFromSnapshot/"},{"categories":["aws"],"content":" 创建lightsail实例这部分操作教程为创建实例，如果已有实例则跳过 使用拥有操作lightsail资源权限的用户（如之前创建的lightsail-admin）登录到控制台 进入 lightsail 控制台（收藏按钮可以控制台创建快捷入口) 创建lightsail实例（左下角可以选择网页语言） 选择区域与可用区（相同地区不同位置的IDC机房） 选择操作系统与基础映像（根据需要选择） 启动脚本用于实例创建并成功启动后执行的脚本（linux: shell，windows: PowerShell），它们都是根用户执行，因此不需要使用类似 sudo 的提权命令 SSH密钥实际是SSH公钥。每个区域都有默认提供的密钥对可以随时下载。只有基于linux系统的实例才能上传自建的公钥 选项实例资源规格 指定实例名称与数量。名称推荐格式为：账户别名-用途-地区-创建日期-可用区。指定数量大于1时，会在名称后面加上-n(n表示序列号)。如：xiaosi-template-20230916-singapore-a-2 表示批量创建中的第二个实例 仅键标签用于指定实例标签，在lightsail 首页可以点击实例下方的该标签筛选实例。推荐标签有：用途、创建日期 键值对标签除了与仅键标签相同的作用以外，还可以用于账单分类、Lightsail资源的访问控制 检查无误后，点击页面最下方的创建按钮，单个实例创建完成可能需要1分钟左右 实例创建后，将会在首页显示。可以点击连接按钮进行业务配置，也可以点击名称进入管理页根据提示使用其它ssh远程工具连接到实例 ","date":"2023-09-16","objectID":"/awsCreateLightsailInstancesFromSnapshot/:3:0","tags":["Lightsail"],"title":"基于Lightsail快照批量创建实例bash脚本使用手册","uri":"/awsCreateLightsailInstancesFromSnapshot/"},{"categories":["aws"],"content":" 创建lightsail实例快照这部分操作教程为创建快照以及复制快照到其它区域，如果创建目标区域已有快照，则可跳过该部分 快照可以简单理解为实例的复制。快照内容取决与创建快照时的实例。可以通过快照创建出几乎相同配置的实例，并分配新的IP地址。快照不可跨区域使用。但可以可以把 A 区域的快照复制到B区域，然后在 B 区域可以使用快照创建lightsail实例 当业务测试没问题后，可创建快照。在lightsail 首页 点击实例名称进入实例管理页面。快照只是复制实例系统盘与数据盘。其它如启动脚本、IP、实例规格等都不会复制。在创建快照前注意是实例名称是否正确。此外，在命名时注意，相同区域中，快照名称是唯一的 创建快照需要3分钟左右。快照除了在实例管理页面中可见，点击lightsail 首页左侧快照按钮进入快照主面，也可以管理该快照。 选择创建实例，则与前面文章中创建实例基本没区别，只是通过快照创建出来的实例不用重新配置业务 选择复制到其它区域，则会提示选择目标区域与编辑快照名称。快照复制通常也要3分钟 ","date":"2023-09-16","objectID":"/awsCreateLightsailInstancesFromSnapshot/:4:0","tags":["Lightsail"],"title":"基于Lightsail快照批量创建实例bash脚本使用手册","uri":"/awsCreateLightsailInstancesFromSnapshot/"},{"categories":["aws"],"content":" 查看lightsail实例快照名称脚本会用到实例快照名称，在lightsail 快照页面中，选择通过选择区域、实例名称、创建日期等条件筛选后，可查看快照名称 ","date":"2023-09-16","objectID":"/awsCreateLightsailInstancesFromSnapshot/:5:0","tags":["Lightsail"],"title":"基于Lightsail快照批量创建实例bash脚本使用手册","uri":"/awsCreateLightsailInstancesFromSnapshot/"},{"categories":["aws"],"content":" 创建访问密钥脚本会用到IAM 用户的访问密钥。只要是有相关权限都行 在IAM 控制面板中，选择用户，进入用户管理界面。注意：选择的用户必须具有使用lightsail实例快照创建实例的相关操作权限。截图中选择文档前面中创建的用户lightsail-admin 选择安全凭证选项卡 选择创建IAM用户访问密钥 选择IAM用户访问密钥使用案例 指定IAM用户访问密钥标签（可选） 保存访问密钥。访问密钥是登录凭证，类似用户密码，非常重要，妥善保管不可泄露。由于访问密钥与秘密访问密钥只能在创建时查看且不可找回、不可重置。因此需要保存到文档，或下载.csv文件 使用脚本创建实例 下载脚本 [root@ip-172-26-7-205 ~]# curl -sLO http://note.xiaosi.host/awsCreateLightsailInstancesFromSnapshot/awsLightsailCreateInstancesFromSnapshot.sh 开始执行脚本，第一个步骤是选择访问凭证名称。访问凭证的ID与key在aws控制台创建 [root@localhost test]# bash awsLightsailCreateInstancesFromSnapshot.sh 0.新建 1.heye02 2.heye01 选择拥有操作权限的配置项：0 开始创建配置文件 指定 aws cli 使用的 profile 名称：xiaosi-test 指定 aws cli 使用的访问密钥 ID：AKIATIE4A5KSSXUNKZX6 指定 aws cli 使用的访问密钥 KEY：QlEBzX3nnyCRMG6Y2iZTQkr3Xtu4HRTECuAb4JL9 按照提示选择地区序列号 0.退出脚本 1.欧洲 （爱尔兰） (eu-west-1) 2.欧洲 （英国-伦敦） (eu-west-2) 3.欧洲 （法国-巴黎） (eu-west-3) 4.欧洲 （德国-法兰克福） (eu-central-1) 5.欧洲 （瑞典-斯德哥尔摩）(eu-north-1) 6.加拿大 （蒙特利尔） (ca-central-1) 7.亚太地区（孟买） (ap-south-1) 8.亚太地区（新加坡） (ap-southeast-1) 9.亚太地区（日本-东京） (ap-northeast-1) 10.亚太地区（韩国-首尔） (ap-northeast-2) 11.亚太地区（澳大利亚-悉尼） (ap-southeast-2) 12.美国东部（俄亥俄） (us-east-2) 13.美国西部（俄勒冈） (us-west-2) 14.美国东部（弗吉尼亚北部） (us-east-1) 选择创建区域的序列号（1-14）：8 按照提示选择快照序列号 1. template 选择用于创建实例的快照序列号：1 按照提示选择实例规格 序列号 月价格(美元) vcpu 内存(G) 磁盘(G) 月流量(G) 操作系统 1 3.5 2 0.5 20 1024 LINUX_UNIX 2 5.0 2 1.0 40 2048 LINUX_UNIX 3 10.0 2 2.0 60 3072 LINUX_UNIX 4 20.0 2 4.0 80 4096 LINUX_UNIX 5 40.0 2 8.0 160 5120 LINUX_UNIX 6 80.0 4 16.0 320 6144 LINUX_UNIX 7 160.0 8 32.0 640 7168 LINUX_UNIX 8 8.0 2 0.5 30 1024 WINDOWS 9 12.0 2 1.0 40 2048 WINDOWS 10 20.0 2 2.0 60 3072 WINDOWS 11 40.0 2 4.0 80 4096 WINDOWS 12 70.0 2 8.0 160 5120 WINDOWS 13 120.0 4 16.0 320 6144 WINDOWS 14 240.0 8 32.0 640 7168 WINDOWS 选择实例规格，注意系统类型（1-14）：1 指定创建实例数量 创建实例数量，默认为 1：1 选择连接公钥 ap-southeast-1 区域没有自定义 ssh 公钥，将使用默认公钥 按照提示放行端口 添加端口规则：“端口”(0到65535) + “/” + “协议”(tcp或udp或icmp) 示例：22/tcp 添加端口规则：对于 tcp或udp 可以使用 “—” 表示tcp或udp端口范围。必须是从小到大 添加端口规则：对于 imcp 协议使用-分隔 ICMP 类型和代码 示例：8080-8088/tcp 示例，ping 命令使用的 icmp ：8-0/icmp 添加端口规则：可以使用 “=” 只允许指定ip访问（支持CIDR格式) 示例：22/tcp=192.178.23.22 示例：122=233/tcp=192.168.0.0/16 添加：根据上面说明，指定实例放行端口 保存：输入 yes 可保存规则 删除：输入 规则编号+d，可删除规则。如 1d 删除第1条规则 ================== 现有规则：================== 1. \"起始端口\": 3389, \"结束端口\": 3389, \"协议\": \"tcp\", \"白名单\": [\"0.0.0.0/0\"] 2. \"起始端口\": 22, \"结束端口\": 22, \"协议\": \"tcp\", \"白名单\": [\"0.0.0.0/0\"] 3. \"类型\": 8, \"代码\": 0, \"协议\": \"icmp\", \"白名单\": [\"0.0.0.0/0\"] =============================================== 根据说明执行添加、删除、保存规则操作：1d 添加：根据上面说明，指定实例放行端口 保存：输入 yes 可保存规则 删除：输入 规则编号+d，可删除规则。如 1d 删除第1条规则 ================== 现有规则：================== 1. \"起始端口\": 22, \"结束端口\": 22, \"协议\": \"tcp\", \"白名单\": [\"0.0.0.0/0\"] 2. \"类型\": 8, \"代码\": 0, \"协议\": \"icmp\", \"白名单\": [\"0.0.0.0/0\"] =============================================== 根据说明执行添加、删除、保存规则操作：37189/udp 添加：根据上面说明，指定实例放行端口 保存：输入 yes 可保存规则 删除：输入 规则编号+d，可删除规则。如 1d 删除第1条规则 ================== 现有规则：================== 1. \"起始端口\": 22, \"结束端口\": 22, \"协议\": \"tcp\", \"白名单\": [\"0.0.0.0/0\"] 2. \"类型\": 8, \"代码\": 0, \"协议\": \"icmp\", \"白名单\": [\"0.0.0.0/0\"] 3. \"起始端口\": 37189, \"结束端口\": 37189, \"协议\": \"udp\", \"白名单\": [\"0.0.0.0/0\"] =============================================== 根据说明执行添加、删除、保存规则操作：yes 确认信息 指定实例名称前缀（推荐格式：账号别名-用途-地区）：xiaosi-singapore-test ==================信息展示：===================== 区域：ap-southeast-1 快照名：template 实例规格：LINUX_UNIX 2核 0.5G内存 20G硬盘 3.5/月 实例数量：1 ssh 公钥文件名：LightsailDefaultKeyPair 实例名称示例：xiaosi-singapore-test-a1-20231007-AovUJ ================================================= 如果上面信息正确，输入 yes 开始创建实例，或输入 no 退出脚本：yes 会输出成为放行端口的实例IP 开始创建实例： 实例创建成功：xiaosi-singapore-test-a1-20231007-AovUJ 已创建实例数量：1 此脚本将等待 90 秒，避免有实例没有完成启动 开始放行实例端口 xiaosi-singapore-test-a1-20231007-AovUJ 实例端口添加成功 可以尝试连接以下 IP： 13.228.71.6 建议删除本次使用的访问密钥 ====================================================== 脚本明码执行，为了安全。有必要删除本次使用的访问密钥。 ====================================================== 输入 yes 立即删除本次使用的访问密钥：yes ===================== 删除完成 ======================= ","date":"2023-09-16","objectID":"/awsCreateLightsailInstancesFromSnapshot/:6:0","tags":["Lightsail"],"title":"基于Lightsail快照批量创建实例bash脚本使用手册","uri":"/awsCreateLightsailInstancesFromSnapshot/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： opti：CentOS UUID生成 [root@localhost ~]# uuidgen 3c41d173-a3f6-4969-9dcc-f5f5220186e2 ","date":"2023-09-02","objectID":"/linuxCMDuuidgen/:0:0","tags":["uuidgen","linux","命令"],"title":"uuidgen - 创建一个新的UUID值","uri":"/linuxCMDuuidgen/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.24 内容来自以下文档： nginx 官方文档：ngx_http_proxy_module nginx 官方文档：ngx_http_proxy_protocol_vendor_module 相关模块 ngx_http_proxy_module 该模块会默认编译，编译时可通过--without-ngx_http_proxy_module取消 ngx_http_proxy_protocol_vendor_module http 代理流程http反向代理流程如下： 在content阶段触发proxy_pass指令 是否命中缓存： 未命中缓存或没有开启缓存进入下一步 命中缓存直接进入第11步 通过指令生成头部和主体发给上游服务 判断proxy_requset_buffering指令是否开启 开启(默认)：缓存请求报文主体部分再进入下一步 关闭：进入下一步 更据负载均衡策略选择上游服务(upstream指令快) 更据参数连接上游服务 发送请求到上游服务， 如果proxy_requset_buffering指令关闭则会在此时边读主体部分边发送 接收上游服务返回的响应头部 处理上游响应头部 判断proxy_buffering指令是否开启： 开启：接收完整的响应主体部分再进入下一步 关闭：直接进入下一步 发送响应头部给客户端 发送响应主体部分给客户端， 如果proxy_buffering指令关闭则会在此时边读主体边发送 判断是否开启缓存： 开启：将主体部分加入缓存再进入下一步 关闭：直接进入下一步 关闭或复用连接，也就是长连接(保存连接) 与上游服务建立连接","date":"2023-08-24","objectID":"/nginxHttpProxy/:0:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_pass Syntax: proxy_pass URL; Default: — Context: location, if in location, limit_except 请求阶段：content 配置上游服务URL地址 协议为：http、htps 地址为：ip、unix:/path/service.socket(UNIX socket)、域名 端口缺省，默认为 80 路径与参数部分可以缺省，不会进行修改。如果有指定，则只修改 location 匹配部分。此外，当 location 匹配地址为为正则表达式时不能含有路径与参数 server { listen 172.0.0.1:830; location / { # 请求地址：172.0.0.1:830/abc/txt # 转发目标：172.0.0.1:831/abc/txt proxy_pass http://172.0.0.1:831; ... } location / { # 注意，与上述配置冲突 # 请求地址：172.0.0.1:830/abc/txt # 转发目标：172.0.0.1:831/txt proxy_pass http://172.0.0.1:831/; ... } location /123 { # 注意，与上述配置冲突 # 请求地址：172.0.0.1:830/123/txt # 转发目标：172.0.0.1:830/txt proxy_pass http://172.0.0.1:831/txt; ... } location /123/ { # 请求地址：172.0.0.1:830/234/txt # 转发目标：172.0.0.1:831/abc/txt proxy_pass http://172.0.0.1:831/abc/; ... } } ","date":"2023-08-24","objectID":"/nginxHttpProxy/:1:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_bind Syntax: proxy_bind address [transparent] | off; Default: — Context: http, server, location This directive appeared in version 0.8.22. ","date":"2023-08-24","objectID":"/nginxHttpProxy/:2:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_connect_timeout Syntax:proxy_connect_timeout time; Default:proxy_connect_timeout 60s; Context:http, server, location 指定与上游服务建立连接超时时间 ","date":"2023-08-24","objectID":"/nginxHttpProxy/:3:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_http_version Syntax:proxy_http_version 1.0 | 1.1; Default:proxy_http_version 1.0; Context:http, server, location This directive appeared in version 1.1.4. 与上游服务连接时使用的协议 ","date":"2023-08-24","objectID":"/nginxHttpProxy/:4:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_set_header Syntax:proxy_set_header field value; Default: proxy_set_header Host $proxy_host; proxy_set_header Connection close; Context:http, server, location 增改请求头部 接收上游服务返回的响应报文","date":"2023-08-24","objectID":"/nginxHttpProxy/:5:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_buffering Syntax:proxy_buffering on | off; Default:proxy_buffering on; Context:http, server, location 启用或禁用缓冲从代理服务器的响应。 ","date":"2023-08-24","objectID":"/nginxHttpProxy/:6:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_read_timeout Syntax:proxy_read_timeout time; Default:proxy_read_timeout 60s; Context:http, server, location 指定从上游响应超时时间，超时会关闭连接 响应客户端","date":"2023-08-24","objectID":"/nginxHttpProxy/:7:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" proxy_redirect Syntax:proxy_redirect default; Syntax:proxy_redirect off; Syntax:proxy_redirect redirect replacement; Default:proxy_redirect default; Context:http, server, location 修改发送给客户端地址的 URL ","date":"2023-08-24","objectID":"/nginxHttpProxy/:8:0","tags":["nginx","http proxy"],"title":"nginx http 代理","uri":"/nginxHttpProxy/"},{"categories":["nginx"],"content":" 运行环境： centos: 7 创建用户 useradd nginx -s /sbin/nologin -M 修改nginx 目录权限 chown -R nginx.nginx /usr/local/nginx/ 允许普通用户监听 1024 以下的端口 setcap cap_net_bind_service=+eip /usr/local/nginx/sbin/nginx 测试权限 sudo -u nginx nginx -t \u0026\u0026 sudo -u nginx nginx -s reload 创建运行 setcap 命令的服务，稍后让其开机自己执行 [root@localhost ~]# cat /etc/systemd/system/nginx-capability.service [Unit] Description=Set capabilities for Nginx Before=nginx.service After=network.target [Service] Type=oneshot ExecStart=/usr/sbin/setcap cap_net_bind_service=+eip /usr/local/nginx/sbin/nginx [Install] WantedBy=default.target 修改 nginx.service 文件 [root@localhost ~]# cat /usr/lib/systemd/system/nginx.service [Unit] Description=The nginx HTTP and reverse proxy server After=network.target remote-fs.target nss-lookup.target nginx-capability.service [Service] Type=forking PIDFile=/usr/local/nginx/logs/nginx.pid ExecStartPre=/usr/bin/rm -f /usr/local/nginx/logs/nginx.pid ExecStartPre=/usr/local/nginx/sbin/nginx -t ExecStart=/usr/local/nginx/sbin/nginx ExecReload=/usr/local/nginx/sbin/nginx -s reload ExecStop=/usr/local/nginx/sbin/nginx -s stop KillSignal=SIGQUIT TimeoutStopSec=5 KillMode=process PrivateTmp=true Restart=on-failure RestartSec=42s # 运行用户与组 User=nginx Group=nginx [Install] WantedBy=multi-user.target 重新加载 Systemd 配置 systemctl daemon-reload 开机启动服务(nginx 与 nginx-capability) systemctl enable nginx-capability.service systemctl enable nginx.service ","date":"2023-08-23","objectID":"/nginxProcessRunsAsUser/:0:0","tags":["nginx"],"title":"用普通用户身份运行 nginx 进程","uri":"/nginxProcessRunsAsUser/"},{"categories":["gitlab"],"content":" 运行环境： 内容来自以下文档： 安装私有化部署版极狐GitLab 配置 Omnibus GitLab 安装极狐GitLab Runner 极狐GitLab Runner 安装","date":"2023-08-22","objectID":"/gitLab/:0:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" linux 安装包 安装依赖 [root@localhost ~]# yum install -y curl policycoreutils-python openssh-server perl ... 防火墙放行http与https协议 [root@localhost ~]# firewall-cmd --add-service=http --add-service=https success [root@localhost ~]# [root@localhost ~]# firewall-cmd --runtime-to-permanent success 安装 Postfix 服务用于发送电子邮件通知，可使用其它方式解决邮件发送 [root@localhost ~]# yum install postfix -y ... [root@localhost ~]# systemctl enable postfix [root@localhost ~]# [root@localhost ~]# systemctl start postfix 下载bash脚本用于配置yum源 [root@localhost ~]# curl -fsSL https://packages.gitlab.cn/repository/raw/scripts/setup.sh \u003e install-gitlab.sh ... [root@localhost ~]# bash install-gitlab.sh ==\u003e Detected OS centos ==\u003e Add yum repo file to /etc/yum.repos.d/gitlab-jh.repo [gitlab-jh] name=JiHu GitLab baseurl=https://packages.gitlab.cn/repository/el/$releasever/ gpgcheck=0 gpgkey=https://packages.gitlab.cn/repository/raw/gpg/public.gpg.key priority=1 enabled=1 ==\u003e Generate yum cache for gitlab-jh ==\u003e Successfully added gitlab-jh repo. To install JiHu GitLab, run \"sudo yum/dnf install gitlab-jh\". 解析域名到gitlab将要使用的ip地址，并等待生效后再进行下一步 [root@localhost ~]# ping gitlab.xiaosi.host PING gitlab.xiaosi.host (103.106.246.103) 56(84) bytes of data. .... 安装gitlab-jh。 EXTERNAL_URL 环境变量指定gitlab使用的协议与域名，如果是https协议，则默认启用 Let’s Encrypt 集成并通过该方式申请证书 GITLAB_ROOT_PASSWORD 环境变量指定 gitlab 使用的 root 用户密码，如果缺省则生成随机密码并保存在 /etc/gitlab/initial_root_password 文件中，该文件24小时后会被删除 [root@localhost ~]# EXTERNAL_URL=\"https://gitlab.xiaosi.host\" [root@localhost ~]# GITLAB_ROOT_PASSWORD=\"J[o?TK@~;mZHp\"%N4H2T2Y\" [root@localhost ~]# yum install -y gitlab-jh Loaded plugins: fastestmirror ... nginxgitlab 自带有 nginx，配置方式为 nginx[nginx directives] = directives。可以在配置文件中/etc/gitlab/gitlab.rb 使用以下配置禁用 nginx['enable'] = false # 监听地址 nginx['listen_addresses'] = [\"103.106.246.103\"] # 监听端口 nginx['listen_port'] = 8081 # 禁用 Let’s Encrypt 集成 letsencrypt['enable'] = false # 证书 nginx['ssl_certificate'] = \"/etc/letsencrypt/live/xiaosi.host/fullchain.pem\" # 密钥 nginx['ssl_certificate_key'] = \"/etc/letsencrypt/live/xiaosi.host/privkey.pem\" # HTTP 重定向到 HTTPS nginx['redirect_http_to_https'] = true # 指定域名与协议，HTTPS external_url \"https://gitlab.xiaosi.host\" 监控指标","date":"2023-08-22","objectID":"/gitLab/:1:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" Grafana从 15.3 版本开始，Grafana 默认不启用，可以编辑配置文件/etc/gitlab/gitlab.rb 启用 grafana['enable'] = true ","date":"2023-08-22","objectID":"/gitLab/:2:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" PrometheusPrometheus 及其 exporter 默认开启。 Prometheus 以 gitlab-prometheus 用户身份运行，并监听 http://localhost:9090。默认情况下，Prometheus 只能从 GitLab 服务器本身访问。 每个 exporter 都会自动设置为 Prometheus 的监控目标，除非单独禁用。 # 关闭 prometheus prometheus_monitoring['enable'] = false prometheus['enable'] = false # 关闭 node_exporter 指标收集 node_exporter['enable'] = false # 启用 Redis 和 Omnibus GitLab 安装实例中的 GitLab 指标 # localhost:9168 gitlab_exporter['enable'] = true ## PgBouncer 指标，localhost:9188 pgbouncer_exporter['enable'] = true # PostgreSQL 指标，localhost:9187 postgres_exporter['enable'] = true 备份","date":"2023-08-22","objectID":"/gitLab/:3:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" 备份配置文件gitlab-ctl backup-etc 命令用于备份 gitlab，受以下参数影响 --backup-path 备份到指定目录 # 指定默认备份目录，值为 false 表示关闭 gitlab_rails['manage_backup_path'] = /data/gitlab/ 如果使用manage_backup_path配置项指定，则该目录只允许user['username']配置指定的用户访问，否则不会创建备份文件 --no-delete-old-backups 保留所有备份 --delete-old-backups 删除过旧的备份，它会删除配置文件中backup_keep_time指定时间之前的备份 # 备份修剪时间，单位为秒，为 0 表示保留所有 gitlab_rails['backup_keep_time'] = 604800 ","date":"2023-08-22","objectID":"/gitLab/:4:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" 使用gitlab-rake备份gitlab-rake命令可以备份以下数据： db:（数据库） uploads:（附件） builds:（CI 作业输出日志） artifacts:（CI 作业产物） lfs:（LFS 对象） terraform_state:（Terraform 状态） registry:（容器数据库镜像） pages:（Pages 内容） repositories:（Git 仓库数据） packages:（软件包） 可以通过添加环境变量 SKIP 排除备注数据，如 [root@localhost ~]# gitlab-backup create SKIP=db,uploads,db,builds,artifacts,lfs,terraform_state,registry,pages,packagess 2024-01-10 15:14:44 UTC -- Dumping database ... [SKIPPED] 2024-01-10 15:14:44 UTC -- Dumping repositories ... 替换组件","date":"2023-08-22","objectID":"/gitLab/:5:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" 使用自己的 nginx 修改配置文件 /etc/gitlab/gitlab.rb # 禁用 gitlab 自带的nginx nginx['enable'] = false # 指定 nginx 运行时的用户名 web_server['external_users'] = ['nginx'] # 把 nginx 使用的 ip 添加到信任名单 gitlab_rails['trusted_proxies'] = [ '103.106.246.103' ] 把 nginx 运行用户加入到 gitlab-www 组中 [root@localhost ~]# usermod -a -G gitlab-www nginx [root@localhost ~]# [root@localhost ~]# id nginx uid=1000(nginx) gid=1000(nginx) groups=1000(nginx),991(gitlab-www) 添加 nginx 反向代理配置文件 [root@localhost nginx]# cat conf/conf.d/gitlab.xiaosi.host ## GitLab ## [root@localhost ~]# cat /usr/local/nginx/conf/conf.d/gitlab.xiaosi.host.nginx.conf ## Modified from nginx http version ## Modified from http://blog.phusion.nl/2012/04/21/tutorial-setting-up-gitlab-on-debian-6/ ## Modified from https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html ## ## Lines starting with two hashes (##) are comments with information. ## Lines starting with one hash (#) are configuration parameters that can be uncommented. ## ################################## ## CONTRIBUTING ## ################################## ## ## If you change this file in a merge request, please also create ## a merge request on https://gitlab.com/gitlab-org/omnibus-gitlab/merge_requests ## ################################### ## configuration ## ################################### ## ## See installation.md#using-https for additional HTTPS configuration details. ## NGINX 'combined' log format with filtered query strings #log_format gitlab_ssl_access '$remote_addr - $remote_user [$time_local] \"$request_method $gitlab_ssl_filtered_request_uri $server_protocol\" $status $body_bytes_sent \"$gitlab_ssl_filtered_http_referer\" \"$http_user_agent\"'; log_format gitlab escape=json '{' '\"responseTime\": \"$time_iso8601\",' '\"requestIP\": \"$remote_addr\",' '\"requestPort\": \"$remote_port\",' '\"requestScheme\": \"$scheme\",' '\"requestProtocol\": \"$server_protocol\",' '\"requsetMethod\": \"$request_method\",' '\"requestDomainName\": \"$host\",' '\"responseUrl\": \"$uri\",' '\"responseIP\": \"$server_addr\",' '\"responseport\": \"$server_port\",' '\"responseStatus\": \"$status\",' '\"responseGitlabUri\": \"$gitlab_ssl_filtered_request_uri\",' '\"responseGitlabreferer\": \"$gitlab_ssl_filtered_http_referer\",' \"\\\"responseSize\\\": \" \"\\\"$bytes_sent\" \"B\\\",\" \"\\\"responseBodySize\\\": \" \"\\\"$body_bytes_sent\" \"B\\\",\" \"\\\"processingConsumeTime\\\": \" \"\\\"$request_time\" \"s\\\",\" '\"processingStatus\": \"$request_completion\",' '\"User-Agent\": \"$http_user_agent\"' '}'; upstream gitlab-workhorse { # GitLab socket file, # for Omnibus this would be: unix:/var/opt/gitlab/gitlab-workhorse/sockets/socket # server unix:/home/git/gitlab/tmp/sockets/gitlab-workhorse.socket fail_timeout=0; server unix:/var/opt/gitlab/gitlab-workhorse/sockets/socket fail_timeout=0; } map $http_upgrade $connection_upgrade_gitlab_ssl { default upgrade; '' close; } ## Remove private_token from the request URI # In: /foo?private_token=unfiltered\u0026authenticity_token=unfiltered\u0026feed_token=unfiltered\u0026... # Out: /foo?private_token=[FILTERED]\u0026authenticity_token=unfiltered\u0026feed_token=unfiltered\u0026... map $request_uri $gitlab_ssl_temp_request_uri_1 { default $request_uri; ~(?i)^(?\u003cstart\u003e.*)(?\u003ctemp\u003e[\\?\u0026]private[\\-_]token)=[^\u0026]*(?\u003crest\u003e.*)$ \"$start$temp=[FILTERED]$rest\"; } ## Remove authenticity_token from the request URI # In: /foo?private_token=[FILTERED]\u0026authenticity_token=unfiltered\u0026feed_token=unfiltered\u0026... # Out: /foo?private_token=[FILTERED]\u0026authenticity_token=[FILTERED]\u0026feed_token=unfiltered\u0026... map $gitlab_ssl_temp_request_uri_1 $gitlab_ssl_temp_request_uri_2 { default $gitlab_ssl_temp_request_uri_1; ~(?i)^(?\u003cstart\u003e.*)(?\u003ctemp\u003e[\\?\u0026]authenticity[\\-_]token)=[^\u0026]*(?\u003crest\u003e.*)$ \"$start$temp=[FILTERED]$rest\"; } ## Remove feed_token from the request URI # In: /foo?private_token=[FILTERED]\u0026authenticity_token=[FILTERED]\u0026feed_token=unfiltered\u0026... # Out: /foo?private_token=[FILTERED]\u0026authenticity_token=[FILTERED]\u0026feed_token=[FILTERED]\u0026... map $gitlab_ssl_temp_request_uri_2 $gitlab_ssl_filtered_request_uri { default $gitlab_ssl_temp_request_uri_2; ~(?i)^(?\u003cs","date":"2023-08-22","objectID":"/gitLab/:6:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" RunnerRunner用于接收和执行GitLab的CI/CD作业的进程 ","date":"2023-08-22","objectID":"/gitLab/:7:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" yum 安装 添加 yum 源 [root@localhost ~]# curl -L \"https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh\" -s -o gitLabRunnerYUm.sh [root@localhost ~]# bash gitLabRunnerYUm.sh Detected operating system as centos/7. Checking for curl... ... 安装 [root@localhost ~]# yum install -y gitlab-runner Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile ... 命令行工具","date":"2023-08-22","objectID":"/gitLab/:8:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" gitlab-rakegitlab rake命令使用Rake管理常见操作 # 常见选项 -T, --tasks [PATTERN] # 输出可操作的任务说明，与 PATTERN -v, --verbose # 日志传递到标准输出 查看gitlab-rake能执行的操作 # Omnibus 与 helm 安装 gitlab-rake -vT # 源码安装 git -H bundle exec rake -vT RAILS_ENV=production ERROR [root@localhost ~]# gitlab-ctl reconfigure ... Error executing action `create` on resource 'group[Webserver user and group]' ... [2023-08-22T17:28:47+08:00] ERROR: Running exception handlers There was an error running gitlab-ctl reconfigure: account[Webserver user and group] (gitlab::web-server line 27) had an error: Mixlib::ShellOut::ShellCommandFailed: group[Webserver user and group] (gitlab::web-server line 40) had an error: Mixlib::ShellOut::ShellCommandFailed: Expected process to exit with [0], but received '3' ---- Begin output of [\"gpasswd\", \"-a\", \"nginx\", \"gitlab-www\"] ---- STDOUT: STDERR: gpasswd: user 'nginx' does not exist ---- End output of [\"gpasswd\", \"-a\", \"nginx\", \"gitlab-www\"] ---- Ran [\"gpasswd\", \"-a\", \"nginx\", \"gitlab-www\"] returned 3 原因：缺少web_server指定的用户与组 web_server['external_users'] = ['nginx'] 解决 [root@localhost ~]# useradd nginx ","date":"2023-08-22","objectID":"/gitLab/:9:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["gitlab"],"content":" fatal: protocol error: bad line length character: This 信息： PS C:\\Users\\xiaosi\\note\u003e git push origin fatal: protocol error: bad line length character: This 解决方法 # https://www.jianshu.com/p/c3420680043c [root@localhost ~]# usermod -s /bin/bash git ","date":"2023-08-22","objectID":"/gitLab/:10:0","tags":["git","gitlab"],"title":"gitlab","uri":"/gitLab/"},{"categories":["k8s"],"content":" 运行环境： 内容来自以下文档： k8s 官方文档：Kubernetes 系统组件指标 k8s 官方文档：资源监控工具 vivo 互联网容器团队 - Han Rucheng：vivo 容器集群监控系统优化之道 ","date":"2023-08-17","objectID":"/k8sMertisc/:0:0","tags":[null],"title":"k8s 观测","uri":"/k8sMertisc/"},{"categories":["aws"],"content":" 运行环境： 内容来自以下文档： s3 命令行参数 列出 S3 存储桶 [root@localhost ~]# aws s3 ls --region \"us-east-1\" --profile \"yh-xiaosi\" 2023-06-06 17:03:58 aws-controltower-logs-223665515173-us-east-1 2023-06-06 17:03:34 aws-controltower-s3-access-logs-223665515173-us-east-1 2023-05-15 19:08:32 yuhai-aws-cloud-formation ","date":"2023-08-15","objectID":"/awsS3/:0:0","tags":["aws","s3"],"title":"s3 - AWS 对象存储服务","uri":"/awsS3/"},{"categories":["linux"],"content":" 运行环境： centos: 7 centos: 8 Rocky Linux 8.5 内容来自以下文档： systemd介绍 systemd文档主页 systemd官网 systemd项目帮助手册索引 systemd-github 服务单元配置 # 说明文档：https://www.freedesktop.org/software/systemd/man/systemd.service.html [Service] ... ","date":"2023-08-05","objectID":"/linuxSystemdService/:0:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" Type # https://www.freedesktop.org/software/systemd/man/systemd.service.html#Type= Type：表示进程启动类型，有以下值： simple: 表示服务的主进程在 ExecStart 中定义的命令或程序上运行二进制文件，systemd 不会监控该进程的状态，且认为服务启动成功。这适用于常驻后台运行的服务或简单的一次性任务。如果指定了 ExecStart= 但 Type= 和 BusName= 均未指定，则为默认值 exec: 和 simple 类似，但会延迟启动，直到子进程创建之后成功后才继续启动后续 单元 forking: 守护进程方式支行。由子进程创建，当启动完成并设置所有通信通道时。 父进程退出，子进程转入后台 父进程退出后 systemd 将继续启动后续单元 oneshot: 执行完命令后直接退出。非常适合一次性任务 dbus notify idle ","date":"2023-08-05","objectID":"/linuxSystemdService/:1:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" PIDFile # https://www.freedesktop.org/software/systemd/man/systemd.service.html#PIDFile= # PID文件位置。notify或simple方式启动的进程不需要该配置确定PID # 示例：指定 nginx PID文件位置 PIDFile=/usr/local/nginx/logs/nginx.pid ","date":"2023-08-05","objectID":"/linuxSystemdService/:2:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" ExecStart # systemctl start ... # 启动服务的操作，可以的多少该指令，会按顺序串行执行 # 说明文档：https://www.freedesktop.org/software/systemd/man/systemd.service.html#ExecStart= ExecStart=/usr/local/nginx/sbin/nginx ","date":"2023-08-05","objectID":"/linuxSystemdService/:3:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" ExecStartPre与ExecStartPost # 在ExecStart之前执行的命令，与ExecStart用法相同 ExecStartPre=/usr/bin/rm -f /usr/local/nginx/logs/nginx.pid ExecStartPre=/usr/local/nginx/sbin/nginx -t # 在ExecStart之后执行的命令，与ExecStart用法相同 ","date":"2023-08-05","objectID":"/linuxSystemdService/:4:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" ExecReload # https://www.freedesktop.org/software/systemd/man/systemd.service.html#ExecReload= # systemctl reload ... # 重载配置文件，与ExecStart用法相同 ExecReload=/usr/local/nginx/sbin/nginx -s reload ","date":"2023-08-05","objectID":"/linuxSystemdService/:5:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" ExecStop # https://www.freedesktop.org/software/systemd/man/systemd.service.html#ExecStop= # 执行 systemctl stop ... 的操作 # 停止服务的指令，与ExecStart用法相同 ","date":"2023-08-05","objectID":"/linuxSystemdService/:6:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" ExecStopPost # https://www.freedesktop.org/software/systemd/man/systemd.service.html#ExecStop= # ExecStop 之后使用的命令，与ExecStart用法相同 ","date":"2023-08-05","objectID":"/linuxSystemdService/:7:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" TimeoutStopSec # https://www.freedesktop.org/software/systemd/man/systemd.service.html#TimeoutStopSec= # 1。每个 ExecStop=命令超时时间。如果其中任何一个超时，后续ExecStop=命令将被跳 # ，服务将被终止SIGTERM # 2. 如果未ExecStop= 指定命令，则服务SIGTERM立即获取 ","date":"2023-08-05","objectID":"/linuxSystemdService/:8:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" PrivateTmp # 布尔值： # - 如果为 true，则为已执行的进程设置一个新的文件系统命名空间，并在其中挂载私有的 # /tmp/ 和 /var/tmp/ 目录， # 这些目录不被命名空间外的进程共享。 这对于保护对进程临时文件的访问很有用，但 # 无法通过 /tmp/ 或 /var/tmp/ 在进程之间进行共享。 # 服务停止后，服务在这些目录中创建的所有临时文件都将被删除 # - false: 默认值 ","date":"2023-08-05","objectID":"/linuxSystemdService/:9:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" 示例","date":"2023-08-05","objectID":"/linuxSystemdService/:10:0","tags":["linux","systemd","systemd.service"],"title":"systemd.service - systemd 服务单元","uri":"/linuxSystemdService/"},{"categories":["linux"],"content":" 运行环境： tar: 1.26 内容来自以下文档： jaywcjlove：Linux Command $ info tar -A, --catenate, --concatenate # 追加 tar 文件至归档 -c, --create # 创建一个新归档 -d, --diff, --compare # 找出归档和文件系统的差异 --delete # 从归档(非磁带！)中删除 -r, --append # 追加文件至归档结尾 -t, --list # 列出归档内容 --test-label # 测试归档卷标并退出 -u, --update # 仅追加比归档中副本更新的文件 -x, --extract, --get # # 从归档中解出文件 # # 操作修饰符: --check-device # 当创建增量归档时检查设备号(默认) -g, --listed-incremental=FILE # 处理新式的 GNU 格式的增量备份 -G, --incremental # 处理老式的 GNU 格式的增量备份 --ignore-failed-read # 当遇上不可读文件时不要以非零值退出 --level=NUMBER # 所创建的增量列表归档的输出级别 -n, --seek # 归档可检索 --no-check-device # 当创建增量归档时不要检查设备号 --no-seek # 归档不可检索 --occurrence[=NUMBER] # 仅处理归档中每个文件的第 NUMBER # 个事件；仅当与以下子命令 --delete, --diff, --extract # 或是 --list # 中的一个联合使用时，此选项才有效。而且不管文件列表是以命令行形式给出或是通过 -T # 选项指定的；NUMBER 值默认为 1 --sparse-version=MAJOR[.MINOR] # 设置所用的离散格式版本(隐含 --sparse) -S, --sparse # 高效处理离散文件 # 重写控制: -k, --keep-old-files don't replace existing files when extracting, treat them as errors --keep-directory-symlink preserve existing symlinks to directories when extracting --keep-newer-files # 不要替换比归档中副本更新的已存在的文件 --no-overwrite-dir # 保留已存在目录的元数据 --overwrite # 解压时重写存在的文件 --overwrite-dir # 解压时重写已存在目录的元数据(默认) --recursive-unlink # 解压目录之前先清除目录层次 --remove-files # 在添加文件至归档后删除它们 --skip-old-files don't replace existing files when extracting, silently skip over them -U, --unlink-first # 在解压要重写的文件之前先删除它们 -W, --verify # 在写入以后尝试校验归档 # 选择输出流: --ignore-command-error # 忽略子进程的退出代码 --no-ignore-command-error # 将子进程的非零退出代码认为发生错误 -O, --to-stdout # 解压文件至标准输出 --to-command=COMMAND # 将解压的文件通过管道传送至另一个程序 # 操作文件属性: --atime-preserve[=METHOD] # 在输出的文件上保留访问时间，要么通过在读取(默认 METHOD= # ‘replace’)后还原时间，要不就不要在第一次(METHOD=‘system’)设置时间 --delay-directory-restore # 直到解压结束才设置修改时间和所解目录的权限 --group= # 名称 强制将 NAME # 作为所添加的文件的组所有者 --mode=CHANGES # 强制将所添加的文件(符号)更改为权限 CHANGES --mtime=DATE-OR-FILE # 从 DATE-OR-FILE 中为添加的文件设置 mtime -m, --touch # 不要解压文件的修改时间 --no-delay-directory-restore # 取消 --delay-directory-restore 选项的效果 --no-same-owner # 将文件解压为您所有(普通用户默认此项) --no-same-permissions # 从归档中解压权限时使用用户的掩码位(默认为普通用户服务) --numeric-owner # 总是以数字代表用户/组的名称 --owner= # 名称 强制将 NAME # 作为所添加的文件的所有者 -p, --preserve-permissions, --same-permissions # 解压文件权限信息(默认只为超级用户服务) --preserve # 与 -p 和 -s 一样 --same-owner # 尝试解压时保持所有者关系一致(超级用户默认此项) -s, --preserve-order, --same-order member arguments are listed in the same order as the files in the archive Handling of extended file attributes: --acls Enable the POSIX ACLs support --no-acls Disable the POSIX ACLs support --no-selinux Disable the SELinux context support --no-xattrs Disable extended attributes support --selinux Enable the SELinux context support --xattrs Enable extended attributes support --xattrs-exclude=MASK specify the exclude pattern for xattr keys --xattrs-include=MASK specify the include pattern for xattr keys # 设备选择和切换: -f, --file=ARCHIVE # 使用归档文件或 ARCHIVE 设备。参数是最后一个参数，后面只能接档案名 --force-local # 即使归档文件存在副本还是把它认为是本地归档 -F, --info-script= # 名称, --new-volume-script=名称 # 在每卷磁带最后运行脚本(隐含 -M) -L, --tape-length=NUMBER # 写入 NUMBER × 1024 字节后更换磁带 -M, --multi-volume # 创建/列出/解压多卷归档文件 --rmt-command=COMMAND # 使用指定的 rmt COMMAND 代替 rmt --rsh-command=COMMAND # 使用远程 COMMAND 代替 rsh --volno-file=FILE # 使用/更新 FILE 中的卷数 # 设备分块: -b, --blocking-factor=BLOCKS # 每个记录 BLOCKS x 512 字节 -B, --read-full-records # 读取时重新分块(只对 4.2BSD 管道有效) -i, --ignore-zeros # 忽略归档中的零字节块(即文件结尾) --record-size=NUMBER # 每个记录的字节数 NUMBER，乘以 512 # 选择归档格式: -H, --format=FORMAT # 创建指定格式的归档 FORMAT # 是以下格式中的一种: gnu GNU tar 1.13.x # 格式 oldgnu GNU # 格式 as per tar \u003c= 1.12 pax POSIX 1003.1-2001 (pax) # 格式 posix # 等同于 pax ustar POSIX 1003.1-1988 (ustar) # 格式 v7 old V7 tar # 格式 --old-archive, --portability # 等同于 --format=v7 --pax-option= # 关键字[[:]=值][,关键字[[:]=值]]... # 控制 pax 关键字 --posix # 等同于 --format=posix -V, --label=TEXT # 创建带有卷名 TEXT # 的归档；在列出/解压时，使用 TEXT # 作为卷名的模式串 # 压缩选项: -a, --auto-compress # 使用归档后缀名来决定压缩程序 -I, --use-compress-program=PROG # 通过 PROG 过滤(必须是能接受 -d # 选项的程序) -j, --bzip2 # 通过 bzip2 过滤归档 -J, --xz # 通过 xz 过滤归档 --lzip # 通过 lzip 过滤归档 --lzma # 通过 lzma 过滤归档","date":"2023-08-05","objectID":"/linuxCmdTar/:0:0","tags":["linux","命令","tar"],"title":"tar - 将许多文件一起保存到单个磁带或磁盘存档中，并且可以从存档中恢复单个文件","uri":"/linuxCmdTar/"},{"categories":["linux"],"content":" tar: Removing leading ‘/’ from member names 原因：该提示不会影响最终效果。tar 命令默认相对路径，使用绝对路径时会有该提示 解决：使用tar -P ","date":"2023-08-05","objectID":"/linuxCmdTar/:1:0","tags":["linux","命令","tar"],"title":"tar - 将许多文件一起保存到单个磁带或磁盘存档中，并且可以从存档中恢复单个文件","uri":"/linuxCmdTar/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： systemd.timer 帮助手册 阮一峰的网络日志：Systemd 定时器教程 滴水可藏海：Docker初识：the input device is not a TTY 时间单位支持以下时间单位 微秒：usec, us, μs 毫秒：msec, ms 秒：seconds, second, sec, s 缺省值 分：minutes, minute, min, m 时：hours, hour, hr, h 天：days, day, d 周：weeks, week, w 月：months, month, M (defined as 30.44 days) 年：years, year, y (defined as 365.25 days) 2 h 2hours 48hr 1y 12month 55s500ms 300ms20s 5day 以下是2012-11-23 18:15:22，时区为 UTC+8 Fri 2012-11-23 11:12:13 → Fri 2012-11-23 11:12:13 2012-11-23 11:12:13 → Fri 2012-11-23 11:12:13 2012-11-23 11:12:13 UTC → Fri 2012-11-23 19:12:13 2012-11-23T11:12:13Z → Fri 2012-11-23 19:12:13 2012-11-23T11:12+02:00 → Fri 2012-11-23 17:12:00 2012-11-23 → Fri 2012-11-23 00:00:00 12-11-23 → Fri 2012-11-23 00:00:00 11:12:13 → Fri 2012-11-23 11:12:13 11:12 → Fri 2012-11-23 11:12:00 now → Fri 2012-11-23 18:15:22 today → Fri 2012-11-23 00:00:00 today UTC → Fri 2012-11-23 16:00:00 yesterday → Fri 2012-11-22 00:00:00 tomorrow → Fri 2012-11-24 00:00:00 tomorrow Pacific/Auckland → Thu 2012-11-23 19:00:00 +3h30min → Fri 2012-11-23 21:45:22 -5s → Fri 2012-11-23 18:15:17 11min ago → Fri 2012-11-23 18:04:22 @1395716396 → Tue 2014-03-25 03:59:56 日历表达式 minutely → *-*-* *:*:00 hourly → *-*-* *:00:00 daily → *-*-* 00:00:00 monthly → *-*-01 00:00:00 weekly → Mon *-*-* 00:00:00 yearly → *-01-01 00:00:00 quarterly → *-01,04,07,10-01 00:00:00 semiannually → *-01,07-01 00:00:00 Sat,Thu,Mon..Wed,Sat..Sun → Mon..Thu,Sat,Sun *-*-* 00:00:00 Mon,Sun 12-*-* 2,1:23 → Mon,Sun 2012-*-* 01,02:23:00 Wed *-1 → Wed *-*-01 00:00:00 Wed..Wed,Wed *-1 → Wed *-*-01 00:00:00 Wed, 17:48 → Wed *-*-* 17:48:00 Wed..Sat,Tue 12-10-15 1:2:3 → Tue..Sat 2012-10-15 01:02:03 *-*-7 0:0:0 → *-*-07 00:00:00 10-15 → *-10-15 00:00:00 monday *-12-* 17:00 → Mon *-12-* 17:00:00 Mon,Fri *-*-3,1,2 *:30:45 → Mon,Fri *-*-01,02,03 *:30:45 12,14,13,12:20,10,30 → *-*-* 12,13,14:10,20,30:00 12..14:10,20,30 → *-*-* 12..14:10,20,30:00 mon,fri *-1/2-1,3 *:30:45 → Mon,Fri *-01/2-01,03 *:30:45 03-05 08:05:40 → *-03-05 08:05:40 08:05:40 → *-*-* 08:05:40 05:40 → *-*-* 05:40:00 Sat,Sun 12-05 08:05:40 → Sat,Sun *-12-05 08:05:40 Sat,Sun 08:05:40 → Sat,Sun *-*-* 08:05:40 2003-03-05 05:40 → 2003-03-05 05:40:00 05:40:23.4200004/3.1700005 → *-*-* 05:40:23.420000/3.170001 2003-02..04-05 → 2003-02..04-05 00:00:00 2003-03-05 05:40 UTC → 2003-03-05 05:40:00 UTC 2003-03-05 → 2003-03-05 00:00:00 03-05 → *-03-05 00:00:00 hourly → *-*-* *:00:00 daily → *-*-* 00:00:00 daily UTC → *-*-* 00:00:00 UTC monthly → *-*-01 00:00:00 weekly → Mon *-*-* 00:00:00 weekly Pacific/Auckland → Mon *-*-* 00:00:00 Pacific/Auckland yearly → *-01-01 00:00:00 annually → *-01-01 00:00:00 *:2/3 → *-*-* *:02/3:00 timer 单元systemcd中的timer单元是一个定时任务，它在指定的时间内运行一个service单元。timer单元配置文件包含可选的[Unit]、[Install]部分与必选的[Timer] 部分 Timer 部分选项","date":"2023-08-03","objectID":"/linuxSystemdTimer/:0:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" OnActiveSecOnActiveSec 该定时器单元生效后，多少时间后触发 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:1:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" AccuracySec计时器精度，默认为一分钟 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:2:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" OnCalendar值为time表达式。有以下注意事项 受 AccuracySec 约束 可以指定多个，如果其中一个值为空，则之前的无效 依赖时间服务器 系统在睡眠状态并不会跳过任务，而是等待系统启动后触发 *-*-* 00:00:01 # 每天0点0分01秒 Weekly # 每周1凌晨0点0分0秒 Wed 2023-*-* # 2023年每周三 Mon..Fri # 周一到周五 2022-6,7,8-1,15 # 2022 年 6、7、8 月的 1 到 15 号 Mon..Fri *-08~04 # 任何年份 8 月末的倒数第四天，同时也须是周一到周五 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:3:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" OnBootSec系统启动后，多少时间开始执行任务 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:4:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" OnStartupSecSystemd 进程启动后，多少时间开始执行任务 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:5:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" OnUnitActiveSec该单元上次执行后，等多少时间再次执行 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:6:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" OnUnitInactiveSec定时器上次关闭后多少时间，再次执行 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:7:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" Unit真正要执行的任务，默认是同名的带有.service后缀的单元 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:8:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" Persistent如果设置了该字段，即使定时器到时没有启动，也会自动执行相应的单元 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:9:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" WakeSystem如果系统休眠，是否自动唤醒系统 示例","date":"2023-08-03","objectID":"/linuxSystemdTimer/:10:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" 每天凌晨执行一次服务 [root@localhost ~]# cat /usr/lib/systemd/system/nginx-long-cutting.timer [Unit] Description=每天凌晨启动nginx-long-cutting.service [Timer] OnCalendar=*-*-* 23:59:59 Persistent=true AccuracySec=1s Unit=nginx-long-cutting.service [Install] WantedBy=timers.target ERROR","date":"2023-08-03","objectID":"/linuxSystemdTimer/:11:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["linux"],"content":" the input device is not a TTY 描述：在使用定时器单元执行任务备份任务时出现以下错误 [root@localhost backup]# journalctl -u freshRssBackup.service ... Jan 29 10:54:28 localhost.localdomain bash[6682]: + docker container exec -it freshrss-db /usr/bin/pg_dump -U freshrss freshrss Jan 29 10:54:28 localhost.localdomain bash[6682]: the input device is not a TTY ... 解决：去掉docker container exec 命令-it参数 # 修改后 docker container exec freshrss-db /usr/bin/pg_dump -U freshrss freshrss 原因：定时任务不会分配交互式终端 ","date":"2023-08-03","objectID":"/linuxSystemdTimer/:12:0","tags":["systemd","定时器单元"],"title":"systemd.timer - 定时器单元","uri":"/linuxSystemdTimer/"},{"categories":["网络通信"],"content":" 运行环境： 内容来自以下文档： bysir：使用Certbot获取免费泛域名(通配符)证书 命令行方式","date":"2023-08-01","objectID":"/cerbotCreatesTls/:0:0","tags":["TLS","cerbot"],"title":"使用 cerbot 生成 TLS 证书","uri":"/cerbotCreatesTls/"},{"categories":["网络通信"],"content":" 安装 yum install -y certbot ","date":"2023-08-01","objectID":"/cerbotCreatesTls/:1:0","tags":["TLS","cerbot"],"title":"使用 cerbot 生成 TLS 证书","uri":"/cerbotCreatesTls/"},{"categories":["网络通信"],"content":" 使用为泛域名申请证书 执行以下命令 [root@localhost ~]# certbot certonly \\ --preferred-challenges dns \\ --manual -d *.xiaosi.host \\ --server https://acme-v02.api.letsencrypt.org/directory Saving debug log to /var/log/letsencrypt/letsencrypt.log Plugins selected: Authenticator manual, Installer None Starting new HTTPS connection (1): acme-v02.api.letsencrypt.org Requesting a certificate for *.xiaosi.host Performing the following challenges: dns-01 challenge for xiaosi.host - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Please deploy a DNS TXT record under the name _acme-challenge.xiaosi.host with the following value: -KIQDFp3Tr6PPUUc6KPiseBtFjiH2zPBZcOy8q5U0K8 Before continuing, verify the record is deployed. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 按照上述提示在域名服务器中解析一个TXT记录，等记录生效后回车继续 Press Enter to Continue Waiting for verification... Cleaning up challenges IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/xiaosi.host/fullchain.pem # 生成的证书链位置 Your key file has been saved at: /etc/letsencrypt/live/xiaosi.host/privkey.pem # 生成的密钥位置 Your certificate will expire on 2023-10-30. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run \"certbot renew\" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 使用 docker 方式从 docker certbot 可以拉取镜像 ","date":"2023-08-01","objectID":"/cerbotCreatesTls/:2:0","tags":["TLS","cerbot"],"title":"使用 cerbot 生成 TLS 证书","uri":"/cerbotCreatesTls/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： 官方文档：ssh-keygen 选项 -t dsa | ecdsa | ed25519 | rsa | rsa1 # 指定创建密钥的类型 -N new_passphrase # new_passphrase 为密钥指定密码，为空表示不设置密码 -f filename # 指定密钥路径与文件名，公钥为密钥文件名加.pub结尾 [root@localhost ssh]# ssh-keygen -t rsa -N \"\" -f /root/ssh/test [root@localhost ssh]# ll ... -rw-------. 1 root root 1679 Jul 23 12:48 test -rw-r--r--. 1 root root 408 Jul 23 12:48 test.pub ","date":"2023-07-23","objectID":"/cmdSsh-keygen/:0:0","tags":["linux","windows","命令","ssh-keygen"],"title":"ssh-keygen — OpenSSH 身份验证密钥实用程序","uri":"/cmdSsh-keygen/"},{"categories":["linux"],"content":" 运行环境： sysstat: 10.1.5 内容来自以下文档： # man sar | cat 网络相关选项 -n { keyword [,...] | ALL } # keyword 表示关键字，多个关键字使用逗号分开，有以下关键字 # DEV, EDEV, NFS, NFSD, SOCK, IP, EIP, ICMP, EICMP, TCP, ETCP, UDP, SOCK6, IP6, EIP6, ICMP6, EICMP6, UDP6. # TCP 关键字查看 TCPv4 的统计信息，该信息来 sadc -S SNMP 命令 # TCP 关键字输出有以下字段，尾部括号中表示 sadc -S SNMP 输出字段 active/s # 每秒TCP连接从CLOSED状态直接转换到SYN-SENT状态的次数(tcpActiveOpens) passive/s # TCP连接每秒从LISTEN状态直接转换到SYN-RCVD状态的次数(tcpPassiveOpens]) iseg/s # 每秒接收到的报文段总数，包括错误接收的报文段数(tcpInSegs) oseg/s # 每秒发送的报文段总数，包括当前连接上的报文段，但不包括只包含重传字节的报文段(tcpOutSegs) 主动和被动计数通常可用于粗略测量服务器负载：新接受的连接数（被动）和下游连接数（主动）。将主动视为出站，将被动视为入站可能会有所帮助，但这并不完全正确（例如，考虑本地主机到本地主机的连接）。重传是网络或服务器问题的迹象；它可能是一个不可靠的网络或者可能是由于服务器过载并丢失数据包。 ","date":"2023-07-22","objectID":"/linuxCmdSar/:0:0","tags":["linux","命令","sar"],"title":"sar —收集、报告或保存系统活动信息","uri":"/linuxCmdSar/"},{"categories":["linux"],"content":" 运行环境： procps-ng: 3.3.10 内容来自以下文档： Help! Linux ate my RAM! ","date":"2023-07-22","objectID":"/linuxCmdFree/:0:0","tags":["linux","命令","free"],"title":"free - 显示系统中空闲和已使用内存的数量","uri":"/linuxCmdFree/"},{"categories":["linux"],"content":" free 命令查看内存使用情况free 命令是由 procps 包提供，因此也是读取 /proc/ 目录下的信息 # 外部命令 使用方式：type [options] 常见选项： --help 查看帮助信息 -V, --version 查看版本 -h, --human 以易读方式显示（1024 转换） --si 以 1000 转换单位 -t, --total 显示物理内存和交换内存总和 -s N, --seconds N 每隔 N 秒查看一次 -c N, --count N 执行 N 次退出 -l, --lohi 显示低内存（64 bit 是用户空间）和高内存（64 bit 是内核空间）信息 -b 以Byte为单位显示内存使用情况。 -k 以KB为单位显示内存使用情况。 -m 以MB为单位显示内存使用情况。 -g 以GB为单位显示内存使用情况。 -o 不显示缓冲区调节列。 示例：查看内存使用情况 [root@centos7 ~]# free -hlt total used free shared buff/cache available Mem: 3.7G 267M 3.0G 11M 388M 3.2G Low: 3.7G 656M 3.0G High: 0B 0B 0B Swap: 2.0G 0B 2.0G Total: 5.7G 267M 5.0G 上述示例中出现的关键词： Men 行 ：物理内存 Low 行 ：内存最低处，即用户空间部分（应该是物理内存，不确定） High 行：内存最高处，即内核空间部分（应该是物理内存，不确定） Swap 行：虚拟内存，即交换分区 total 行：总量，物理内存和交换分区总量 total 列：总量，对应物理内存或虚拟内存总量 used 列：已使用内存，包含共享内存(shared 列) free 列：未使用内存 shared 列：共享内存 buff/cache 列：缓存和缓冲区的大小 available 列：新进程可用内存，包含可回收的缓存 ","date":"2023-07-22","objectID":"/linuxCmdFree/:1:0","tags":["linux","命令","free"],"title":"free - 显示系统中空闲和已使用内存的数量","uri":"/linuxCmdFree/"},{"categories":["linux"],"content":" 运行环境： sysstat: 10.1.5 内容来自以下文档： Netflix Technology Blog：60000 毫秒 Linux 性能分析 # man mpstat | cat pidstat [root@localhost ~]# dnf -y install sysstat ... 如果想对某个进程进行全面具体的追踪，没有什么比 pidstat 更合适的了——栈空间、缺页情况、主被动切换等信息尽收眼底。 pidstat [ -d ] [ -h ] [ -I ] [ -l ] [ -r ] [ -s ] [ -t ] [ -U [ username ] ] [ -u ] [ -V ] [ -w ] [ -C comm ] [ -p { pid [,...] | SELF | ALL } ] [ -T { TASK | CHILD | ALL } ] [ interval [ count ] ] -t: 可以将进程中各个线程的详细信息罗列出来 -r: 显示缺页错误和内存使用状况，缺页错误是程序需要访问映射在虚拟内存空间中但是还尚未被加载到物理内存中的一个分页，缺页错误两个主要类型是 - minflt/s 指的 minor faults，当需要访问的物理页面因为某些原因(比如共享页面、缓存机制等)已经存在于物理内存中了，只是在当前进程的页表中没有引用，MMU 只需要设置对应的 entry 就可以了，这个代价是相当小的 - majflt/s 指的 major faults，MMU 需要在当前可用物理内存中申请一块空闲的物理页面(如果没有可用的空闲页面，则需要将别的物理页面切换到交换空间去以释放得到空闲物理页面)，然后从外部加载数据到该物理页面中，并设置好对应的 entry，这个代价是相当高的，和前者有几个数据级的差异 -s: 栈使用状况，包括 StkSize 为线程保留的栈空间，以及 StkRef 实际使用的栈空间。使用ulimit -s发现CentOS 6.x上面默认栈空间是10240K，而 CentOS 7.x、Ubuntu系列默认栈空间大小为8196K -u: CPU使用率情况 -w: 线程上下文切换的数目，还细分为cswch/s因为等待资源等因素导致的主动切换，以及nvcswch/s线程CPU时间导致的被动切换的统计 -C: 可以指定某个字符串，然后Command中如果包含这个字符串，那么该程序的信息就会被打印统计出来 -l: 可以显示完整的程序名和参数 # 查看 sshd 进程信息 [root@localhost ~]# pidstat -C \"sshd\" Linux 4.18.0-348.7.1.el8_5.x86_64 (localhost.localdomain) 01/23/2022 _x86_64_ (4 CPU) 12:49:37 AM UID PID %usr %system %guest %wait %CPU CPU Command 12:49:37 AM 0 1013 0.00 0.00 0.00 0.00 0.00 0 sshd 12:49:37 AM 0 1655 0.00 0.00 0.00 0.00 0.00 1 sshd 12:49:37 AM 0 1659 0.00 0.01 0.00 0.00 0.01 2 sshd ","date":"2023-07-22","objectID":"/linuxCmdPidstat/:0:0","tags":["linux","命令","pidstat"],"title":"pidstat - 报告Linux任务的统计信息","uri":"/linuxCmdPidstat/"},{"categories":["linux"],"content":" 运行环境： sysstat: 10.1.5 内容来自以下文档： Netflix Technology Blog：60000 毫秒 Linux 性能分析 # man mpstat | cat 安装 [root@localhost ~]# yum install -y sysstat ... 选项 mpstat [ -A ] [ -u ] [ -V ] [ -I { SUM | CPU | SCPU | ALL } ] [ -P { cpu [,...] | ON | ALL } ] [ interval [ count ] ] -P { cpu [,...] | ON | ALL } # CPU 指定 CPU 编号，ON 表示只看使用中的CPU，ALL 表示所有处理器 [ interval [ count ] ] # interval 表示查找间隔时间（秒）；count 表示查看次数，缺省为手动关闭 -u # 显示 CPU 使用率，是默认使用的。有以下字段 输出信息 [root@localhost ~]# mpstat -P ALL 1 Linux 3.10.0-1160.92.1.el7.x86_64 (localhost.localdomain) 07/22/2023 _x86_64_ (4 CPU) 01:12:16 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 01:12:17 PM all 0.50 0.00 0.25 0.00 0.00 0.00 0.25 0.00 0.00 99.00 01:12:17 PM 0 0.00 0.00 1.01 0.00 0.00 0.00 0.00 0.00 0.00 98.99 01:12:17 PM 1 0.00 0.00 0.00 0.00 0.00 0.00 1.00 0.00 0.00 99.00 01:12:17 PM 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 01:12:17 PM 3 1.01 0.00 1.01 0.00 0.00 0.00 0.00 0.00 0.00 97.98 ... Average: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle Average: all 0.34 0.00 0.34 0.00 0.00 0.00 0.08 0.00 0.00 99.25 Average: 0 0.34 0.00 0.34 0.00 0.00 0.00 0.00 0.00 0.00 99.33 Average: 1 0.34 0.00 0.67 0.00 0.00 0.00 0.34 0.00 0.00 98.66 Average: 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 Average: 3 0.67 0.00 0.33 0.00 0.00 0.00 0.33 0.00 0.00 98.66 01:23:24 PM # 当前时间 CPU # CPU 核心编号，all 表示总计 %usr # 用户空间级进程 CPU 利用率占比 %nice # nice 优先级进程 CPU 利用率占比 %sys # 内核空间级进程 CPU 利用率占比 %iowait # 磁盘 IO 时间占比 %irq # 硬中断时间占比 %soft # 软件中断时间占比 %steal # 虚拟 CPU 等待时间占比 %guest # 运行虚拟处理器所花费的时间百分比 %gnice # %idle # 空闲时间占比 Average: # 平均时间 ","date":"2023-07-22","objectID":"/linuxCmdMpstat/:0:0","tags":["linux","命令","mpstat"],"title":"mpstat - 报告处理器相关的统计信息","uri":"/linuxCmdMpstat/"},{"categories":["linux"],"content":" 运行环境： 内容来自以下文档： Netflix Technology Blog：60000 毫秒 Linux 性能分析 # man vmstat | cat vmstat 查看虚拟内存使用情况vmstat 命令用于查看虚拟内存使用情况，该命令读取以下文件 /proc/meminfo /proc/stat /proc/stat # 外部命令 使用方式：vmstat [options] [delay [count]] delay 表示间隔时间，每隔 delay 秒显示一次 count 表示显示次数，显示 count 次之后退出，默认只显示一次 常见选项： -V 查看 vmstat 版本 --help 查看帮助 -a, --active 查看活跃（active）和非活跃（inactive）的内存 -n, --one-header 只显示一次标题 -s, --stats 查看事件计数器和内存统计表 -d, --disk 查看磁盘相关信息 -D, --disk-sum 查看磁盘统计表 -p, --partition \u003cdevice\u003e 查看磁盘分区相关信息 -S, --unit 指定显示单位 k(1000换算)，K(1024换算，默认值)，m，M(1024换算) -t, --timestamp 查看时间戳 -w, --wide 宽度模式，排版比默认要宽 -f：显示从系统启动至今的fork数量 -m：显示slabinfo -s：显示内存相关统计信息及多种系统活动数量 显示字段vmstat 输出报告中第一行是字段说明，第二行是自上次重启以来的平均值，之后的信息才是间隔时间内的平均值 Procs（进程相关） r：运行进程数量，包含正在运行和等待运行的进程数量，但不包括磁盘I/O b: 阻塞等待I/O完成的进程数 Memory（内存相关） swpd：使用虚拟内存总量 free：空闲物理内存总量 buff：缓冲区内存总量 cache：缓存总量 inact：活动状态内存总量（-a选项） active：非活动状态总量（a选项） Swap（交换分区） si：磁盘到虚拟内存的总量 so：虚拟内存到磁盘的总量 IO（磁盘吞吐） bi：块设备发送的块（blocks/每秒）磁盘输出 bo：块设备接收的块（blocks/每秒）输入磁盘 System（系统） in：每秒系统中断的数量，包含预测时间（clock） cs：每秒进程切换导致上下文切换数量 CPU（CPU,百分比显示，是每秒占比 cpu 时间片比值） us：运行非内核代码时间 sy：运行内核代码时间 id：空闲时间，在内核 2.5.41 之前包含 IO （磁盘）等待时间 wa：等待 IO （磁盘）时间 st：偷取虚拟机时间（如果不为0 ，则把 cpu 调度分配给其他虚拟机，原本是给当前虚拟机） Reads(从磁盘读取，-d 选项) total：成功读取次数 merged：分组读取次数（1次 I/O） secrors：扇区读取成功次数 ms：读取使用时间（毫秒） Writes(写入磁盘，-d 选项) total：成功写入磁盘次数 merged：分组写入次数（1次 I/O） secrors：扇区写入成功次数 ms：写入使用时间 IO(读写事件,-d选项) sur：正则进行中 ms：话费时间(毫秒) -p 选项才有 reads：读取分区总数 read sectors：读取扇区总数 writes：写入分区总数 requested writes：写入分区请求总数 查看统计表 [root@c8 ~]# vmstat -sSM 3752 M total memory 345 M used memory 258 M active memory 269 M inactive memory 2977 M free memory 3 M buffer memory 426 M swap cache 2047 M total swap 0 M used swap 2047 M free swap 3076 non-nice user cpu ticks 289 nice user cpu ticks 4487 system cpu ticks 7046864 idle cpu ticks 2881 IO-wait cpu ticks 22384 IRQ cpu ticks 5114 softirq cpu ticks 0 stolen cpu ticks 349680 pages paged in 88174 pages paged out 0 pages swapped in 0 pages swapped out 1778266 interrupts 2481714 CPU context switches 1595741042 boot time 2243 forks 每隔 1 秒 查看一次，总共查看 2次 [root@c8 ~]# vmstat -SM 1 2 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 2977 3 426 0 0 5 1 25 35 0 0 99 0 0 0 0 0 2977 3 426 0 0 0 0 92 118 0 0 100 0 0 查看磁盘情况 [root@c8 ~]# vmstat -SM -d disk- ------------reads------------ ------------writes----------- -----IO------ total merged sectors ms total merged sectors ms cur sec sr0 0 0 0 0 0 0 0 0 0 0 sda 5949 47 699360 64835 2058 460 176354 15458 0 8 dm-0 5546 0 615718 64105 2470 0 176226 22163 0 7 dm-1 98 0 4440 65 0 0 0 0 0 0 ","date":"2023-07-22","objectID":"/linuxCmdVmstat/:0:0","tags":["linux"],"title":"vmstat — 报告虚拟内存统计信息","uri":"/linuxCmdVmstat/"},{"categories":["linux"],"content":" 运行环境： util-linux: 2.23.2 内容来自以下文档： Netflix Technology Blog：60000 毫秒 Linux 性能分析 [root@localhost ~]# dmesg | tail [166476.332505] IPv6: ADDRCONF(NETDEV_UP): eth0: link is not ready [166476.333562] IPv6: ADDRCONF(NETDEV_CHANGE): eth0: link becomes ready [166476.333590] IPv6: ADDRCONF(NETDEV_CHANGE): vethe04d374: link becomes ready [166476.333635] docker0: port 3(vethe04d374) entered blocking state [166476.333639] docker0: port 3(vethe04d374) entered forwarding state [166604.533549] docker0: port 3(vethe04d374) entered disabled state [166604.537597] docker0: port 3(vethe04d374) entered disabled state [166604.541208] device vethe04d374 left promiscuous mode [166604.541235] docker0: port 3(vethe04d374) entered disabled state [178471.874838] IPv6: ADDRCONF(NETDEV_UP): eth0: link is not ready ","date":"2023-07-22","objectID":"/linuxCmdDemsg/:0:0","tags":["linux","cmd","dmesg"],"title":"dmesg - 打印或控制内核环缓冲区","uri":"/linuxCmdDemsg/"},{"categories":["linux"],"content":" 运行环境： procps-ng: 3.3.10 内容来自以下文档： Netflix 技术博客：60000 毫秒 Linux 性能分析 # man uptime | cat # uptime -v [root@localhost ~]# man uptime | cat UPTIME(1) User Commands UPTIME(1) ... SYNOPSIS uptime [options] OPTIONS -p, --pretty # 查找系统已运行时间，效果为：up 6 days, 15 hours, 10 minutes -h, --help # 查看帮助信息 -s, --since # 查看系统启动时间，格式为： yyyy-mm-dd HH:MM:SS -V, --version # 查看版本 FILES /var/run/utmp # 从该文件中读取当前正在登录系统的用户信息 /proc # 从该目录中读取进程信息 [root@localhost ~]# uptime 10:46:33 up 6 days, 15:19, 2 users, load average: 0.09, 0.13, 0.13 平均负载(load average)表示在时间内(1 分钟、5 分钟、15 分钟)进程等待运行数量。在 Linux 系统上，这些数字包括想要在 CPU 上运行的进程，以及在不间断 I/O（通常是磁盘 I/O）中被阻止的进程。如果1分钟平均负载\u003e5分钟平均负载\u003e15分钟平均负载，那说明负载逐渐变高，正式检查问题的最佳时机。反之说负载情况逐渐得到改善。 ","date":"2023-07-22","objectID":"/linuxCmdUptime/:0:0","tags":["linux","cmd","uptime"],"title":"uptime - 查看系统运行时长","uri":"/linuxCmdUptime/"},{"categories":["容器"],"content":" 运行环境： docker-ce: 24.0.4 内容来自以下文档： docker 官方文档：命令行输出格式 输出格式Docker使用Go模板(Go templates)，可以用它来操纵某些命令(--format string选项)和日志驱动程序的输出格式。如 docker container ls --format [root@localhost ~]# docker container ls --help ... Aliases: docker container ls, docker container list, docker container ps, docker ps Options: --format string Format output using a custom template: 'table': Print output in table format with column headers (default) 'table TEMPLATE': Print output in table format using the given Go template 'json': Print in JSON format 'TEMPLATE': Print output using the given Go template. Refer to https://docs.docker.com/go/formatting/ for more information about formatting output with templates ... ","date":"2023-07-17","objectID":"/dockerCli/:0:0","tags":["容器","docker"],"title":"docker - Docker镜像和容器命令行接口","uri":"/dockerCli/"},{"categories":["容器"],"content":" 表格 名称 含义 .ID 容器ID .Image 镜像ID .Command 执行的命令 .CreatedAt 容器创建时间 .RunningFor 运行时长 .Ports 暴露的端口 .Status 容器状态 .Names 容器名称 .Label 分配给容器的所有标签 .Mounts 容器挂载的卷 .Networks 容器所用的网络名称 ","date":"2023-07-17","objectID":"/dockerCli/:1:0","tags":["容器","docker"],"title":"docker - Docker镜像和容器命令行接口","uri":"/dockerCli/"},{"categories":["容器"],"content":" 内容来自以下文档： docker compose github 地址 安装docker 从2.19已经加入到子命令（docker compose），如果没可以从 github 下载二进制文件 w[root@localhost ~]# get https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m) [root@localhost ~]# chmod +x docker-compose-Linux-x86_64 [root@localhost ~]# ./docker-compose-Linux-x86_64 version Docker Compose version v2.20.0 [root@localhost ~]# mv docker-compose-Linux-x86_64 /usr/bin/docker-compose ","date":"2023-07-17","objectID":"/dockerCompose/:0:0","tags":["docker","docker compose"],"title":"docker compose - 定义容器运行工具","uri":"/dockerCompose/"},{"categories":["容器"],"content":" 运行环境： docker-ce: 24.0.4 内容来自以下文档： docker 官方文档: dockerd 防火墙规则dockerd 命令行选项： --ip6tables # 自动添加 ip6tables 规则 --iptables # 自动添加 iptables 规则，默认值为 true /etc/docker/daemon.json 配置项： { ... \"iptables\": false, ... } 禁止 docker 添加防火墙规则会导致有以下问题： 使用 bridge 类型的容器将无法访问主机服务，需要手动添加防火墙规则 # 172.17.0.0/16 是网桥的IP段 firewall-cmd --add-rich-rule 'rule family=\"ipv4\" source address=\"172.17.0.0/16\" accept' \u0026\u0026 firewall-cmd --runtime-to-permanent ","date":"2023-07-15","objectID":"/dockerdConfig/:0:0","tags":["容器","docker"],"title":"dockerd 配置项","uri":"/dockerdConfig/"},{"categories":["prometheus"],"content":" 运行环境： centos: 7 内容来自以下文档： yunlzheng：prometheus-book kevinkrcai：一文带你了解 Prometheus configuration 我是阳明：Prometheus Relabeling 重新标记的使用 民工哥技术之路：构建企业级监控平台系列（十三）：Prometheus Server 配置详解 简介在Prometheus的架构设计中，Prometheus Server并不直接服务监控特定的目标，其主要任务负责数据的收集，存储并且对外提供数据查询支持。因此为了能够能够监控到某些东西，如主机的CPU使用率，我们需要使用到Exporter。Prometheus周期性的从Exporter暴露的HTTP服务地址（通常是/metrics）拉取监控样本数据。架构图如下： 安装","date":"2023-06-25","objectID":"/prometheus/:0:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 二进制文件 从官网下载二进制 [root@localhost ~]# wget -P /data/download/ https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz [root@localhost ~]# tar -zxf /data/download/prometheus-2.45.0.linux-amd64.tar.gz -C /data/prometheus [root@localhost ~]# cd /data/prometheus/ \u0026\u0026 ls console_libraries consoles LICENSE NOTICE prometheus prometheus.yml promtool 创建运行用户与组 [root@localhost prometheus]# useradd --no-create-home --shell /bin/false prometheus [root@localhost prometheus]# chown -R prometheus:prometheus /data/prometheus 创建 prometheus.service 文件，以守护进程方式运行 [root@localhost prometheus]# cat /etc/systemd/system/prometheus.service [Unit] Description=Prometheus Server After=network.target [Service] User=prometheus Group=prometheus Type=simple ExecStart=/data/prometheus/prometheus \\ --config.file=/data/prometheus/prometheus.yml \\ --storage.tsdb.path=/data/prometheus/data \\ --web.console.templates=/data/prometheus/consoles \\ --web.console.libraries=/data/prometheus/console_libraries [Install] WantedBy=multi-user.target [root@localhost prometheus]# systemctl daemon-reload [root@localhost prometheus]# systemctl start prometheus \u0026\u0026 systemctl status prometheus ● prometheus.service - Prometheus Server Loaded: loaded (/etc/systemd/system/prometheus.service; disabled; vendor preset: disabled) Active: active (running) since Sun 2023-09-03 16:30:17 CST; 7s ago Main PID: 19837 (prometheus) ... ","date":"2023-06-25","objectID":"/prometheus/:1:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" docker方式运行 [root@localhost prometheus]# cat docker-prometheus.sh docker container run -d \\ --name \"prometheus\" \\ -p 9090:9090 \\ -v /data/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \\ prom/prometheus:v2.49.1 \\ --config.file=/etc/prometheus/prometheus.yml \\ --storage.tsdb.retention.time 3d 命令行参数 [root@localhost prometheus]# ./prometheus --help usage: prometheus [\u003cflags\u003e] -h, --[no-]help # 查看帮助 --version # 显示版本信息 --config.file= # 指定运行配置文件 运行地址 --web.listen-address=“0.0.0.0:9090” # ui、api、telemetry监听地址信息 --web.config.file=\"\" # TLS或身份验证配置文件 --web.read-timeout=5m # 页面读取请求最大超时时间 --web.max-connections=512 # 同时访问Prometheus页面的最大连接数，默认为512 --web.external-url=\u003cURL\u003e # Prometheus对外提供的url(eg: Prometheus通过反向代理提供服务)。用于生成一个相对和绝对的链接返回给Prometheus本身。如果这个url有路径部分，它将用于Prometheus所有HTTP端点的前缀。如果省略了，则相关的url组件将自动派生。 --web.route-prefix=\u003cpath\u003e # Web端点内部路由的前缀。默认路径：web.external-url --web.user-assets=\u003cpath\u003e # 静态资源路径，可以在/user下找到 --web.enable-lifecycle # 通过HTTP请求启用关闭和重新加载 --web.enable-admin-api # 启用管理控制操作的api端点 --web.console.templates=\"consoles\" # 到控制台模板目录的路径，可以在consoles/目录下找到。 --web.console.libraries=\"console_libraries\" # 控制台库目录的路径 –web.page-title=”Prometheus时间序列采集和处理服务器” # Prometheus实例的文件标题。 --web.cors.origin=\".*\" # 正则表达式为CORS原点。它已完全锚定。例子:“https ?: / / (domain1 | domain2) \\。com” 存储 --storage.tsdb.path=\"data/\" # 数据存储的基本路径 --storage.tsdb.min-block-duration=2h # 在持久化之前数据块的最短保存期 --storage.tsdb.max-block-duration=\u003cduration\u003e # 在持久化之前数据块的最大保存期(默认为保存期的10%) --storage.tsdb.retention=STORAGE.TSDB.RETENTION # 样品保存的时间。此标志已被弃用，请使用\"--storage.tsdb.retention.time\" --storage.tsdb.retention.time=STORAGE.TSDB.RETENTION.TIME # 样品保存的时间，默认为15d。支持单位:y, w, d, h, m, s, ms。 --storage.tsdb.retention.size= # 存储的最大字节数。支持单位:B、KB、MB、GB、TB、PB、EB。 --storage.tsdb.no-lockfile # 不在数据目录中创建lockfile。 –storage.tsdb.allow-overlapping-blocks # 允许重叠块，从而支持垂直压缩和垂直查询合并。 –storage.tsdb.wal-compression # 压缩tsdb WAL。 –storage.remote.flush-deadline= # 关闭或重新加载配置时需要等待多长时间刷新样例。 –storage.remote.read-sample-limit=5e7 # 在单个查询中通过远程读接口返回的最大样本总数。0意味着没有限制。对于流响应类型，此限制将被忽略。 –storage.remote.read-concurrent-limit=10 # 并发远程读调用的最大数量。0意味着没有限制。 –storage.remote.read-max-bytes-in-frame=1048576 # 在编组前流化远程读取响应类型的单个帧中的最大字节数。请注意，客户端可能也有帧大小的限制。默认情况下为1MB。 –rules.alert.for-outage-tolerance=1h # 忍受Prometheus故障恢复“for”警报状态的最大时间。 --rules.alert.for-grace-period=10m # 警报和恢复“for”状态之间的最小持续时间。仅对配置的“for”时间大于宽限期的警报进行维护。 –rules.alert.resend-delay=1m # 在向Alertmanager重新发送警报之前等待的最短时。间。 --alertmanager.notification-queue-capacity=10000 # 等待报警通知队列的大小。 --alertmanager.timeout=10s # 发送警报到Alertmanager的超时时间。 --query.lookback-delta=5m # 允许在表达式求值期间检索度量值的delta差值。 --query.timeout=2m # 一个查询在终止之前可以执行的最长时间(如果超过2min，就会自动kill掉)。 --query.max-concurrency=20 # 并发执行的最大查询数，默认为20。 –query.max-samples=50000000 # 单个查询可以加载到内存中的最大样本数。注意，如果查询尝试将比这个更多的样本加载到内存中，那么查询将会失败，因此这也限制了查询可以返回的样本数量。 --enable-feature= # 逗号分隔要启用的功能名称，有效选项：agent、examplar-storage、expand-external-labels、memory--snapshot-on-shutdown、promql-at-modifier、promql-negative-offset、remote-write-reciver、extra-scrape-metrics、new-service-discovery-manager，详情请查看https://prometheus.io/docs/prometheus/latest/feature_flags/。 --log.level=info # 开启打印日志级别(debug,info,warn,error,fatal)。默认为info。 --log.format=logfmt # 日志消息的输出格式。其中一个:[logfmt, json]。 Prometheus 的本地存储不支持不符合 POSIX 标准的文件系统，因为可能会发生不可恢复的损坏。不支持 NFS 文件系统（包括 AWS 的 EFS）。NFS 可能符合 POSIX 标准，但大多数实现并非如此。为了可靠性，强烈建议使用本地文件系统。如果同时指定了时间和大小保留策略，则将使用先触发的触发器。过期块清理在后台进行。删除过期的块最多可能需要两个小时。块必须完全过期才能被删除。 Prometheus 的本地存储并不是为了持久的长期存储。本地存储由于某种原因而损坏，解决该问题的最佳策略是关闭 Prometheus，然后删除整个存储目录。 配置文件 https://prometheus.io/docs/prometheus/latest/configuration/configuration/ 配置文件是yml格式的文本，默认在以下目录，可以通过--config.file指定新的配置文件 二进制文件包：执行文件目录中的prometheus.yml 容器：/etc/prometheus/prometheus.yml 配置文件分为以下部分 global: 全局配置。做为其它配置项默认配置 scrape_config: 抓取目标服务地址 rule_files: 报警规则的文件 alerting: Alertmanager配置 remote_write: 远程写入功能相关的设置 remote_read: 远程读取相关功能的设置 ","date":"2023-06-25","objectID":"/prometheus/:2:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" global 配置 global: # 默认情况抓取目标的频率，默认1分钟 [ scrape_interval: \u003cduration\u003e | default = 1m ] # 抓取请求超时的时间，默认10S [ scrape_timeout: \u003cduration\u003e | default = 10s ] # 评估规则的频率，默认1分钟 [ evaluation_interval: \u003cduration\u003e | default = 1m ] # 外部系统标签用于区分prometheus服务实例 # 外部系统（federation、远程、storage、Alertmanager） external_labels: [ \u003clabelname\u003e: \u003clabelvalue\u003e ... ] # PromQL查询记录到的文件。重新加载配置将重新打开该文件。 [ query_log_file: \u003cstring\u003e ] ","date":"2023-06-25","objectID":"/prometheus/:3:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 目标组如何抓取组与目标组参数 scrape_configs: # 默认情况下，分配给临时度量的作业名称。 - job_name: \u003cjob_name\u003e # 从这项工作中抓取目标的频率。 [ scrape_interval: \u003cduration\u003e | default = \u003cglobal_config.scrape_interval\u003e ] # 此作业时的每次抓取超时时间 [ scrape_timeout: \u003cduration\u003e | default = \u003cglobal_config.scrape_timeout\u003e ] # 要从目标获取度量的HTTP资源路径 [ metrics_path: \u003cpath\u003e | default = /metrics ] # honor_labels主要用于解决prometheus server的label与exporter端用户自定义label冲突的问题。 # 为“true”，则通过保留标签来解决标签冲突值，并忽略冲突的服务器端标签。 # 为“false”，则通过重命名解决标签冲突，采集端标签将添加exported_前缀 [ honor_labels: \u003cboolean\u003e | default = false ] # 如果honor_timestamps设置为“true”，则将显示度量的时间戳由目标将被使用。 # 为“false”，则会显示度量的时间戳，将忽略由目标创建的。 [ honor_timestamps: \u003cboolean\u003e | default = true ] # 配置用于请求的协议方案。 [ scheme: \u003cscheme\u003e | default = http ] # 可选的HTTP URL参数 params: [ \u003cstring\u003e: [\u003cstring\u003e, ...] ] # 使用配置的用户名和密码，密码和密码文件是互斥的。 basic_auth: [ username: \u003cstring\u003e ] [ password: \u003csecret\u003e ] [ password_file: \u003cstring\u003e ] # 使用设置每个刮取请求的“Authorization”标头为配置的凭据。 authorization: # 设置请求的请求头身份验证类型。 [ type: \u003cstring\u003e | default: Bearer ] # 设置请求的凭据。这是和credentials_file相互排斥的 [ credentials: \u003csecret\u003e ] # 使用从中读取的凭据设置请求的凭据 [ credentials_file: \u003cfilename\u003e ] # 可选的OAuth 2.0配置。不能与基本授权或授权同时使用。 oauth2: [ \u003coauth2\u003e ] # 配置抓取请求是否遵循HTTP 3xx重定向。 [ follow_redirects: \u003cbool\u003e | default = true ] # 配置请求的TLS设置。 tls_config: [ \u003ctls_config\u003e ] # 可选的代理URL [ proxy_url: \u003cstring\u003e ] # 服务发现配置，以下只是部分值 # k8s 服务发现 kubernetes_sd_configs: # 静态目标发现 static_configs: ","date":"2023-06-25","objectID":"/prometheus/:4:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 静态目标发现配置 # 静态目标发现 static_configs: # 目标列表 targets: [ - '\u003chost\u003e[:prot]' ] # 指标附加的标签列表 labels: [ \u003clabelname\u003e: \u003clabelvalue\u003e ... ] ","date":"2023-06-25","objectID":"/prometheus/:5:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 基于文件内容的服务发现基于文件的服务发现方式，可以将target配置信息写入单独的JSON和YAML配置文件中，然后将这些配置文件添加到file_sd_configs配置项中，Prometheus server 会定期检测这些文件的变化，若发生变化，则会重新配置target信息。同时，Prometheus server也会定期全量加载这些配置文件中的target信息 scrape_configs: #此处定义了自动发现的采集任务名称，可以依据自己的业务定义多个自动发现任务 - job_name: 'file_ds' file_sd_configs: - files: - targets/*.json #采集文件路径 refresh_interval: 5m #自动发现间隔时间，默认5m ","date":"2023-06-25","objectID":"/prometheus/:6:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 标签重写Relabeling 是作为一系列转换步骤实现的，我们可以在 Prometheus 的配置文件中应用这些步骤来过滤或修改标记对象 发现的抓取目标（relabel_configs）：即实际抓取之前 抓取的单个样本（metric_relabel_configs）：即抓取后保存到时序数据库之前 发送给 Alertmanager 的报警（alert_relabel_configs） 写到远程存储的样本（write_relabel_configs） relabel_configs: - [ source_labels: '[' \u003clabelname\u003e [, ...] ']' ] [ separator: \u003cstring\u003e | default = ; ] [ target_label: \u003clabelname\u003e ] [ regex: \u003cregex\u003e | default = (.*) ] [ modulus: \u003cint\u003e ] [ replacement: \u003cstring\u003e | default = $1 ] [ action: \u003crelabel_action\u003e | default = replace ] source_labels 原标签列表，即被操作的标签列表 separator: source_labels 的分隔符，默认为; target_label: 目标标签，即操作后的标签 regex: RE2 正则表达式，用于触发修改的条件，默认值为(.*) modulus: 模数，串联的源标签哈希值的模，主要用于 Prometheus 水平分片 replacement: 用于替换的值 action: 执行操作，有： replace: 对满足regex的标签进行标签值替换 lowercase: uppercase: keep: 标签值与regex匹配，保留匹配的对象，删除不匹配对象 drop: 标签值与regex匹配，删除匹配的对象，保留不匹配对象 keepequal: dropequal: hashmod: labelmap: 标签名与regex匹配，把值复制/映射到replacement指定的标签中 labeldrop: labelkeep: 示例： 把 env 标签设置为 production action: replace replacement: production target_label: env 把端口替换为80 action: replace source_labels: [__address__] regex: ([^:]+)(?::\\d+)? # 第一个捕获组匹配的是 host，第二个匹配的是 port 端口。 replacement: \"$1:80\" target_label: __address__ relabel_configs 部分可以在抓取之前通过标签重写主机信息，可以使用以下变量 __address__: scrape_configs.job_name.static_configs.targets值 __scheme__: 协议，值为 http 或 https __metrics_path__: 抓取路径 __param_\u003cname\u003e: URL 参数名称\u003cname\u003e __meta_: 临时标签使用 __tpm 做为后缀 relabel_configs: # 以下列表都是可选的 - source_labels: # 匹配的标签值列表 target_label: # 被修改的标签 regex: # 值是 RE2 正则表达式，用于触发修改的条件，默认值为(.*) modulus: # replacement: # 修改后的值 action: # 修改方式，默认值为：replace action 指定修改方式，有以下方式（部分） replace: 如果 regex 条件满足，则修改 target_label 指定的标签值为 replacement 指定的值 drop: 删除 relabel_configs: - source_labels: [__address__] target_label: instance regex: (.*) - source_labels: [__address__] target_label: __address__ replacement: prometheus:9090 # 抓取频率设置 - source_labels: [__address__] target_label: __scrape_interval__ regex: (target1:9090) replacement: 10s # 目标主机1的抓取频率为10秒 - source_labels: [__address__] target_label: __scrape_interval__ regex: (target2:8080) replacement: 30s # 目标主机2的抓取频率为30秒 - source_labels: [__address__] target_label: __scrape_interval__ regex: (target3:9100) replacement: 15s # 目标主机3的抓取频率为15秒 # 身份验证设置 - source_labels: [__address__] target_label: __scheme__ regex: (target2:8080) replacement: https # 目标主机2使用HTTPS协议 # 请求路径和端口设置 - source_labels: [__address__] target_label: __metrics_path__ regex: (target1:9090) replacement: /metrics-path1 # 目标主机1的请求路径 - source_labels: [__address__] target_label: __metrics_path__ regex: (target2:8080) replacement: /metrics-path2 # 目标主机2的请求路径 - source_labels: [__address__] target_label: __metrics_path__ regex: (target3:9100) replacement: /metrics-path3 # 目标主机3的请求路径 - source_labels: [__address__] target_label: __address__ regex: (target2:8080) replacement: target2:8443 # 目标主机2的端口设置为8443 action: replace regex: (target3:9100) replacement: target3:9200 # 目标主机3的端口设置为9200 action: replace 指标指标格式如下 \u003cmetric name\u003e{\u003clabel name\u003e=\u003clabel value\u003e, ...} metric name: 指标表示特征，指标名称满足正则表达式：[a-zA-Z_:][a-zA-Z0-9_:]*，冒号（:）通常为用户自定义 label name: 标签表示不同维度，标签名满足正则表达式：[a-zA-Z_][a-zA-Z0-9_]*, 以__开头为prometheus自用的 label value: 标签值可以包含任何Unicode字符，如果值为空等效标签不存在 Prometheus 底层存储上其实并没有对指标做类型的区分，都是以时间序列的形式存储，但是为了方便用户的使用和理解不同监控指标之间的差异，定义了 4 种不同的指标类型： 计数器 counter: 只增不减，只有重置后归零 仪表盘 gauge: 动态变化的数据，如内存占用、CPU利用率 直方图 histogram: 是累计直方图，可以观察到指标在各个不同的区间范围的分布情况。 摘要 summary: 百分位数，可以直观的观察到样本的中位数，P90 和 P99。 PromQLPrometheus通过指标名称（metrics name）以及对应的一组标签（labelset）唯一定义一条时间序列。指标名称反映了监控样本的基本标识，而label则在这个基本特征上为采集到的数据提供了多种特征维度。用户可以基于这些特征维度过滤，聚合，统计从而产生新的计算后的一条时间序列。PromQL是Prometheus内置的数据查询语言，其提供对时间序列数据丰富的查询，聚合以及逻辑运算能力的支持。并且被广泛应用在Prometheus的日常应用当中，包括对数据查询、可视化、告警处理当中。语法格式如下： 查看指标名称所有时间序列 \u003cmetric name\u003e # 或 \u003cmetric name\u003e{} 根据指标标签过滤时间序列 # 指标之前使用逗号, 表示标签之间逻辑为和 \u003cmetric name\u003e{\u003clabel name\u003e!=\u003clabel value\u003e, ...} # 相等 \u003cmetric name\u003e{\u003clabel name\u003e=\u003clabel value\u003e, ...} # 不相等 \u003cmetric name\u003e{\u003clabel name\u003e!=\u003clabel value\u003e, ...} # 正则表达式相等 \u003cmetric name\u003e{\u003clabel name\u003e=~\u003clabel value\u003e, ...} # 正则表达式不相等 \u003cme","date":"2023-06-25","objectID":"/prometheus/:7:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 运算在PromQL操作符中优先级由高到低为： ^(幂运算) *(乘法), /(除法), %(求余) +(加法), -(减法) ==(相等), !=(不相等), \u003c=(大于等于), \u003c(大于), \u003e=(小于等于), \u003e(小于) and(逻辑和), unless(排除) or(逻辑或) 可以使用 bool 修饰符改变布尔运算符的行为，结果为true则返回1 http_requests_total \u003e bool 1000 ","date":"2023-06-25","objectID":"/prometheus/:8:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 向量匹配向量与向量之间进行运算操作时会基于默认的匹配规则：依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行运算，如果没找到匹配元素，则直接丢弃 一对一匹配模式会从操作符两边表达式获取的瞬时向量依次比较并找到唯一匹配(标签完全一致)的样本值。 vector1 \u003coperator\u003e vector2 # vector 是指标向量 # \u003cbin-op\u003e 二元操作运算符 # ignoring 表示匹配时忽略的指标列表，用逗号分隔 \u003cvector expr\u003e \u003cbin-op\u003e ignoring(\u003clabel list\u003e) \u003cvector expr\u003e # on 表示只配置某些标签 \u003cvector expr\u003e \u003cbin-op\u003e on(\u003clabel list\u003e) \u003cvector expr\u003e 多对一和一对多两种匹配模式指的是“一”侧的每一个向量元素可以与\"多\"侧的多个元素匹配的情况。在这种情况下，必须使用group修饰符：group_left或者group_right来确定哪一个向量具有更高的基数（充当“多”的角色） # group_left 表示对左侧向量按照指定的标签列表进行聚合操作 \u003cvector expr\u003e \u003cbin-op\u003e ignoring(\u003clabel list\u003e) group_left(\u003clabel list\u003e) \u003cvector expr\u003e # group_right 表示对右侧向量按照指定的标签列表进行聚合操作 \u003cvector expr\u003e \u003cbin-op\u003e ignoring(\u003clabel list\u003e) group_right(\u003clabel list\u003e) \u003cvector expr\u003e \u003cvector expr\u003e \u003cbin-op\u003e on(\u003clabel list\u003e) group_left(\u003clabel list\u003e) \u003cvector expr\u003e \u003cvector expr\u003e \u003cbin-op\u003e on(\u003clabel list\u003e) group_right(\u003clabel list\u003e) \u003cvector expr\u003e 一对多示例 # 库内容 A={metric=\"temperature\", location=\"room1\", sensor=\"sensor1\", value=\"25\"} B={metric=\"temperature\", location=\"room1\", sensor=\"sensor2\", value=\"22\"} C={metric=\"temperature\", location=\"room2\", sensor=\"sensor1\", value=\"23\"} # 执行的 PromQL： # 指标 A 与 B 进行加法运算 # 忽略 sensor 标签 # 根据左侧 A 指标的 location 标签值聚合 A + ignoring(sensor) group_left(location) B # 结果 result={metric=\"temperature\", location=\"room1\", value=\"47\"} ","date":"2023-06-25","objectID":"/prometheus/:9:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 函数 https://prometheus.io/docs/prometheus/latest/querying/functions/#increase job: 标签值为scrape_configs.job_name值，即 job 名称 instance: 标签值为 scrape_configs.job_name.static_configs.targets值，即目标地址及其端口 UP{}: 如果能够连接目标则值为1，否则为0 scrape_duration_seconds{}: 收集耗时 scrape_samples_scraped{}: job收集的样本数量 scrape_series_added{}: 以下函数作用域瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个新的时间序列。 sum (求和) min (最小值) max (最大值) avg (平均值) stddev (标准差) stdvar (标准方差) count (计数) count_values (对value进行计数) bottomk (后n条时序) topk (前n条时序) quantile (分位数) 使用聚合操作的语法如下： \u003caggr-op\u003e([parameter,] \u003cvector expression\u003e) [without|by (\u003clabel list\u003e)] # aggr-op: 聚合操作函数 # parameter: 聚合操作函数参数 # vector expression: 指标名 # without: 所有标签 # by: 指定标签 指标增长差： increase(v range-vector)函数其中参数v是一个区间向量，increase函数获取区间向量中的第一个后最后一个样本并返回其增长量 rate(v range-vector)，在指定时间区间内，计算每秒数值差 irate(v range-vector) 同上，但能反应出的是瞬时增长率 predict_linear(v range-vector, t scalar)根据当前样本时间差推算未来时间内的值 示例：查看 CPU 使用率 sum by(instance) (irate(node_cpu_seconds_total{instance=\"103.106.246.112:9100\",job=\"node\", mode!=\"idle\"}[10m15s])) / on(instance) group_left sum by (instance)((irate(node_cpu_seconds_total{instance=\"103.106.246.112:9100\",job=\"node\"}[10m15s]))) # sum by(instance) (irate(node_cpu_seconds_total{instance=\"103.106.246.112:9100\",job=\"node\", mode!=\"idle\"}[10m15s])) # 计算出所有 CPU 在 10m15s 内空闲时间总和 # sum 根据 instance 标签计算总值 # node_cpu_seconds_total 指标是 Counter 类型，因此要使用 irate 查看 # on(instance) group_left 表示以左边语句中的 instance 标签(主机地址)进行匹配 # sum by (instance) ((irate(node_cpu_seconds_total{instance=\"103.106.246.112:9100\",job=\"node\"}[10m15s]))) # 以同样的方式算出CPU 在 10m15s 内CPU使用时间总和 # *100 是把单位换成 % 比 示例：查看目标机器 CPU 数量 # 计算出机器CPU 数量 count(count(node_cpu_seconds_total{instance=\"103.106.246.112:9100\",job=\"node\"}) by (cpu)) 示例：查看目标机器最近 5 分钟 CPU 使用率 # cpu 5 分钟负载 / cpu 核心数 avg(node_load5{instance=\"103.106.246.112:9100\",job=\"node\"}) / count(count(node_cpu_seconds_total{instance=\"103.106.246.112:9100\",job=\"node\"}) by (cpu)) * 100 示例：查看目标机器内存使用率 # 100 - ((node_memory_MemAvailable_bytes{instance=\"103.106.246.112:9100\",job=\"node\"}) / node_memory_MemTotal_bytes{instance=\"103.106.246.112:9100\",job=\"node\"}) * 100 ","date":"2023-06-25","objectID":"/prometheus/:10:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" rate()rate 函数可以用来求指标的平均变化速率（rate函数=时间区间前后两个点的差/时间范围） ","date":"2023-06-25","objectID":"/prometheus/:10:1","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" irate()irate 函数可以求出来的就是瞬时变化率（时间区间内最后两个样本点的差/最后两个样本点的时间差） Exporter规范所有的Exporter程序都需要按照Prometheus的规范，返回监控的样本数据。样本数据规范如下(//表示注释) # HELP \u003cmetrics_name\u003e \u003cdoc_string\u003e // 指标名称 说明信息 # TYPE \u003cmetrics_name\u003e \u003cmetrics_type\u003e // 指标名称 指标类型 // 样本数据格式：指标名称 标签名与值 float64类型的指标值 时间戳 \u003cmetrics_name\u003e [{\u003clabel name\u003e=\u003clabel value\u003e}] \u003cfloat64\u003e [timestamp] 以 # HELP 开头表示指标说明信息，\u003cdoc_string\u003e 部分为使用Prometheus的用户提供上下文说明 以 # TYPE 开头表示指标类型，如果缺省，则为 UNTYPED。其它类型有： Counter: 计数器类型，只增不减，但可以重置为 0 Gauge: 动态值，表示当前的值 Histogram: 在一定时间内持续采样 Summary: 指标名称应该反应监控对象，名称符合正则表达式[a-zA-Z_:][a-zA-Z0-9_:]* 如 prometheus_http_requests_total 表示 prometheus http 连接数。指标名称没有强制规范，但良好易读的指标应该满足以下条件 指标名称应该有个特定于应用程序的指标前缀。如 prometheus_* 表示特定于Prometheus服务器 指标名称应该有个基本单位。如 bytes(字节) 、seconds(秒)、info(二进制文件元数据) 指标名称应该有被测量的名称。如 cpu 标签用于区分被测量的特征，键值标签对的每个唯一组合都代表一个新的时间序列，过多的标签会导致存储数量的增加。 标签名必须满足正则表达式 [a-zA-Z_][a-zA-Z0-9_]* ，且以 __ 开头的标签被Prometheus保留使用，因此api_http_requests_total{method=\"POST\", handler=\"/messages\"} 与 {__name__=\"api_http_requests_total\"，method=\"POST\", handler=\"/messages\"} 两种方式均表示的同一条time-series 标签值标签值可以包含任何 Unicode 字符，但具有空标签值的标签被视为等同于不存在的标签 检测数据是一个 float64 值，其后有个可选精确到毫秒的时间戳，但通常是由Prometheus主动获取时才会获取检测指标值，因此通常是没有的 下面是 node_exporter 中的样本数据 [root@localhost var]# curl 127.0.0.1:9100/metrics # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.5049e-05 go_gc_duration_seconds{quantile=\"0.25\"} 8.6675e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.9667e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000112079 go_gc_duration_seconds{quantile=\"1\"} 0.000176933 go_gc_duration_seconds_sum 0.384272714 go_gc_duration_seconds_count 3853 .... # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.20.4\"} 1 ... # TYPE go_memstats_alloc_bytes_total counter go_memstats_alloc_bytes_total 7.170472736e+09 node_exporter [root@localhost prometheus]# curl -sOL https://github.com/prometheus/node_exporter/releases/download/v1.6.0/node_exporter-1.6.0.linux-amd64.tar.gz [root@localhost prometheus]# tar -zxf node_exporter-1.6.0.linux-amd64.tar.gz [root@localhost prometheus]# ./node_exporter-1.6.0.linux-amd64/node_exporter --version node_exporter, version 1.6.0 (branch: HEAD, revision: ff7f9d69b645cb691dd3e84dc3afc88f5c006962) build user: root@f9c3ed0cfbd3 build date: 20230527-12:03:54 go version: go1.20.4 platform: linux/amd64 tags: netgo osusergo static_build [root@localhost prometheus]# cp node_exporter-1.6.0.linux-amd64/node_exporter /usr/local/bin/ node_exporter 选项有以下规律 --[no-]-collector.*: 启用或禁用某指标收集器 --[no-]collector.disable-defaults --collector.* ...: 只启用或禁用某些指标收集器 可以使用正则表达式缩小指标收集器的范围，如：--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/) [root@localhost ~]# node_exporter --help usage: node_exporter [\u003cflags\u003e] Flags: -h, --[no-]help Show context-sensitive help (also try --help-long and --help-man). ... --web.telemetry-path=\"/metrics\" Path under which to expose metrics. --[no-]web.disable-exporter-metrics Exclude metrics about the exporter itself (promhttp_*, process_*, go_*). --web.max-requests=40 Maximum number of parallel scrape requests. Use 0 to disable. --[no-]collector.disable-defaults Set all collectors to disabled by default. --runtime.gomaxprocs=1 The target number of CPUs Go will run on (GOMAXPROCS) ($GOMAXPROCS) --[no-]web.systemd-socket Use systemd socket activation listeners instead of port listeners (Linux only). --web.listen-address=:9100 ... Addresses on which to expose metrics and web interface. Repeatable for multiple addresses. --web.config.file=\"\" [EXPERIMENTAL] Path to configuration file that can enable TLS or authentication. See: https://github.com/prometheus/exporter-toolkit/blob/master/docs/web-configuration.md --log.level=info Only log messages with the given severity or above. One of: [debug, info, warn, error] --log.format=logfmt Output format of log messages. One of: [logfmt, json] --[no-]vers","date":"2023-06-25","objectID":"/prometheus/:10:2","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 选项与指标node_exporter 会启用以下指标 go_gc_duration_seconds go_gc_duration_seconds_count go_gc_duration_seconds_sum go_goroutines go_info go_memstats_alloc_bytes go_memstats_alloc_bytes_total go_memstats_buck_hash_sys_bytes go_memstats_frees_total go_memstats_gc_sys_bytes go_memstats_heap_alloc_bytes go_memstats_heap_idle_bytes go_memstats_heap_inuse_bytes go_memstats_heap_objects go_memstats_heap_released_bytes go_memstats_heap_sys_bytes go_memstats_last_gc_time_seconds go_memstats_lookups_total go_memstats_mallocs_total go_memstats_mcache_inuse_bytes go_memstats_mcache_sys_bytes go_memstats_mspan_inuse_bytes go_memstats_mspan_sys_bytes go_memstats_next_gc_bytes go_memstats_other_sys_bytes go_memstats_stack_inuse_bytes go_memstats_stack_sys_bytes go_memstats_sys_bytes go_threads node_exporter_build_info process_cpu_seconds_total process_max_fds process_open_fds process_resident_memory_bytes process_start_time_seconds process_virtual_memory_bytes process_virtual_memory_max_bytes promhttp_metric_handler_errors_total promhttp_metric_handler_requests_in_flight promhttp_metric_handler_requests_total 如果启用了其它指标（包含默认启用的），会产生以下两个指标： # # 抓取指标耗时 node_scrape_collector_duration_seconds # 收集是否成功 node_scrape_collector_success ","date":"2023-06-25","objectID":"/prometheus/:11:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" CPU 相关指标与选项 --collector.cpufreq --collector.cpu.guest --collector.cpu.info --collector.cpu node_cpu_guest_seconds_total node_cpu_seconds_total --collector.loadavg node_load1 # cpu 平均负载 node_load5 node_load15 node_cpu_seconds_total node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"idle\"} # cpu 空闲时间占比 % node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"iowait\"} # 磁盘 IO 时间占比 node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"irq\"} # node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"nice\"} node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"softirq\"} node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"steal\"} node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"system\"} node_cpu_seconds_total{cpu=\"0\", instance=\"103.106.246.112:9100\", job=\"node\", mode=\"user\"} ","date":"2023-06-25","objectID":"/prometheus/:12:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 流量相关指标与选项 --collector.ethtool node_ethtool_info node_ethtool_peer_ifindex node_ethtool_received_gso_checksum_fixup node_network_asymmetricpause_advertised node_network_asymmetricpause_supported node_network_autonegotiate node_network_autonegotiate_advertised node_network_autonegotiate_supported node_network_pause_advertised node_network_pause_supported --collector.netdev node_network_receive_bytes_total node_network_receive_compressed_total node_network_receive_drop_total node_network_receive_errs_total node_network_receive_fifo_total node_network_receive_frame_total node_network_receive_multicast_total node_network_receive_nohandler_total node_network_receive_packets_total node_network_transmit_bytes_total node_network_transmit_carrier_total node_network_transmit_colls_total node_network_transmit_compressed_total node_network_transmit_drop_total node_network_transmit_errs_total node_network_transmit_fifo_total node_network_transmit_packets_total node_network_receive_bytes_total # 类型 counter # 网卡接收总字节数量 ","date":"2023-06-25","objectID":"/prometheus/:13:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 文件系统指标与选项 --collector.filesystem node_filesystem_avail_bytes node_filesystem_device_error node_filesystem_files node_filesystem_files_free node_filesystem_free_bytes node_filesystem_readonly node_filesystem_size_bytes # gauge 类型指标： # node_filesystem_free_bytes: 文件系统剩余总字节数 # node_filesystem_avail_bytes: 非root 可用的字节数 # node_filesystem_device_error # node_filesystem_files: # node_filesystem_files_free: # node_filesystem_readonly: 是否为只读 # node_filesystem_size_bytes: 文件系统总字节数 ","date":"2023-06-25","objectID":"/prometheus/:14:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 磁盘指标与选项 --collector.diskstats node_disk_device_mapper_info node_disk_filesystem_info node_disk_info node_disk_io_now node_disk_io_time_seconds_total node_disk_io_time_weighted_seconds_total node_disk_read_bytes_total node_disk_reads_completed_total node_disk_reads_merged_total node_disk_read_time_seconds_total node_disk_writes_completed_total node_disk_writes_merged_total node_disk_write_time_seconds_total node_disk_written_bytes_total # gauge 类型指标： # node_scrape_collector_success: 收集指标耗时 # node_scrape_collector_success: 收集是否成功 # node_disk_device_mapper_info: lvm 信息 # node_disk_filesystem_info: 文件系统信息 # node_disk_info: 从/sys/block/ 获取的块设备信息 # node_disk_io_now: 块设备正在进行 I/O 数量 # counter 类型指标: # node_disk_io_time_seconds_total: I/O 总耗时时间 # node_disk_io_time_weighted_seconds_total: # node_disk_read_bytes_total: 成功读取的总字节数 # node_disk_read_time_seconds_total: 读取操作总时间(秒) # node_disk_reads_completed_total: 成功读取总次数 # node_disk_reads_merged_total: 合并读取总次数 # node_disk_written_bytes_total: 成功写入的总字节数 # node_disk_write_time_seconds_total: 写入操作总时间(秒) # node_disk_writes_completed_total: 成功写入总次数 # node_disk_writes_merged_total: 合并写入总次数 ","date":"2023-06-25","objectID":"/prometheus/:15:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 内存指标与选项 --collector.meminfo node_memory_Active_anon_bytes node_memory_Active_bytes node_memory_Active_file_bytes node_memory_AnonHugePages_bytes node_memory_AnonPages_bytes node_memory_Bounce_bytes node_memory_Buffers_bytes node_memory_Cached_bytes node_memory_CmaFree_bytes node_memory_CmaTotal_bytes node_memory_CommitLimit_bytes node_memory_Committed_AS_bytes node_memory_DirectMap2M_bytes node_memory_DirectMap4k_bytes node_memory_Dirty_bytes node_memory_HardwareCorrupted_bytes node_memory_HugePages_Free node_memory_Hugepagesize_bytes node_memory_HugePages_Rsvd node_memory_HugePages_Surp node_memory_HugePages_Total node_memory_Inactive_anon_bytes node_memory_Inactive_bytes node_memory_Inactive_file_bytes node_memory_KernelStack_bytes node_memory_Mapped_bytes node_memory_MemAvailable_bytes node_memory_MemFree_bytes node_memory_MemTotal_bytes node_memory_Mlocked_bytes node_memory_NFS_Unstable_bytes node_memory_PageTables_bytes node_memory_Percpu_bytes node_memory_Shmem_bytes node_memory_Slab_bytes node_memory_SReclaimable_bytes node_memory_SUnreclaim_bytes node_memory_SwapCached_bytes node_memory_SwapFree_bytes node_memory_SwapTotal_bytes node_memory_Unevictable_bytes node_memory_VmallocChunk_bytes node_memory_VmallocTotal_bytes node_memory_VmallocUsed_bytes node_memory_Writeback_bytes node_memory_WritebackTmp_bytes --collector.meminfo_numa node_memory_numa_Active node_memory_numa_Active_anon node_memory_numa_Active_file node_memory_numa_AnonHugePages node_memory_numa_AnonPages node_memory_numa_Bounce node_memory_numa_Dirty node_memory_numa_FilePages node_memory_numa_HugePages_Free node_memory_numa_HugePages_Surp node_memory_numa_HugePages_Total node_memory_numa_Inactive node_memory_numa_Inactive_anon node_memory_numa_Inactive_file node_memory_numa_interleave_hit_total node_memory_numa_KernelStack node_memory_numa_local_node_total node_memory_numa_Mapped node_memory_numa_MemFree node_memory_numa_MemTotal node_memory_numa_MemUsed node_memory_numa_Mlocked node_memory_numa_NFS_Unstable node_memory_numa_numa_foreign_total node_memory_numa_numa_hit_total node_memory_numa_numa_miss_total node_memory_numa_other_node_total node_memory_numa_PageTables node_memory_numa_Shmem node_memory_numa_Slab node_memory_numa_SReclaimable node_memory_numa_SUnreclaim node_memory_numa_Unevictable node_memory_numa_Writeback node_memory_numa_WritebackTmp node_memory_MemAvailable_bytes # 内存可用字节，包含共用内存 # 指标类型：gauge node_memory_MemTotal_bytes # 内存大小，单位字节 # 指标类型：gauge ","date":"2023-06-25","objectID":"/prometheus/:16:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" 其它选项与指标 --collector.netclass.ignore-invalid-speed --collector.netclass.netlink --collector.netclass_rtnl.with-stats --collector.netdev.address-info --collector.netdev.enable-detailed-metrics --collector.netdev.netlink --collector.ntp.server-is-local --collector.perf.disable-hardware-profilers --collector.perf.disable-software-profilers --collector.perf.disable-cache-profilers --collector.rapl.enable-zone-label --collector.stat.softirq --collector.systemd.enable-task-metrics --collector.systemd.enable-restarts-metrics --collector.systemd.enable-start-time-metrics --collector.arp node_arp_entries --collector.bcache --collector.bonding --collector.btrfs --collector.buddyinfo node_buddyinfo_blocks --collector.cgroups node_cgroups_cgroups node_cgroups_enabled --collector.conntrack node_nf_conntrack_entries node_nf_conntrack_entries_limit node_nf_conntrack_stat_drop node_nf_conntrack_stat_early_drop node_nf_conntrack_stat_found node_nf_conntrack_stat_ignore node_nf_conntrack_stat_insert node_nf_conntrack_stat_insert_failed node_nf_conntrack_stat_invalid node_nf_conntrack_stat_search_restart --collector.dmi --collector.drbd --collector.drm --collector.edac --collector.entropy node_entropy_available_bits node_entropy_pool_size_bits --collector.fibrechannel --collector.filefd node_filefd_allocated node_filefd_maximum --collector.hwmon node_hwmon_chip_names node_hwmon_sensor_label node_hwmon_temp_celsius node_hwmon_temp_crit_alarm_celsius node_hwmon_temp_crit_celsius node_hwmon_temp_max_celsius --collector.infiniband --collector.interrupts node_interrupts_total --collector.ipvs --collector.ksmd node_ksmd_full_scans_total node_ksmd_merge_across_nodes node_ksmd_pages_shared node_ksmd_pages_sharing node_ksmd_pages_to_scan node_ksmd_pages_unshared node_ksmd_pages_volatile node_ksmd_run node_ksmd_sleep_seconds --collector.lnstat node_lnstat_allocs_total node_lnstat_delete_list_total node_lnstat_delete_total node_lnstat_destroys_total node_lnstat_drop_total node_lnstat_early_drop_total node_lnstat_entries_total node_lnstat_expect_create_total node_lnstat_expect_delete_total node_lnstat_expect_new_total node_lnstat_forced_gc_runs_total node_lnstat_found_total node_lnstat_gc_dst_overflow_total node_lnstat_gc_goal_miss_total node_lnstat_gc_ignored_total node_lnstat_gc_total_total node_lnstat_hash_grows_total node_lnstat_hits_total node_lnstat_icmp_error_total node_lnstat_ignore_total node_lnstat_in_brd_total node_lnstat_in_hit_total node_lnstat_in_hlist_search_total node_lnstat_in_martian_dst_total node_lnstat_in_martian_src_total node_lnstat_in_no_route_total node_lnstat_insert_failed_total node_lnstat_insert_total node_lnstat_in_slow_mc_total node_lnstat_in_slow_tot_total node_lnstat_invalid_total node_lnstat_lookups_total node_lnstat_new_total node_lnstat_out_hit_total node_lnstat_out_hlist_search_total node_lnstat_out_slow_mc_total node_lnstat_out_slow_tot_total node_lnstat_periodic_gc_runs_total node_lnstat_rcv_probes_mcast_total node_lnstat_rcv_probes_ucast_total node_lnstat_res_failed_total node_lnstat_searched_total node_lnstat_search_restart_total node_lnstat_unresolved_discards_total --collector.logind node_logind_sessions --collector.mdadm --collector.mountstats --collector.netclass node_network_address_assign_type node_network_carrier node_network_carrier_changes_total node_network_device_id node_network_dormant node_network_flags node_network_iface_id node_network_iface_link node_network_iface_link_mode node_network_info node_network_mtu_bytes node_network_net_dev_group node_network_protocol_type node_network_speed_bytes node_network_transmit_queue_length node_network_up --collector.netstat node_netstat_Icmp6_InErrors node_netstat_Icmp6_InMsgs node_netstat_Icmp6_OutMsgs node_netstat_Icmp_InErrors node_netstat_Icmp_InMsgs node_netstat_Icmp_OutMsgs node_netstat_Ip6_InOctets node_netstat_Ip6_OutOctets node_netstat_IpExt_InOctets node_netstat_IpExt_OutOctets node_netstat_Ip_Forwarding node_netstat_Tcp_ActiveOpens node_netstat_Tcp_CurrE","date":"2023-06-25","objectID":"/prometheus/:17:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["prometheus"],"content":" Warning: Error fetching server time: Detected 37.920000076293945 seconds time difference between your browser and the server. Prometheus relies on accurate time and time drift might cause unexpected query results.","date":"2023-06-25","objectID":"/prometheus/:18:0","tags":["prometheus"],"title":"prometheus 是一个开源系统监控和警报工具包","uri":"/prometheus/"},{"categories":["容器"],"content":" 运行环境： 内容来自以下文档： Harbor官方文档 如何重置管理员密码? 安装下载 [root@localhost download]# wget https://github.com/goharbor/harbor/releases/download/v2.8.2/harbor-offline-installer-v2.8.2.tgz --2023-06-21 14:49:15-- https://github.com/goharbor/harbor/releases/download/v2.8.2/harbor-offline-installer-v2.8.2.tgz Resolving github.com (github.com)... 20.205.243.166 [root@localhost download]# tar zxf harbor-offline-installer-v2.8.2.tgz -C ~/ [root@localhost download]# cd ~/harbor/ 修改配置文件，所有未注释的都是必须的 [root@localhost harbor]# cat harbor.yml.tmpl \u003e harbor.yml \"[root@localhost harbor]# bash install.sh [Step 0]: checking if docker is installed ... Note: docker version: 23.0.6 ... ","date":"2023-06-21","objectID":"/harbor/:0:0","tags":[null],"title":"harbor","uri":"/harbor/"},{"categories":["容器"],"content":" 重置管理员密码 进入harbor-db 容器 [root@localhost ~]# docker container ls | grep harbor-db 884987b73e2d goharbor/harbor-db:v2.8.2 \"/docker-entrypoint.…\" 19 hours ago Up 7 minutes (healthy) harbor-db postgres [ / ]$ psql -U postgres psql (13.11) Type \"help\" for help. 修改密码 registry=# \\c registry registry=# update harbor_user set salt='', password='' where user_id = 1; UPDATE 1 registry=# select * from harbor_user; user_id | username | email | password | realname | comment | deleted | reset_uuid | salt | sysadmin_flag | creation_time | update_time | password_version --------+-----------+-------+----------+----------------+----------------+---------+------------+------+---------------+----------------------------+----------------------------+------------------ 2 | anonymous | | | anonymous user | anonymous user | t | | salt | f | 2023-06-21 08:03:31.666841 | 2023-06-21 08:03:32.230277 | sha1 1 | admin | | | system admin | admin user | f | | | t | 2023-06-21 08:03:31.666841 | 2023-06-21 12:57:36.025387 | sha256 registry=# exit postgres [ / ]$ exit exit 重启相关容器 [root@localhost ~]# docker container restart $(docker container ls | grep goharbor | awk '{print $1}') 55d30f687d6c b6c8b376fb1d c1971cdb6e7e 69546a10ae0d 2f5813a89aff 884987b73e2d 84f1430f34ca 433e15bd352a a0070d1aaa4e 在浏览器使用初始密码登录后重新设置密码 ","date":"2023-06-21","objectID":"/harbor/:1:0","tags":[null],"title":"harbor","uri":"/harbor/"},{"categories":["aws"],"content":" 运行环境： 内容来自以下文档： [name][name] [name]: [root@localhost ~]# aws ecr create-repository --repository-name xiaosi \\ \u003e --region ap-southeast-1 --profile \"zjc-yuhai\" { \"repository\": { \"repositoryArn\": \"arn:aws:ecr:ap-southeast-1:968767926216:repository/xiaosi\", \"registryId\": \"968767926216\", \"repositoryName\": \"xiaosi\", \"repositoryUri\": \"968767926216.dkr.ecr.ap-southeast-1.amazonaws.com/xiaosi\", \"createdAt\": \"2023-06-21T11:58:05+08:00\", \"imageTagMutability\": \"MUTABLE\", \"imageScanningConfiguration\": { \"scanOnPush\": false }, \"encryptionConfiguration\": { \"encryptionType\": \"AES256\" } } } # 使用docker 登录 # 账户为: AWS # 地址格式：aws_account_id.dkr.ecr.region.amazonaws.com [root@localhost ~]# aws ecr get-login-password --region ap-southeast-1 --profile \"zjc-yuhai\" \\ docker login --username AWS --password-stdin 968767926216.dkr.ecr.ap-southeast-1.amazonaws.com WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded [root@localhost ~]# cat /root/.docker/config.json { \"auths\": { \"968767926216.dkr.ecr.ap-southeast-1.amazonaws.com\": { \"auth\": \"QVdTOmV5SndZWGxzYjJGa0lqb2lSVFZSY1cxSk1rOUNibXRpYkV4Mk ... } ","date":"2023-06-21","objectID":"/awsECR/:0:0","tags":["ECR","aws"],"title":"aws","uri":"/awsECR/"},{"categories":["k8s"],"content":" 运行环境： 内容来自以下文档： API 概述 API 惯例 Kubernetes API 概念 RESTfulKubernetes API 是通过 HTTP 提供的基于资源 (RESTful) 的编程接口。 它支持通过标准 HTTP 动词（POST、PUT、PATCH、DELETE、GET）检索、创建、更新和删除主要资源。 资源 URL 大致格式为：/apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE/NAME（大写字段表示需要替换对应名称） apis/GROUP/: 表示api 资源组，如果是核心资料则以 api表示，且没有GROUP部分。如 /api/v1/pods namespaces/NAMESPACE/: 名称空间，如果为集群资源，则缺省 RESOURCETYPE: 表示资源类型，如果缺省后面资源名称则表示某类资源集合 NAME: 具体的资源名称 HTTP 请求方式 API 请求动词 说明 GET 或 HEAD get 获取单个资源 GET 或 HEAD list 获取某类资源集合 POST create 创建资源 PUT update 更新资源，如果资源不存在则创建 PATH patch 修改资源字段 DELETE delete 删除单个资源 DELETE deletecollection 删除某类型资源 post 示例 PS 2023/06/18 21:03:35 \u003e curl.exe -s -w \"\\n响应状态码：%{http_code}\" ` \u003e\u003e --cert .\\localK8s\\xiaosi.crt --key .\\localK8s\\xiaosi.key --cacert .\\localK8s\\ca.crt ` \u003e\u003e -H \"Content-Type: application/yaml\" ` \u003e\u003e --data-binary \"@xiaosiNamespace.yaml\" ` \u003e\u003e -X POST https://192.168.232.100:6443/api/v1/namespaces { \"kind\": \"Status\", \"apiVersion\": \"v1\", \"metadata\": {}, \"status\": \"Failure\", \"message\": \"namespaces is forbidden: User \\\"xiaosi\\\" cannot create resource \\\"namespaces\\\" in API group \\\"\\\" at the cluster scope\", \"reason\": \"Forbidden\", \"details\": { \"kind\": \"namespaces\" }, \"code\": 403 } 响应状态码：403 常用参数","date":"2023-06-18","objectID":"/k8sApiConcepts/:0:0","tags":["k8s"],"title":"k8s RESTfula","uri":"/k8sApiConcepts/"},{"categories":["k8s"],"content":" whactwatch 参数能持续监控某资源或某类资源变更，需要与 resourceVersion 参数一起使用 ","date":"2023-06-18","objectID":"/k8sApiConcepts/:1:0","tags":["k8s"],"title":"k8s RESTfula","uri":"/k8sApiConcepts/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.27 内容来自以下文档： ","date":"2023-06-17","objectID":"/k8sCoreDNS/:0:0","tags":["k8s","CoreDNS"],"title":"CoreDNS 是 Kubernetes 的默认 DNS 服务","uri":"/k8sCoreDNS/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.27 内容来自以下文档： k8s 官方文档：自动扩缩集群 DNS 服务 githup 地址：cluster-proportional-autoscaler ","date":"2023-06-17","objectID":"/k8sElasticDnsServer/:0:0","tags":["k8s","扩缩 NDS 服务"],"title":"k8s DNS服务自动扩缩","uri":"/k8sElasticDnsServer/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.27 内容来自以下文档： k8s 官方文档：为 Pod 和容器管理资源 k8s 官方文档：[为容器分派扩展资源][为容器分派扩展资源] k8s 官方文档：为节点发布扩展资源 [为容器分派扩展资源]https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/extended-resource/ ","date":"2023-06-17","objectID":"/k8sExtendedResources/:0:0","tags":["k8s","扩展计算资源"],"title":"k8s 定义非 Kubernetes 内置计算资源","uri":"/k8sExtendedResources/"},{"categories":["aws"],"content":" 运行环境： eksctl: 0.143.0 kubectl: v1.27.1 OS: linux 内容来自以下文档： eksctl 安装 eksctl # https://github.com/weaveworks/eksctl/releases [root@localhost ~]# history | grep eks wget https://github.com/weaveworks/eksctl/releases/download/v0.143.0/eksctl_Linux_amd64.tar.gz tar zxf eksctl_Linux_amd64.tar.gz cd eksctl_Linux_amd64.tar.gz ./eksctl --help mv eksctl /usr/local/bin/ eksctl --help [root@localhost ~]# eksctl version 0.143.0 [root@localhost ~]# eksctl --help ... Usage: eksctl [command] [flags] Commands: eksctl anywhere EKS anywhere eksctl associate Associate resources with a cluster eksctl completion Generates shell completion scripts for bash, zsh or fish eksctl create Create resource(s) eksctl delete Delete resource(s) eksctl deregister Deregister a non-EKS cluster eksctl disassociate Disassociate resources from a cluster eksctl drain Drain resource(s) eksctl enable Enable features in a cluster eksctl get Get resource(s) eksctl help Help about any command eksctl info Output the version of eksctl, kubectl and OS info eksctl register Register a non-EKS cluster eksctl scale Scale resources(s) eksctl set Set values eksctl unset Unset values eksctl update Update resource(s) eksctl upgrade Upgrade resource(s) eksctl utils Various utils eksctl version Output the version of eksctl Common flags: -C, --color string # 输出日志颜色 值为: true, false, fabulous (default \"true\") -d, --dumpLogs dump logs to disk on failure if set to true -h, --help # 查看帮助 -v, --verbose int # 设置输出日志级别，1~5，默认为 3 Use 'eksctl [command] --help' for more information about a command. For detailed docs go to https://eksctl.io/ 创建集群eksclt 命令是使用CloudFormation 创建资源 [root@localhost ~]# eksctl create cluster --help ... -n, --name string # 指定集群名称 --tags stringToString # 创建标签，如：\"k1=v1,k2=v2\" -r, --region string # 指定区域，从 默认从AWS config（~/.aws/config） 中获取 --with-oidc Enable the IAM OIDC provider --zones strings # 指定可用区，如 us-east-1a。可多次指定该选项指定多个可用区 --version string # 指定 k8s 版本，可使用 eksctl create cluster --help | grep '\\--version' 命令查看 -f, --config-file string # 通过 yaml 文件创建，如果为 - 表示从标准输入中获取 # 配置字段见 https://eksctl.io/usage/schema/ --timeout duration maximum waiting time for any long-running operation (default 25m0s) --fargate Create a Fargate profile scheduling pods in the default and kube-system namespaces onto Fargate --dry-run # 生成用于eksctl创建集群使用的yaml文件 # Initial nodegroup flags: # 创建节点组 --without-nodegroup # 不创建工作节点组 VPC networking flags: --vpc-cidr ipNet # 指定 VPC 地址，该地址也是 pod 范围地址，默认值为 192.168.0.0/16 # 掩码必须为 /16 或 /24 --vpc-private-subnets strings # 指定现有的私有子网名称 --vpc-public-subnets strings # 指定现有的私有公有网名称 --vpc-from-kops-cluster string re-use VPC from a given kops cluster --vpc-nat-mode string # VPC net 模式，值为HighlyAvailable, Single（默认）, Disable 之一 AWS client flags: -p, --profile string # awc cli 配置文件，里面包含身份验证与权限 --cfn-role-arn string IAM role used by CloudFormation to call AWS API on your behalf --cfn-disable-rollback for debugging: If a stack fails, do not roll it back. Be careful, this may lead to unintentional resource consumption! Output kubeconfig flags: --kubeconfig string # 指定 kubeconfig 方便位置，默认保存为 /root/.kube/config --authenticator-role-arn string AWS IAM role to assume for authenticator --set-kubeconfig-context if true then current-context will be set in kubeconfig; if a context is already set then it will be overwritten (default true) --auto-kubeconfig save kubeconfig file by cluster name, e.g. \"/root/.kube/eksctl/clusters/unique-unicorn-1689731334\" --write-kubeconfig toggle writing of kubeconfig (default true) Common flags: -C, --color string toggle colorized logs (valid options: true, false, fabulous) (default \"true\") -d, --dumpLogs dump logs to disk on failure if set to true -h, --help help for this command -v, --verbose int set log level, use 0 to silence, 4 for debugging and 5 for debugging with AWS debug logging (default 3) eksctl create fargateprofile Create a Fargate profile eksctl create iamidentitymapping Create an IAM identity mapping eksctl create iamserviceaccount Cre","date":"2023-06-15","objectID":"/awsEksctl/:0:0","tags":["eksctl","aws"],"title":"eksctl","uri":"/awsEksctl/"},{"categories":["aws"],"content":" 创建 VPC默认情况下 VPC 使用的IP范围是 192.168.0.0/16 ，该VPC会创建8个子网，其中私有与公各3 个，剩下2做为保留使用。 创建节点组 [root@localhost ~]# eksctl create nodegroup --help Create a nodegroup Usage: eksctl create nodegroup [flags] Aliases: nodegroup, ng # AWS client flags: -p, --profile string # awc cli 配置文件，里面包含身份验证与权限 --cfn-role-arn string IAM role used by CloudFormation to call AWS API on your behalf --cfn-disable-rollback for debugging: If a stack fails, do not roll it back. Be careful, this may lead to unintentional resource consumption! # General flags: -c, --cluster string # 集群名称 --tags stringToString Used to tag the AWS resources. List of comma separated KV pairs \"k1=v1,k2=v2\" (default []) -r, --region string # eks 所在区域 --version string # -f, --config-file string # 通过 yaml 文件创建，如果为 - 表示从标准输入中获取 # 配置字段见 https://eksctl.io/usage/schema/ --include strings nodegroups to include (list of globs), e.g.: 'ng-team-?,prod-*' --exclude strings nodegroups to exclude (list of globs), e.g.: 'ng-team-?,prod-*' --update-auth-configmap Add nodegroup IAM role to aws-auth configmap (default true) --timeout duration maximum waiting time for any long-running operation (default 25m0s) --subnet-ids strings Define an optional list of subnet IDs to create the nodegroup in --dry-run # 生成用于eksctl创建集群使用的yaml文件 --skip-outdated-addons-check whether the creation of ARM nodegroups should proceed when the cluster addons are outdated # New nodegroup flags: -n, --name string # 节点组名称 -t, --node-type string # 节点实例类型 --instance-types strings # 节点实例类型列表，如 --instance-types=c3.large,c4.large,c5.large -N, --nodes int # 节点数量，默认值为 2 -m, --nodes-min int # 节点最小数量，默认值为 2 -M, --nodes-max int # 节点最大数据，默认值为 2 --node-volume-size int # 节点使用的 EBS 大小，默认为 80G --node-volume-type string # 节点存储卷类型 (valid options: gp2, gp3, io1, sc1, st1) (default \"gp3\") --max-pods-per-node int # 节点最大 pod 数据，不能超过 EC2 类型限制 --ssh-access # control SSH access for nodes. Uses ~/.ssh/id_rsa.pub as default key path if enabled --ssh-public-key string # 从本地路径导入公钥 --enable-ssm Enable AWS Systems Manager (SSM) --node-ami string # 'auto-ssm', 'auto' or an AMI ID (advanced use) --node-ami-family string # 使用节点AMI 'AmazonLinux2' or 'Ubuntu2004' or 'Ubuntu1804' (default \"AmazonLinux2\") --node-private-networking # 部署在私有子网中 --node-security-groups strings # 指定节点使用的安全组 --node-labels stringToString # 节点标签列表 如 \"k1=v1,k2=v2\" (default []) --node-zones strings # 节点可用区，名称格式为为区域[a-z] --instance-prefix string # ec2 实例名称前缀 --instance-name string # overrides the default instance's name --disable-pod-imds Blocks IMDS requests from non-host networking pods --managed Create EKS-managed nodegroup (default true) --spot # spot 类型实例 # Addons flags: --asg-access enable IAM policy for cluster-autoscaler --external-dns-access enable IAM policy for external-dns --full-ecr-access enable full access to ECR --appmesh-access enable full access to AppMesh --appmesh-preview-access enable full access to AppMesh Preview --alb-ingress-access enable full access for alb-ingress-controller --install-neuron-plugin install Neuron plugin for Inferentia and Trainium nodes (default true) --install-nvidia-plugin install Nvidia plugin for GPU nodes (default true) # Instance Selector options flags: --instance-selector-vcpus int an integer value (2, 4 etc) --instance-selector-memory string 4 or 4GiB --instance-selector-cpu-architecture string x86_64, or arm64 --instance-selector-gpus int an integer value # Common flags: -C, --color string toggle colorized logs (valid options: true, false, fabulous) (default \"true\") -d, --dumpLogs dump logs to disk on failure if set to true -h, --help help for this command -v, --verbose int set log level, use 0 to silence, 4 for debugging and 5 for debugging with AWS debug logging (default 3) 节点组","date":"2023-06-15","objectID":"/awsEksctl/:1:0","tags":["eksctl","aws"],"title":"eksctl","uri":"/awsEksctl/"},{"categories":["aws"],"content":" 删除节点组 eksctl delete nodegroup [flags] --approve # 应用更改，当使用 -f 指定配置文件时用 error [root@localhost ~]# eksctl delete cluster -n eks01 --profile zjc-yuhai 2023-06-15 15:46:12 [ℹ] deleting EKS cluster \"eks01\" 2023-06-15 15:46:12 [ℹ] will drain 0 unmanaged nodegroup(s) in cluster \"eks01\" 2023-06-15 15:46:12 [ℹ] starting parallel draining, max in-flight of 1 2023-06-15 15:46:43 [ℹ] deleted 0 Fargate profile(s) 2023-06-15 15:46:43 [✔] kubeconfig has been updated 2023-06-15 15:46:43 [ℹ] cleaning up AWS load balancers created by Kubernetes objects of Kind Service or Ingress Error: cannot list Kubernetes Services: Get \"https://8742BF8C4FF724BEF2BECE107D4EB0E2.gr7.ap-southeast-1.eks.amazonaws.com/api/v1/services\": dial tcp 172.16.180.188:443: i/o timeout ","date":"2023-06-15","objectID":"/awsEksctl/:2:0","tags":["eksctl","aws"],"title":"eksctl","uri":"/awsEksctl/"},{"categories":["aws"],"content":" 内容来自以下文档： EKS 用户指南 AWS 负载均衡器控制器 使用 eksctl 搭建 eks 集群","date":"2023-06-08","objectID":"/awsEks/:0:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 安装 eksctl # https://github.com/weaveworks/eksctl/releases [root@localhost ~]# history | grep eks wget https://github.com/weaveworks/eksctl/releases/download/v0.143.0/eksctl_Linux_amd64.tar.gz tar zxf eksctl_Linux_amd64.tar.gz cd eksctl_Linux_amd64.tar.gz ./eksctl --help mv eksctl /usr/local/bin/ eksctl --help [root@localhost ~]# eksctl version 0.143.0 ","date":"2023-06-08","objectID":"/awsEks/:1:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 安装 AWS CLI ","date":"2023-06-08","objectID":"/awsEks/:2:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 安装 kubectl cat \u003c\u003cEOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF [root@localhost ~]# yum install -y kubectl --disableexcludes=kubernetes Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile .... ","date":"2023-06-08","objectID":"/awsEks/:3:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 创建集群 [root@localhost ~]# eksctl create cluster \\ --profile \"xiaosi\" \\ --region \"ap-southeast-1\" \\ --name \"eks01\" \\ --version \"1.27\" \\ --without-nodegroup \\ --kubeconfig \"/root/.kube/singapore-eks01-config\" \\ --tags \"user=xiaosi\" 2023-07-23 16:40:42 [ℹ] eksctl version 0.143.0 2023-07-23 16:40:42 [ℹ] using region ap-southeast-1 ... 2023-07-23 16:52:48 [✔] saved kubeconfig as \"/root/.kube/singapore-eks01-config\" 2023-07-23 16:52:48 [ℹ] no tasks 2023-07-23 16:52:48 [✔] all EKS cluster resources for \"eks01\" have been created 2023-07-23 16:52:50 [ℹ] kubectl command should work with \"/root/.kube/singapore-eks01-config\", try 'kubectl --kubeconfig=/root/.kube/singapore-eks01-config get nodes' 2023-07-23 16:52:50 [✔] EKS cluster \"eks01\" in \"ap-southeast-1\" region is ready [root@localhost ~]# eksctl get cluster --profile \"xiaosi\" --region \"ap-southeast-1\" NAME REGION EKSCTL CREATED eks01 ap-southeast-1 True 使用 aws 命令创建节点组格式 https://awscli.amazonaws.com/v2/documentation/api/latest/reference/eks/create-nodegroup.html aws eks create-nodegroup --cluster-name \u003cvalue\u003e # eks名称 --nodegroup-name \u003cvalue\u003e # 节点组名称 --subnets \u003cvalue\u003e # 节点组子网 --node-role \u003cvalue\u003e # 节点角色ARN --remote-access \u003cvalue\u003e # 指定 允许远程访问的列表 --scaling-config \u003cvalue\u003e # 自动扩缩 --ami-type \u003cvalue\u003e # AMI 类型 --instance-types \u003cvalue\u003e # 实例类型 --capacity-type \u003cvalue\u003e # 购买模型 示例 aws eks create-nodegroup \\ --cluster \"eks01\" \\ --nodegroup-name \"work-arm64-spot\" \\ --subnets \"subnet-03f985d37e90c79e2\" \"subnet-05b08efbdc8bb1e69\" \"subnet-0f783da364e506e14\" \\ --node-role \"arn:aws:iam::223665515173:role/eks-nodegroup\" \\ --remote-access \"ec2SshKey=xiaosi-singapore-ec2\" \\ --scaling-config \"minSize=1,maxSize=6,desiredSize=1\" \\ --ami-type \"AL2_ARM_64\" \\ --instance-types \"c6g.large\" \\ --capacity-type \"SPOT\" \\ --profile \"yh-xiaosi\" \\ --region \"ap-southeast-1\" 示例 aws eks create-nodegroup \\ --cluster \"xiaosi\" \\ --nodegroup-name \"private-a\" \\ --subnets \"subnet-0921ac14d1573d55f\" \\ --remote-access \"ec2SshKey=ec2\" \\ --node-role \"arn:aws:iam::223665515173:role/KarpenterNodeRole-xiaosi\" \\ --ami-type \"AL2_ARM_64\" \\ --instance-types \"c6g.large\" \\ --capacity-type \"ON_DEMAND\" \\ --scaling-config \"minSize=1,maxSize=2,desiredSize=1\" \\ --profile \"yh-xiaosi\" \\ --region \"ap-southeast-1\" | jq 示例 [root@localhost ~]# aws eks create-nodegroup \\ --cluster \"xiaosi\" \\ --nodegroup-name \"private-b\" \\ --subnets \"subnet-0821ddb76fdf30d03\" \\ --remote-access \"ec2SshKey=ec2\" \\ --node-role \"arn:aws:iam::223665515173:role/KarpenterNodeRole-xiaosi\" \\ --ami-type \"AL2_ARM_64\" \\ --instance-types \"c6g.large\" \\ --capacity-type \"ON_DEMAND\" \\ --scaling-config \"minSize=1,maxSize=2,desiredSize=1\" \\ --profile \"yh-xiaosi\" \\ --region \"ap-southeast-1\" | jq { \"nodegroup\": { ... 使用 eksctl 创建节点组只有使用eksctl命令创建的eks集群才能被eksctl识别 [root@localhost ~]# ssh-keygen -t rsa -N \"\" -f .eks/zjc-yuhai/singapore/node01 Generating public/private rsa key pair. Your identification has been saved in .eks/zjc-yuhai/singapore/node01. Your public key has been saved in .eks/zjc-yuhai/singapore/node01.pub. ... # 命令行 eksctl create nodegroup \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --cluster \"eks01\" \\ --spot \\ --name \"node01\" \\ --nodes 1 \\ --nodes-max 6 \\ --node-zones \"ap-southeast-1a\" \\ --node-labels \"user=xiaosi,zone=ap-southeast-1a\" \\ --instance-types=\"c6a.xlarge,c5a.xlarge,c6i.xlarge,c5.xlarge\" \\ --ssh-access \\ --ssh-public-key ~/.eks/zjc-yuhai/singapore/node01.pub [root@localhost singapore]# cat eks01-node01.yaml --- # https://eksctl.io/usage/schema/ apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: eks01 # 集群名称 region: ap-southeast-1 # 区域 managedNodeGroups: - name: node01 # 节点组名称 labels: # 节点标签 user: xiaosi availabilityZones: - ap-southeast-1a instanceTypes: # 节点实例类型列表 - c6a.xlarge - c5a.xlarge - c6i.xlarge - c5.xlarge desiredCapacity: 1 # 所需节点数据 minSize: 1 # 最小节点数 maxSize: 6 # 最大节点数 volumeSize: 80 # 节点容量，单位为G privateNetworking: false # 是否部署在私有子网 # 购买 spot 类型，最多存在 8 小时，到期删除节点组 spot: false ssh: # 启用 AWS Session Manager enableSsm: true # 启用ssh远程连接 allo","date":"2023-06-08","objectID":"/awsEks/:4:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 定义 AWS ALB 资源配置Ingress.metadata.annotations 可用注解在AWS Load Balancer Controller Igresss Annotations 查看完整理的说明 ALB,（Application Load Balancer）使用注意事项 Service.spec.loadBalancerClass: 字段值必须显示指定为 service.k8s.aws/alb，否则会同时创建 nlb IngressClass.spec.controller: 指定为 ingress.k8s.aws/alb Ingress 资源被创建时才会创建alb，反之删除相关Ingress也会回收alb ","date":"2023-06-08","objectID":"/awsEks/:5:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 资源标签创建 aws alb 资源时会默认加入以下标签： elbv2.k8s.aws/cluster: ${clusterName} ingress.k8s.aws/stack: ${stackID} ingress.k8s.aws/resource: ${resourceID} 可使用alb.ingress.kubernetes.io/tags标签添加标签 alb.ingress.kubernetes.io/tags: user=xiaosi,application=Equal ","date":"2023-06-08","objectID":"/awsEks/:5:1","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 是否公有alb.ingress.kubernetes.io/scheme 标签有以下值 internet-facing: 公有，会分配一个公有IP地址 internal: 仅vpc内部可用 ","date":"2023-06-08","objectID":"/awsEks/:5:2","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 监听端口alb.ingress.kubernetes.io/listen-ports 标签指定监听端口列表，默认会监听 80 或 443(取决是否使用alb.ingress.kubernetes.io/certificate-arn注解) ... metadata: namespace: default name: ingress annotations: alb.ingress.kubernetes.io/listen-ports: | [ {\"HTTP\": 80}, {\"HTTPS\": 443}, {\"HTTP\": 8080}, {\"HTTPS\": 8443} ] spec: # ... (rest of the spec) ","date":"2023-06-08","objectID":"/awsEks/:5:3","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 指定操作条件ingress 本身满足基于路径与主机名的条件，其它基于源IP、HTTP请求头部、HTTP请求方法、查询字符串（url 中?以后的部分）需要添加 alb.ingress.kubernetes.io/conditions.${conditions-name} 注解指定ALB 规则条件类型 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: namespace: default name: ingress annotations: alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/actions.rule-path1: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"200\", \"messageBody\": \"Host is www.example.com OR anno.example.com\" } } alb.ingress.kubernetes.io/conditions.rule-path1: | [ { \"field\": \"host-header\", \"hostHeaderConfig\": { \"values\": [\"anno.example.com\"] } } ] alb.ingress.kubernetes.io/actions.rule-path2: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"200\", \"messageBody\": \"Path is /path2 OR /anno/path2\" } } alb.ingress.kubernetes.io/conditions.rule-path2: | [ { \"field\": \"path-pattern\", \"pathPatternConfig\": { \"values\": [\"/anno/path2\"] } } ] alb.ingress.kubernetes.io/actions.rule-path3: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"200\", \"messageBody\": \"Http header HeaderName is HeaderValue1 OR HeaderValue2\" } } alb.ingress.kubernetes.io/conditions.rule-path3: | [ { \"field\": \"http-header\", \"httpHeaderConfig\": { \"httpHeaderName\": \"HeaderName\", \"values\": [\"HeaderValue1\", \"HeaderValue2\"] } } ] alb.ingress.kubernetes.io/actions.rule-path4: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"200\", \"messageBody\": \"Http request method is GET OR HEAD\" } } alb.ingress.kubernetes.io/conditions.rule-path4: | [ { \"field\": \"http-request-method\", \"httpRequestMethodConfig\": { \"Values\": [\"GET\", \"HEAD\"] } } ] alb.ingress.kubernetes.io/actions.rule-path5: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"200\", \"messageBody\": \"Query string is paramA:valueA1 OR paramA:valueA2\" } } alb.ingress.kubernetes.io/conditions.rule-path5: | [ { \"field\": \"query-string\", \"queryStringConfig\": { \"values\": [ {\"key\": \"paramA\", \"value\": \"valueA1\"}, {\"key\": \"paramA\", \"value\": \"valueA2\"} ] } } ] alb.ingress.kubernetes.io/actions.rule-path6: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"200\", \"messageBody\": \"Source IP is 192.168.0.0/16 OR 172.16.0.0/16\" } } alb.ingress.kubernetes.io/conditions.rule-path6: | [ { \"field\": \"source-ip\", \"sourceIpConfig\": { \"values\": [\"192.168.0.0/16\", \"172.16.0.0/16\"] } } ] alb.ingress.kubernetes.io/actions.rule-path7: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"200\", \"messageBody\": \"multiple conditions applies\" } } alb.ingress.kubernetes.io/conditions.rule-path7: | [ { \"field\": \"http-header\", \"httpHeaderConfig\": { \"httpHeaderName\": \"HeaderName\", \"values\": [\"HeaderValue\"] } }, { \"field\": \"query-string\", \"queryStringConfig\": { \"values\": [{\"key\": \"paramA\", \"value\": \"valueA\"}] } }, { \"field\": \"query-string\", \"queryStringConfig\": { \"values\": [{\"key\": \"paramB\", \"value\": \"valueB\"}] } } ] spec: ingressClassName: alb rules: - host: www.example.com http: paths: - path: /path1 pathType: Exact backend: service: name: rule-path1 port: name: use-annotation - path: /path2 pathType: Exact backend: service: name: rule-path2 port: name: use-annotation - path: /path3 pathType: Exact backend: service: name: rule-path3 port: name: use-annotation - path: /path4 pathType: Exact backend: service: name: rule-path4 port: name: use-annotation - path: /path5 pathType: Exact backend: service: name: rule-path5 port: name: use-annotation - path: /path6 pathType: Exact backend: service: name: rule-path6 port: name: use-annotation - path: /path7 pathType: Exact backend: service: name: rule-path7 port: name: use-annotation ","date":"2023-06-08","objectID":"/awsEks/:5:4","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 指定操作类型alb.ingress.kubernetes.io/actions.${action-name} 指定ALB 规则操作类型。有以下注意事项 同一个alb.ingress.kubernetes.io/actions注解的规则冲突或配置错误会导致alb创建失败 Ingress.spec.rules.http.paths.backend.service.prot.name 值必须是use-annotation。如果指定了值但没有指定其注解会默认创建 503 状态码 ${action-name}值必须与Ingress.spec.rules.http.paths.backend.service.name值相同 ${action-name}值与Service.spec.use-annotation相同且会默认创建流量转发（到EC2或pod ip） 下面是官网的一个示例 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: namespace: default name: ingress annotations: alb.ingress.kubernetes.io/scheme: internet-facing # 自定义 503 响应码 alb.ingress.kubernetes.io/actions.response-503: | { \"type\": \"fixed-response\", \"fixedResponseConfig\": { \"contentType\": \"text/plain\", \"statusCode\": \"503\", \"messageBody\": \"503 error text\" } } # 重定向 alb.ingress.kubernetes.io/actions.redirect-to-eks: | { \"type\": \"redirect\", \"redirectConfig\": { \"host\": \"aws.amazon.com\", \"path\": \"/eks/\", \"port\": \"443\", \"protocol\": \"HTTPS\", \"query\": \"k=v\", \"statusCode\": \"HTTP_302\" } } # 转发到指定目标组 alb.ingress.kubernetes.io/actions.forward-single-tg: | { \"type\": \"forward\", \"targetGroupARN\": \"arn-of-your-target-group\" } # 按权重转发到目标 alb.ingress.kubernetes.io/actions.forward-multiple-tg: | { \"type\": \"forward\", \"forwardConfig\": { \"targetGroups\": [ { \"serviceName\": \"service-1\", \"servicePort\": \"http\", \"weight\": 20 }, { \"serviceName\": \"service-2\", \"servicePort\": 80, \"weight\": 20 }, { \"targetGroupARN\": \"arn-of-your-non-k8s-target-group\", \"weight\": 60 } ], \"targetGroupStickinessConfig\": { \"enabled\": true, \"durationSeconds\": 200 } } } spec: ingressClassName: alb rules: - http: paths: - path: /503 pathType: Exact backend: service: name: response-503 port: name: use-annotation - path: /eks pathType: Exact backend: service: name: redirect-to-eks port: name: use-annotation - path: /path1 pathType: Exact backend: service: name: forward-single-tg port: name: use-annotation - path: /path2 pathType: Exact backend: service: name: forward-multiple-tg port: name: use-annotation ... 如果操作类型冲突，可以创建Ingress.spec.rules时指定多个记录，如下面301跳转与流量转发示例 [root@localhost alb]# cat alb-ingress.yaml --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: namespace: game-2048-alb-https name: ingress-2048-alb-https annotations: alb.ingress.kubernetes.io/tags: user=xiaosi alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/certificate-arn: | arn:aws:acm:ap-southeast-1:968767926216:certificate/3487a0a2-c072-4eac-8da5-3d3c0f02275e alb.ingress.kubernetes.io/listen-ports: | [ {\"HTTP\": 80}, {\"HTTPS\": 443} ] # http 重定向到 https alb.ingress.kubernetes.io/actions.http-301: | { \"Type\": \"redirect\", \"RedirectConfig\": { \"Protocol\": \"HTTPS\", \"Port\": \"443\", \"Host\": \"#{host}\", \"Path\": \"/#{path}\", \"Query\": \"#{query}\", \"StatusCode\": \"HTTP_301\" } } # 后端转发 alb.ingress.kubernetes.io/actions.service-2048-alb-https: | { \"type\": \"forward\", \"forwardConfig\": { \"targetGroups\": [ { \"serviceName\": \"service-2048-alb-https\", \"servicePort\": 80, \"weight\": 20 } ], \"targetGroupStickinessConfig\": { \"enabled\": true, \"durationSeconds\": 200 } } } spec: ingressClassName: aws-alb tls: - hosts: - game2048s.xiaosi.host rules: - host: game2048s.xiaosi.host http: paths: - path: / pathType: Prefix backend: service: name: http-301 port: name: use-annotation - host: game2048s.xiaosi.host http: paths: - path: / pathType: Prefix backend: service: name: service-2048-alb-https port: name: use-annotation ","date":"2023-06-08","objectID":"/awsEks/:5:5","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 后端地址类型alb.ingress.kubernetes.io/target-type 标签值指定alb通过何种方式把流量转发到后端。有以下值 instance: 流量转发到EC2实例IP，使用该方式 service 类型必须是 NodePort 方式 ip: 流量直接转发到 pod IP ","date":"2023-06-08","objectID":"/awsEks/:5:6","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" alb 属性alb.ingress.kubernetes.io/load-balancer-attributes 指定负载均衡器属性 ","date":"2023-06-08","objectID":"/awsEks/:5:7","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 目标组属性alb.ingress.kubernetes.io/target-group-attributes 指定alb 目标组属性 ","date":"2023-06-08","objectID":"/awsEks/:5:8","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 目标组健康检查 alb.ingress.kubernetes.io/healthcheck-protocol: 指定使用协议，值为 HTTPS 或 HTTP alb.ingress.kubernetes.io/healthcheck-port: 指定目标检测端口，有以下值 指定一个tcp端口，如 80 traffic-port: （默认值）alb.ingress.kubernetes.io/target-type: instance 且 k8s sevice 类型为 NodePort 时自动获取端口 my-port: alb.ingress.kubernetes.io/target-type 值为 instance 或 ip 时自动获取端口 alb.ingress.kubernetes.io/healthcheck-path: 指定请求路径 alb.ingress.kubernetes.io/healthcheck-interval-seconds: 指定健康检查时间间隔，单位为秒 alb.ingress.kubernetes.io/healthcheck-timeout-seconds: 指定健康检查超时时间，单位为秒 alb.ingress.kubernetes.io/success-codes: 指定健康检查正常响应码，如 200。多种响应码使用逗号分隔，如200,201。如果是连续的，可以使用连字符，如 200-230 alb.ingress.kubernetes.io/healthy-threshold-count: 连续多少次探测成功视为健康 alb.ingress.kubernetes.io/unhealthy-threshold-count: 连续多少次探测失败视为不健康 ","date":"2023-06-08","objectID":"/awsEks/:5:9","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" TLSalb.ingress.kubernetes.io/certificate-arn: 指定 tls 证书地址，该证书地址必须是 AWS Certificate Manager 生成的ARN地址。多个地址使用逗号分隔 它等效以下alb.ingress.kubernetes.io/actions规则 alb.ingress.kubernetes.io/listen-ports: | [ {\"HTTP\": 80}, {\"HTTPS\": 443} ] alb.ingress.kubernetes.io/actions.http-301: | { \"Type\": \"redirect\", \"RedirectConfig\": { \"Protocol\": \"HTTPS\", \"Port\": \"443\", \"Host\": \"#{host}\", \"Path\": \"/#{path}\", \"Query\": \"#{query}\", \"StatusCode\": \"HTTP_301\" } } ","date":"2023-06-08","objectID":"/awsEks/:5:10","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" ALB HTTP 示例一创建 IngressClass [root@localhost AwsLoadBalancerController]# cat albIngressClass.yaml apiVersion: networking.k8s.io/v1 kind: IngressClass metadata: labels: app.kubernetes.io/name: aws-load-balancer-controller name: aws-alb spec: controller: ingress.k8s.aws/alb [root@localhost AwsLoadBalancerController]# zjcSingaporeYh apply -f albIngressClass.yaml ingressclass.networking.k8s.io/aws-alb unchanged 创建示例应用 [root@localhost AwsLoadBalancerController]# cat alb-http.yaml --- apiVersion: v1 kind: Namespace metadata: name: game-2048-alb-http --- apiVersion: apps/v1 kind: Deployment metadata: namespace: game-2048-alb-http name: deployment-2048-alb-http spec: selector: matchLabels: app.kubernetes.io/name: app-2048-alb-http replicas: 5 template: metadata: labels: app.kubernetes.io/name: app-2048-alb-http spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: alpha.eksctl.io/nodegroup-name operator: In values: - test tolerations: - key: \"zone\" value: \"ap-southeast-1a\" operator: \"Equal\" - key: \"application\" value: \"test\" operator: \"Equal\" containers: - image: public.ecr.aws/l6m2t8p7/docker-2048:latest imagePullPolicy: Always name: app-2048-alb-http ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: namespace: game-2048-alb-http name: service-2048-alb-http spec: ports: - name: http port: 80 targetPort: 80 protocol: TCP type: LoadBalancer loadBalancerClass: service.k8s.aws/alb selector: app.kubernetes.io/name: app-2048-alb-http --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: namespace: game-2048-alb-http name: ingress-2048-alb-http annotations: alb.ingress.kubernetes.io/tags: user=xiaosi,protocol=http alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip spec: ingressClassName: aws-alb rules: - host: game2048.xiaosi.host http: paths: - path: / pathType: Prefix backend: service: name: service-2048-alb-http port: name: http [root@localhost AwsLoadBalancerController]# zjcSingaporeYh apply -f alb-http.yaml namespace/game-2048-alb-http unchanged deployment.apps/deployment-2048-alb-http unchanged service/service-2048-alb-http unchanged ingress.networking.k8s.io/ingress-2048-alb-http unchanged 查看alb dns，域名解析cnaame 到该 DNS [root@localhost AwsLoadBalancerController]# zjcSingaporeYh -n game-2048-alb-http get ingress ingress-2048-alb-http -o json | jq '.status.loadBalancer' { \"ingress\": [ { \"hostname\": \"k8s-game2048-ingress2-fd8e68509a-912052858.ap-southeast-1.elb.amazonaws.com\" } ] } [root@localhost AwsLoadBalancerController]# curl -I game2048.xiaosi.host HTTP/1.1 200 OK Date: Tue, 01 Aug 2023 08:55:31 GMT Content-Type: text/html Content-Length: 3988 Connection: keep-alive Server: nginx Last-Modified: Wed, 06 Oct 2021 17:35:37 GMT ETag: \"615dde69-f94\" Accept-Ranges: bytes 清理资源 [root@localhost AwsLoadBalancerController]# zjcSingaporeYh delete -f alb-http.yaml namespace \"game-2048-alb-http\" deleted deployment.apps \"deployment-2048-alb-http\" deleted service \"service-2048-alb-http\" deleted ingress.networking.k8s.io \"ingress-2048-alb-http\" deleted ","date":"2023-06-08","objectID":"/awsEks/:6:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" ALB HTTPS 示例一部署 IngressClass [root@localhost yh-eks]# cat albIngressClass.yaml apiVersion: networking.k8s.io/v1 kind: IngressClass metadata: labels: app.kubernetes.io/name: aws-load-balancer-controller name: aws-alb spec: controller: ingress.k8s.aws/alb [root@localhost yh-eks]# zjcSingaporeYh apply -f albIngressClass.yaml ingressclass.networking.k8s.io/aws-alb unchanged 在ACM 控制台中上传TLS证书，获取到ARN地址 创建资源 [root@localhost yh-eks]# cat albIngressClass.yaml apiVersion: networking.k8s.io/v1 kind: IngressClass metadata: labels: app.kubernetes.io/name: aws-load-balancer-controller name: aws-alb spec: controller: ingress.k8s.aws/alb [root@localhost yh-eks]# [root@localhost yh-eks]# cat alb-https.yaml --- apiVersion: v1 kind: Namespace metadata: name: game-2048-alb-https --- apiVersion: apps/v1 kind: Deployment metadata: namespace: game-2048-alb-https name: deployment-2048-alb-https spec: selector: matchLabels: app.kubernetes.io/name: app-2048-alb-https replicas: 5 template: metadata: labels: app.kubernetes.io/name: app-2048-alb-https spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: alpha.eksctl.io/nodegroup-name operator: In values: - test tolerations: - key: \"zone\" value: \"ap-southeast-1a\" operator: \"Equal\" - key: \"application\" value: \"test\" operator: \"Equal\" containers: - image: public.ecr.aws/l6m2t8p7/docker-2048:latest imagePullPolicy: Always name: app-2048-alb-https ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: namespace: game-2048-alb-https name: service-2048-alb-https spec: ports: - name: use-annotation port: 80 targetPort: 80 protocol: TCP type: LoadBalancer loadBalancerClass: service.k8s.aws/alb selector: app.kubernetes.io/name: app-2048-alb-https --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: namespace: game-2048-alb-https name: ingress-2048-alb-https annotations: alb.ingress.kubernetes.io/tags: user=xiaosi alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/certificate-arn: | arn:aws:acm:ap-southeast-1:968767926216:certificate/3487a0a2-c072-4eac-8da5-3d3c0f02275e alb.ingress.kubernetes.io/listen-ports: | [ {\"HTTP\": 80}, {\"HTTPS\": 443} ] alb.ingress.kubernetes.io/actions.service-2048-alb-https: | { \"Type\": \"redirect\", \"RedirectConfig\": { \"Protocol\": \"HTTPS\", \"Port\": \"443\", \"Host\": \"#{host}\", \"Path\": \"/#{path}\", \"Query\": \"#{query}\", \"StatusCode\": \"HTTP_301\" } } spec: ingressClassName: aws-alb rules: - host: game2048s.xiaosi.host http: paths: - path: / pathType: Prefix backend: service: name: service-2048-alb-https port: name: use-annotation [root@localhost yh-eks]# zjcSingaporeYh apply -f alb-https.yaml namespace/game-2048-alb-https created deployment.apps/deployment-2048-alb-https created service/service-2048-alb-https created ingress.networking.k8s.io/ingress-2048-alb-https created ","date":"2023-06-08","objectID":"/awsEks/:7:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 定义 AWS NLB 资源Service.metadata.annotations可用注解在AWS Load Balancer Controller Service Annotations查看完整说明，使用ELB(Network Load Balancers)有以下注意事项 Service.spec.loadBalancerClass: 指定为 ingress.k8s.aws/nlb ","date":"2023-06-08","objectID":"/awsEks/:8:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 资源标签","date":"2023-06-08","objectID":"/awsEks/:8:1","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 是否公有service.beta.kubernetes.io/aws-load-balancer-scheme 注解有以下值： internet-facing: 表示面向互联网 internal: 面向内部，即私有子网 ","date":"2023-06-08","objectID":"/awsEks/:8:2","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 后端地址类型service.beta.kubernetes.io/aws-load-balancer-nlb-target-type 标签值指定nlb通过何种方式把流量转发到后端。有以下值 instance: 流量转发到EC2实例IP，使用该方式 service 类型必须是 NodePort 方式 ip: 流量直接转发到 pod IP ","date":"2023-06-08","objectID":"/awsEks/:8:3","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 路由子网service.beta.kubernetes.io/aws-load-balancer-subnets 注解指定面向上游请求的子网ID，如面向公网，则指定公有子网。默认请问下会根据后端服务可用区自动识别可用子网 service.beta.kubernetes.io/aws-load-balancer-subnets: subnet-0d3e58597af009c84 ","date":"2023-06-08","objectID":"/awsEks/:8:4","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 公网 IP默认情况下，AWS 随机分配公网 IP 地址。可以通过service.beta.kubernetes.io/aws-load-balancer-eip-allocations 注解指定弹性elb使用的EIP ID来分配固定IP，有以下注意事项 service.beta.kubernetes.io/aws-load-balancer-scheme 注解值必须是internet-facing EIP数量必须与nlb路由公有子网数量相同，多个EIP ID 使用逗号分隔 下面是个示例 [root@localhost yh-eks]# cat nlb-service.yaml apiVersion: v1 kind: Service metadata: namespace: nlb-nginx name: service-nlb annotations: service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip service.beta.kubernetes.io/aws-load-balancer-type: external service.beta.kubernetes.io/aws-load-balancer-subnets: subnet-0d3e58597af009c84 service.beta.kubernetes.io/aws-load-balancer-eip-allocations: eipalloc-07ceee1a128133e5f spec: ports: - name: tcp port: 80 targetPort: 80 protocol: TCP type: LoadBalancer loadBalancerClass: service.k8s.aws/nlb selector: app: nginx ","date":"2023-06-08","objectID":"/awsEks/:8:5","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" nlb 属性service.beta.kubernetes.io/aws-load-balancer-attributes 指定负载均衡器属性 service.beta.kubernetes.io/aws-load-balancer-attributes: access_logs.s3.enabled=true,access_logs.s3.bucket=my-access-log-bucket,access_logs.s3.prefix=my-app ","date":"2023-06-08","objectID":"/awsEks/:8:6","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 目标组属性service.beta.kubernetes.io/aws-load-balancer-target-group-attributes 指定nlb 目标组属性 stickiness.enabled=true,stickiness.type=source_ip ","date":"2023-06-08","objectID":"/awsEks/:8:7","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" 目标组健康检查 service.beta.kubernetes.io/aws-load-balancer-healthcheck-protocol: 指定与后端服务进行健康检查使用的协议 可用值有 tcp（默认值）、http、https 当 Service.spec.externalTrafficPolicy: Cluster 默认值为 tcp 当 Service.spec.externalTrafficPolicy: Local 值不能为 tcp，它默认值为 http service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: 指定与后端服务进行检查检查使用的端口 service.beta.kubernetes.io/aws-load-balancer-healthcheck-healthy-threshold: 连续多少次探测成功视为健康 service.beta.kubernetes.io/aws-load-balancer-healthcheck-unhealthy-threshold: 连续多少次探测失败视为不健康 service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval: 指定健康检查时间间隔，单位为秒 service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout: 指定健康检查超时时间，单位为秒 service.beta.kubernetes.io/aws-load-balancer-healthcheck-path: 指定http[s]检测路径，默认值为/healthz service.beta.kubernetes.io/aws-load-balancer-healthcheck-success-codes: 指定http[s] 指定健康检查正常响应码，如 200。多种响应码使用逗号分隔，如200,201。如果是连续的，可以使用连字符，如 200-230 service.beta.kubernetes.io/aws-load-balancer-ssl-cert: 与后端服务使用HTTPS进行健康时使用的TLS证书地址，该证书地址必须是 AWS Certificate Manager 生成的ARN地址。多个地址使用逗号分隔 ","date":"2023-06-08","objectID":"/awsEks/:8:8","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" NLB 示例NLB 由 service 资源引用，以下是示例 [root@localhost AwsLoadBalancerController]# cat game-2048-elb.yaml --- apiVersion: v1 kind: Namespace metadata: name: game-2048-elb --- apiVersion: apps/v1 kind: Deployment metadata: namespace: game-2048-elb name: deployment-2048-elb spec: selector: matchLabels: app.kubernetes.io/name: app-2048-elb replicas: 5 template: metadata: labels: app.kubernetes.io/name: app-2048-elb spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: alpha.eksctl.io/nodegroup-name operator: In values: - test tolerations: - key: \"zone\" value: \"ap-southeast-1a\" operator: \"Equal\" - key: \"application\" value: \"test\" operator: \"Equal\" containers: - image: public.ecr.aws/l6m2t8p7/docker-2048:latest imagePullPolicy: Always name: app-2048-elb ports: - name: tcp containerPort: 80 --- apiVersion: v1 kind: Service metadata: namespace: game-2048-elb name: service-2048-elb annotations: service.beta.kubernetes.io/aws-load-balancer-type: external service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing spec: ports: - port: 80 targetPort: 80 protocol: TCP type: LoadBalancer selector: app.kubernetes.io/name: app-2048-elb 部署资源 [root@localhost AwsLoadBalancerController]# zjcSingaporeYh apply -f game-2048-elb.yaml namespace/game-2048-elb unchanged deployment.apps/deployment-2048-elb unchanged service/service-2048-elb created 检查资源运行状况 [root@localhost AwsLoadBalancerController]# zjcSingaporeYh -n game-2048-elb get pod,service NAME READY STATUS RESTARTS AGE pod/deployment-2048-elb-7ff4bc8674-4vh8j 1/1 Running 0 11m pod/deployment-2048-elb-7ff4bc8674-8l5w5 1/1 Running 0 11m pod/deployment-2048-elb-7ff4bc8674-bsxg2 1/1 Running 0 11m pod/deployment-2048-elb-7ff4bc8674-gl5rt 1/1 Running 0 11m pod/deployment-2048-elb-7ff4bc8674-ktlk5 1/1 Running 0 11m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/service-2048-elb LoadBalancer 10.100.10.216 k8s-game2048-service2-45fa707215-5dcf47f226fcbff8.elb.ap-southeast-1.amazonaws.com 80:30018/TCP 9m51s 尝试请求 [root@localhost AwsLoadBalancerController]# curl -I k8s-game2048-service2-45fa707215-5dcf47f226fcbff8.elb.ap-southeast-1.amazonaws.com HTTP/1.1 200 OK Server: nginx Date: Fri, 28 Jul 2023 14:36:11 GMT Content-Type: text/html Content-Length: 3988 Last-Modified: Wed, 06 Oct 2021 17:35:37 GMT Connection: keep-alive ETag: \"615dde69-f94\" Accept-Ranges: bytes 控制层面日志集群控制层面日志不会发送到 CloudWatch Logs 中。必须单独启用每个日志类型来为集群发送日志 # 版本必须大于 16.139 [root@localhost ~]# aws --version aws-cli/2.13.1 Python/3.11.4 Linux/3.10.0-1160.92.1.el7.x86_64 exe/x86_64.centos.7 prompt/off 以下集群控制层面日志类型可用。每个日志类型对应一个 Kubernetes 控制面板组件 api: 集群的 API server audit: 审计日志提供单个用户、管理员或影响集群的系统组件的记录 authenticator: 身份验证器日志对于 Amazon EKS 是唯一的。这些日志代表 Amazon EKS 使用 IAM 凭证用于 Kubernetes 基于角色的访问控制 (RBAC, Role based access control) 身份验证的控制面板组件 controllerManager: kube-controller-manager 日志 scheduler: kube-scheduler日志 使用 aws 命令启用相关日志 [root@localhost ~]# aws eks update-cluster-config \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --name \"yh-eks\" \\ --logging '{\"clusterLogging\":[{\"types\":[\"api\",\"audit\",\"authenticator\",\"controllerManager\",\"scheduler\"],\"enabled\":true}]}' { \"update\": { \"id\": \"53156b6d-3417-4975-ae32-06acc9614767\", \"status\": \"InProgress\", \"type\": \"LoggingUpdate\", \"params\": [ { \"type\": \"ClusterLogging\", \"value\": \"{\\\"clusterLogging\\\":[{\\\"types\\\":[\\\"api\\\",\\\"audit\\\",\\\"authenticator\\\",\\\"controllerManager\\\",\\\"scheduler\\\"],\\\"enabled\\\":true}]}\" } ], \"createdAt\": \"2023-07-30T15:26:03.362000+08:00\", \"errors\": [] } } 可以根据上面的.update.id 字段值查看状态，当 update.status 字段值为 Successful 表示成功。可以在相同区域中 的CloudWatch 日志组（/aws/eks/eksname/cluster）查看日志 [root@localhost ~]# aws eks describe-update \\ --profile \"zjc-yuhai\" \\ --region \"ap-southeast-1\" \\ --name \"yh-eks\" \\ --update-id \"53156b6d-3417-4975-ae32-06acc9614767\" { \"update\": { \"id\": \"53156b6d-3417-4975-ae32-06acc9614767\", \"status\": \"Successful\", \"type\": \"LoggingUpdate\", \"params","date":"2023-06-08","objectID":"/awsEks/:9:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["aws"],"content":" Failed build model due to unable to resolve at least one subnet (0 match VPC and tags) 错误情况 LoadBalancer 处于 pending 状态 [root@localhost prometheus]# kubectl get -f grafanaService.yaml NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE grafana LoadBalancer 172.20.127.75 \u003cpending\u003e 80:31943/TCP 87s 事件显示没有指定vpc子网 [root@localhost prometheus]# kubectl describe service grafana -n prometheus Name: grafana ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedBuildModel 118s service Failed build model due to unable to resolve at least one subnet (0 match VPC and tags) 原因：子网缺少以下标签，aws-load-balancer-controller自动识别子网失败 私有子网：kubernetes.io/role/internal-elb: 1 公有子网：kubernetes.io/role/elb: 1 解决：对应子网添加相应标签后，重新部署资源 ","date":"2023-06-08","objectID":"/awsEks/:10:0","tags":["eks","aws"],"title":"eks","uri":"/awsEks/"},{"categories":["k8s"],"content":" 运行环境： calico: 3.25.1 k8s: 1.27 内容来自以下文档： calico 官方文档 安装最新版Calico calico 安装字段说明 Kubernetes 上的 Calico 快速入门 为 k8s 安装 calico 网络插件 下载 yaml 文件 wget https://raw.githubusercontent.com/projectcalico/calico/v3.25.1/manifests/calico-etcd.yaml 根据calico 安装字段说明修改yaml文件 [root@node01 ~]# vi calico-etcd.yaml ... # 修改 Secret 资源 --- # Source: calico/templates/calico-etcd-secrets.yaml # The following contains k8s Secrets for use with a TLS enabled etcd cluster. # For information on populating Secrets, see http://kubernetes.io/docs/user-guide/secrets/ apiVersion: v1 kind: Secret type: Opaque metadata: name: calico-etcd-secrets namespace: kube-system data: # Populate the following with etcd TLS configuration if desired, but leave blank if # not using TLS for etcd. # The keys below should be uncommented and the values populated with the base64 # encoded contents of each file that would be associated with the TLS data. # Example command for encoding a file contents: cat \u003cfile\u003e | base64 -w 0 # etcd 集群的 TLS 证书默认在 /etc/kubernetes/pki/etcd/ etcd-key: LS0tLS1CRUdJTiB... # 指定 etcd 集群密钥（base64编码格式） etcd-cert: LS0tLS1CRUdJTiB... # 指定 etcd 集群公钥（base64编码格式） etcd-ca: LS0tLS1CRUdJ... # 指定 etcd 集群CA 公钥（ase64编码格式） --- # Source: calico/templates/calico-config.yaml # This ConfigMap is used to configure a self-hosted Calico installation. kind: ConfigMap apiVersion: v1 metadata: name: calico-config namespace: kube-system data: # Configure this with the location of your etcd cluster. # 指定 etcd 地址 etcd_endpoints: \"https://192.168.232.101:2379,https://192.168.232.102:2379,https://192.168.232.103:2379\" # If you're using TLS enabled etcd uncomment the following. # You must also populate the Secret below with these files. # 以下是证书挂在位置，不需要修改 etcd_key: \"/calico-secrets/etcd-key\" etcd_ca: \"/calico-secrets/etcd-ca\" etcd_cert: \"/calico-secrets/etcd-cert\" etcd_key: \"/calico-secrets/etcd-key\" .... --- # Source: calico/templates/calico-node.yaml # This manifest installs the calico-node container, as well # as the CNI plugins and network config on # each master and worker node in a Kubernetes cluster. kind: DaemonSet apiVersion: apps/v1 metadata: name: calico-node namespace: kube-system labels: k8s-app: calico-node spec: .... # calico-node 容器中添加或修改以下变量 # 指定 pod IP 地址范围，有以下要求 # 范围不能超过 kube-controller-manager --cluster-cidr 指定的范围 # 不能与其它 k8s 网络插件 冲突 - name: CALICO_IPV4POOL_CIDR value: \"192.168.0.0/16\" # k8s api server 地址，如果有代理（如高可用）则为代理地址 - name: KUBERNETES_SERVICE_HOST value: \"192.168.232.100\" # k8s api server http 端口 - name: KUBERNETES_SERVICE_PORT value: \"6443\" # k8s api server https 端口 - name: KUBERNETES_SERVICE_PORT_HTTPS value: \"6443\" # 检测此主机的 IPv4 地址的方法 - name: IP_AUTODETECTION_METHOD value: \"interface=ens160\" ... 部署 [root@node01 ~]# kubectl apply -f calico-etcd.yaml poddisruptionbudget.policy/calico-kube-controllers configured serviceaccount/calico-kube-controllers unchanged serviceaccount/calico-node unchanged secret/calico-etcd-secrets unchanged configmap/calico-config unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node created deployment.apps/calico-kube-controllers created 确认部署的 pod 都在运行 [root@node01 ~]# kubectl get pod -n kube-system | grep calico calico-kube-controllers-c4d664d7-svnv2 1/1 Running 0 2m26s calico-node-6sw54 1/1 Running 0 2m26s calico-node-99qjf 1/1 Running 0 2m26s calico-node-jmn8r 1/1 Running 0 2m26s calico-node-mwlvc 1/1 Running 0 2m26s calico-node-vbgjp 1/1 Running 0 2m26s ","date":"2023-06-04","objectID":"/calicoForKubernets/:0:0","tags":["cni","k8s","calico"],"title":"k8s 网络插件 calico","uri":"/calicoForKubernets/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.27 内容来自以下文档： k8s 官方文档：Deployments deploymentdeployment 为 pod 和 ReplicaSet 提供声明式更新，只需要在 deployment 中描述想要的目标是什么，deployment 会自动将 pod 和 ReplocaSet 的实际状态，也可以定义一个全新的 deployment 来创建 ReplicaSet 或删除已有的 deployment 并创建一个新的来替换。 注意：不该手动由 deployment 创建的 ReplicaSet 典型的用例： 用 deployment 来创建 ReplicaSet。ReplicaSet 在后台创建 pod 。检查启动状态，看是否成功 然后，通过更新 deployment 的 .sepc.template.spec 字段来声明 pod 的状态，这会创建一个新的 ReplicaSet，deployment 会按照控制的速率将 pod 从旧的 ReplicaSet 移动到新的 ReplicaSet 中 如果当前状态不稳定，回滚到之前在 deployment revision，每次回滚都会更新 deployment 的 revision 扩容 deployment 满足更高的负载 暂停 deployment 来修复应用 Pod 副本，然后恢复上线 根据 deployment 的状态判断上线是否能撑住 清除旧的不必要的 ReplicaSet 定义 podDeployment是使用ReplicaSet创建的pod。以下是 calico 网络插件使用的 Deployment 资源 [root@node01 ~]# kubectl -n kube-system get ReplicaSet | grep calico-kube-controllers calico-kube-controllers-c4d664d7 1 1 1 27d [root@node01 ~]# kubectl -n kube-system get Deployments calico-kube-controllers -o yaml apiVersion: apps/v1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: \"1\" kubectl.kubernetes.io/last-applied-configuration: | {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",...} creationTimestamp: \"2023-04-30T19:54:02Z\" generation: 1 labels: k8s-app: calico-kube-controllers name: calico-kube-controllers namespace: kube-system resourceVersion: \"465394\" uid: d9df2c34-39f2-4fdd-9cc9-06de728ecf31 spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: k8s-app: calico-kube-controllers strategy: type: Recreate template: metadata: creationTimestamp: null labels: k8s-app: calico-kube-controllers name: calico-kube-controllers namespace: kube-system spec: containers: - env: - name: ETCD_ENDPOINTS valueFrom: configMapKeyRef: key: etcd_endpoints name: calico-config - name: ETCD_CA_CERT_FILE valueFrom: configMapKeyRef: key: etcd_ca name: calico-config - name: ETCD_KEY_FILE valueFrom: configMapKeyRef: key: etcd_key name: calico-config - name: ETCD_CERT_FILE valueFrom: configMapKeyRef: key: etcd_cert name: calico-config - name: ENABLED_CONTROLLERS value: policy,namespace,serviceaccount,workloadendpoint,node image: docker.io/calico/kube-controllers:v3.25.1 imagePullPolicy: IfNotPresent livenessProbe: exec: command: - /usr/bin/check-status - -l failureThreshold: 6 initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 10 name: calico-kube-controllers readinessProbe: exec: command: - /usr/bin/check-status - -r failureThreshold: 3 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /calico-secrets name: etcd-certs dnsPolicy: ClusterFirst hostNetwork: true nodeSelector: kubernetes.io/os: linux priorityClassName: system-cluster-critical restartPolicy: Always schedulerName: default-scheduler securityContext: {} serviceAccount: calico-kube-controllers serviceAccountName: calico-kube-controllers terminationGracePeriodSeconds: 30 tolerations: - key: CriticalAddonsOnly operator: Exists - effect: NoSchedule key: node-role.kubernetes.io/master - effect: NoSchedule key: node-role.kubernetes.io/control-plane volumes: - name: etcd-certs secret: defaultMode: 288 secretName: calico-etcd-secrets ... Deployment.spec.template: 该字段是必选值，它定义pod的模板，与pod定义语法基本相同，只是不需要定义apiVersion或kind字段 Deployment.spec.replicas: 该字段定义 pod 数量 Deployment.spec.selector: 该字段是必选值，它定义归属与当前当前控制器所管理pod的标签。注意： Deployment.spec.selector 字段必须匹配 Deployment.spec.template.metadata.labels 字段，否则请求会被apiserver拒绝 k8s 通过标签选择器确定pod数量，因此，手动创建对应的标签的pod，也会视为控制器创建 如果多个控制器标签选择器发生冲突，即pod被多个控制器管理，则控制器之间会因冲突而无法正常工作 ","date":"2023-05-28","objectID":"/k8sDeployment/:0:0","tags":["k8s","Deployment"],"title":"k8s Deployment 控制器","uri":"/k8sDeployment/"},{"categories":["k8s"],"content":" 最小就绪时间与部署超时时间Deployment.spec.progressDeadlineSeconds 字段指定处于为完成状态最长时间(秒)，当超过该时间后，修改Deployment状态为失败。该值默认为600s。失败后Deployment控制器会添加以下状态字段。此后k8s对已停止的 Deployment 不执行任何操作。 Deployment.status.controllers.replicas: ProgressDeadlineExceeded Deployment.status.controllers.status: \"True\" Deployment.status.controllers.type: Progressing 如果指定了部署超时时间，则指定的时间不能小于就绪时间，Deployment.spec.minReadySeconds 字段指定pod就绪状态保持时间(秒)，当超过该时间后才认为pod可用。默认时间为0，即pod进入就绪状态后就视为可用。 扩缩 pod调整 pod 数量为以下方式： 修改Deployment.spec.replicas 字段值 为 Deployment 设置自动缩放器实现水平扩缩 更新与回滚仅pod模板（Deployment.spec.template）发生改变时，才会触发更新操作，产生新的ReplicaSet控制器资源创建pod。更新过程受以下字段影响 Deployment.spec.strategy.type: 该字段指定更新策略，有以下值 Recreate: 重建pod。在新建pod前终止现有pod RollingUpdate: 滚动更新（默认值）。先扩展一定数量新的pod，再缩减旧一部分旧的pod，循环操作，直到完成更新 Deployment.spec.strategy.rollingUpdate: 该字段仅在使用滚动更新时有效，用于指定扩缩比例。有以下值 maxSurge: 最大pod数量或百分比，如果为比列会换成数值，默认为25% maxUnavailable: 最大不可用 Pod 数量或百分比，如果为比列会换成数值，默认为25% k8s在计算可用pod数量时不会计算终止过程中的pod数量，因此会出现pod实际数量比maxSurge字段值高 ","date":"2023-05-28","objectID":"/k8sDeployment/:1:0","tags":["k8s","Deployment"],"title":"k8s Deployment 控制器","uri":"/k8sDeployment/"},{"categories":["k8s"],"content":" 暂停更新与恢复更新暂停更新可用于修改更新，只有恢复更新后才会接下来的操作 # 暂停现在的更新 kubectl rollout pause deployment/... # 恢复更新 kubectl rollout resume deployment/... ","date":"2023-05-28","objectID":"/k8sDeployment/:2:0","tags":["k8s","Deployment"],"title":"k8s Deployment 控制器","uri":"/k8sDeployment/"},{"categories":["k8s"],"content":" 保留版本与回滚Deployment控制器使用ReplicaSet控制器实现回滚的，Deployment.spec.revisionHistoryLimit 字段指定保留的历史ReplicaSet控制器用于回滚，默认为10，即保留最近10次Deployment控制器修改记录。旧 ReplicaSet 会消耗 etcd 中的资源。如果值为0意味着Deployment无法使用回滚功能 # 查看 Deployment 修订历史 kubectl rollout history deployment/... # 选择回滚 kubectl rollout undo deployment/nginx-deployment --to-revision=2 状态Deployment.status.conditions下的type、status、reason字段描述了Deployment状态信息 status: availableReplicas: 1 conditions: - lastTransitionTime: \"2023-04-30T19:54:02Z\" lastUpdateTime: \"2023-04-30T19:55:20Z\" message: ReplicaSet \"calico-kube-controllers-c4d664d7\" has successfully progressed. reason: NewReplicaSetAvailable status: \"True\" type: Progressing - lastTransitionTime: \"2023-05-28T05:02:42Z\" lastUpdateTime: \"2023-05-28T05:02:42Z\" message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: \"True\" type: Available observedGeneration: 1 readyReplicas: 1 replicas: 1 updatedReplicas: 1 当执行以下任务时，Deployment标记为Progressing状态（进行中）： Deployment 创建新的 ReplicaSet Deployment 正在为其最新的 ReplicaSet 扩容 Deployment 正在为其旧有的 ReplicaSet(s) 缩容 新的 Pod 已经可用 当进入Progressing状态时，Deployment 控制器会向 Deployment.status.conditions 中添加包含下面属性的状况条目 type: Progressing status: \"True\" reason: NewReplicaSetCreated | reason: FoundNewReplicaSet | reason: ReplicaSetUpdated 当 Deployment 具有以下特征时，将其标记为Complete状态（已完成）: 与 Deployment 关联的所有副本都已更新到指定的最新版本，这意味着之前请求的所有更新都已完成。 与 Deployment 关联的所有副本都可用。 未运行 Deployment 的旧副本 当进入complete状态时，Deployment 控制器会向 Deployment.status.conditions 中添加包含下面属性的状况条目 type: Progressing status: \"True\" reason: NewReplicaSetAvailable Deployment 可能会在尝试部署其最新的 ReplicaSet 受挫，一直处于Failed状态。 造成此情况一些可能因素如下 配额（Quota）不足 就绪探测（Readiness Probe）失败 镜像拉取错误 权限不足 限制范围（Limit Ranges）问题 应用程序运行时的配置错误 操作","date":"2023-05-28","objectID":"/k8sDeployment/:3:0","tags":["k8s","Deployment"],"title":"k8s Deployment 控制器","uri":"/k8sDeployment/"},{"categories":["k8s"],"content":" 查看指定名称空间中的deployment资源列表 PS 2023/06/23 12:59:52 \u003e curl.exe -s --cert .\\xiaosi.crt --key .\\xiaosi.key --cacert .\\ca.crt ` \u003e\u003e -X GET https://192.168.232.100:6443/apis/apps/v1/namespaces/nginx-ingress/deployments ` \u003e\u003e | jq-win64.exe --color-output '.items[].metadata.name' \"nginx-ingress\" ","date":"2023-05-28","objectID":"/k8sDeployment/:4:0","tags":["k8s","Deployment"],"title":"k8s Deployment 控制器","uri":"/k8sDeployment/"},{"categories":["aws"],"content":" 内容来自以下文档： IAM JSON 策略元素参考 AWS CLI IAM 策略文档策略文档是 json 格式，由以下部分组成 Version: 必选字段，指定策略语言的版本，值为2012-10-17或2008-10-17 Id: 可选字段，指定标识符，某些产品可能要求唯一 Statement: 必选字段，指定策略元素数组，有以下元素 Sid: 可选字段，指定标签符，策略文件中要求唯一 Effect: 必选字段，指定策略为允许(Allow)或拒绝(Deny) Principal: 必选字段，指定访问资源的主体 NotPrincipal: 可选字段，指定策略排他性 Action: Action 或 NotAction 字段必选其一，指定操作 NotAction: 可选字段，指定操作排他性 Resource: Resource 或 NotResource 字段必选其一，指定资源对象 NotResource: 可选字段，指定资源对象排他性 Condition: 可选字段，指定策略生效的条件 ","date":"2023-05-24","objectID":"/awsIam/:0:0","tags":["iam"],"title":"使用 AIM 安全地控制对 AWS 资源的访问","uri":"/awsIam/"},{"categories":["aws"],"content":" Principal基于资源的策略必须使用 Principal 字段，且无法在基于身份的策略中使用。可以在策略中指定以下任意主体，当存到多个主体时，它们逻辑关系是或： AWS 服务：为 AWS 服务预定所需的IAM角色，打开使用IAM 的AWS服务，检查服务在 Service-linked role（服务相关角色）列中是否具有 Yes，然后打开 Yes（是）链接以查看该服务的服务相关角色文档 AWS 账户 IAM 角色 IAM 用户 角色会话 联合身份用户会话 所有主体 以下是官方文档给出的示例 # AWS 账户 \"Principal\": { \"AWS\": \"arn:aws:iam::123456789012:root\" } # AWS 账户，等效上面 \"Principal\": { \"AWS\": \"123456789012\" } \"Principal\": { \"AWS\": [ \"arn:aws:iam::123456789012:root\", \"999999999999\" ], # 规范用户 ID \"CanonicalUser\": \"79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be\" } # IAM 用户 \"Principal\": { \"AWS\": [ \"arn:aws:iam::AWS-account-ID:user/user-name-1\", \"arn:aws:iam::AWS-account-ID:user/user-name-2\" ] } # AWS 服务 \"Principal\": { \"Service\": [ \"ecs.amazonaws.com\", \"elasticloadbalancing.amazonaws.com\" ] } IAM 用户 [root@localhost ~]# aws sts get-caller-identity | jq . { \"UserId\": \"AIDATIE4A5KS5IXIT2O2G\", \"Account\": \"223665515173\", \"Arn\": \"arn:aws:iam::223665515173:user/xiaosi\" } ","date":"2023-05-24","objectID":"/awsIam/:1:0","tags":["iam"],"title":"使用 AIM 安全地控制对 AWS 资源的访问","uri":"/awsIam/"},{"categories":["aws"],"content":" 密码 查看密码策略 [cloudshell-user@ip-10-6-33-126 ~]$ aws iam get-account-password-policy { \"PasswordPolicy\": { \"MinimumPasswordLength\": 22, \"RequireSymbols\": true, \"RequireNumbers\": true, \"RequireUppercaseCharacters\": true, \"RequireLowercaseCharacters\": true, \"AllowUsersToChangePassword\": true, \"ExpirePasswords\": true, \"MaxPasswordAge\": 1, \"PasswordReusePrevention\": 6, \"HardExpiry\": false } } ","date":"2023-05-24","objectID":"/awsIam/:2:0","tags":["iam"],"title":"使用 AIM 安全地控制对 AWS 资源的访问","uri":"/awsIam/"},{"categories":["aws"],"content":" 查看用户权限 # 托管策略 [root@localhost ~]# aws iam list-attached-user-policies --user-name xiaosi --profile \"xiaosi:ap-southeast-1\" { \"AttachedPolicies\": [ { \"PolicyName\": \"AdministratorAccess\", \"PolicyArn\": \"arn:aws:iam::aws:policy/AdministratorAccess\" } ] } # 用户定义策略 [root@localhost ~]# aws iam list-user-policies --user-name xiaosi --profile \"xiaosi\" | jq . { \"PolicyNames\": [] } [root@localhost ~]# aws iam get-policy --policy-arn \"arn:aws:iam::aws:policy/AdministratorAccess\" --profile \"xiaosi:ap-southeast-1\" { \"Policy\": { \"PolicyName\": \"AdministratorAccess\", \"PolicyId\": \"ANPAIWMBCKSKIEE64ZLYK\", \"Arn\": \"arn:aws:iam::aws:policy/AdministratorAccess\", \"Path\": \"/\", \"DefaultVersionId\": \"v1\", \"AttachmentCount\": 7, \"PermissionsBoundaryUsageCount\": 0, \"IsAttachable\": true, \"Description\": \"Provides full access to AWS services and resources.\", \"CreateDate\": \"2015-02-06T18:39:46+00:00\", \"UpdateDate\": \"2015-02-06T18:39:46+00:00\", \"Tags\": [] } } [root@localhost ~]# aws iam get-policy-version --policy-arn \"arn:aws:iam::aws:policy/AdministratorAccess\" --version-id v1 --profile \"xiaosi\" | jq . { \"PolicyVersion\": { \"Document\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"*\", \"Resource\": \"*\" } ] }, \"VersionId\": \"v1\", \"IsDefaultVersion\": true, \"CreateDate\": \"2015-02-06T18:39:46+00:00\" } } ","date":"2023-05-24","objectID":"/awsIam/:3:0","tags":["iam"],"title":"使用 AIM 安全地控制对 AWS 资源的访问","uri":"/awsIam/"},{"categories":["aws"],"content":" 绑定策略","date":"2023-05-24","objectID":"/awsIam/:4:0","tags":["iam"],"title":"使用 AIM 安全地控制对 AWS 资源的访问","uri":"/awsIam/"},{"categories":["aws"],"content":" 判断权限 aws iam simulate-principal-policy --policy-source-arn \u003c用户ARN或角色ARN\u003e --action-names \u003c要检查的权限操作\u003e --resource-arns \u003c资源ARN\u003e V1 版本 { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"Statement1\", \"Effect\": \"Deny\", \"Action\": [ \"account:GetAccountInformation\", # 授予检索账户信息的权限 \"account:GetContactInformation\", # 授予权限以检索账户的主要联系人信息 \"account:PutContactInformation\", # 授予权限以更新账户的主要联系人信息 \"billing:Get*\", \"billing:PutContractInformation\",# 授予设置账户合同信息、最终用户组织名称，以及账户是否用于为公共部门客户提供服务的权限 \"billing:RedeemCredits\", # 授予兑换AWS服务抵扣金的权限 \"consolidatedbilling:GetAccountBillingRole\", # 授予获取账户角色（付款人、关联角色、常规）的权限 \"invoicing:Get*\", \"payments:CreatePaymentInstrument\", # 授予创建付款方式的权限 \"payments:DeletePaymentInstrument\", # 授予删除付款方式的权限 \"payments:Get*\", \"payments:List*\", \"payments:Make*\", \"payments:Update*\", \"payments:UpdatePaymentPreferences\", # 授予更新付款偏好（首选付款货币、首选付款方式等）的权限 \"purchase-orders:ListPurchaseOrderInvoices\", # 授予列出采购订单发票的权限 \"purchase-orders:ListPurchaseOrders\", # 授予列出账户所有采购订单的权限 \"support:AddAttachmentsToSet\", # 授予向 AWS Support 案例添加一个或多个附件的权限 \"support:CreateCase\", # 授予创建新 AWS Support 案例的权限 \"tax:BatchPut*\", \"tax:Delete*\", \"tax:Get*\", \"tax:List*\", \"tax:ListTaxRegistrations\", # 授予查看税务登记的权限 \"tax:Put*\", \"tax:PutTaxRegistration\", # 授予权限以更新税登记数据 \"tax:UpdateExemptions\" # 授予更新免税数据的权限 ], \"Resource\": [ \"*\" ] } ] } aa account:PutAlternateContact # 修改账户的备用联系人 account:PutContactInformation # 更新账户的主要联系人信息 billing:GetBillingPreferences # 查看账单首选项的权限 billing:GetCredits # 查看已兑换的服务抵扣金的权限 billing:PutContractInformation # 置账户合同信息、最终用户组织名称，以及账户是否用于为公共部门客户提供服务的权限 billing:RedeemCredits # 兑换AWS服务抵扣金的权限 billing:UpdateBillingPreferences # 更新账单首选项的权限 billing:UpdateIAMAccessPreference # 更新“允许 IAM 访问”账单首选项的权限 budgets:CreateBudgetAction budgets:DeleteBudgetAction budgets:DescribeBudgetAction budgets:DescribeBudgetActionHistories budgets:DescribeBudgetActionsForAccount budgets:DescribeBudgetActionsForBudget budgets:ExecuteBudgetAction budgets:ModifyBudget budgets:UpdateBudgetAction budgets:ViewBudget ce:CreateCostCategoryDefinition ce:DeleteCostCategoryDefinition ce:DescribeCostCategoryDefinition ce:GetCostAndUsage ce:ListCostAllocationTags ce:ListCostCategoryDefinitions ce:ListTagsForResource ce:TagResource ce:UntagResource ce:UpdateCostAllocationTagsStatus ce:UpdateCostCategoryDefinition consolidatedbilling:Get* consolidatedbilling:GetAccountBillingRole consolidatedbilling:List* cur:DeleteReportDefinition cur:DescribeReportDefinitions cur:Get* cur:GetClassic* cur:GetUsage* cur:ModifyReportDefinition cur:PutClassic* cur:PutReportDefinition cur:Validate* freetier:Get freetier:Get* freetier:Put* invoicing:Get* invoicing:List* invoicing:Put* payments:CreatePaymentInstrument payments:DeletePaymentInstrument payments:Get* payments:GetPaymentInstrument payments:GetPaymentStatus payments:List* payments:Make* payments:Update* payments:UpdatePaymentPreferences pricing:DescribeServices purchase-orders:AddPurchaseOrder purchase-orders:DeletePurchaseOrder purchase-orders:GetPurchaseOrder purchase-orders:ListPurchaseOrderInvoices purchase-orders:ListPurchaseOrders purchase-orders:UpdatePurchaseOrder purchase-orders:UpdatePurchaseOrderStatus s3:CreateBucket s3:GetBucketLocation s3:ListAllMyBuckets s3:PutBucketPolicy support:AddAttachmentsToSet support:CreateCase sustainability:GetCarbonFootprintSummary tax:BatchPut* tax:Delete* tax:Get* tax:List* tax:ListTaxRegistrations tax:Put* tax:PutTaxRegistration tax:UpdateExemptions IAM 用户权限 \"iam:UpdateLoginProfile\", # \"iam:DeleteAccessKey\", \"iam:ListMFADevices\", \"iam:GetLoginProfile\", \"iam:ChangePassword\", \"iam:CreateAccessKey\", \"iam:ListAccessKeys\" \"iam:GetUser # 查看用户ARN 创建日期等 \"iam:ListUserPolicies # 查看权限 ","date":"2023-05-24","objectID":"/awsIam/:5:0","tags":["iam"],"title":"使用 AIM 安全地控制对 AWS 资源的访问","uri":"/awsIam/"},{"categories":["aws"],"content":" 内容来自以下文档： [name][name] [name]: error","date":"2023-05-19","objectID":"/awsOrganization/:0:0","tags":["aws","organization"],"title":"组织多账户管理","uri":"/awsOrganization/"},{"categories":["aws"],"content":" 成员账户无法下载 CSV 报告。如果您需要其他数据，请联系您的管理账户管理员成员账户下载账单文件.csv时出现以下报错 ","date":"2023-05-19","objectID":"/awsOrganization/:1:0","tags":["aws","organization"],"title":"组织多账户管理","uri":"/awsOrganization/"},{"categories":["aws"],"content":" 运行环境： awscli: 2 内容来自以下文档： [AWS CloudFormation 用户指南][AWS CloudFormation 用户指南] 查看查看堆栈名与状态 [root@localhost ~]# aws cloudformation list-stacks --profile \"xiaosi\" --region \"ap-southeast-1\" | jq \"[.StackSummaries[] | {StackName,StackStatus}]\" [ { \"StackName\": \"eksctl-attractive-painting-1686793950-cluster\", \"StackStatus\": \"DELETE_COMPLETE\" }, { \"StackName\": \"eksctl-eks03-nodegroup-ng-785ac8ef\", \"StackStatus\": \"CREATE_COMPLETE\" }, { \"StackName\": \"eksctl-eks03-cluster\", \"StackStatus\": \"CREATE_COMPLETE\" }, ... 查看指定堆栈名的状态、创建时间、唯一标识符号 [root@localhost ~]# aws cloudformation list-stacks --profile \"xiaosi\" --region \"ap-southeast-1\" | \\ jq '.StackSummaries[] | select(.StackName == \"eksctl-eks01-cluster\") | {StackName,StackStatus,CreationTime,StackId} ' { \"StackName\": \"eksctl-eks01-cluster\", \"StackStatus\": \"CREATE_COMPLETE\", \"CreationTime\": \"2023-07-23T08:40:42.974000+00:00\", \"StackId\": \"arn:aws:cloudformation:ap-southeast-1:223665515173:stack/eksctl-eks01-cluster/9c18e720-2934-11ee-926b-0288e98b54b2\" } { \"StackName\": \"eksctl-eks01-cluster\", \"StackStatus\": \"DELETE_COMPLETE\", \"CreationTime\": \"2023-06-13T02:25:56.125000+00:00\", \"StackId\": \"arn:aws:cloudformation:ap-southeast-1:223665515173:stack/eksctl-eks01-cluster/a056e020-0991-11ee-a9b1-02cee91e39c4\" } ","date":"2023-05-15","objectID":"/awsCloudFormationCli/:0:0","tags":["aws","CloudFormation"],"title":"aws CloudFormation 相关命令行","uri":"/awsCloudFormationCli/"},{"categories":["aws"],"content":" 运行环境： awscli: 2 内容来自以下文档： AWS CloudFormation 用户指南 ScalingProcesses.member.N CloudFormationAWS CloudFormation 可以通过模板文件快速部署 aws 资源。 模板文件可以是.ymal、.json、.txt结尾，但必须使用以下格式 ECMA-404 JSON 标准 支持yaml v1.1，除了以下功能 binary、omap、pairs、set 和 timestamp Aliases 哈希合并 模板文件是保存在S3 中。虽然可以引用本地模板文件，但 CloudFormation 会将其上传到您 AWS 账户中的 S3 桶。CloudFormation 为您上传模板文件的每个区域创建一个桶。具有您 AWS 账户中 Amazon Simple Storage Service（Amazon S3）权限的任何人均可访问桶。如果 CloudFormation 创建的存储桶已存在，则将模板添加到该存储桶。 模板文件格式以下是模板文件组成部分 AWSTemplateFormatVersion 可选字段，定义的模板格式版本，只有唯一值：“2010-09-09”。模板格式版本与 API 或 WSDL 版本不同。模板格式版本可独立于 API 和 WSDL 版本，进行独立更改 Description 可选字段，模板相关描述。描述声明的值必须是长度介于 0 和 1024 个字节之间的文字字符串。在堆栈更新期间，无法更新 Description 部分本身。只能在包括添加、修改或删除资源的更改时更新 # 示例 Description: \u003e Here are some details about the template. Metadata 可选字段，自定义对象。某些 AWS CloudFormation 功能可在 Metadata 部分中检索自定义的设置或配置信息。在堆栈更新期间，无法更新 Metadata 部分本身。只能在包括添加、修改或删除资源的更改时更新。此外 CloudFormation 不会转换、修改或编辑 Metadata 部分中包含的任何信息 # 示例 Metadata: AWS::CloudFormation::Interface: ParameterGroups: - ParameterGroup ParameterLabels: ParameterLabel Parameters 可选字段，定义对象。用于自定义参数。其它部分可以引用该值。 # 格式 Parameters: ParameterLogicalID: Type: DataType ParameterProperty: value 一个 AWS CloudFormation 模板中最多可包含 200 个参数 必须为每个参数提供一个逻辑名称 (也称为逻辑 ID)，该名称必须是字母数字，并且在模板内的所有逻辑名称中必须是唯一的 必须向每个参数指定一个 AWS CloudFormation 支持的参数类型 必须向每个参数分配一个运行时的值，使 AWS CloudFormation 能够成功预置堆栈 必须在同一模板内声明和引用参数 Rules: 可选字段。判断堆栈创建或堆栈更新过程中传递给模板的参数 Mappings: 可选字段。预设键值对，使用 Fn::FindInMap 内部函数来检索映射中的值 Conditions: 可选字段。条件满足时创建或更新资源 Transform: 可选字段。可重复引用的对象 Resources: 必选字段。定义部署的资源 Outputs: 可选字段。输出信息 Parameters 补充示例 ... Parameters: InstanceTypeParameter: Type: String Default: t2.micro AllowedValues: - t2.micro - m1.small - m1.large Description: Enter t2.micro, m1.small, or m1.large. Default is t2.micro. ... Ec2Instance: Type: AWS::EC2::Instance Properties: InstanceType: # Ref 字段引用了 Parameters.InstanceTypeParameter 字段值 Ref: InstanceTypeParameter ImageId: ami-0ff8a91507f77f867 Properties.Name字段支持以下值 Type 必须指定，该字段指定数据类型，有以下值： String：字符串 Number: 整数或浮点数，但模板中的其他位置使用该参数时，该参数值将变成字符串 List\u003cNumber\u003e: 一组用逗号分隔的整数或浮点数。但模板中的其他位置使用该参数时，该参数值将变成字符串列表 CommaDelimitedList: 一组用逗号分隔的文本字符串。但模板中的其他位置使用该参数时，该参数值将变成字符串列表 AWS::EC2::AvailabilityZone::Name: 可用区 List\u003cAWS::EC2::AvailabilityZone::Name\u003e: 某个区域内的可有区列表 AWS::EC2::Image::Id: EC2 镜像 ID List\u003cAWS::EC2::Image::Id\u003e: EC2 镜像 ID 列表 AWS::EC2::Instance::Id: EC2 实例 ID List\u003cAWS::EC2::Instance::Id\u003e: EC2 实例 ID 列表 AWS::EC2::KeyPair::KeyName: EC2 密钥对名称 AWS::EC2::SecurityGroup::GroupName: EC2-Classic 或默认 VPC 安全组名称 List\u003cAWS::EC2::SecurityGroup::GroupName\u003e: EC2-Classic 或默认 VPC 安全组名称列表 AWS::EC2::SecurityGroup::Id: 安全组 ID List\u003cAWS::EC2::SecurityGroup::Id\u003e: 安全组 ID 列表 AWS::EC2::Subnet::Id: 子网 ID List\u003cAWS::EC2::Subnet::Id\u003e: 子网 ID 列表 AWS::EC2::Volume::Id: EBS ID List\u003cAWS::EC2::Volume::Id\u003e: EBS ID 列表 AWS::EC2::VPC::Id: VPC ID List\u003cAWS::EC2::VPC::Id\u003e: VPC ID 列表 AWS::Route53::HostedZone::Id: Route 53 托管区域 ID List\u003cAWS::Route53::HostedZone::Id\u003e: Route 53 托管区域 ID 列表 AWS::SSM::Parameter::Name: Systems Manager 参数键的名称 AWS::SSM::Parameter::Value\u003cString\u003e: 字符串的 Systems Manager 参数 AWS::SSM::Parameter::Value\u003cList\u003cString\u003e\u003e: 字符串列表的 Systems Manager 参数 AWS::SSM::Parameter::Value\u003cCommaDelimitedList\u003e: 字符串列表的 Systems Manager 参数 AWS::SSM::Parameter::Value\u003cAWS-specific\u003e: 特定于 AWS 的参数类型的 Systems Manager 参数 AWS::SSM::Parameter::Value\u003cList\u003cAWS-specific\u003e\u003e: 特定于 AWS 的参数类型的列表 Systems Manager 参数 AllowedPattern: 值为正则表达式，适用于以下类型： String: 匹配整个字符串 CommaDelimitedList: 匹配字符串列表中的每个值 AllowedValues: 包含参数允许字符串值或字符串列表 ConstraintDescription: 用于在违反约束时的错误提示 Default: 模板适当类型的值，用于在创建堆栈时未指定值的情况下 Description: 用于描述参数的长度最多为 4000 个字符的字符串 MaxLength: String 类型最大长度 MinLength: String 类型最小长度 MinValue: Number 类型最大值 MaxValue: Number 类型最大值 NoEcho: 值为true时使用星号替代参数输出信息，以下信息除外 Metadata模板部分 Outputs模板部分 Resources 补充 # 格式 Resources: Logical ID: # 自定义的资源名称，整个模板唯一。必须为字母数字 Type: Resource type # 资源类型 Properties: Set of properties # 资源声明 CreationPolicy # 可选的资源属性 DeletionPolicy # 可选的资源属性 DependsOn # 可选的资源属性 Metadata # 可选的资源属性 UpdatePolicy # 可选的资源属性 UpdateReplacePolicy # 可选的资源属","date":"2023-05-15","objectID":"/awsCloudFormation/:0:0","tags":["aws","CloudFormation"],"title":"使用 AWS CloudFormation 部署 AWS 资源","uri":"/awsCloudFormation/"},{"categories":["aws"],"content":" CreationPolicyCreationPolicy 属性与以下资源关联，以防止其状态达到创建完成（CREATE_COMPLETE），直到AWS CloudFormation收到指定数量的成功信号或超过超时时间。 AWS::AppStream::Fleet AWS::AutoScaling::AutoScalingGroup AWS::EC2::Instance AWS::CloudFormation::WaitCondition # EC2 格式如下 CreationPolicy: AutoScalingCreationPolicy: MinSuccessfulInstancesPercent: Integer ResourceSignal: Count: Integer Timeout: String --- # AppStream 格式如下 CreationPolicy: StartFleet: Type: Boolean AutoScalingCreationPolicy: 自动伸缩组状态为 CREATE_COMPLETE 所需要收到成功信号数量占比。满足条件后自动伸缩组状态为 CREATE_COMPLETE。默认值为 1 MinSuccessfulInstancesPercent: 可选字段，值为整数（1~100）。指定收到成功信号占比，向下取整。默认值为 100 ResourceSignal: 自动伸缩组状态为 CREATE_COMPLETE 所需要收到成功信号数量与超时时间。如果资源在超时期限过期之前收到失败信号或未收到指定数目的信号，则资源创建将失败并且将回滚 CloudFormation 堆栈 Count: 可选字段，值为整数。用于指定收到成功信号数量， Timeout: 可选字段，值为字符串（ISO_8601 时间格式(PT#H#M#S)）。用于指定超时时间。超时期限自 CloudFormation 开始创建资源后开始计算，但最长指定时间为12小时。默认值为 PT5M 示例 WebServerGroup: Type: 'AWS::AutoScaling::AutoScalingGroup' Properties: VPCZoneIdentifier: !Ref Subnets LaunchConfigurationName: !Ref LaunchConfig MinSize: '1' MaxSize: '5' DesiredCapacity: !Ref WebServerCapacity TargetGroupARNs: - !Ref ALBTargetGroup CreationPolicy: ResourceSignal: Timeout: PT5M Count: !Ref WebServerCapacity UpdatePolicy: AutoScalingRollingUpdate: MinInstancesInService: '1' MaxBatchSize: '1' PauseTime: PT15M WaitOnResourceSignals: 'true' ","date":"2023-05-15","objectID":"/awsCloudFormation/:1:0","tags":["aws","CloudFormation"],"title":"使用 AWS CloudFormation 部署 AWS 资源","uri":"/awsCloudFormation/"},{"categories":["aws"],"content":" UpdatePolicyUpdatePolicy 属性指定 AWS CloudFormation 如何处理以下资源的更新： AWS::AppStream::Fleet AWS::AutoScaling::AutoScalingGroup AWS::ElastiCache::ReplicationGroup AWS::OpenSearchService::Domain AWS::Elasticsearch::Domain AWS::Lambda::Alias AWS::AppStream::Fleet 更新策略 UpdatePolicy: StopBeforeUpdate: Type: Boolean StartAfterUpdate: Type: Boolean StopBeforeUpdate: 可选字段，值为yes 或 no。用于指定更新前停止指定的实例集 StopBeforeUpdate: 可选字段，值为yes 或 no。用于指定更新后启动指定的实例集 AWS::AutoScaling::AutoScalingGroup 资源更新策略 UpdatePolicy: AutoScalingReplacingUpdate: WillReplace: Boolean --- UpdatePolicy: AutoScalingRollingUpdate: MaxBatchSize: Integer MinInstancesInService: Integer MinSuccessfulInstancesPercent: Integer PauseTime: String SuspendProcesses: - List of processes WaitOnResourceSignals: Boolean --- UpdatePolicy: AutoScalingScheduledAction: IgnoreUnmodifiedGroupSizeProperties: Boolean AutoScalingReplacingUpdate.WillReplace: 字段值为 true 时，保留旧的伸缩组，直到新的伸缩组创建完成，在创建新组时，不会分离或附加任何实例。如果更新组成功，则删除旧的伸缩组；如果更新失败，则回滚到旧的伸缩组，删除新的伸缩组。有以下注意事项： 要有足够的 EC2 容量来容纳旧的和新的自动扩缩组 指定匹配的 CreationPolicy 策略，可能会导致状态失败 当 WillReplace: true 且同时使用 AutoScalingRollingUpdate 策略时，AutoScalingReplacingUpdate 策略优先级高 AutoScalingRollingUpdate: 滚动更新 MaxBatchSize: 可选字段，值为整数（1~100）。用于指定单次滚动更新最大数量 MinInstancesInService: 可选字段，值为整数。用于指定旧的伸缩组中保持服务的数量。默认值为0 MinSuccessfulInstancesPercent: 可选字段，值为整数（0~100），默认值为 100。指定更新成功状态所需要的新实例数量百分比，向上去整。必须与 WaitOnResourceSignal、PauseTime 字段同时使用 WaitOnResourceSignal: 可选字段，值为 true 或 false，默认值为 false。指定自动扩缩组在更新期间是否等待来自新实例的信号。可以使用该属性确保在自动扩缩组继续更新之前实例已完成应用程序安装和配置。 PauseTime: 可选字段，值为字符串（ISO_8601 时间格式(PT#H#M#S)）。指定滚动更新间隔时间，在该时间内如果没有收到新实例更新成功信号，则认为更新失败，触发回滚。最大值为PT1H，在 WaitOnResourceSignal 启用的情况下默认值为 PT5M SuspendProcesses: 可选字段，值为[ScalingProcesses.member.N][ScalingProcesses.member.N]之一。用于暂停更新 ","date":"2023-05-15","objectID":"/awsCloudFormation/:2:0","tags":["aws","CloudFormation"],"title":"使用 AWS CloudFormation 部署 AWS 资源","uri":"/awsCloudFormation/"},{"categories":["aws"],"content":" AWS::ElasticLoadBalancingV2::Listener为应用程序负载平衡器、网络负载平衡器或网关负载平衡器指定侦听器。 Type: AWS::ElasticLoadBalancingV2::Listener Properties: AlpnPolicy: - String Certificates: - Certificate DefaultActions: - Type: String AuthenticateCognitoConfig: AuthenticateCognitoConfig AuthenticateOidcConfig: AuthenticateOidcConfig FixedResponseConfig: FixedResponseConfig ForwardConfig: ForwardConfig Order: Integer RedirectConfig: RedirectConfig TargetGroupArn: String LoadBalancerArn: String Port: Integer Protocol: String SslPolicy: String LoadBalancerArn: 必须字段，指定负载均衡器的Amazon Resource Name (ARN)。 Port: 可选字段，值为1~65535。负载均衡器正在侦听的端口。不能为网关负载均衡器指定端口 Protocol: 可选字段，值为 ( GENEVE | HTTP | HTTPS | TCP | TCP_UDP | TLS | UDP )。用于从客户端连接到负载均衡器的协议 DefaultActions: 必选字段，默认规则的操作。不能为默认规则定义条件。 Type: 必选字段，不中断更新, 指定动作类型。字符串值为 ( authenticate-cognito | authenticate-oidc | fixed-response | forward | redirect ) TargetGroupArn: 可选字段，不中断更新。指定目标组的ARN (Amazon Resource Name)。仅当Tyep: forward且希望路由到单个目标组时才需要指定。要路由到一个或多个目标组，请使用ForwardConfig Resources: ALBListener: Type: 'AWS::ElasticLoadBalancingV2::Listener' Properties: DefaultActions: - Type: forward TargetGroupArn: !Ref ALBTargetGroup LoadBalancerArn: !Ref ApplicationLoadBalancer Port: '80' Protocol: HTTP ALBTargetGroup: Type: 'AWS::ElasticLoadBalancingV2::TargetGroup' Properties: HealthCheckIntervalSeconds: 10 HealthCheckTimeoutSeconds: 5 HealthyThresholdCount: 2 Port: 80 Protocol: HTTP UnhealthyThresholdCount: 5 VpcId: !Ref VpcId TargetGroupAttributes: - Key: stickiness.enabled Value: 'true' - Key: stickiness.type Value: lb_cookie - Key: stickiness.lb_cookie.duration_seconds Value: '30' ","date":"2023-05-15","objectID":"/awsCloudFormation/:3:0","tags":["aws","CloudFormation"],"title":"使用 AWS CloudFormation 部署 AWS 资源","uri":"/awsCloudFormation/"},{"categories":["aws"],"content":" AWS::ElasticLoadBalancingV2::LoadBalancer指定应用程序负载均衡器、网络负载均衡器或网关负载均衡器。 Type: AWS::ElasticLoadBalancingV2::LoadBalancer Properties: IpAddressType: String LoadBalancerAttributes: - LoadBalancerAttribute Name: String Scheme: String SecurityGroups: - String SubnetMappings: - SubnetMapping Subnets: - String Tags: - Tag Type: String Subnets: 公网子网id。每个可用分区只能指定一个子网。必须指定子网或子网映射，但不能同时指定两者。如果要指定弹性IP地址，请指定子网映射，而不是子网。 ... Parameters: Subnets: Type: 'List\u003cAWS::EC2::Subnet::Id\u003e' Description: The list of SubnetIds in your Virtual Private Cloud (VPC) ConstraintDescription: \u003e- ... # 示例 Resources: ApplicationLoadBalancer: Type: 'AWS::ElasticLoadBalancingV2::LoadBalancer' Properties: Subnets: !Ref Subnets ","date":"2023-05-15","objectID":"/awsCloudFormation/:4:0","tags":["aws","CloudFormation"],"title":"使用 AWS CloudFormation 部署 AWS 资源","uri":"/awsCloudFormation/"},{"categories":["aws"],"content":" AWS::ElasticLoadBalancingV2::TargetGroupAWS::ElasticLoadBalancingV2::TargetGroup 指定应用程序负载均衡器、网络负载均衡器或网关负载均衡器的目标组。 # 格式 Type: AWS::ElasticLoadBalancingV2::TargetGroup Properties: HealthCheckEnabled: Boolean HealthCheckIntervalSeconds: Integer HealthCheckPath: String HealthCheckPort: String HealthCheckProtocol: String HealthCheckTimeoutSeconds: Integer HealthyThresholdCount: Integer IpAddressType: String Matcher: Matcher Name: String Port: Integer Protocol: String ProtocolVersion: String Tags: - Tag TargetGroupAttributes: - Key: String Value: String Targets: - TargetDescription TargetType: String UnhealthyThresholdCount: Integer VpcId: String HealthCheckIntervalSeconds: 可选字段，不中断更新，值为整数（5~300）。用于指定单个目标的运行存活探测检查间隔时间（秒）。以下是各协议默认时间： GENEVE: 10 lambda: 35 TCP、TLS、UDP、TCP_UDP、HTTP、HTTPS: 30 HealthCheckTimeoutSeconds: 可选字段，不中断更新，值为整数（2~120）。用于判断存活探测失败的超时时间（秒）。以下是各协议默认超时时间 GENEVE: 5 lambda: 30 TCP、TLS、UDP、TCP_UDP、HTTP、HTTPS: 6 HealthyThresholdCount: 可选字段，不中断更新，值为整数（2~10）。用于判断单个目标为健康状态的存活探测成功次数。各协议默认时间为 5 Port: 视情况可选字段，重建更新，值为整数（1~65535）。用于指定与后端目标端口。分为以下情况： 后端为 lambda 时不用指定 后端为 GENEVE 协议时端口为 6081 Protocol: 视情况可选字段，重建更新，值为字符串（GENEVE | HTTP | HTTPS | TCP | TCP_UDP | TLS | UDP）。用于指定与后端连接使用的协议。当后端为 lambda 时不指定 UnhealthyThresholdCount: 可选字段，不中断更新，值为整数（2~10）。用于判断单个目标为不健康状态的存活探测失败次数。以下是各协议默认失败次数： GENEVE、TCP、TLS、UDP、TCP_UDP、HTTP、HTTPS: 2 lambda: 5 VpcId: 视情况可选字段，重建更新，值为字符串（VPC ID）。用于指定负载均衡器使用的 VPC。除 lambda 后端以外必须指定该字段 TargetGroupAttributes: 可选字段，值为k/v列表，不中断更新。用于指定目标组属性。有以下Key： 所有负载均衡器都支持的 key stickiness.lb_cookie.duration_seconds stickiness.enabled 是否启用会话粘连。值为 （true | false ）。默认值为 false stickiness.type 会话粘连类型，有以下值： lb_cookie app_cookie source_ip: 源 ip source_ip_dast_ip source_ip_dast_ip_proto ALB 类型且后端目标为IP或实例支持的 key load_balancing.algorithm.type slow_start.duration_seconds stickiness.app_cookie.cookie_name stickiness.app_cookie.duration_seconds stickiness.lb_cookie.duration_seconds: 基于lb_cookie会话粘连时间，即 lb_cookie 有效期。值为（1~604800）秒，默认值为86400秒 示例 ... Parameters: ALBTargetGroup: Type: 'AWS::ElasticLoadBalancingV2::TargetGroup' Properties: HealthCheckIntervalSeconds: 10 HealthCheckTimeoutSeconds: 5 HealthyThresholdCount: 2 Port: 80 Protocol: HTTP UnhealthyThresholdCount: 5 VpcId: !Ref VpcId TargetGroupAttributes: - Key: stickiness.enabled Value: 'true' - Key: stickiness.type Value: lb_cookie - Key: stickiness.lb_cookie.duration_seconds Value: '30' ","date":"2023-05-15","objectID":"/awsCloudFormation/:5:0","tags":["aws","CloudFormation"],"title":"使用 AWS CloudFormation 部署 AWS 资源","uri":"/awsCloudFormation/"},{"categories":["aws"],"content":" AWS::AutoScaling::AutoScalingGroupAWS::AutoScaling::AutoScalingGroup 定义自动伸缩 EC2 实例集合 # 格式 Type: AWS::AutoScaling::AutoScalingGroup Properties: AutoScalingGroupName: String AvailabilityZones: - String CapacityRebalance: Boolean Context: String Cooldown: String DefaultInstanceWarmup: Integer DesiredCapacity: String DesiredCapacityType: String HealthCheckGracePeriod: Integer HealthCheckType: String InstanceId: String LaunchConfigurationName: String LaunchTemplate: LaunchTemplateSpecification LifecycleHookSpecificationList: - LifecycleHookSpecification LoadBalancerNames: - String MaxInstanceLifetime: Integer MaxSize: String MetricsCollection: - MetricsCollection MinSize: String MixedInstancesPolicy: MixedInstancesPolicy NewInstancesProtectedFromScaleIn: Boolean NotificationConfigurations: - NotificationConfiguration PlacementGroup: String ServiceLinkedRoleARN: String Tags: - TagProperty TargetGroupARNs: - String TerminationPolicies: - String VPCZoneIdentifier: - String VPCZoneIdentifier: 视情况可选字段，中断后更新，值为字符串列表（subnets id）。用于创建“自动伸缩”组实例的VPC子网id列表。如果该资源属于公网子网，且属于同一stack模板中定义的VPC，则必须使用 DependsOn 属性声明 vpc 网关依赖。默认情况下更新该字段时，它将保留相同的Auto Scaling组，并根据指定的子网用新实例替换旧实例。 LaunchConfigurationName: 可选字段，不中断更新，值为字符串（AWS::AutoScaling::LaunchConfiguration类型的资源名称），用于指定启动实例的配置信息。不能与LaunchTemplate、MixedInstancesPolicy、InstanceId 字段同时使用 MinSize: 必选字段，不中断更新，值为字符串。用于指定伸缩组实例最小数量 MaxSize: 必选字段，不中断更新，值为字符串。用于指定伸缩组实例最大数量。在使用使用实例加权的混合实例策略实，扩展实例可能高于该值才能满足需求，在这种情况下该值解释为权重(定义每个实例对组的期望容量贡献多少个单元的权重) DesiredCapacity: 可选字段，不中断更新，值为字符串（MixSize =\u003c DesiredCapacity \u003e= MaxSize）。用于指定初始所需容量。默认值与 MixSize 字段相同。当自动伸缩达到该值时，状态更新为 CREATE_COMPLETE TargetGroupARNs: 可选字段，不中断更新，值为字符串列表。指定需要与自动伸缩组关联的弹性负载均衡目标组的ARN (Amazon Resource Names) ","date":"2023-05-15","objectID":"/awsCloudFormation/:6:0","tags":["aws","CloudFormation"],"title":"使用 AWS CloudFormation 部署 AWS 资源","uri":"/awsCloudFormation/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.27 rocky: 8 kernel: 4.18.0-425.19.2.el8_7.x86_64 内容来自以下文档： k8s官方文档：Kubernetes API 访问控制 k8s官方文档：API 访问控制 k8s官方文档：审计 访问 k8s api 过程用户或服务访问 k8s api 会经历以下过程 通过安全方式连接（TLS） 身份认证 权限判断 准入控制 审计 与 apiserver 连接需要通过HTTPS与apiserver进行连接，因此需要把集群跟证书导入到客户端以防止MITM攻击。 用户认证k8s 集群中的用户分为以下两类： 服务账号：针对 pod 中应用进程设计的账户，由k8s api管理 普通用户：针对操作人员设计的账户。这些账户不受 k8s 集群管理。普通用户通常是通过以下方式管理： 管理员配置的私钥 用户数据库（如Keystone、Google Accounts） 包含用户名和密码列表的文件 虽然k8s并不包含用来代表普通用户账号的对象。 普通用户的信息也无法通过 API 调用添加到集群中。但k8s可以通过身份认证插件来识别用户身份，并应用到后续的鉴权。 k8s通过认证插件识别用户。当api收到http请求后，身份认证插件通过客户端证书（TLS）、令牌（Bearer Token）、身份认证代理（proxy）等方式将以下信息与请求进行关联，这些信息只有通过鉴权后才赋予实质的意义 用户名：用来辩识最终用户的字符串。如user01、user@example.com 用户ID：用来辩识最终用户的字符串。通常具有唯一性 用户组：取值为一组字符串，其中各个字符串用来标明用户是某个命名的用户逻辑集合的成员 附加字段：一组额外的键-值映射，键是字符串，值是一组字符串； 用来保存一些鉴权组件可能觉得有用的额外信息 可以启用多个身份认证模块，当启动多个模块后，只要有其中一个模块通过后直接判定身份认证通过，不再进行身份认证。k8s并不能决定身份认证模块的运行顺序。对于所有通过身份认证的用户，并添加到 system:authenticated组员列表中；没有明确被身份认证拒绝且允许匿名请求，视其为匿名用户，并添加到 system:anonymous 与 system:unauthenticated 组员中 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:0:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 通过 X509 证书识别用户如果 apiserver 启动时传递 --client-ca-file 选项，则可以启动客户端证书身份认证 [root@node01 ~]# kubectl get pod kube-apiserver-node01.my.host -n kube-system -o yaml | grep '\\--client-ca-file' - --client-ca-file=/etc/kubernetes/pki/ca.crt 所引用的文件必须包含一个或者多个证书机构，用来验证向 API 服务器提供的客户端证书。 如果提供了客户端证书并且证书被验证通过，则 subject 中的公共名称（Common Name） 就被作为请求的用户名。 自 Kubernetes 1.4 开始，客户端证书还可以通过证书的 organization 字段标明用户的组成员信息。 要包含用户的多个组成员信息，可以在证书中包含多个 organization 字段。 客户端证书可以使用以下方式生成： 手动使用工具签发，如 openssl、easyrsa、cfssl 等 使用k8s的CertificateSigningRequest签发 手动使用 openssl 签发 [root@node01 ~]# cd /etc/kubernetes/pki/ # 为用户生成密钥 [root@node01 pki]# openssl genrsa -out user01.key 2048 Generating RSA private key, 2048 bit long modulus (2 primes) .....................................................................+++++ ..................................................+++++ e is 65537 (0x010001) # 生成请求证书（SCR） # user01 用户，且属于 users 组与 kube 组 [root@node01 pki]# openssl req -new -key user01.key -out user01.scr -subj \"/CN=user01/O=users/O=kube\" [root@node01 pki]# ls user01* user01.key user01.scr # 使用 apiserver 的 CA 证书为客户端生成证书 [root@node01 pki]# openssl x509 -req -in user01.scr -CA ca.crt -CAkey ca.key -CAcreateserial -out user01.crt -days 120 Signature ok subject=CN = user01, O = users, O = kube Getting CA Private Key [root@node01 pki]# ls user01.* | sed 's/ /\\n/g' user01.crt # 用户证书，访问 apiserver 时会用到 user01.key # 用户密钥，访问 apiserver 时会用到 user01.scr ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:1:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 通过静态令牌文件识别用户静态令牌文件是一个SVC格式的文本文件，该文件每行至少有3个列：令牌、用户名、用户组。用户组可以有多个，但必须用双引号括起来。令牌文件在apiserver启动时使用--token-auth-file选项引用，在不重启apiserver的情况下无法改变令牌已生效的列表 # 默认是没有使用的 [root@node01 pki]# kubectl get pod kube-apiserver-node01.my.host -n kube-system -o yaml | grep '\\--token-auth-file' 下面是SVC格式的文档 token-dfsuna-sfdsam3,user01,294710,\"group1,group2,group3\" 使用该方式时，http请求头部中要添加Authorization头部，值为：Bearer \u003ctoken\u003e。如 Authorization: Bearer token-dfsuna-sfdsam3 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:2:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 服务账户认证服务账号（Service Account）认证是一种自动被启用的用户认证机制，使用经过签名的持有者令牌来验证请求。服务账号通常由 API 服务器自动创建并通过 ServiceAccount 准入控制器关联到集群中运行的 Pod 上。 持有者令牌会挂载到 Pod 中可预知的位置，允许集群内进程与 API 服务器通信。 服务账号也可以使用 Pod.spec.serviceAccountName 字段显式地关联到 Pod 上。不过也可以在集群外部使用。 [root@node03 ~]# kubectl -n kube-system get pod kube-apiserver-node01.my.host -o json \\ \u003e | jq '.spec.containers[0].command' \\ \u003e | grep \"service-account-key-file\\|service-account-lookup|tls-private-key-file\" \"--service-account-key-file=/etc/kubernetes/pki/sa.pub\", --service-account-key-file 选项指定用于验证 ServiceAccount 令牌的TLS文件，文件包含 PEM 编码的 x509 RSA 或 ECDSA 私钥或公钥，文件可以包含多个密钥，也可以多次使用该选项。如果该参数缺省则使用 --tls-private-key-file 选项 --service-account-lookup 选项启用时会回收被删除的令牌 Kubernetes 在 v1.22 版本之前都会自动创建用来访问 Kubernetes API 的凭据。 这一老的机制是基于创建可被挂载到运行中 Pod 内的令牌 Secret 来实现的。 在最近的版本中，API 凭据是直接通过 TokenRequest API 来获得的，这一凭据会使用投射卷挂载到 Pod 中。使用这种方式获得的令牌有确定的生命期，并且在挂载它们的 Pod 被删除时自动作废。但仍然可以手动创建 服务账号令牌。只有在无法使用 TokenRequest API 来获取令牌， 并且能够接受因为将永不过期的令牌凭据写入到可读取的 API 对象而带来的安全风险时， 才应该创建服务账号令牌 Secret 对象。使用这种 Secret 类型时，需要确保对象的注解 kubernetes.io/service-account-name 被设置为某个已有的服务账号名称。 如果同时负责 ServiceAccount 和 Secret 对象的创建，应该先创建 ServiceAccount 对象。当 Secret 对象被创建之后，某个 Kubernetes控制器会填写 Secret 的其它字段，例如 kubernetes.io/service-account.uid 注解以及 data 字段中的 token 键值，使之包含实际的令牌内容。 # 在当前名称空间创建服务账号 [root@node03 ~]# kubectl create serviceaccount jenkins serviceaccount/jenkins created # 调用 TokenRequest API 获得令牌，是一个已签名的 JWT 令牌 [root@node03 ~]# kubectl create token jenkins eyJhbGciOiJSUzI1NiIsImtpZCI6ImZVOW8wN2RyRHF5d19H... 手动创建服务令牌示例 kubectl apply -f - \u003c\u003cEOF apiVersion: v1 kind: Secret metadata: name: secret-sa-sample annotations: kubernetes.io/service-account.name: \"sa-name\" # 服务账户名称 type: kubernetes.io/service-account-token # 这行是必须的 data: # 可以像 Opaque Secret 一样在这里添加额外的键/值偶对 extra: YmFyCg== EOF 服务账号被身份认证后，所确定的用户名为 system:serviceaccount:\u003c名字空间\u003e:\u003c服务账号\u003e， 并被分配到用户组 system:serviceaccounts 和 system:serviceaccounts:\u003c名字空间\u003e ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:3:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 启动引导令牌（Bootstrap Tokens）认证启动引导令牌是一种简单的持有者令牌（Bearer Token），这种令牌是在新建集群 或者在现有集群中添加新节点时使用的。 它被定义成一个特定类型的 Secret（bootstrap.kubernetes.io/token）， 并存在于 kube-system 名字空间中。 这些 Secret 会被 API 服务器上的启动引导认证组件（Bootstrap Authenticator）读取。 控制器管理器中的控制器 TokenCleaner 能够删除过期的令牌。 这些令牌也被用来在节点发现的过程中会使用的一个特殊的 ConfigMap 对象。 BootstrapSigner 控制器也会使用这一 ConfigMap。 启动引导令牌 Secret 清单文件可能看起来像下面这样： apiVersion: v1 kind: Secret metadata: # name 必须是 \"bootstrap-token-\u003ctoken id\u003e\" 格式的 name: bootstrap-token-07401b # 令牌必须存在于 kube-system 名字空间中 namespace: kube-system # type 必须是 'bootstrap.kubernetes.io/token' type: bootstrap.kubernetes.io/token stringData: # 供人阅读的描述，可选。 description: \"The default bootstrap token generated by 'kubeadm init'.\" # 令牌 ID 和秘密信息，它们必须符合正则表达式 [a-z0-9]{6}\\.[a-z0-9]{16}。必需 token-id: 07401b token-secret: f395accd246ae52d # 可选的过期时间字段，一个使用 RFC3339 来编码的 UTC 绝对时间。可选 expiration: 2017-03-10T03:22:11Z # 允许的用法（可选） usage-bootstrap-authentication: \"true\" # 可用于 authentication （身份认证） usage-bootstrap-signing: \"true\" # 用于 cluster-info ConfigMap 的签名 # 令牌要认证为的额外组，必须以 \"system:bootstrappers:\" 开头 auth-extra-groups: system:bootstrappers:worker,system:bootstrappers:ingress 启动引导令牌默认是启用的 [root@node03 ~]# kubectl -n kube-system get pod kube-apiserver-node01.my.host -o json | jq '.spec.containers[0].command' | grep 'enable-bootstrap-token-auth' \"--enable-bootstrap-token-auth=true\", 过期的令牌可以通过启用控制器管理器中的 tokencleaner 控制器来删除。 --controllers=*,tokencleaner 鉴权k8s 使用 apiserver 对 api 请求根据所有策略评估所有请求属性来决定允许或拒绝请求。 默认是拒绝，只有明确允许的操作才会执行。尽管如此，依赖于特定对象种类的特定字段的访问控制和策略是由准入控制器处理 k8s鉴权模块仅审查api请求中的以下属性： 用户名 用户组 附加字段 API 请求路径 API 请求动词。用于资源请求。有以下： HTTP 请求动词。用于非资源请求。有以下： 资源名称 子资源 名称空间 API组 API 请求动词 说明 get 获取单个资源 list 获取某类资源集合 watch 持续观察资源更新 create 创建资源 update 更新资源，如果资源不存在则创建 patch 修改资源字段 delete 删除单个资源 deletecollection 删除某类型资源 proxy bind RBAC鉴权专有，能更新或创建RoleBinding与ClusterRoleBinding资源 escalate RBAC鉴权专有，能更新或创建Role与ClusterRole资源 apiserver启动时根据--authorization-mode选项值启动鉴权模块。当配置了多个鉴权模块时，k8s 将按顺序使用每个模块。 如果任何鉴权模块批准或拒绝请求，则立即返回该决定，并且不会与其他鉴权模块协商。如果请求被拒绝则返回http 403状态码 [root@node01 ~]# kubectl get pod kube-apiserver-node01.my.host -n kube-system -o yaml | grep '\\--authorization-mode' - --authorization-mode=Node,RBAC 有以下鉴权模块： Node: 一个专用鉴权模式，根据调度到 kubelet 上运行的 Pod 为 kubelet 授予权限 ABAC: 基于属性的访问控制。它定义了一种访问控制范型，通过使用将属性组合在一起的策略， 将访问权限授予用户 RBAC: 基于角色的访问控制。是一种基于企业内个人用户的角色来管理对计算机或网络资源的访问的方法 Webhook: 它是一个 HTTP 回调，发生某些事情时调用 HTTP POST 进行简单的事件通知 AlwaysDeny: 它会阻止所有请求 AlwaysAllow: 它会允许所有请求 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:4:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" RBAC 鉴权基于角色（Role）的访问控制（RBAC）是一种基于组织中用户的角色来调节控制对计算机或网络资源的访问的方法。RBAC 鉴权机制使用 rbac.authorization.k8s.io API 组来驱动鉴权决定， 允许你通过 Kubernetes API 动态配置策略。 在 kube-apiserver --authorization-mode 选项包含 RBAC 参数时表示启用了 RBAC 鉴权 [root@node1 ~]# kubectl get pod kube-apiserver-node1.localdomain -n kube-system -o=jsonpath='{$.spec.containers[0].command}' | jq | grep \"authorization-mode\" \"--authorization-mode=Node,RBAC\", RBAC API 声明了以下 k8s 对象： 权限定义对象，一组相关权限规则。权限是纯粹累加的，不存在拒绝某种操作的规则。 Role: 某个名称空间内权限 ClusterRole: 定义集群级别区域权限 角色绑定对象： RoleBinding: 将 Role 定义的权限赋予一个或者一组用户 ClusterRoleBinding: 将 ClusterRole 定义的权限赋予一个或者一组用户 它们的生效范围： RoleBinding 绑定 Role：在固定名称空间生效。且 RoleBinding 和 Role 必须在同一名称空间，如果名称空间被删除，就算重新创建同名的名称空间。旧权限也不会生效 [root@node03 ~]# kubectl auth can-i create pod --as=xiaosi --namespace=test yes [root@node03 ~]# [root@node03 ~]# kubectl delete ns test namespace \"test\" deleted [root@node03 ~]# [root@node03 ~]# kubectl auth can-i create pod --as=xiaosi --namespace=test no [root@node03 ~]# [root@node03 ~]# kubectl create ns test namespace/test created [root@node03 ~]# [root@node03 ~]# kubectl auth can-i create pod --as=xiaosi --namespace=test no RoleBinding 绑定 ClusterRole：在 RoleBingding 定义的名称空间生效 ClusterRoleBinding 绑定 ClusterRole：在整个集群生效 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" Role 与 ClusterRoleRBAC 的 Role 或 ClusterRole 中包含一组代表相关权限的规则。 这些权限是纯粹累加的。不存在拒绝某操作的规则。Role 总是用来在某个名字空间内设置访问权限，创建 Role 时必须指定该 Role 所属的名字空间。ClusterRole 则是一个集群作用域的资源。 role 示例 --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: note name: user-role rules: - apiGroups: [\"v1\"] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] --- ClusterRole 示例 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: user-cluster-role rules: - apiGroups: [\"v1\"] resources: [\"nodes\"] verbs: [\"get\", \"watch\", \"list\"] ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:1","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 聚合的 ClusterRole可以把若干个 ClusterRole 聚合起来，形成一个复合的 ClusterRole。作为集群控制面的一部分，控制器会监视带有 aggregationRule 的 ClusterRole 对象集合。 aggregationRule 为控制器定义一个标签选择算符供后者匹配应该组合到当前 ClusterRole 的 roles 字段中的 ClusterRole 对象 下面是一个聚合 ClusterRole 的示例： apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: monitoring aggregationRule: # 聚合标签 clusterRoleSelectors: - matchLabels: rbac.example.com/aggregate-to-monitoring: \"true\" rules: [] # 控制面自动填充这里的规则 再创建一个带有 rbac.example.com/aggregate-to-monitoring: true 标签的 ClusterRole 新的规则也会被添加到名为 monitoring 的 ClusterRole 中 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: monitoring-endpoints labels: rbac.example.com/aggregate-to-monitoring: \"true\" # 当你创建 \"monitoring-endpoints\" ClusterRole 时， # 下面的规则会被添加到 \"monitoring\" ClusterRole 中 rules: - apiGroups: [\"\"] resources: [\"services\", \"endpoints\", \"pods\"] verbs: [\"get\", \"list\", \"watch\"] ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:2","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" RoleBinding 和 ClusterRoleBindingRoleBinding 与 ClusterRoleBinding 都是用于把权限与某个或某些用户、用户组、服务账号关联，这些主体名称没有过多限制。以下前缀是 k8s 系统保留的： system: system:serviceaccount:: 是用于服务账户用户名的前缀 system:serviceaccounts:: 是用于服务账户组名的前缀 RoleBinding 示例 apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: user-role-binding namespace: note subjects: - kind: User name: user roleRef: kind: Role name: user-role apiGroup: rbac.authorization.k8s.io ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:3","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 默认的 Roles 和 RoleBindingsAPI 服务会创建一组默认的 ClusterRole 与 ClusterRoleBinding 对象，它们都带有 kubernetes.io/bootstrapping=rbac-defaults 。其中有很多用 system: 作为前缀来标识对应资源是直接由集群控制面管理的。因此修改这些资源时要小心，可能导致集群无法正常运作。 每次启动时 API 服务器都会为默认的 ClusterRole 添加缺少的权限，并为默认的 ClusterRoleBindin 添加缺少的主体。这种机制称为自动协商，它有助于保证角色和角色绑定在新的发行版本中有权限或主体变更时仍然保持最新。如果想禁用则把它们的注解 rbac.authorization.kubernetes.io/autoupdate 由 true 改为 false。注意，缺少默认权限和角色绑定主体可能会导致集群无法正常工作。如果启用了 RBAC 鉴权，则该机制是默认启用的 无论是经过身份验证的还是未经过身份验证的用户， 默认的角色绑定都授权他们读取被认为是可安全地公开访问的 API (由名为 system:discovery 的ClusterRole 资源定义) RBAC 会发现以下ClusterRole并通过自动协商机制修复 默认的 ClusterRole 默认绑定的主体 说明 system:basic-user system:authenticated 组 允许用户以只读的方式去访问他们自己的基本信息。在 k8s 1.14 版本之前是 system:unauthenticated 组的一员 system:discovery system:authenticated 组 允许以只读方式访问 API 发现端点，这些端点用来发现和协商 API 级别。在 k8s 1.14 版本之前是 system:unauthenticated 组的一员 system:public-info-viewer system:authenticated 组 system:unauthenticated 组 允许对集群的非敏感信息进行只读访问，在 k8s 1.14 版本中引入 以下 ClusterRole 是面向用户的，允许管理员使用 ClusterRole 聚合标签来添加用于定制资源的规则。 默认的 ClusterRole 默认关联的主体 说明 cluster-admin system:masters 组 允许超级用户在平台上的任何资源上执行所有操作。在 RoleBinding 资源中关联时，可以授权控制角色绑定所在名字空间中的所有资源，包括名字空间本身。 admin 无 允许管理员访问权限，旨在使用 RoleBinding 在名字空间内执行授权。可授予对名字空间中的大多数资源的读/写权限， 包括创建角色和角色绑定的能力。 此角色不允许对资源配额或者名字空间本身进行写操作。不允许对 k8s 1.22 以上版本的 Endpoints 资源进行写操作 edit 无 允许对名字空间的大多数对象进行读/写操作。此角色不允许查看或者修改角色或者角色绑定。 不过可以访问 Secret，以名字空间中任何 ServiceAccount 的身份运行 Pod， 所以可以用来了解名字空间内所有服务账户的 API 访问级别。 不允许对 k8s 1.22 以上版本的 Endpoints 资源进行写操作 view 无 允许对名字空间的大多数对象有只读权限。 它不允许查看角色或角色绑定。此角色不允许查看 Secrets，因为读取 Secret 的内容意味着可以访问名字空间中 ServiceAccount 的凭据信息，进而允许利用名字空间中任何 ServiceAccount 的身份访问 API（这是一种特权提升）。 面向用户的 ClusterRole 聚合标签： metadata: labels: rbac.authorization.k8s.io/aggregate-to-admin: \"true\" rbac.authorization.k8s.io/aggregate-to-edit: \"true\" rbac.authorization.k8s.io/aggregate-to-view: \"true\" 以下是核心组件的 ClusterRole 默认的 ClusterRole 默认关联的主体 说明 system:kube-scheduler system:kube-scheduler 用户 允许访问 scheduler 组件所需要的资源 system:volume-scheduler system:kube-scheduler 用户 允许访问 kube-scheduler 组件所需要的资源 system:kube-controller-manager system:kube-controller-manager 用户 允许访问控制器管理器组件所需要的资源 system:node 无 允许访问 kubelet 所需要的资源，包括对所有 Secret 的读操作和对所有 Pod 状态对象的写操作。官方建议是使用 node 鉴权来实现这些权限，之所以得到保留是为了与从 v1.8 之前版本升级而来的集群兼容。 system:node-proxier system:kube-proxy 用户 允许访问 kube-proxy 组件所需要的资源。 以下是其它组件的 ClusterRole 默认的 ClusterRole 默认关联的主体 说明 system:auth-delegator 无 第三方的身份认证和鉴权检查操作权限 system:kube-aggregator 无 为 kube-aggregator 组件定义的权限 system:kube-dns 无 kube-system 名称空间中的 kube-dns 服务账号 system:kubelet-api-admin 无 允许 kubelet API 的完全访问的权限 system:node-bootstrapper 无 允许访问执行 kubelet TLS 启动引导所需要的权限 system:node-problem-detector 无 为 node-problem-detector 组件定义的权限 system:persistent-volume-provisioner 无 允许访问大部分动态卷驱动所需要的权限 system:monitoring system:monitoring 组 允许对控制平面监控端点的读取访问权限 控制器管理器（kube-controller-manager）的 ClusterRole。当使用 kube-controller-manager --use-service-account-credentials 启动时，使用单独的服务账户来启动每个控制器。 每个内置控制器都有相应的、前缀为 system:controller: 的角色。 否则它使用自己的身份凭据来运行所有的控制器，该身份必须被授予所有相关的角色 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:4","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 初始化与预防权限提升RBAC API 会阻止用户通过编辑角色或者角色绑定来提升权限。 由于这一点是在 API 级别实现的，所以在 RBAC 鉴权组件未启用的状态下依然可以正常工作。 只有在符合以下条件之一的情况才能创建/更新权限： 已经拥有角色中包含的所有权限，且其作用域与正被修改的对象作用域相同。即明确授权允许修改或创建其它 Role/ClusterRole 的权限 授权 escalate 权限 只以在符合以下条件之一才能创建或修改关联主体： 有权限创建或更新 RoleBinding 或 ClusterRoleBinding 对象 有 bind 权限 下面的 ClusterRole 和 RoleBinding 将允许用户 user-1 把名字空间 user-1-namespace 中的 admin、edit 和 view 角色赋予其他用户。 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: role-grantor rules: - apiGroups: [\"rbac.authorization.k8s.io\"] resources: [\"rolebindings\"] verbs: [\"create\"] - apiGroups: [\"rbac.authorization.k8s.io\"] resources: [\"clusterroles\"] verbs: [\"bind\"] # 忽略 resourceNames 意味着允许绑定任何 ClusterRole resourceNames: [\"admin\",\"edit\",\"view\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: role-grantor-binding namespace: user-1-namespace roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: role-grantor subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: user-1 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:5","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 服务账户权限默认的 RBAC 策略为控制面组件、节点和控制器授予权限。 但是不会对 kube-system 名字空间之外的服务账户授予权限。 （除了授予所有已认证用户的发现权限）。可以根据需要向特定 ServiceAccount 授予特定权限。以下是按从最安全到最不安全的授权顺序： 为特定应用的服务账户授予权限（最佳实践） 授予某名字空间中的 default 服务账户权限 授予名字空间中所有服务账户权限 在集群范围内为所有服务账户授予一个受限权限（不鼓励） 授予超级用户访问权限给集群范围内的所有服务帐户（强烈不鼓励） ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:6","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" Endpoints 写入权限在 k8s 1.22 之前的版本中，edit 与 admin 角色包含对 Endpoints 资源写入权限作为 [CVE-2021-25740][CVE-2021-25740] 安全问题的缓解措施。在 k8s 1.22 及其以后的版本中不包含该权限（升级到 k8s 1.22 及其以后版本保留了该权限）。如果希望在新集群的聚合角色里保留此访问权限，你可以创建下面 ClusterRole： apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: kubernetes.io/description: |- Add endpoints write permissions to the edit and admin roles. This was removed by default in 1.22 because of CVE-2021-25740. See https://issue.k8s.io/103675. This can allow writers to direct LoadBalancer or Ingress implementations to expose backend IPs that would not otherwise be accessible, and can circumvent network policies or security controls intended to prevent/isolate access to those backends. labels: rbac.authorization.k8s.io/aggregate-to-edit: \"true\" name: custom:aggregate-to-edit:endpoints # 你可以随意愿更改这个 name rules: `: apiGroups: [\"\"] resources: [\"endpoints\"] verbs: [\"create\", \"delete\", \"deletecollection\", \"patch\", \"update\"] ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:5:7","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" Node 鉴权节点鉴权是一种特殊用途的鉴权模式，专门对 kubelet 发出的 API 请求进行授权。允许 kubelet 执行 API 操作。 读取： services、endpoints、nodes、pods 以及绑定到 kubelet 节点的 Pod 相关资源（Secret、ConfigMap、PersistentVolumeClaim 和持久卷） 写入：事件、pod 及其状态（启用 NodeRestriction 准入插件以限制 kubelet 只能修改绑定到自身的 Pod）、节点及其状态（启用 NodeRestriction 准入插件以限制 kubelet 只能修改自己的节点） 对于基于 TLS 的启动引导过程时使用的 certificationsigningrequests API 的读/写权限 为委派的身份验证/鉴权检查创建 TokenReview 和 SubjectAccessReview 的能力 在以后的版本中节点鉴权器可能会添加或删除权限，以确保 kubelet 具有正确操作所需的最小权限集。为了获得节点鉴权器的授权，kubelet 必须使用一个凭证以表示它在 system:nodes 组中，用户名为 system:node:\u003cnodeName\u003e。上述的组名和用户名格式要与 kubelet TLS 启动引导 过程中为每个 kubelet 创建的标识相匹配。 节点名称必须与 kubelet 注册时使用的节点名称一致。获取节点名称优先级从上往下： 使用 kubelet --cloud-provider 选项时具体的主机名可能由云提供商确定 使用 kubelet --hostname-override 选项指定的值 使用 hostname 命令提供的值 在 kube-apiserver --authorization-mode 选项包含 Node 参数时表示启用了 Node 鉴权。想限制 kubelet 可写入的 API 对象需要使用 kube-apiserver --enable-admission-plugins 选项启用 NodeRestriction 准入管制器插件 Node 鉴权只授权于 system:nodes 组的主体，如果 kubelet 具有 system:nodes 组的凭证，但无法给出关联的节点标识（system:node:... 格式的用户名），也不会被 Node 鉴权模式授权。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:6:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 版本变动使用 RBAC 时，将继续创建 system:node 集群角色，以便与将其他用户或组绑定到该角色的部署方法兼容。 在 k8s 1.6 版本中，使用 RBAC 鉴权时，名为 system:nodes 的 ClusterRole 资源会自动关联到 system:node 组 在 k8s 1.7 版本中，不再推荐将 system:nodes 组自动绑定到 system:node 角色，因为节点鉴权器通过对 Secret 和 ConfigMap 访问的额外限制完成了相同的任务。 如果同时启用了 Node 和 RBAC 鉴权模。如果同时启用了 RBAC 与 Node 鉴权，则不会自动绑定 在 k8s 1.8 版本中，绑定将根本不会被创建 从 k8s 1.7 版本之前升级的使用 RBAC 群将继续按原样运行，因为 system:nodes 组绑定已经存在。如果集群管理员希望开始使用 Node 鉴权器和 NodeRestriction 准入插件来限制节点对 API 的访问。可以通过以下操作完成： 启用 Node 鉴权与 NodeRestriction 准入控制器插件 确保所有 kubelet 的凭据符合组/用户名要求 审核 API 服务器日志以确保 Node 鉴权器不会拒绝来自 kubelet 的请求（日志中没有持续的 NODE DENY 消息） 删除 system:node 集群角色绑定 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:6:1","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 从 ABAC 鉴权转换到 RBAC 鉴权原来运行较老版本 k8s 的集群通常会使用限制宽松的 ABAC 策略， 包括授予所有服务帐户全权访问 API 的能力。默认的 RBAC 策略为控制面组件、节点和控制器等授予有限的权限，但不会为 kube-system 名称空间外的服务账户授权（除了授予所有认证用户的发现权限之外），这样做虽然安全得多，但可能会干扰期望自动获得 API 权限的现有工作负载。 这里有两种方法来完成这种转换: 方法 1：同时运行 RBAC 和 ABAC 鉴权模式， 并指定包含现有的 ABAC 策略的策略文件： # --vmodule=rbac RBAC 日志记录级别 --vmodule=rbac*=5 --authorization-mode=...,RBAC,ABAC --authorization-policy-file=mypolicy.json api 服务启动后用服务账户去做 ABAC 鉴权授予的权限，根据日志 ABAC 中的拒绝提示（以 RBAC 为前缀）创建或修改 RBAC 直到没有拒绝日志后从 --authorization-mode= 选项中移除 ABAC 参数与删除 --authorization-policy-file 选项 方法2：使用 RBAC 角色绑定复制宽松的 ABAC 策略： # 允许 所有 服务帐户充当集群管理员。 容器中运行的所有应用程序都会自动收到服务帐户的凭据，可以对 API 执行任何操作， 包括查看 Secret 和修改权限。 # 不推荐使用该方式 kubectl create clusterrolebinding permissive-binding \\ --clusterrole=cluster-admin \\ --user=admin \\ --user=kubelet \\ --group=system:serviceaccounts ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:7:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 检查 API 访问权限authorization.k8s.io API 组可以把apiserver鉴权公开给外部服务。该api组有以下资源 SubjectAccessReview: 对任意用户的访问进行评估（整个集群） LocalSubjectAccessReview: 对任意用户的访问进行评估（指定名称空间内） SelfSubjectRulesReview: 返回用户在指定名称空间内的操作权限集合 kubectl auth can-i 命令使用 SelfSubjectAccessReview 资源类型快速确定用户是否可以执行给定操作 # 检查名字空间 dev 里的 dev-sa 服务账户是否可以列举名字空间 target 里的 Pod [root@node1 ~]# kubectl auth can-i list pods --namespace target --as system:serviceaccount:dev:dev-sa no # 检查当前用户可以在 dev 名称空间是否允许创建 deployments [root@node1 ~]# kubectl auth can-i create deployments --namespace dev yes # --as 指定用户 # 检查 dave 用户在 dev 名称空间中是否可能查看 secrets 类资源 [root@node01 ~]# kubectl auth can-i list secrets --namespace dev --as dave no SelfSubjectAccessReview 示例 [root@node01 ~]# kubectl create -f`: -o yaml \u003c\u003c EOF apiVersion: authorization.k8s.io/v1 kind: SelfSubjectAccessReview spec: resourceAttributes: group: apps name: deployments verb: create namespace: dev EOF apiVersion: authorization.k8s.io/v1 kind: SelfSubjectAccessReview metadata: creationTimestamp: null spec: resourceAttributes: group: apps name: deployments namespace: dev verb: create status: allowed: true 准入控制器准入控制器是一段代码，它会在请求通过认证和授权之后、对象被持久化之前拦截到达 API 服务器的请求。可以执行验证和变更操作。它只限制创建、删除、修改对象或连接到代理的请求，不限制读取对象之类的请求。 准入控制过程分为以下两个阶段，某些控制器既是变更准入控制器又是验证准入控制器。如果两个阶段之一的任何一个控制器拒绝了某请求，则整个请求将立即被拒绝，并向最终用户返回错误。 运行变更准入控制器 运行验证准入控制器 准入控制器有很多，它们都编译进 kube-apiserver 可执行文件，并且只能由集群管理员配置。 启用准入控制器：kube-apiserver --enable-admission-plugins=NamespaceLifecycle,LimitRanger ... 关闭准入控制器：kube-apiserver --disable-admission-plugins=PodNodeSelector,AlwaysDeny ... 查看已启用的准入控制器：kube-apiserver -h | grep enable-admission-plugins ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:8:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" CertificateApproval此准入控制器获取审批 CertificateSigningRequest 资源的请求并执行额外的鉴权检查， 以确保针对设置了 spec.signerName 的 CertificateSigningRequest 资源而言， 审批请求的用户有权限对证书请求执行审批操作。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:9:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" CertificateSigning此准入控制器监视对 CertificateSigningRequest 资源的 status.certificate 字段的更新请求， 并执行额外的鉴权检查，以确保针对设置了 spec.signerName 的 CertificateSigningRequest 资源而言， 签发证书的用户有权限对证书请求执行签发操作 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:10:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" CertificateSubjectRestriction此准入控制器监视 spec.signerName 被设置为 kubernetes.io/kube-apiserver-client 的 CertificateSigningRequest 资源创建请求，并拒绝所有将 group（或 organization attribute） 设置为 system:masters 的请求 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:11:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" DefaultIngressClass该准入控制器监测没有请求任何特定 Ingress 类的 Ingress 对象创建请求，并自动向其添加默认 Ingress 类。当未配置默认 Ingress 类时，此准入控制器不执行任何操作。如果有多个 Ingress 类被标记为默认 Ingress 类， 此控制器将拒绝所有创建 Ingress 的操作，并返回错误信息。 要修复此错误，管理员必须重新检查其 IngressClass 对象，并仅将其中一个标记为默认 （通过注解 ingressclass.kubernetes.io/is-default-class）。 此准入控制器会忽略所有 Ingress 更新操作，仅处理创建操作。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:12:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" DefaultStorageClass此准入控制器监测没有请求任何特定存储类的 PersistentVolumeClaim 对象的创建请求， 并自动向其添加默认存储类。 当未配置默认存储类时，此准入控制器不执行任何操作。如果将多个存储类标记为默认存储类， 此控制器将拒绝所有创建 PersistentVolumeClaim 的请求，并返回错误信息。 要修复此错误，管理员必须重新检查其 StorageClass 对象，并仅将其中一个标记为默认。 此准入控制器会忽略所有 PersistentVolumeClaim 更新操作，仅处理创建操作。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:13:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" DefaultTolerationSeconds此准入控制器基于 k8s-apiserver 的输入参数 default-not-ready-toleration-seconds 和 default-unreachable-toleration-seconds 为 Pod 设置默认的容忍度，以容忍 notready:NoExecute 和 unreachable:NoExecute 污点 （如果 Pod 尚未容忍 node.kubernetes.io/not-ready:NoExecute 和 node.kubernetes.io/unreachable:NoExecute 污点的话）。 default-not-ready-toleration-seconds 和 default-unreachable-toleration-seconds 的默认值是 5 分钟 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:14:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" LimitRanger此准入控制器会监测传入的请求，并确保请求不会违反 Namespace 中 LimitRange 对象所设置的任何约束。 如果你在 Kubernetes 部署中使用了 LimitRange 对象，则必须使用此准入控制器来执行这些约束。 LimitRanger 还可以用于将默认资源请求应用到没有设定资源约束的 Pod； 当前，默认的 LimitRanger 对 default 名字空间中的所有 Pod 都设置 0.1 CPU 的需求 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:15:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" MutatingAdmissionWebhook此准入控制器调用任何与请求匹配的变更（Mutating） Webhook。匹配的 Webhook 将被顺序调用。 每一个 Webhook 都可以自由修改对象。如果由此准入控制器调用的 Webhook 有副作用（如：减少配额）， 则它 必须 具有协调系统，因为不能保证后续的 Webhook 和验证准入控制器都会允许完成请求。如果你禁用了 MutatingAdmissionWebhook，那么还必须使用 --runtime-config 标志禁止 admissionregistration.k8s.io/v1 组/版本中的 MutatingWebhookConfiguration， 二者都是默认启用的 谨慎编写和安装变更 webhook 当用户尝试创建的对象与返回的对象不同时，用户可能会感到困惑。 当他们读回的对象与尝试创建的对象不同，内建的控制回路可能会出问题 与覆盖原始请求中设置的字段相比，使用原始请求未设置的字段会引起问题的可能性较小。 应尽量避免覆盖原始请求中的字段设置。 内建资源和第三方资源的控制回路未来可能会出现破坏性的变更，使现在运行良好的 Webhook 无法再正常运行。即使完成了 Webhook API 安装，也不代表该 Webhook 会被提供无限期的支持。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:16:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" NamespaceLifecycle该准入控制器禁止在一个正在被终止的 Namespace 中创建新对象，并确保针对不存在的 Namespace 的请求被拒绝。 该准入控制器还会禁止删除三个系统保留的名字空间，即 default、 kube-system 和 kube-public ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:17:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" PersistentVolumeClaimResize 特性状态： Kubernetes v1.24 [stable] 此准入控制器检查传入的 PersistentVolumeClaim 调整大小请求，对其执行额外的验证检查操作。除非 PVC 的 StorageClass 明确地将 allowVolumeExpansion 设置为 true 来显式启用调整大小。 否则，默认情况下该准入控制器会阻止所有对 PVC 大小的调整。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:18:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" PodSecurity 特性状态： Kubernetes v1.25 [stable] PodSecurity 取代了一个名为 PodSecurityPolicy 的旧准入控制器。在新 Pod 被准入之前对其进行检查， 根据请求的安全上下文和 Pod 所在命名空间允许的 Pod 安全性标准的限制来确定新 Pod 是否应该被准入。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:19:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" Priority优先级准入控制器使用 priorityClassName 字段并用整型值填充优先级。 如果找不到优先级，则拒绝 Pod ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:20:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" ResourceQuota此准入控制器会监测传入的请求，并确保它不违反任何一个 Namespace 中的 ResourceQuota 对象中列举的约束。如果你在 Kubernetes 部署中使用了 ResourceQuota， 则必须使用这个准入控制器来强制执行配额限制。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:21:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" RuntimeClass如果你所定义的 RuntimeClass 包含 Pod 开销， 这个准入控制器会检查新的 Pod。 被启用后，此准入控制器会拒绝所有已经设置了 overhead 字段的 Pod 创建请求。 对于配置了 RuntimeClass 并在其 .spec 中选定 RuntimeClass 的 Pod， 此准入控制器会根据相应 RuntimeClass 中定义的值为 Pod 设置 .spec.overhead ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:22:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" ServiceAccount此准入控制器实现了 ServiceAccount 的自动化 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:23:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" StorageObjectInUseProtectionStorageObjectInUseProtection 插件将 kubernetes.io/pvc-protection 或 kubernetes.io/pv-protection finalizers 添加到新创建的持久卷申领（PVC） 或持久卷（PV）中。如果用户尝试删除 PVC/PV，除非 PVC/PV 的保护控制器移除终结器（finalizers）， 否则 PVC/PV 不会被删除。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:24:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" TaintNodesByCondition该准入控制器为新创建的节点添加 NotReady 和 NoSchedule 污点。 这些污点能够避免一些竞态条件的发生，而这类竞态条件可能导致 Pod 在更新节点污点以准确反映其所报告状况之前，就被调度到新节点上。 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:25:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" ValidatingAdmissionPolicy此准入控制器针对传入的匹配请求实现 CEL 校验。当 validatingadmissionpolicy 和 admissionregistration.k8s.io/v1alpha1 特性门控组/版本被启用时， 此特性被启用。如果任意 ValidatingAdmissionPolicy 失败，则请求失败 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:26:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" ValidatingAdmissionWebhook此准入控制器调用与请求匹配的所有验证性 Webhook。 匹配的 Webhook 将被并行调用。如果其中任何一个拒绝请求，则整个请求将失败。 该准入控制器仅在验证（Validating）阶段运行；与 MutatingAdmissionWebhook 准入控制器所调用的 Webhook 相反，它调用的 Webhook 不可以变更对象。 如果以此方式调用的 Webhook 有其它副作用（如：减少配额），则它 必须 具有协调机制。 这是因为无法保证后续的 Webhook 或其他验证性准入控制器都允许请求完成。 如果你禁用了 ValidatingAdmissionWebhook，还必须通过 --runtime-config 标志来禁用 admissionregistration.k8s.io/v1 组/版本中的 ValidatingWebhookConfiguration 对象 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:27:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" NodeRestriction该准入控制器限制某个 kubelet 可以修改的 Node 与 Pod 资源对象，它通过限制 system:nodes 组（成员名格式为 system:node:\u003cnodeName\u003e ）的权限实现的。但无法更新或删除 Node 对象的污点。 该插件对 kubelet 做了以下限制： 允许 kubelet 添加、修改、删除以下标签 : kubernetes.io/hostname : kubernetes.io/arch : kubernetes.io/os : beta.kubernetes.io/instance-type : node.kubernetes.io/instance-type : failure-domain.beta.kubernetes.io/region （已弃用） : failure-domain.beta.kubernetes.io/zone（已弃用）: topology.kubernetes.io/region : topology.kubernetes.io/zone : kubelet.kubernetes.io/ 为前缀的标签 : node.kubernetes.io/` 为前缀的标签 禁止 kubelet 添加、修改、删除以下标签 : node-restriction.kubernetes.io/为前缀的标签（这类前缀的标签时保留给管理员的，用以为Node对象设置标签以隔离工作负载）: kubernetes.io 为前缀的标签（除非明确允许） : k8s.io` 为前缀的标签（除非明确允许） 审计k8s审计（Auditing）功能提供了与安全相关的、按时间顺序排列的记录集， 记录每个用户、使用 apiserver 的应用以及控制面自身引发的活动。它从以下维度记录日志： 发生了什么？ 什么时候发生的？ 谁触发的？ 活动发生在哪个（些）对象上？ 在哪观察到的？ 它从哪触发的？ 活动的后续处理行为是什么？ 审计日志记录功能会增加 apiserver 的内存消耗，因为需要为每个请求存储审计所需的某些上下文。 内存消耗取决于审计日志记录的配置。每个请求都可被记录其相关阶段： RequestReceived: 此阶段对应审计处理器接收到请求后，并且在委托给 其余处理器之前生成的事件。 ResponseStarted: 在响应消息的头部发送后，响应消息体发送前生成的事件。 只有长时间运行的请求（例如 watch）才会生成这个阶段。 ResponseComplete: 当响应消息体完成并且没有更多数据需要传输的时候。 Panic: 当 panic 发生时生成 ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:28:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 审计策略审计策略对象结构定义在 audit.k8s.io API 组 。处理事件时，将按顺序与规则列表进行比较。第一个匹配规则设置事件的审计级别（Audit Level）。已定义的审计级别有： None: 符合这条规则的日志将不会记录。 Metadata: 记录请求的元数据（请求的用户、时间戳、资源、动词等等）， 但是不记录请求或者响应的消息体。 Request: 记录事件的元数据和请求的消息体，但是不记录响应的消息体。 这不适用于非资源类型的请求。 RequestResponse: 记录事件的元数据，请求和响应的消息体。这不适用于非资源类型的请求 `kube-apiserver --audit-policy-file` 指定审计策略文件，如果没有启动时没有指定。则不记录事件。下面是官方的一个示例文件 apiVersion: audit.k8s.io/v1 # 这是必填项。 kind: Policy # 不要在 RequestReceived 阶段为任何请求生成审计事件。 omitStages: - \"RequestReceived\" rules: # 必须有该字段 # 在日志中用 RequestResponse 级别记录 Pod 变化。 - level: RequestResponse resources: - group: \"\" # 资源 \"pods\" 不匹配对任何 Pod 子资源的请求， # 这与 RBAC 策略一致。 resources: [\"pods\"] # 在日志中按 Metadata 级别记录 \"pods/log\"、\"pods/status\" 请求 - level: Metadata resources: - group: \"\" resources: [\"pods/log\", \"pods/status\"] # 不要在日志中记录对名为 \"controller-leader\" 的 configmap 的请求。 - level: None resources: - group: \"\" resources: [\"configmaps\"] resourceNames: [\"controller-leader\"] # 不要在日志中记录由 \"system:kube-proxy\" 发出的对端点或服务的监测请求。 - level: None users: [\"system:kube-proxy\"] verbs: [\"watch\"] resources: - group: \"\" # core API 组 resources: [\"endpoints\", \"services\"] # 不要在日志中记录对某些非资源 URL 路径的已认证请求。 - level: None userGroups: [\"system:authenticated\"] nonResourceURLs: - \"/api*\" # 通配符匹配。 - \"/version\" # 在日志中记录 kube-system 中 configmap 变更的请求消息体。 - level: Request resources: - group: \"\" # core API 组 resources: [\"configmaps\"] # 这个规则仅适用于 \"kube-system\" 名字空间中的资源。 # 空字符串 \"\" 可用于选择非名字空间作用域的资源。 namespaces: [\"kube-system\"] # 在日志中用 Metadata 级别记录所有其他名字空间中的 configmap 和 secret 变更。 - level: Metadata resources: - group: \"\" # core API 组 resources: [\"secrets\", \"configmaps\"] # 在日志中以 Request 级别记录所有其他 core 和 extensions 组中的资源操作。 - level: Request resources: - group: \"\" # core API 组 - group: \"extensions\" # 不应包括在内的组版本。 # 一个抓取所有的规则，将在日志中以 Metadata 级别记录所有其他请求。 - level: Metadata # 符合此规则的 watch 等长时间运行的请求将不会 # 在 RequestReceived 阶段生成审计事件。 omitStages: - \"RequestReceived\" ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:29:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["k8s"],"content":" 日志存放位置kube-apiserver 默认提供以下存储位置 写入文件系统 --audit-log-path 选项指定日志文件路径，缺省时不写入日志文件（默认值） --audit-log-maxage 选项指定日志文件保留天数 --audit-log-maxbackup 选项指定日志文件最大数量 --audit-log-maxsize 选项指定日志文件切割时的大小(MB) 发送到外部 HTTP API ","date":"2023-05-01","objectID":"/k8sApiControllingAccess/:30:0","tags":["k8s","API 访问控制"],"title":"k8s API 访问控制","uri":"/k8sApiControllingAccess/"},{"categories":["neovim"],"content":" 运行环境： neovim: 0.10.0 内容来自以下文档： neovim 参考手册 命令 普通模式 插入模式 命令行模式 可视模式 选择模式 操作等待模式 终端 Lang :[nore]map yes - - yes yes yes - - :n[nore]map yes - - - - - - - :[nore]map! - yes yes - - - - - :i[nore]map - yes - - - - - - :c[nore]map - - yes - - - - - :v[nore]map - - - yes yes - - - :x[nore]map - - - yes - - - - :s[nore]map - - - - yes - - - :o[nore]map - - - - - yes - - :t[nore]map - - - - - - yes - :l[nore]map - yes yes - - - - yes ","date":"2023-04-30","objectID":"/neovimShortcutKey/:0:0","tags":["neovim","快捷键"],"title":"neovim 快捷键","uri":"/neovimShortcutKey/"},{"categories":["容器"],"content":" 运行环境： docker hub 准备工作 dokcer hub 帐号：官网地址为 docker hub 镜像标签：格式为 docker.io/用户名/镜像名称:标签 登陆帐号 -u 表示指定 docker hub 用户名，可以忽略，以交互式输入 [root@localhost ~]# docker login -u yuhais Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 上传镜像在上传之前修改镜像格式为[docker.io]/注册用户名/镜像名:标签 [root@localhost ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE registry.k8s.io/kube-controller-manager v1.27.1 c6b511817822 2 weeks ago 112MB ... [root@localhost ~]# [root@localhost ~]# docker image tag registry.k8s.io/kube-controller-manager:v1.27.1 docker.io/yuhais/kube-controller-manager:v1.27.1 [root@localhost ~]# [root@localhost ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE yuhais/kube-controller-manager v1.27.1 c6b511817822 2 weeks ago 112MB ... 上传时间可能很长耐心等待 [root@localhost ~]# docker image push yuhais/kube-controller-manager:v1.27.1 The push refers to repository [docker.io/yuhais/kube-controller-manager] e399ae6c8bfd: Pushing [=====================\u003e ] 45.65MB/108.4MB 861fc30f18a9: Mounted from yuhais/kube-apiserver 4cb10dd2545b: Mounted from yuhais/kube-apiserver d2d7ec0f6756: Mounted from yuhais/kube-apiserver 1a73b54f556b: Mounted from yuhais/kube-apiserver e624a5370eca: Waiting d52f02c6501c: Waiting ff5700ec5418: Waiting 399826b51fcf: Waiting 6fbdf253bbc2: Waiting d0157aa0c95a: Waiting ","date":"2023-04-29","objectID":"/dockerRepository/:0:0","tags":["docker","容器仓库"],"title":"docker 仓库","uri":"/dockerRepository/"},{"categories":["linux"],"content":" 运行环境： rocky: 8.7 内容来自以下文档： dnf 官方文档 error","date":"2023-04-25","objectID":"/linuxDnf/:0:0","tags":["dnf","linux","软件包管理"],"title":"DNF是YUM的下一个主要版本","uri":"/linuxDnf/"},{"categories":["linux"],"content":" Curl error (6) [root@node01 ~]# dnf -y install wget Rocky Linux 8 - AppStream 0.0 B/s | 0 B 00:00 Errors during downloading metadata for repository 'appstream': - Curl error (6): Couldn't resolve host name for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64\u0026repo=AppStream-8 [Could not resolve host: mirrors.rockylinux.org] 错误：为仓库 'appstream' 下载元数据失败 : Cannot prepare internal mirrorlist: Curl error (6): Couldn't resolve host name for https://mirrors.rockylinux.org/mirrorlist?arch=x86_64\u0026repo=AppStream-8 [Could not resolve host: mirrors.rockylinux.org] 无法连接地址，排查是是无法解析域名 [root@node01 ~]# echo 'nameserver 8.8.8.8' \u003e\u003e /etc/resolv.conf ","date":"2023-04-25","objectID":"/linuxDnf/:1:0","tags":["dnf","linux","软件包管理"],"title":"DNF是YUM的下一个主要版本","uri":"/linuxDnf/"},{"categories":["aws"],"content":" 运行环境： cli: 2 内容来自以下文档： 将 Amazon EC2 与 AWS CLI 结合使用 ec2 cli2 CPU 积分一个 CPU 积分等于一个 vCPU 按 100% 利用率运行一分钟，或者 vCPU、利用率和时间的等效组合（例如， 一个 vCPU 按 50% 利用率运行两分钟，或者两个 vCPU 按 25% 利用率运行两分钟）。 ","date":"2023-04-25","objectID":"/awsEc2/:0:0","tags":["aws","ec2"],"title":"aws 云服务器","uri":"/awsEc2/"},{"categories":["aws"],"content":" 运行环境： cli: 2 内容来自以下文档： aws cli2 用户指南 快速使用安装查看：AWS CLI 安装和更新说明 [root@localhost ~]# wget https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip [root@localhost ~]# unzip -u awscli-exe-linux-x86_64.zip [root@localhost ~]# ll aws total 80 drwxr-xr-x. 6 root root 4096 Jul 13 22:16 dist -rwxr-xr-x. 1 root root 4047 Jul 13 22:04 install -rw-r--r--. 1 root root 1465 Jul 13 22:04 README.md -rw-r--r--. 1 root root 68282 Jul 13 22:04 THIRD_PARTY_LICENSES [root@localhost ~]# ./aws/install You can now run: /usr/local/bin/aws --version 创建密钥步骤： 在网页控制台创建IAM用户 配置权限 在安全凭证下选项卡下的访问密钥创访问密钥 创建完成记录访问密钥与秘密访问密钥（或下载.csv 文件） aws cli 添加密钥 # --profile 创建一个配置文件 [root@localhost ~]# aws configure --profile awsXiaoSiCli.txt # 输入访问密钥 AWS Access Key ID [None]: AKIA**** # 输入访问私密密钥 AWS Secret Access Key [None]: EKh*** # 设置默认地区(可选) Default region name [None]: # 设置输出格式(可选)，默认为 json # 可以是 table、text、yaml-stream、yaml、json Default output format [None]: json 常用选项 --profile 指定命名的配置 列出配置数据 [root@localhost ~]# aws configure list Name Value Type Location ---- ----- ---- -------- profile \u003cnot set\u003e None None access_key ****************ZV4H shared-credentials-file secret_key ****************9c33 shared-credentials-file region ap-southeast-1 config-file ~/.aws/config 查看配置文件 [root@localhost ~]# aws configure list-profiles awsXiaoSiCli.txt default my-hk zjcCli 指定使用配置文件 [root@localhost ~]# aws iam list-access-keys --profile zjcCli | jq . { \"AccessKeyMetadata\": [ { \"UserName\": \"yuhai\", \"AccessKeyId\": \"AKIA6DDYRN7EE4VD7KTW\", \"Status\": \"Active\", \"CreateDate\": \"2023-06-01T06:30:53+00:00\" }, { \"UserName\": \"yuhai\", \"AccessKeyId\": \"AKIA6DDYRN7EJCN272X3\", \"Status\": \"Active\", \"CreateDate\": \"2023-06-01T07:29:23+00:00\" } ] } 配置AWS CLI 凭证和配置设置的优先顺序如下： aws命令行中的--region、--output、--profile 选项 环境变量： AWS_ACCESS_KEY_ID: 访问密钥 AWS_SECRET_ACCESS_KEY: 私密密钥 AWS_DEFAULT_REGION: 地区 CLI凭证文件： windows: C:\\Users\\USERNAME\\.aws\\credentials linux: C:\\Users\\USERNAME\\.aws\\credentials CLI配置文件： windows: C:\\Users\\USERNAME\\.aws\\config linux: C:\\Users\\USERNAME\\.aws\\config 容器凭证 Amazon EC2 实例配置文件凭证 如果使用 configure 创建的配置文件，密钥信息保存在crconfigure，地区与输出格式保存在config ","date":"2023-04-25","objectID":"/awsCli2/:0:0","tags":["aws","cli2"],"title":"aws 命令行工具","uri":"/awsCli2/"},{"categories":["aws"],"content":" 配置项配置文件支持以下配置项 ##### 全局 # 访问密钥 aws_access_key_id = AKIAIOSFODNN7EXAMPLE # 私密密钥 aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY # 会话令牌 aws_session_token = AQoEXAMPLEH4aoAH.... # 地区 # 使用 AWS_REGION 环境变量、AWS_DEFAULT_REGION 环境变量或 --region 命令行选项% region = us-west-2 # 用于验证 SSL 证书的 CA 证书捆绑包（具有 .pem 扩展名的文件） # 可以被 AWS_CA_BUNDLE 环境变量或 --ca-bundle 命令行选项覆盖 ca_bundle = dev/apps/ca-certs/cabundle-2019mar05.pem # CLI2 命令行自动提示 # 可以使用 aws_cli_auto_prompt 环境变量或 # --cli-auto-prompt 和 --no-cli-auto-prompt 命令行参数覆盖此设置 # on 每次尝试运行 aws 命令时都会使用完整的自动提示模式 cli_auto_prompt = on # on-partial 使用部分自动提示模式 cli_auto_prompt = on-partial # 指定 AWS CLI 版本 2 如何解释二进制输入参数 # 可以使用 --cli-binary-format raw-in-base64-out 参数指定 cli_binary_format = raw-in-base64-out ","date":"2023-04-25","objectID":"/awsCli2/:1:0","tags":["aws","cli2"],"title":"aws 命令行工具","uri":"/awsCli2/"},{"categories":["neovim"],"content":" 运行环境： neovim: 0.10.0 内容来自以下文档： vim 参考手册 neovim 参考手册 Ex 命令行在普通模式使用 : 后neovim会把光标移动到窗口下方，在该模式下可执行 Ex 命令。 命令行编辑 快捷键 说明 \u003cInsert\u003e 在插入和替换之间切换 \u003cCTRL-C 不执行命令，退出命令行模式 \u003cCTRL-[\u003e 或 \u003cEsc\u003e 退出命令行模式 \u003cLeft\u003e 光标左移 \u003cS-Left\u003e 或 \u003cC-Left\u003e 光标左移一个字串 (WORD) \u003cCTRL-B\u003e 或 \u003cHome\u003e 光标移动至命令的起始 \u003cRight\u003e 光标右移 \u003cS-Right\u003e 或 \u003cC-Right\u003e 光标右移一个字串 (WORD) \u003cCTRL-E\u003e 或 \u003cEnd\u003e 光标移动至命令的末尾 \u003cCTRL-H\u003e 或 \u003cBS\u003e 删除光标前面的字符 \u003cCTRL-W\u003e 删除光标前的单词 ( word )。单词范围受 iskeyword 选项影响 \u003cCTRL-U\u003e 删除光标所在位置与行首之间的所有字符 \u003cDel\u003e 删除光标后面的字符 \u003cCTRL-V\u003e 下一个字符如果是非数字字符，按本义插入。 或不超过三个的数字字符可用于输入单个字节的十进制编码。这里的非数字和三个数字字符不经过映射 \u003cCTRL-Q\u003e 同 \u003cCTRL-V\u003e 但在终端环境没效果 \u003cCTRL-SHIFT-V\u003e 或 \u003cCTRL-SHIFT-Q\u003e 同 \u003cCTRL-V\u003e {char1} \u003cBS\u003e {char2} 或 \u003cCTRL-K\u003e {char1} {char2} 输入二合字母，如果 {char1} 是一个特殊键，插入该键 \u003c\u003e 形式的编码 \u003cCTRL-R\u003e\u003cCTRL-F\u003e 插入光标下的文件名 \u003cCTRL-R\u003e\u003cCTRL-P\u003e 插入光标下的文件名与路径 \u003cCTRL-R\u003e\u003cCTRL-W\u003e 插入光标下的单词 \u003cCTRL-R\u003e\u003cCTRL-A\u003e 插入光标下的字串 \u003cCTRL-R\u003e\u003cCTRL-L\u003e 插入光标下的文本行 \u003cCTRL-R\u003e {register} 插入寄存器里的内容。当按下 \u003cCTRL-R\u003e 时，屏幕会显示一个 \" 字 符，提示你输入一个寄存器的名字。映射、缩写、补全功能不会生效， 但 \u003cBS\u003e \u003cbr\u003e \u003cCTRL-W\u003e 仍旧可能结束命令行模式，并使剩余的字符被接下来其他的模式解释 ` { \u003cCTRL-\\\u003e e {expr} 使用表达式 \u003cUp\u003e 在历史记录中查找开始部分与当前输入匹配的前一条命令 \u003cDown\u003e 在历史记录中查找开始部分与当前输入匹配的下一条命令 \u003cCTRL-Y\u003e 当存在无模式选择时，复制该选择区域的内容至剪贴板 \u003cCTRL-]\u003e 激活缩写，但不插入任何字符 \u003cCTRL-M\u003e 或 \u003cCTRL-J\u003e 或 \u003cCR\u003e 或 \u003cNL\u003e 执行输入的命令 ","date":"2023-04-25","objectID":"/neovimExCmd/:0:0","tags":["neovim","Ex 命令"],"title":"neovim Ex 命令","uri":"/neovimExCmd/"},{"categories":["neovim"],"content":" 运行环境： nvim: 0.10.0 内容来自以下文档： neovim用户手册 vim参考手册 自动命令自动命令是由事件触发自动执行的一系列操作 事件 事件 说明 BufNewFile 开始编辑尚不存在的文件 BufReadPre 开始编辑新缓冲区，读入文件前 BufRead 开始编辑新缓冲区，读入文件后 BufReadPost 开始编辑新缓冲区，读入文件后 BufReadCmd 开始编辑新缓冲区前 FileReadPre 用 “:read” 命令读入文件前 FileReadPost 用 “:read” 命令读入文件后 FileReadCmd 用 “:read” 命令读入文件前 FilterReadPre 用过滤命令读入文件前 FilterReadPost 用过滤命令读入文件后 StdinReadPre 从标准输入读入缓冲区前 StdinReadPost 从标准输入读入缓冲区后 BufWrite 开始把整个缓冲区写回到文件 BufWritePre 开始把整个缓冲区写回到文件 BufWritePost 把整个缓冲区写回到文件后 BufWriteCmd 把整个缓冲区写回到文件前 FileWritePre 开始把缓冲区部分内容写回到文件 FileWritePost 把缓冲区部分内容写回到文件后 FileWriteCmd 把缓冲区部分内容写回到文件前 FileAppendPre 开始附加到文件 FileAppendPost 附加到文件后 FileAppendCmd 附加到文件前 FilterWritePre 开始为过滤命令或 diff 写到文件 FilterWritePost 为过滤命令或 diff 写到文件后 BufAdd 刚把缓冲区附加到缓冲区列表后 BufCreate 刚把缓冲区附加到缓冲区列表后 BufDelete 从缓冲区列表删除缓冲区前 BufWipeout 从缓冲区列表完全删除缓冲区前 BufFilePre 改变当前缓冲区名字前 BufFilePost 改变当前缓冲区名字后 BufEnter 进入缓冲区后 BufLeave 转到其它缓冲区前 BufWinEnter 在窗口显示缓冲区前 BufWinLeave 从窗口删除缓冲区前 BufUnload 卸载缓冲区前 BufHidden 刚把缓冲区变为隐藏前 BufNew 刚建立新缓冲区后 SwapExists 检测到交换文件已经存在 FileType 设置 ‘filetype’ 选项时 Syntax 设置 ‘syntax’ 选项时 EncodingChanged ’encoding’ 选项改变后 TermChanged ’term’ 的值改变后 OptionSet 设置任何选项后 VimEnter 完成所有的初始化步骤后 UIEnter 在初始化后，如果成功启动 UI ，执行相关操作 GUIFailed 退出 UI TermResponse 收到 t_RV 的终端应答后 QuitPre 用 :quit 时，决定是否退出之前 ExitPre 用可使 Vim 退出的命令时 VimLeavePre 退出 Vim 前，在写入 viminfo 文件之前 VimLeave 退出 Vim 前，在写入 viminfo 文件之后 VimSuspend 暂停 Vim 时 VimResume Vim 在暂停后恢复运行时 TerminalOpen 建立终端缓冲区后 TerminalWinOpen 在新窗口建立终端缓冲区后 FileChangedShell Vim 注意到文件在编辑开始后被改变 FileChangedShellPost 对在编辑开始后被改变的文件的处理完成后 FileChangedRO 对只读文件进行第一次修改前 DiffUpdated 刷新比较结果后 DirChangedPre 工作目录改变前 DirChanged 工作目录改变后 ShellCmdPost 执行外壳命令后 ShellFilterPost 用外壳命令执行完过滤后 CmdUndefined 调用没有定义的用户命令 FuncUndefined 调用没有定义的用户函数 SpellFileMissing 使用不存在的拼写文件 SourcePre 执行 Vim 脚本之前 SourcePost 执行 Vim 脚本之后 SourceCmd 执行 Vim 脚本之前 VimResized Vim 窗口大小改变后 FocusGained Vim 得到输入焦点 FocusLost Vim 失去输入焦点 CursorHold 用户有一段时间没有按键 CursorHoldI 在插入模式下，用户有一段时间没有按键 CursorMoved 普通模式下移动了光标 CursorMovedI 插入模式下移动了光标 WinNew 创建新窗口后 TabNew 创建新标签页后 WinClosed 关闭窗口后 TabClosed 关闭标签页后 WinEnter 进入其它窗口后 WinLeave 离开窗口前 TabEnter 进入其它标签页后 TabLeave 离开标签页前 CmdwinEnter 进入命令行窗口后 CmdwinLeave 离开命令行窗口前 CmdlineChanged 命令行文本发生改变后 CmdlineEnter 光标移到命令行后 CmdlineLeave 光标离开命令行前 InsertEnter 开始插入模式前 InsertChange 在插入或替换模式下输入 时 InsertLeave 离开插入模式时 InsertLeavePre 离开插入模式前 InsertCharPre 插入模式输入每个字符前 ModeChanged 改变模式后 TextChanged 普通模式中对文本进行改变后 TextChangedI 弹出菜单不可见时，插入模式中对文本进行改变后 TextChangedP 弹出菜单可见时，插入模式中对文本进行改变后 TextChangedT 终端模式中对文本进行改变后 TextYankPost 文本抽出或删除后 SafeState 没有任何待定字符，等待用户键入字符 SafeStateAgain 重复出现 的 SafeState ColorSchemePre 载入色彩方案前 ColorScheme 载入色彩方案后 RemoteReply 得到了 Vim 服务器的应答 QuickFixCmdPre 执行快速修复命令前 QuickFixCmdPost 执行快速修复命令后 SessionLoadPost 载入会话文件后 MenuPopup 刚要显示弹出菜单前 CompleteChanged 插入模式补全菜单被改变后 CompleteDonePre 插入模式补全结束之后，清理 info 之前 CompleteDone 插入模式补全结束之后，清理 info 之后 User 和 “:doautocmd” 一起使用 SigUSR1 检测到 SIGUSR1 信号后 WinScrolled 滚动窗口或改变窗口大小后 ","date":"2023-04-22","objectID":"/neovimAutocmd/:0:0","tags":["neovim"],"title":"noevim 自动命令","uri":"/neovimAutocmd/"},{"categories":["vim"],"content":" 运行环境： vim: 9 vim: 8 内容来自以下文档： vim参考手册 自动命令自动命令是由事件触发自动执行的一系列操作 事件 事件 说明 BufNewFile 开始编辑尚不存在的文件 BufReadPre 开始编辑新缓冲区，读入文件前 BufRead 开始编辑新缓冲区，读入文件后 BufReadPost 开始编辑新缓冲区，读入文件后 BufReadCmd 开始编辑新缓冲区前 FileReadPre 用 “:read” 命令读入文件前 FileReadPost 用 “:read” 命令读入文件后 FileReadCmd 用 “:read” 命令读入文件前 FilterReadPre 用过滤命令读入文件前 FilterReadPost 用过滤命令读入文件后 StdinReadPre 从标准输入读入缓冲区前 StdinReadPost 从标准输入读入缓冲区后 BufWrite 开始把整个缓冲区写回到文件 BufWritePre 开始把整个缓冲区写回到文件 BufWritePost 把整个缓冲区写回到文件后 BufWriteCmd 把整个缓冲区写回到文件前 FileWritePre 开始把缓冲区部分内容写回到文件 FileWritePost 把缓冲区部分内容写回到文件后 FileWriteCmd 把缓冲区部分内容写回到文件前 FileAppendPre 开始附加到文件 FileAppendPost 附加到文件后 FileAppendCmd 附加到文件前 FilterWritePre 开始为过滤命令或 diff 写到文件 FilterWritePost 为过滤命令或 diff 写到文件后 BufAdd 刚把缓冲区附加到缓冲区列表后 BufCreate 刚把缓冲区附加到缓冲区列表后 BufDelete 从缓冲区列表删除缓冲区前 BufWipeout 从缓冲区列表完全删除缓冲区前 BufFilePre 改变当前缓冲区名字前 BufFilePost 改变当前缓冲区名字后 BufEnter 进入缓冲区后 BufLeave 转到其它缓冲区前 BufWinEnter 在窗口显示缓冲区前 BufWinLeave 从窗口删除缓冲区前 BufUnload 卸载缓冲区前 BufHidden 刚把缓冲区变为隐藏前 BufNew 刚建立新缓冲区后 SwapExists 检测到交换文件已经存在 FileType 设置 ‘filetype’ 选项时 Syntax 设置 ‘syntax’ 选项时 EncodingChanged ’encoding’ 选项改变后 TermChanged ’term’ 的值改变后 OptionSet 设置任何选项后 VimEnter 完成所有的初始化步骤后 GUIEnter 成功启动 GUI 后 GUIFailed 启动 GUI 失败之后 TermResponse 收到 t_RV 的终端应答后 QuitPre 用 :quit 时，决定是否退出之前 ExitPre 用可使 Vim 退出的命令时 VimLeavePre 退出 Vim 前，在写入 viminfo 文件之前 VimLeave 退出 Vim 前，在写入 viminfo 文件之后 VimSuspend 暂停 Vim 时 VimResume Vim 在暂停后恢复运行时 TerminalOpen 建立终端缓冲区后 TerminalWinOpen 在新窗口建立终端缓冲区后 FileChangedShell Vim 注意到文件在编辑开始后被改变 FileChangedShellPost 对在编辑开始后被改变的文件的处理完成后 FileChangedRO 对只读文件进行第一次修改前 DiffUpdated 刷新比较结果后 DirChangedPre 工作目录改变前 DirChanged 工作目录改变后 ShellCmdPost 执行外壳命令后 ShellFilterPost 用外壳命令执行完过滤后 CmdUndefined 调用没有定义的用户命令 FuncUndefined 调用没有定义的用户函数 SpellFileMissing 使用不存在的拼写文件 SourcePre 执行 Vim 脚本之前 SourcePost 执行 Vim 脚本之后 SourceCmd 执行 Vim 脚本之前 VimResized Vim 窗口大小改变后 FocusGained Vim 得到输入焦点 FocusLost Vim 失去输入焦点 CursorHold 用户有一段时间没有按键 CursorHoldI 在插入模式下，用户有一段时间没有按键 CursorMoved 普通模式下移动了光标 CursorMovedI 插入模式下移动了光标 WinNew 创建新窗口后 TabNew 创建新标签页后 WinClosed 关闭窗口后 TabClosed 关闭标签页后 WinEnter 进入其它窗口后 WinLeave 离开窗口前 TabEnter 进入其它标签页后 TabLeave 离开标签页前 CmdwinEnter 进入命令行窗口后 CmdwinLeave 离开命令行窗口前 CmdlineChanged 命令行文本发生改变后 CmdlineEnter 光标移到命令行后 CmdlineLeave 光标离开命令行前 InsertEnter 开始插入模式前 InsertChange 在插入或替换模式下输入 时 InsertLeave 离开插入模式时 InsertLeavePre 离开插入模式前 InsertCharPre 插入模式输入每个字符前 ModeChanged 改变模式后 TextChanged 普通模式中对文本进行改变后 TextChangedI 弹出菜单不可见时，插入模式中对文本进行改变后 TextChangedP 弹出菜单可见时，插入模式中对文本进行改变后 TextChangedT 终端模式中对文本进行改变后 TextYankPost 文本抽出或删除后 SafeState 没有任何待定字符，等待用户键入字符 SafeStateAgain 重复出现 的 SafeState ColorSchemePre 载入色彩方案前 ColorScheme 载入色彩方案后 RemoteReply 得到了 Vim 服务器的应答 QuickFixCmdPre 执行快速修复命令前 QuickFixCmdPost 执行快速修复命令后 SessionLoadPost 载入会话文件后 MenuPopup 刚要显示弹出菜单前 CompleteChanged 插入模式补全菜单被改变后 CompleteDonePre 插入模式补全结束之后，清理 info 之前 CompleteDone 插入模式补全结束之后，清理 info 之后 User 和 “:doautocmd” 一起使用 SigUSR1 检测到 SIGUSR1 信号后 WinScrolled 滚动窗口或改变窗口大小后 ","date":"2023-04-22","objectID":"/vimAutocmd/:0:0","tags":["vim"],"title":"vim 自动命令","uri":"/vimAutocmd/"},{"categories":["neovim"],"content":" 运行环境： nvim: 0.10.0 内容来自以下文档： neovim 初始化过程 vim 初始化过程 neovim 安装neovim (简写 Nvim)是 vim 重构版本，不再兼容 vi，它与 vim 操作基本没有区别。没有 vim 那么重的历史包袱。是一个干净的 vim。可以从 neovimReleases下载安装包 初始化过程在启动时，Nvim 检查环境变量和文件并相应地设置值，过程如下： 设置 shell 配置项 处理参数 启动服务器（除非给出 --listen）并设置 v:servername 等待 UI 连接 设置默认映射和默认自动命令，创建弹出菜单 启用文件插件(语法和缩进) 加载用户配置 启用文件类型检测 启用语法高亮 加载插件脚本 设置shellpipe 配置项和shellredir 配置项 如果使用-n命令参数，则将updatecount 配置项设置为零 如果给出了 -b 配置项，则设置binary配置项 读取共享数据文件 如果给出 -q 配置项，则读取 quickfix 文件，否则退出 打开缓冲区窗口 执行启动命令 如果 Nvim -u 指定配置文件或使用 Nvim -es 启动，则跳过第5步之前的所有初始化。如果未设置 $MYVIMRC 变量，使用nvim -u NORC不读取文件。如果使用 nvim -u NONE 选项不加载语法插件与语法高亮 ","date":"2023-04-22","objectID":"/neovimInitialization/:0:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" shell 配置项环境变量 SHELL（如果存在）用于设置shell配置项。 在 Win32 上，如果未设置 SHELL，则使用 COMSPEC 变量。 shell 配置项指定执行外部命令时使用的shell路径 ","date":"2023-04-22","objectID":"/neovimInitialization/:1:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 处理参数检查启动 NVim 命令的配置项和文件名。 为所有文件创建缓冲区（但尚未加载）。 -V 参数可用于显示或记录接下来发生的事情，对于调试初始化很有用。 ","date":"2023-04-22","objectID":"/neovimInitialization/:2:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 启动服务在管道或tcp地址上启动 RPC服务器并设备监听地址 ","date":"2023-04-22","objectID":"/neovimInitialization/:3:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 连接用户界面Nvim --embed 配置项开始等待用户界面连接，然后再继续加载用户配置。该配置项使用 stdin/stdout 作为 msgpack-RPC 通道，因此应用程序可以通过 RPC API 嵌入并控制 Nvim使用 stdin/stdout 作为 msgpack-RPC 通道，因此应用程序可以通过 RPC API 嵌入并控制 Nvim。等待客户端（embedder）在获取启动文件和读取缓冲区之前调用 nvim_ui_attach()，以便 UI 可以确定性地处理（显示）早期消息、对话框等。客户端可以在 nvim_ui_attach 之前执行其他请求（例如 nvim_get_api_info for 特征检测）。 在此预启动阶段，用户配置当然不可用（类似于 --cmd）。 ","date":"2023-04-22","objectID":"/neovimInitialization/:4:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 设置默认映射、默认自动命令、创建弹出菜单Nvim 在启动时创建以下默认映射，可以通过简单地删除映射来禁用配置中的任何这些 nnoremap Y y$ nnoremap \u003cC-L\u003e \u003cCmd\u003enohlsearch\u003cBar\u003ediffupdate\u003cBar\u003enormal! \u003cC-L\u003e\u003cCR\u003e inoremap \u003cC-U\u003e \u003cC-G\u003eu\u003cC-U\u003e inoremap \u003cC-W\u003e \u003cC-G\u003eu\u003cC-W\u003e xnoremap * y/\\V\u003cC-R\u003e\"\u003cCR\u003e xnoremap # y?\\V\u003cC-R\u003e\"\u003cCR\u003e nnoremap \u0026 :\u0026\u0026\u003cCR\u003e 默认自动命令存在于以下组中。 可以使用:autocmd! {group}删除、使用 :autocmd {group} 查看是如何定义的。 BufReadCmd: 创建终端缓冲区 nvim_cmdwin: 命令行窗口限制为1行(maxlines=1) 如果mousemodel 设置为popup 或popup_setpos，则这是按下鼠标右键时显示的菜单。菜单定义如下 aunmenu PopUp vnoremenu PopUp.Cut \"+x vnoremenu PopUp.Copy \"+y anoremenu PopUp.Paste \"+gP vnoremenu PopUp.Paste \"+P vnoremenu PopUp.Delete \"_x nnoremenu PopUp.Select\\ All ggVG vnoremenu PopUp.Select\\ All gg0oG$ inoremenu PopUp.Select\\ All \u003cC-Home\u003e\u003cC-O\u003eVG anoremenu PopUp.-1- \u003cNop\u003e anoremenu PopUp.How-to\\ disable\\ mouse \u003cCmd\u003ehelp disable-mouse\u003cCR\u003e ","date":"2023-04-22","objectID":"/neovimInitialization/:5:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 启用文件插件(语法与缩进)执行以下命令，如果指定 -u 选项则跳过 :runtime! ftplugin.vim indent.vim ","date":"2023-04-22","objectID":"/neovimInitialization/:6:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 加载初始化配置如果 exrc 配置项开启，则在当前目录下搜索以下文件，文件优先级顺序如下 .nvim.lua .nvimrc .exrc 初始化配置文件按以下顺序加载： $VIMINIT 环境变量指定的 Ex 命令行 加载用户初始化配置文件 $XDG_CONFIG_DIRS/nvim/init.vim $EXINIT 环境变量指定的 Ex 命令行与 $MYVIMRC 环境变量的第一个有效果位置 用户初始化配置文件（init.vim或init.lua）在以下目录，它们不能同时存在： unix: ~/.config/nvim/init.vim windows: ~/AppData/Local/nvim/init.vim $XDG_CONFIG_HOME/nvim/init.vim: $XDG_CONFIG_HOME 变量默认值如下 unix: ~/.config/nvim/ windows: ~/AppData/Local/nvim/ 加载 sysint.vim 文件，优先级如下： $XDG_CONFIG_DIRS 变量目录下的 sysint.vim 文件 :version输出中的提示，通常是$VIM/sysinit.vim ","date":"2023-04-22","objectID":"/neovimInitialization/:7:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 启用文件类型检测执行以下命令，可以使用filetype off 关闭。如果使用 -u NONE选项则跳过 :runtime! filetype.lua ","date":"2023-04-22","objectID":"/neovimInitialization/:8:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 加载插件脚本加载 runtimepath 配置项指定目录中的配置文件，按以下规则顺序如下： 按字母排序 优先加载*.vim，其次加载*.lua 以after结尾的目录中配置文件最后加载 相当于执行以下命令： :runtime! plugin/**/*.vim :runtime! plugin/**/*.lua 在以下情况下不会加载插件： loadplugins 配置项在用户初始化文件中被重置 使用 --noplugin 选项运行 使用 --clean 选项运行 使用 -u NONE 选项运行 ","date":"2023-04-22","objectID":"/neovimInitialization/:9:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 设置 shellpipe 配置项和 shellredir 配置项 shellredir 选项用于指定:!命令输出信息流向哪里（标准输出、错误输出、临时文件、文件） shellpipe 选项用于指定 :make 命令输出信息流向哪里 ","date":"2023-04-22","objectID":"/neovimInitialization/:10:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 如果使用-n命令参数，则将 updatecount 配置项设置为零updatecount 选项用于指定 .swp （交换分区）文件写入磁盘的条件，单位是字符数量。当为0时表示不创建 .swp 文件 ","date":"2023-04-22","objectID":"/neovimInitialization/:11:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 如果给出了 -b 配置项，则启用binary配置项binary 配置选项是为编辑二进制文件设置一系列配置项，该选项默认是关闭的 ","date":"2023-04-22","objectID":"/neovimInitialization/:12:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 读取共享数据文件共享数据文件（shared data file、Shada file、ShaDa file）记录以下信息： 命令行历史 搜索字符串历史记录 输入行历史记录 非空寄存器的内容 多个文件的标记 位置标记 最后执行的搜索或替换模式 缓冲区列表 全局变量 ","date":"2023-04-22","objectID":"/neovimInitialization/:13:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 如果给出 -q 配置项，则读取 quickfix 文件quickfix 文件由 quickfix 指定。它用于记录编译器错误信息的文件，方便通过跳转方式到错误位置进行修复 ","date":"2023-04-22","objectID":"/neovimInitialization/:14:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 打开缓冲区窗口 如果使用 -o 命令行选项，则打开一个空白缓冲区窗口用于初始化完成后加载文件 如果使用 -p 命令行选项，则打开一个空白标签页用于初始化完成后加载文件 如果给出 -q 命令行选项，则跳转到第一个错误。将加载所有窗口的缓冲区，而不会触发 BufAdd 自动命令 ","date":"2023-04-22","objectID":"/neovimInitialization/:15:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" 执行启动命令 如果使用 -t 命令行选项，则跳转到指定标记 如果使用 -c 与 +cmd 命令行选项，则执行指定的命令 重置起始标记，has(\"vim_starting\") 的输出为 0 v:vim_did_enter 变量值设置为 1 执行 VimEnter 自动命令 配置项","date":"2023-04-22","objectID":"/neovimInitialization/:16:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" shell https://yianwillis.github.io/vimcdoc/doc/options.html#'shell' https://neovim.io/doc/user/options.html#'shell' ","date":"2023-04-22","objectID":"/neovimInitialization/:17:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["neovim"],"content":" exrc https://neovim.io/doc/user/options.html#'exrc' ","date":"2023-04-22","objectID":"/neovimInitialization/:18:0","tags":["vim","neovim"],"title":"neovim 初始化","uri":"/neovimInitialization/"},{"categories":["ansible"],"content":" 运行环境： ansible: 2.9 内容来自以下文档： ansible 文档 清单文件清单文件中定义了被管理主机信息，存储格式是以配置文件中inventory部分enable_plugins选项指定。通常是yaml或ini格式 [root@localhost ~]# grep 'enable_plugins' /etc/ansible/ansible.cfg #enable_plugins = host_list, virtualbox, yaml, constructed ini 格式示例： mail.example.com [webservers] foo.example.com bar.example.com [dbservers] one.example.com two.example.com three.example.com 以下是yaml 格式示例，它表达含义与上面的 ini 格式相同 all: hosts: mail.example.com: children: webservers: hosts: foo.example.com: bar.example.com: dbservers: hosts: one.example.com: two.example.com: three.example.com: ","date":"2023-04-18","objectID":"/ansible/:0:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 主机分组可以把被管理的服务器按需求进行分组（如地理位置、用途、系统版本等），一个服务器可以在不同的组中。ansible默认有以下2个组： all: 所有被管理的主机 ungrouped: 未分组的主机 all: hosts: mail.example.com: children: webservers: hosts: foo.example.com: bar.example.com: dbservers: hosts: one.example.com: two.example.com: three.example.com: east: hosts: foo.example.com: one.example.com: two.example.com: west: hosts: bar.example.com: three.example.com: prod: hosts: foo.example.com: one.example.com: two.example.com: test: hosts: bar.example.com: three.example.com: ","date":"2023-04-18","objectID":"/ansible/:1:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 组嵌套组可以嵌套， ini 格式：使用:children做为后缀 json 格式：使用children:字段 以下是 json 示例 all: hosts: mail.example.com: children: webservers: hosts: foo.example.com: bar.example.com: dbservers: hosts: one.example.com: two.example.com: three.example.com: east: hosts: foo.example.com: one.example.com: two.example.com: west: hosts: bar.example.com: three.example.com: prod: children: east: test: children: west: ","date":"2023-04-18","objectID":"/ansible/:2:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 主机范围当主机名是连续的序列(连续的数字或字母)或步长(只限数字)时可以指定范围减少清单文件 [webserverso] www[01:50].example.com [webservers1] www[01:50:2].example.com [databases] db-[a:f].example.com ... webservers0: hosts: www[01:50].example.com: ... webservers1: hosts: www[01:50:2].example.com: ","date":"2023-04-18","objectID":"/ansible/:3:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 主机变量在主机名后面可以添加自定义变量，多个变量以空格分隔 [atlanta] host1 http_port=80 maxRequestsPerChild=808 host2 http_port=303 maxRequestsPerChild=909 atlanta: hosts: host1: http_port: 80 maxRequestsPerChild: 808 host2: http_port: 303 maxRequestsPerChild: 909 ini 格式中远程端口可以写在主机名后 badwolf.example.com:5309 ","date":"2023-04-18","objectID":"/ansible/:4:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 清单目录可以定义多个清单文件，使用多个 -i 选项引用它们。也可以把多个文件放入单独的目录中，使用 -i 选项引用该目录。Ansible 根据文件名以 ASCII 顺序加载清单源。如果您在一个文件或目录中定义父组，在其他文件或目录中定义子组，则必须首先加载定义子组的文件，否则报错 Unable to parse /path/to/source_of_parent_groups as an inventory source inventory/ openstack.yml # configure inventory plugin to get hosts from OpenStack cloud dynamic-inventory.py # add additional hosts with dynamic inventory script on-prem # add static hosts and groups parent-groups # add static hosts and groups ","date":"2023-04-18","objectID":"/ansible/:5:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 变量组一个组以及嵌套组可以共享一些变量 [atlanta] host1 host2 [atlanta:vars] ntp_server=ntp.atlanta.example.com proxy=proxy.atlanta.example.com atlanta: hosts: host1: host2: vars: ntp_server: ntp.atlanta.example.com proxy: proxy.atlanta.example.com ","date":"2023-04-18","objectID":"/ansible/:6:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 变量组嵌套变量组可以进行嵌套，子变量优先级高于父变量 ini 格式以 :vars 结尾 json 格式用 vars: 字段 [atlanta] host1 host2 [raleigh] host2 host3 [southeast:children] atlanta raleigh [southeast:vars] some_server=foo.southeast.example.com halon_system_timeout=30 self_destruct_countdown=60 escape_pods=2 [usa:children] southeast northeast southwest northwest all: children: usa: children: southeast: children: atlanta: hosts: host1: host2: raleigh: hosts: host2: host3: vars: some_server: foo.southeast.example.com halon_system_timeout: 30 self_destruct_countdown: 60 escape_pods: 2 northeast: northwest: southwest: ","date":"2023-04-18","objectID":"/ansible/:7:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 自定义变量文件可以把变量放在单独的yaml文件或目录中 /etc/ansible/group_vars/raleigh # can optionally end in '.yml', '.yaml', or '.json' /etc/ansible/group_vars/webservers /etc/ansible/host_vars/foosball 变量Ansible 预使用了一些变量 ","date":"2023-04-18","objectID":"/ansible/:8:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 连接到主机相关变量设置以下变量控制 Ansible 如何与远程主机交互(ssh方式)： ansible_connection: 到主机的连接类型。这可以是任何 ansible 连接插件的名称。 ansible_host: 要连接的主机的名称 ansible_port: 要连接的主机的远程端口号，缺省为 22 ansible_user: 要连接的主机的用户名 ansible_password: 连接到主机时使用的用户名的密码 ansible_ssh_private_key_file: ssh 使用的私钥文件，默认为 ~/.ssh/ ansible_ssh_common_args: 连接后默认执行的命令行 ansible_sftp_extra_args: 连接后默认执行的命令行(sftp) ansible_scp_extra_args: 连接后默认执行的命令行(scp) ansible_ssh_extra_args: 连接后默认执行的命令行(ssh) ansible_ssh_pipelining: 是否使用 SSH 流水线，会覆盖配置文件中 pipelining 选项值。(在 2.2 版本中加入) ansible_become: 是否允许使用 su 或 sudo 命令 ansible_sudo: 是否允许使用 sudu 命令 ansible_su: 是否允许使用 su 命令 ansible_become_method: 允许设置权限升级方法 ansible_become_user: 允许设置你通过权限升级成为的用户 ansible_sudo_user: 允许使用 sudo 命令提权的用户 ansible_su_user: 允许使用 su 命令提权的用户 ansible_become_password: 提权使用到的密码 ansible_sudo_password: 使用 sudo 命令用到的密码 ansible_su_password: 使用 su 命令用到的密码 ansible_become_exe: 使用 su 或 sudo 命令提权后允许执行的可执行文件 ansible_sudo_exe: 使用 sudo 命令提权后允许执行的可执行文件 ansible_su_exe: 使用 su 命令提权后允许执行的可执行文件 ansible_become_flags: 使用 sudo 命令或 su 命令的参数，覆盖配置文件中 sudo_flags 选项值 ansible_sudo_flags: 使用 sudo 命令命令的参数 ansible_su_flags: 使用 su 命令的参数 ansible_shell_type: 目标系统内核外壳类型，默认情况下，命令使用 -style 语法进行格式化sh ansible_python_interpreter: 目标主机 python 路径，默认为 /usr/bin/python* ansible_*_interpreter: ansible_shell_executable: 目标主机shell 路径，默认为 /bin/sh。覆盖配置文件中 executable 选项值 连接方式默认情况下，Ansible 使用本机 OpenSSH，因为它支持 ControlPersist（一种性能特性）、Kerberos 和~/.ssh/configJump Host 设置等选项。如果控制机器使用不支持 ControlPersist 的旧版本 OpenSSH，Ansible 将回退到名为paramiko的 OpenSSH Python 实现。除了 ssh 方式 Ansible 还支持本地连接 localhost 与 docker 连接。使用 ansible_connection 配置项目指定。更多相关 ssh 连接设置查看 ansible.builtin.ssh ","date":"2023-04-18","objectID":"/ansible/:9:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" ssh 相关配置默认情况下会检查密钥文件，当known_hosts文件中有同个主机有多个密钥时会报错，当没有主机连接记录时会要手动确认。如果想关闭该功能要修改 ANSIBLE_HOST_KEY_CHECKING 环境变量或配置文件中的 host_key_checking 配置项值为 False PlaybooksAnsible Playbooks 提供了一种可重复、可重用、简单的配置管理和多机部署系统，非常适合部署复杂的应用程序。它使用 yaml 文档声明执行方式 --- - name: Update web servers hosts: webservers remote_user: root tasks: - name: Ensure apache is at the latest version ansible.builtin.yum: name: httpd state: latest - name: Write the apache config file ansible.builtin.template: src: /srv/httpd.j2 dest: /etc/httpd.conf - name: Update db servers hosts: databases remote_user: root tasks: - name: Ensure postgresql is at the latest version ansible.builtin.yum: name: postgresql state: latest - name: Ensure that postgresql is started ansible.builtin.service: name: postgresql state: started name: 该字段指定说明信息，会输出到标准输出 hosts: 该字段指定被操作的主机，可以是主机名、主机组（清单文件中定义） remote_user: 该字段指定远程用户 tasks: 执行的任务列表。默认情况下，Ansible 针对与主机模式匹配的所有机器按顺序执行每个任务，一次一个。每个任务执行一个带有特定参数的模块。当一个任务在所有目标机器上执行完毕后，Ansible 会继续执行下一个任务 tasks.name: 说明信息，会输出到标准输出 tasks.ansible.*: 调用模块执行的操作。模块会检查是否已达到所需的最终状态，如果已达到该状态，则退出而不执行任何操作，大多数的模块具有幂等性（无论运行 playbook 一次还是多次，结果都应该是相同的）。但并非所有剧本和模块都以这种方式运行 ","date":"2023-04-18","objectID":"/ansible/:10:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 任务状态","date":"2023-04-18","objectID":"/ansible/:11:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 重置 failed 条件https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_error_handling.html#defining-failure ","date":"2023-04-18","objectID":"/ansible/:11:1","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 重置 changed 条件https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_error_handling.html#defining-changed ","date":"2023-04-18","objectID":"/ansible/:11:2","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 过滤器Ansible 使用 Jinja2 模板来启用动态表达式以及对变量和事实的访问。在目标机器上发送和执行任务之前，所有模板都发生在 Ansible 控制器上。这种方法最大限度地减少了对目标的包要求（jinja2 仅在控制器上需要）。它还限制了 Ansible 传递给目标机器的数据量。Ansible 在控制器上解析模板，只将每个任务需要的信息传递给目标机器，而不是将所有数据都传递到控制器上，然后在目标机器上解析。 Ansible 使用 ansible.builtin.template 将文件模板化到目标主机。它使用的文件和数据必须是 utf-8 编码的 ","date":"2023-04-18","objectID":"/ansible/:12:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 过滤数据处理数据过滤器可让您将 JSON 数据转换为 YAML 数据、拆分 URL 以提取主机名、获取字符串的 SHA1 哈希值、添加或乘以整数等等。有以下过滤器： Ansible 过滤器 Jinja2 过滤器 python 方法转换数据 ","date":"2023-04-18","objectID":"/ansible/:13:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 处理未定义变量在 playbook 中可以使用 {{ }} 引用变量，如果引用的变量不存在则会报错，可以通过忽略变量、提供默认值、使变量可选项等方式处理 default() 函数可以为变量提供一个默认值，如下面示例，当 some_variable 变量不存在时其值为 5 {{ some_variable | default(5) }} 从 2.8 开始还可以同时设置多少默认值，如 {{ lookup('env', 'MY_USER') | default('admin', true) }} default() 值为 omit 时可以将特定变量设为可选的。如下面示例创建文件指定其mask值 - name: Touch files with an optional mode ansible.builtin.file: dest: \"{{ item.path }}\" state: touch mode: \"{{ item.mode | default(omit) }}\" loop: - path: /tmp/foo - path: /tmp/bar - path: /tmp/baz mode: \"0444\" 如果已经配置忽略未定义的变量的情况下，要强制必须有某些变量能可以使用 mandatory 关键字强制报错 {{ variable | mandatory }} undef 关键字可以重写变量 galaxy_url: \"https://galaxy.ansible.com\" galaxy_api_key: \"{{ undef(hint='You must specify your Galaxy API key') }}\" ","date":"2023-04-18","objectID":"/ansible/:13:1","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 为 true/false/null 定义不同的值在 1.9 版本中加入的新功能，创建一个测试，然后定义一个值在测试返回 true 时使用，在测试返回 false 时使用另一个值 {{ (status == 'needs_restart') | ternary('restart', 'continue') }} 在 2.8 版本中增强了该功能，可以定义一个值用于 true，一个值用于 false，第三个值用于 null {{ enabled | ternary('no shutdown', 'shutdown', omit) }} ","date":"2023-04-18","objectID":"/ansible/:13:2","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 查看数据类型type_debug 关键字可以查看变量的底层 python 数据类型 {{ myvar | type_debug }} ","date":"2023-04-18","objectID":"/ansible/:13:3","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 将字典转换为列表dict2items 关键字可以将字典转换为适合列表 {{ dict | dict2items }} 在 2.8 版本中增强了该功能。可以指定键值对 {{ files | dict2items(key_name='file', value_name='path') }} ","date":"2023-04-18","objectID":"/ansible/:13:4","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 将列表转换为字典在 2.7 版本开始可以使用items2dict过滤器将列表转换为字典，将内容映射成键值对 {{ tags | items2dict }} 也可以指定键值对，但并非所有列表都使用key做为键，value做为值 fruits: - fruit: apple color: red - fruit: pear color: yellow - fruit: grapefruit color: yellow 上面的列表必须指定键值对，否则会报错：KeyError: keyKey, Error: my_typo {{ tags | items2dict(key_name='fruit', value_name='color') }} ","date":"2023-04-18","objectID":"/ansible/:13:5","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 强制数据类型从 1.6 版本开始可以将值转换为特定类型 # 将其识别为布尔值而不是字符串 - ansible.builtin.debug: msg: test when: some_string_value | bool # 将它识别为一个整数而不是一个字符串 - shell: echo \"only on Red Hat 6, derivatives, and later\" when: ansible_facts['os_family'] == \"RedHat\" and ansible_facts['lsb']['major_release'] | int \u003e= 6 ","date":"2023-04-18","objectID":"/ansible/:13:6","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 判断数据从 Ansible 2.5 开始，使用 jinja 测试作为过滤器将生成弃用警告。从 Ansible 2.9+ 开始，需要使用 jinja 测试语法。语法如下 variable is test_name ","date":"2023-04-18","objectID":"/ansible/:14:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 比较字符串将字符串与子字符串或正则表达式进行匹配可以使用以下关键字： match: 从字符串开头匹配 search: 匹配部分字符串 regex: 使用正则表达式匹配 以上所有的字符串测试也采用可选的ignorecase和multiline参数 vars: url: \"https://example.com/users/foo/resources/bar\" tasks: - debug: msg: \"matched pattern 1\" when: url is match(\"https://example.com/users/.*/resources\") - debug: msg: \"matched pattern 2\" when: url is search(\"users/.*/resources/.*\") - debug: msg: \"matched pattern 3\" when: url is search(\"users\") - debug: msg: \"matched pattern 4\" when: url is regex(\"example\\.com/\\w+/foo\") ","date":"2023-04-18","objectID":"/ansible/:14:1","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 判断是否加密从 2.10 开始可以使用vault_encrypted关键字测试值是否加密 vars: variable: !vault | $ANSIBLE_VAULT;1.2;AES256;dev 61323931353866666336306139373937316366366138656131323863373866376666353364373761 3539633234313836346435323766306164626134376564330a373530313635343535343133316133 36643666306434616266376434363239346433643238336464643566386135356334303736353136 6565633133366366360a326566323363363936613664616364623437336130623133343530333739 3039 tasks: - debug: msg: '{{ (variable is vault_encrypted) | ternary(\"Vault encrypted\", \"Not vault encrypted\") }}' ","date":"2023-04-18","objectID":"/ansible/:14:2","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" truthy and falsy从 Ansible 2.10 开始，您现在可以像 Python 一样执行 truthy 和 falsy 检查，这两个关键字可以加 convert_bool 参数尝试转换为布尔值 - debug: msg: \"Truthy\" when: value is truthy vars: value: \"some string\" - debug: msg: \"Falsy\" when: value is falsy vars: value: \"\" - debug: msg: \"Truthy\" when: value is truthy(convert_bool=True) vars: value: \"yes\" - debug: msg: \"Falsy\" when: value is falsy(convert_bool=True) vars: value: \"off\" ","date":"2023-04-18","objectID":"/ansible/:14:3","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 版本号比较从1.6 版本开始可使用 version_compare 函数对比数值，到 2.5 版本改名为 version。它的第一个参数为数值，第二个参数为运算符，第三个参数为strict或version_type。 vars: my_version: 1.2.3 tasks: - debug: msg: \"my_version is higher than 1.0.0\" when: my_version is version('1.0.0', '\u003e') 如下示例。如果ansible_facts['distribution_version']大于或等于 12.04，则此测试返回 True，否则返回 False {{ ansible_facts['distribution_version'] is version('12.04', '\u003e=') }} version 函数可接受以下运算符 \u003c, lt, \u003c=, le, \u003e, gt, \u003e=, ge, ==, =, eq, !=, \u003c\u003e, ne strict 参数值为 True(启用严格匹配) 或 False(宽松匹配，也是默认值) {{ sample_version_var is version('1.0', operator='lt', strict=True) }} 从 Ansible 2.11 开始，version 函数接受一个 version_type 参数，该参数不能同时与 strict 参数使用。version_type 参数有以下值： loose: 宽松匹配 strict: 版本号由两个或三个点分隔的数字部分组成，末尾有一个可选的[a|b][0-9]标签 semver/semantic: 版本比较 pep440: 2.14 版本本添加的，实现Python PEP-440版本控制规则对比 {{ sample_semver_var is version('2.0.0-rc.1+build.123', 'lt', version_type='semver') }} {{ '2.14.0rc1' is version('2.14.0', 'lt', version_type='pep440') }} ","date":"2023-04-18","objectID":"/ansible/:14:4","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 集合比较从2.1版本开始可以使用issubset函数(子集)与issuperset函数(超集)判断一个集合是否包含另一个集合。从2.5 版本开始改名为 subset 与 superset vars: a: [1,2,3,4,5] b: [2,3] tasks: - debug: msg: \"A includes B\" when: a is superset(b) - debug: msg: \"B is included in A\" when: b is subset(a) ","date":"2023-04-18","objectID":"/ansible/:14:5","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 列表是否包含值从2.8版本开始，可以使用contains函数判断列表中是否含有某个值。通常与select、reject、selectattr和rejectattr函数一起使用 vars: lacp_groups: - master: lacp0 network: 10.65.100.0/24 gateway: 10.65.100.1 dns4: - 10.65.100.10 - 10.65.100.11 interfaces: - em1 - em2 - master: lacp1 network: 10.65.120.0/24 gateway: 10.65.120.1 dns4: - 10.65.100.10 - 10.65.100.11 interfaces: - em3 - em4 ## 判断 interfaces 列表是否含有 em1 tasks: - debug: msg: \"{{ (lacp_groups|selectattr('interfaces', 'contains', 'em1')|first).master }}\" ","date":"2023-04-18","objectID":"/ansible/:14:6","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 判断列表值是否为 True从2.4版本可以使用 any 和 all 来检查列表中的任何或所有元素是否为真 vars: mylist: - 1 - \"{{ 3 == 3 }}\" - True myotherlist: - False - True tasks: - debug: msg: \"all are true!\" when: mylist is all - debug: msg: \"at least one is true\" when: myotherlist is any ","date":"2023-04-18","objectID":"/ansible/:14:7","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 判断路径 - debug: msg: \"path is a directory\" when: mypath is directory - debug: msg: \"path is a file\" when: mypath is file - debug: msg: \"path is a symlink\" when: mypath is link - debug: msg: \"path already exists\" when: mypath is exists - debug: msg: \"path is {{ (mypath is abs)|ternary('absolute','relative')}}\" - debug: msg: \"path is the same file as path2\" when: mypath is same_file(path2) - debug: msg: \"path is a mount\" when: mypath is mount - debug: msg: \"path is a directory\" when: mypath is directory vars: mypath: /my/patth - debug: msg: \"path is a file\" when: \"'/my/path' is file\" ","date":"2023-04-18","objectID":"/ansible/:14:8","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 检查任务状态从2.1开始，还可以使用success、failure、change、skip来进行语法匹配 tasks: - shell: /usr/bin/foo register: result ignore_errors: True - debug: msg: \"it failed\" when: result is failed # in most cases you'll want a handler, but if you want to do something right now, this is nice - debug: msg: \"it changed\" when: result is changed - debug: msg: \"it succeeded in Ansible \u003e= 2.1\" when: result is succeeded - debug: msg: \"it succeeded\" when: result is success - debug: msg: \"it was skipped\" when: result is skipped ","date":"2023-04-18","objectID":"/ansible/:14:9","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 判断类型type_debug 类型测试比较 tasks: - name: \"String interpretation\" vars: a_string: \"A string\" a_dictionary: {\"a\": \"dictionary\"} a_list: [\"a\", \"list\"] assert: that: # Note that a string is classed as also being \"iterable\" and \"sequence\", but not \"mapping\" - a_string is string and a_string is iterable and a_string is sequence and a_string is not mapping # Note that a dictionary is classed as not being a \"string\", but is \"iterable\", \"sequence\" and \"mapping\" - a_dictionary is not string and a_dictionary is iterable and a_dictionary is mapping # Note that a list is classed as not being a \"string\" or \"mapping\" but is \"iterable\" and \"sequence\" - a_list is not string and a_list is not mapping and a_list is iterable - name: \"Number interpretation\" vars: a_float: 1.01 a_float_as_string: \"1.01\" an_integer: 1 an_integer_as_string: \"1\" assert: that: # Both a_float and an_integer are \"number\", but each has their own type as well - a_float is number and a_float is float - an_integer is number and an_integer is integer # Both a_float_as_string and an_integer_as_string are not numbers - a_float_as_string is not number and a_float_as_string is string - an_integer_as_string is not number and a_float_as_string is string # a_float or a_float_as_string when cast to a float and then to a string should match the same value cast only to a string - a_float | float | string == a_float | string - a_float_as_string | float | string == a_float_as_string | string # Likewise an_integer and an_integer_as_string when cast to an integer and then to a string should match the same value cast only to an integer - an_integer | int | string == an_integer | string - an_integer_as_string | int | string == an_integer_as_string | string # However, a_float or a_float_as_string cast as an integer and then a string does not match the same value cast to a string - a_float | int | string != a_float | string - a_float_as_string | int | string != a_float_as_string | string # Again, Likewise an_integer and an_integer_as_string cast as a float and then a string does not match the same value cast to a string - an_integer | float | string != an_integer | string - an_integer_as_string | float | string != an_integer_as_string | string - name: \"Native Boolean interpretation\" loop: - yes - true - True - TRUE - no - No - NO - false - False - FALSE assert: that: # Note that while other values may be cast to boolean values, these are the only ones which are natively considered boolean # Note also that `yes` is the only case sensitive variant of these values. - item is boolean ","date":"2023-04-18","objectID":"/ansible/:14:10","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 获取当前时间now 函数获取对象的本地时间，有以下参数： utc: 使用UTC标准时间。值为 True 或 False(默认值) 自定义格式，参考strftime-strptime-behavior ","date":"2023-04-18","objectID":"/ansible/:15:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 循环Ansible 提供loop、with_\u003clookup\u003e和until关键字来多次执行任务 ","date":"2023-04-18","objectID":"/ansible/:16:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 遍历列表loop关键字可以输入一个列表（以逗号分割），item 变量循环获取 loop 列表的每个值。 - name: Add several users ansible.builtin.user: name: \"{{ item }}\" state: present groups: \"wheel\" loop: - testuser1 - testuser2 - name: Optimal yum ansible.builtin.yum: name: \"{{ list_of_packages }}\" state: present - name: Non-optimal yum, slower and may cause issues with interdependencies ansible.builtin.yum: name: \"{{ item }}\" state: present loop: \"{{ list_of_packages }}\" 可以使用 Jinja2 表达式迭代复杂列表 - name: Give users access to multiple databases community.mysql.mysql_user: name: \"{{ item[0] }}\" priv: \"{{ item[1] }}.*:ALL\" append_privs: true password: \"foo\" loop: \"{{ ['alice', 'bob'] | product(['clientdb', 'employeedb', 'providerdb']) | list }}\" 从Ansible 2.5 引入了一个名为query的新 Jinja2 函数。该函数始终反回一个列表 loop: \"{{ query('inventory_hostnames', 'all') }}\" # 等效 loop: \"{{ lookup('inventory_hostnames', 'all', wantlist=True) }}\" ","date":"2023-04-18","objectID":"/ansible/:16:1","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 遍历哈希如果是键值对列表可以引用子键 - name: Add several users ansible.builtin.user: name: \"{{ item.name }}\" state: present groups: \"{{ item.groups }}\" loop: - { name: 'testuser1', groups: 'wheel' } - { name: 'testuser2', groups: 'root' } ","date":"2023-04-18","objectID":"/ansible/:16:2","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 遍历字典如果是遍历字典，需要使用 dict2items 关键字转换为列表 - name: Using dict2items ansible.builtin.debug: msg: \"{{ item.key }} - {{ item.value }}\" loop: \"{{ tag_data | dict2items }}\" vars: tag_data: Environment: dev Application: payment ","date":"2023-04-18","objectID":"/ansible/:16:3","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 重复执行任务知道满足条件从 1.4 版本开始，可以使用 until 关键字重试任务，ansible-playbook -vv 可以查看重试的次数，结果在注册变量中的 attempts 键 - name: Retry a task until a certain condition is met ansible.builtin.shell: /usr/bin/foo register: result # 重试条件 until: result.stdout.find(\"all systems go\") != -1 # 重试次数 retries: 5 # 重试间隔时间，单位秒 delay: 10 ","date":"2023-04-18","objectID":"/ansible/:16:4","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 遍历清单文件可以使用 ansible_play_batch 变量、 groups 变量、inventory_hostnames 变量遍历清单列表 - name: Show all the hosts in the inventory ansible.builtin.debug: msg: \"{{ item }}\" loop: \"{{ groups['all'] }}\" - name: Show all the hosts in the current play ansible.builtin.debug: msg: \"{{ item }}\" loop: \"{{ ansible_play_batch }}\" - name: Show all the hosts in the inventory ansible.builtin.debug: msg: \"{{ item }}\" loop: \"{{ query('inventory_hostnames', 'all') }}\" - name: Show all the hosts matching the pattern, ie all but the group www ansible.builtin.debug: msg: \"{{ item }}\" loop: \"{{ query('inventory_hostnames', 'all:!www') }}\" ","date":"2023-04-18","objectID":"/ansible/:16:5","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 限制循环输出信息loop_control.label 关键字能指定 loop 关键字的输出信息，使用 no_log: yes 能禁止输出信息 - name: Create servers digital_ocean: name: \"{{ item.name }}\" state: present loop: - name: server1 disks: 3gb ram: 15Gb network: nic01: 100Gb nic02: 10Gb ... loop_control: label: \"{{ item.name }}\" ","date":"2023-04-18","objectID":"/ansible/:16:6","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 暂停循环从2.2 版本开始，可以使用loop_control下pause 字段能控制循环任务间隔时间（秒） # main.yml - name: Create servers, pause 3s before creating next community.digitalocean.digital_ocean: name: \"{{ item }}\" state: present loop: - server1 - server2 loop_control: pause: 3 ","date":"2023-04-18","objectID":"/ansible/:16:7","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 循环列表的索引从2.5 版本开始，可以使用loop_control下index_var字段能获取列表索引值 - name: Count our fruit ansible.builtin.debug: msg: \"{{ item }} with index {{ my_idx }}\" loop: - apple - banana - pear loop_control: index_var: my_idx ","date":"2023-04-18","objectID":"/ansible/:16:8","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" loop 扩展信息从 2.8 版本开始，可以启用loop_control.extended启用以下变量，它会占用更多的内存 ansible_loop.allitems: 循环中的列表值。从2.14开始可以使用true或false关闭 ansible_loop.index: 循环中索引(从1开始) ansible_loop.index0: 循环中索引(从0开始) ansible_loop.revindex: 循环次数 ansible_loop.revindex0: 循环次数(从0开始) ansible_loop.first: 如果为 True 表示第一次迭代 ansible_loop.last: 如果为 True 表示最后一次迭代 ansible_loop.length: 循环中的项目个数 ansible_loop.previtem ansible_loop.nextitem ","date":"2023-04-18","objectID":"/ansible/:16:9","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 执行任务位置执行的操作可以在当前主机执行，也可以目标主机上执行(默认)。以下操作只能在本地执行 include add_host debug 如果某些操作想在特定主机上执行可以使用delegate_to指定，指定的目标主机不一定是在清单文件中，但这样会缺少部分变量导致任务执行失败，可以使用ansible.builtin.add_host 模块添加到清单文件中 --- - hosts: webservers serial: 5 tasks: - name: Take out of load balancer pool ansible.builtin.command: /usr/bin/take_out_of_pool {{ inventory_hostname }} delegate_to: 127.0.0.1 - name: Actual steps would go here ansible.builtin.yum: name: acme-web-stack state: latest - name: Add back to load balancer pool ansible.builtin.command: /usr/bin/add_back_to_pool {{ inventory_hostname }} delegate_to: 127.0.0.1 ","date":"2023-04-18","objectID":"/ansible/:17:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 本地执行 --- - hosts: webservers serial: 5 tasks: - name: Take out of load balancer pool ansible.builtin.command: /usr/bin/take_out_of_pool {{ inventory_hostname }} delegate_to: 127.0.0.1 --- # host 指定为 127.0.0.1 表示本机 - hosts: localhost # 修改默认的远程连接类型（可选） connection: local serial: 5 tasks: - name: Take out of load balancer pool ansible.builtin.command: /usr/bin/take_out_of_pool {{ inventory_hostname }} --- # ... tasks: - name: Take out of load balancer pool local_action: ansible.builtin.command /usr/bin/take_out_of_pool {{ inventory_hostname }} https://cloud.tencent.com/developer/article/1519723 ","date":"2023-04-18","objectID":"/ansible/:17:1","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 条件句when 字段用于当满足条件(Jinja 条件判断、jinja 测试语句、ansible 过滤器)满足才执行操作。该子句是没有双花括号的原始 Jinja2 表达式。它是值为列表，每个列表表示一个条件判断，当有多个列表时所有条件满足才执行 tasks: # selinux 状态为 enabled 时执行 - name: Configure SELinux to start mysql on any port ansible.posix.seboolean: name: mysql_connect_any state: true persistent: true when: ansible_selinux.status == \"enabled\" 当有多个条件时可以使用括号、逻辑运算符进行复杂的判断 tasks: - name: Shut down CentOS 6 and Debian 7 systems ansible.builtin.command: /sbin/shutdown -t now when: (ansible_facts['distribution'] == \"CentOS\" and ansible_facts['distribution_major_version'] == \"6\") or (ansible_facts['distribution'] == \"Debian\" and ansible_facts['distribution_major_version'] == \"7\") --- tasks: - name: Shut down CentOS 6 systems ansible.builtin.command: /sbin/shutdown -t now when: - ansible_facts['distribution'] == \"CentOS\" - ansible_facts['distribution_major_version'] == \"6\" --- tasks: - ansible.builtin.shell: echo \"only on Red Hat 6, derivatives, and later\" when: ansible_facts['os_family'] == \"RedHat\" and ansible_facts['lsb']['major_release'] | int \u003e= 6 ","date":"2023-04-18","objectID":"/ansible/:18:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 任务状态为 failed 触发其它任务block 可以把多个任务进行分组处理，并提供以下异常处理方式： rescue字段用于block字段中的任意一个任务失败(failed状态)时触发的任务 always 字段是 block字段任务执行后（不管成功还是失败）都会执行 - name: Attempt and graceful roll back demo block: - name: Print a message ansible.builtin.debug: msg: 'I execute normally' - name: Force a failure ansible.builtin.command: /bin/false - name: Never print this ansible.builtin.debug: msg: 'I never execute, due to the above task failing, :-(' rescue: - name: Print when errors ansible.builtin.debug: msg: 'I caught an error' - name: Force a failure in middle of recovery! \u003e:-) ansible.builtin.command: /bin/false - name: Never print this ansible.builtin.debug: msg: 'I also never execute :-(' always: - name: Always do this ansible.builtin.debug: msg: \"This always executes\" 如果block中的任务触发rescue字段，且这些字段中定义的任务执行成功。则不会中段后续任务。也不会触发any_errors_fatal与max_fail_percentage配置项。但ansible输出信息中任然有失败信息。可以在 rescue 中使用meta: flush_handlers忽略错误 tasks: - name: Attempt and graceful roll back demo block: - name: Print a message ansible.builtin.debug: msg: 'I execute normally' changed_when: true notify: run me even after an error - name: Force a failure ansible.builtin.command: /bin/false rescue: - name: Make sure all handlers run meta: flush_handlers handlers: - name: Run me even after an error ansible.builtin.debug: msg: 'This handler runs even on error' rescue 提供以下变量，这些变量在 2.14 开始可以在 rescue 外获取 ansible_failed_task.: 待补充 ansible_failed_result: 待补充 ","date":"2023-04-18","objectID":"/ansible/:19:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 任务状态为 changed 时触发其他任务notify 字段可以在任务状态为 changed 时调用 handlers 字段中的任务。handlers 字段中的任务列表名称是全局唯一的，按执行顺序以yaml文件定义为准，而不是notify列表顺序 tasks: - name: Template configuration file ansible.builtin.template: src: template.j2 dest: /etc/foo.conf # 任务状态结果为 changed 时调用 handlers 列表中 # 名为 Restart apache 与 Restart memcached 任务 notify: - Restart apache - Restart memcached handlers: # 优先执行 - name: Restart memcached ansible.builtin.service: name: memcached state: restarted # 最后执行 - name: Restart apache ansible.builtin.service: name: apache state: restarted 如果tasks列表中有多少任务调用同一个 handlers 任务则它们中最后的一个任务状态为 changed 才会调用，忽略之前的调用。 默认情况下只有 tasks 任务列表正常结束（没有失败，因为失败会中断剧本执行）后才会调用 handlers 列表，这样可以保证handlers 列表中的任务只会执行一次。可以使用tasks.meta字段直接调用（插队）。 tasks: - name: Some tasks go here ansible.builtin.shell: ... # 调用 handlers 任务列表中任务 - name: Flush handlers meta: flush_handlers - name: Some other tasks ansible.builtin.shell: .. handlers 任务列表中的任务是可以使用 listen 字段进行分组。notify 字段可以调用分组 tasks: - name: Restart everything command: echo \"this task will restart the web services\" notify: \"restart web services\" handlers: - name: Restart memcached service: name: memcached state: restarted listen: \"restart web services\" - name: Restart apache service: name: apache state: restarted listen: \"restart web services\" ","date":"2023-04-18","objectID":"/ansible/:20:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" Playbooks 错误处理默认情况下，ansible 收到非0的状态码或模块返回的错误时（状态），会停止该主机上继续执行其他任务，其它主机不受影响。 ","date":"2023-04-18","objectID":"/ansible/:21:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 忽略 failed 状态当模块执行状态为 failed 时可以启用 ignore_errors 字段忽略错误，使后续任务能继续在目标主机执行 - name: Do not count this as a failure ansible.builtin.command: /bin/false ignore_errors: true ","date":"2023-04-18","objectID":"/ansible/:21:1","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 忽略 UNREACHABLE 错误由于主机无法连接导致报错 UNREACHABLE，可以启用ignore_unreachable 关键字忽略该错误(这有什么用途？) - name: This executes, fails, and the failure is ignored ansible.builtin.command: /bin/true ignore_unreachable: true - name: This executes, fails, and ends the play for this host ansible.builtin.command: /bin/true ","date":"2023-04-18","objectID":"/ansible/:21:2","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 确保 shell 命令成功ansible.builtin.shell 模块执行的命令返回值不为 0 时，任务状态码为 failed。因此可以通过使用 || 让命令返回的状态码为 0 tasks: - name: Run this command and ignore the result ansible.builtin.shell: /usr/bin/somecommand || /bin/true ","date":"2023-04-18","objectID":"/ansible/:21:3","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" 等待补充https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_error_handling.html#ensuring-success-for-command-and-shell ","date":"2023-04-18","objectID":"/ansible/:21:4","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["ansible"],"content":" ansible-lint运行 playbook 之前验证它们以捕获语法错误和其他问题。ansible-playbook命令提供了多个验证选项，包括--check、--diff、--list-hosts、--list-tasks和--syntax-check。用于验证剧本的工具描述了用于验证和测试剧本的其他工具。也可以使用 ansible-lint 命令 ","date":"2023-04-18","objectID":"/ansible/:22:0","tags":["ansible"],"title":"Ansible 是一种 IT 自动化工具","uri":"/ansible/"},{"categories":["windows"],"content":" ","date":"2023-04-18","objectID":"/windowsWsl/","tags":["wsl"],"title":"Windows Subsystem for Linux ","uri":"/windowsWsl/"},{"categories":["windows"],"content":" 运行环境： wsl: 1.2 内容来自以下文档： WSL 文档 error","date":"2023-04-18","objectID":"/windowsWsl/:0:0","tags":["wsl"],"title":"Windows Subsystem for Linux ","uri":"/windowsWsl/"},{"categories":["windows"],"content":" Error code: Wsl/WININET_E_NAME_NOT_RESOLVED PS 2023/04/18 09:12:55 \u003e wsl --install 无法从“https://raw.githubusercontent.com/microsoft/WSL/master/distributions/DistributionInfo.json”中提取列表分发。无法解析服务器的名称或地址 Error code: Wsl/WININET_E_NAME_NOT_RESOLVED 服务器无法解析网址 PS 2023/04/18 09:16:36 \u003e ping raw.githubusercontent.com Ping 请求找不到主机 raw.githubusercontent.com。请检查该名称，然后重试。 修改DNS地址之后就可以 ","date":"2023-04-18","objectID":"/windowsWsl/:1:0","tags":["wsl"],"title":"Windows Subsystem for Linux ","uri":"/windowsWsl/"},{"categories":["windows"],"content":" Error code: Wsl/WSL_E_WSL_OPTIONAL_COMPONENT_REQUIRED PS 2023/04/18 08:56:31 \u003e wsl -l -v 此应用程序需要适用于 Linux 的 Windows 子系统可选组件。 可能需要重新启动系统才能使更改生效。 Error code: Wsl/WSL_E_WSL_OPTIONAL_COMPONENT_REQUIRED ","date":"2023-04-18","objectID":"/windowsWsl/:2:0","tags":["wsl"],"title":"Windows Subsystem for Linux ","uri":"/windowsWsl/"},{"categories":["linux"],"content":" 运行环境： centos: 7 iftopiftop 用于查看网卡带宽 [root@localhost ~]# man iftop | cat IFTOP(8) System Manager's Manual IFTOP(8) # SYNOPSIS iftop -h | [-nNpblP] [-u unit] [-i interface] [-f filter code] [-F net/mask] [-G net6/mask6] # OPTIONS -h # 查看简要帮助信息 -n # 不解析主机名 -N # 不要将端口号转换为服务，如80=\u003eHTTP -p # 以混杂模式运行，因此不直接通过指定接口的流量也被统计在内。 -P # 显示端口号 -l # 显示链路层 -b # 不显示图形状 -m limit Set the upper limit for the bandwidth scale. Specified as a number with a 'K', 'M' or 'G' suffix. -u bits|bytes|packets Display bandwidth rates in the given unit (per second). -B Synonym for -u bits. -i interface Listen to packets on interface. -f filter code Use filter code to select the packets to count. Only IP packets are ever counted, so the specified code is evaluated as (filter code) and ip. -F net/mask Specifies an IPv4 network for traffic analysis. If specified, iftop will only include packets flowing in to or out of the given network, and packet direction is determined relative to the network boundary, rather than to the interface. You may specify mask as a dotted quad, such as /255.255.255.0, or as a single number specifying the number of bits set in the netmask, such as /24. -G net6/mask6 Specifies an IPv6 network for traffic analysis. The value of mask6 can be given as a prefix length or as a numerical address string for more compound bitmasking. -c config file Specifies an alternate config file. If not specified, iftop will use ~/.iftoprc if it exists. See below for a description of config files -t text output mode Use text interface without ncurses and print the output to STDOUT. ","date":"2023-04-12","objectID":"/linuxCmdIftop/:0:0","tags":["linux","命令"],"title":"iftop - 显示主机在接口上的带宽使用情况","uri":"/linuxCmdIftop/"},{"categories":["hugo"],"content":" 运行环境： hugo aaa ","date":"2023-04-08","objectID":"/hugoTest/:0:0","tags":["test"],"title":"hugo 测试页面","uri":"/hugoTest/"},{"categories":["linux"],"content":" 运行环境： centos: 7 convmv 安装 [root@localhost hugo]# history | grep conv 864 yum install convmv 帮助信息 [root@localhost hugo]# man convmv | cat ... # SYNOPSIS convmv [options] FILE(S) ... DIRECTORY(S) # OPTIONS -f ENCODING # 指定当前文件名使用的编码，即转换前的编码 -t ENCODING # 指定转换后的编码 -i interactive mode (ask y/n for each action) -r # 递归方式遍历目录 --nfc target files will be normalization form C for UTF-8 (Linux etc.) --nfd target files will be normalization form D for UTF-8 (OS X etc.). --qfrom , --qto be more quiet about the \"from\" or \"to\" of a rename (if it screws up your terminal e.g.). This will in fact do nothing else than replace any non-ASCII character (bytewise) with ? and any control character with * on printout, this does not affect rename operation itself. --exec command execute the given command. You have to quote the command and #1 will be substituted by the old, #2 by the new filename. Using this option link targets will stay untouched. Example: convmv -f latin1 -t utf-8 -r --exec \"echo #1 should be renamed to #2\" path/to/files --list list all available encodings. To get support for more Chinese or Japanese encodings install the Perl HanExtra or JIS2K Encode packages. --lowmem keep memory footprint low by not creating a hash of all files. This disables checking if symlink targets are in subtree. Symlink target pointers will be converted regardlessly. If you convert multiple hundredthousands or millions of files the memory usage of convmv might grow quite high. This option would help you out in that case. --nosmart by default convmv will detect if a filename is already UTF8 encoded and will skip this file if conversion from some charset to UTF8 should be performed. \"--nosmart\" will also force conversion to UTF-8 for such files, which might result in \"double encoded UTF-8\" (see section below). --fixdouble using the \"--fixdouble\" option convmv does only convert files which will still be UTF-8 encoded after conversion. That's useful for fixing double-encoded UTF-8 files. All files which are not UTF-8 or will not result in UTF-8 after conversion will not be touched. Also see chapter \"How to undo double UTF-8 ...\" below. --notest # 重命名文件 --parsable This is an advanced option that people who want to write a GUI front end will find useful (some others maybe, too). It will convmv make print out what it would do in an easy parsable way. The first column contains the action or some kind of information, the second column mostly contains the file that is to be modified and if appropriate the third column contains the modified value. Each column is separated by \\0\\n (nullbyte newline). Each row (one action) is separated by \\0\\0\\n (nullbyte nullbyte newline). --preserve-mtimes modifying filenames usually causes the parent directory's mtime being updated. This option allows to reset the mtime to the old value. If your filesystem supports sub-second resolution the sub-second part of the atime and mtime will be lost as Perl does not yet support that. --replace if the file to which shall be renamed already exists, it will be overwritten if the other file content is equal. --unescape this option will remove this ugly % hex sequences from filenames and turn them into (hopefully) nicer 8-bit characters. After --unescape you might want to do a charset conversion. This sequences like %20 etc. are sometimes produced when downloading via http or ftp. --upper , --lower turn filenames into all upper or all lower case. When the file is not ASCII-encoded, convmv expects a charset to be entered via the -f switch. --dotlessi care about the dotless i/I issue. A lowercase version of \"I\" will also be dotless while an uppercase version of \"i\" will also be dotted. This is an issue for Turkish and Azeri. By the way: The superscript dot of the letter i was added in the Middle Ages to distinguish the letter (in manuscripts) from adjacent vertical strokes in such letters as u, m, and n. J is a variant form of i which emerged at this time and subsequently became a separate letter.","date":"2023-04-02","objectID":"/linux_cmd_convmv/:0:0","tags":["linux","文件名编码转换"],"title":"convmv -将文件名从一种编码转换为另一种编码","uri":"/linux_cmd_convmv/"},{"categories":["aws"],"content":" 一家公司有多个 AWS 账户，这些账户由各个业务部门拥有。其中一个账户最近受到攻击。攻击者启动了大量实例，导致该账户产生很高的账单金额。该公司解决了安全漏洞，但解决方案架构师需要开发一款解决方案，以防止所有账户过度支出。每个业务部门都希望保留对其 AWS 账户的完全控制权。解决方案架构师应建议采取哪种解决方案来满足这些要求？ A 使用 AWS Organizations。将每个 AWS 账户添加到管理账户。创建一个使用 ec2:instanceType条件键的 SCP，以防止在每个账户中启动高成本实例类型。 B 将客户托管的新 IAM 策略附加到每个账户中的 IAM 组。将策略配置为使用 ec2:instanceType条件键来防止启动高成本实例类型。将所有现有 IAM 用户置于每个组中。 C 为每个 AWS 账户开启账单提醒。创建 Amazon CloudWatch 告警，以便在账户超过指定支出阈值时随时向账户管理员发送 Amazon Simple Notification Service (Amazon SNS) 通知。 D 在每个账户中打开 AWS Cost Explorer。定期查看每个账户的 Cost Explorer 报告，以确保支出不超过预期金额。 点击查看答案 SAP-CO2样题1：C 选项 A 和 B 不正确，因为每个业务部门都希望保留对其账户的控制权。这些选项不会阻止启动大量实例。 选项 D 是一个手动流程，不会直接提供有关过度支出的提醒。 选项 C 可行，使用 Amazon CloudWatch 创建账单告警，超过阈值时使用 Amazon Simple Notification Service 发送电子邮件通知。账单告警将向公司提供有关超支的提醒，而不会剥夺任何业务部门的控制权。 一家公司在 AWS Organizations 内的某个组织中拥有多个 AWS 账户。该公司已将其本地部署 Active Directory 与 AWS Single Sign-On (AWS SSO) 集成在一起，以授予 Active Directory 用户跨所有账户管理基础设施的最低权限。解决方案架构师必须集成需要对所有 AWS 账户拥有只读访问权限的第三方监控解决方案。监控解决方案将在其自己的 AWS 账户中运行。解决方案架构师应该怎么做才能为监控解决方案提供所需的权限？ A 在 AWS SSO 目录中创建一个用户。为该用户分配只读权限集。为该用户分配需要监控的所有 AWS 账户。向第三方监控解决方案提供用户名和密码。 B 在组织的管理账户中创建一个 IAM 角色。允许第三方监控解决方案的 AWS 账户代入该角色。 C 邀请第三方监控解决方案的 AWS 账户加入组织。启用所有功能。 D 创建一个为第三方监控解决方案定义新 IAM 角色的 AWS CloudFormation 模板。在信任策略中指定第三方监控解决方案的 AWS 账户。使用堆栈集跨所有关联的 AWS 账户创建 IAM 角色。 点击查看答案 SAP-CO2样题2：D 选项 A 不正确，因为 AWS Single Sign-On (AWS SSO) 提供的凭证是临时的。应用程序将失去权限，必须重新登录。 选项 B 将仅授予对管理账户的访问权限。 选项 C 不正确，因为当账户加入组织时，该账户将无法获得访问组织中其他账户的权限。 选项 D 可行。AWS CloudFormation StackSets 只需一次操作即可跨多个账户部署 IAM 角色。 一个团队正在构建一个托管在公共 Amazon S3 存储桶中的 HTML 表单。该表单使用 JavaScript 将数据发布到 Amazon API Gateway API 终端节点。API 终端节点已与 AWS Lambda 函数相集成。该团队已在API Gateway 控制台中测试了每种方法，并收到了有效响应。团队必须完成哪些步骤组合，才能使表单成功发布到 API 终端节点并收到有效响应？ （请选择两项） A 配置 S3 存储桶以允许跨域资源共享 (CORS)。 B 将表单托管在 Amazon EC2 上，而不是在 Amazon S3 上。 C 请求增加 API Gateway 的配额。 D 在 API Gateway 中启用跨域资源共享 (CORS)。 E 配置 S3 存储桶进行 Web 托管。 点击查看答案 SAP-CO2样题3：D 选项 A 不正确，因为必须将 CORS 标头配置为由 API 终端节点的动态响应返回。为 S3 存储桶配置 CORS无济于事。 选项 B 不正确，因为从 Amazon EC2 上运行的 Web 服务器，而不是从 S3 存储桶提供静态网页没有什么优势。 选项 C 不正确，因为 API Gateway 对每个 AWS 区域的默认配额为每秒 10000 个请求。如有必要，您可以增加此配额。 选项 D 可行，跨域资源共享 (CORS) 是一项浏览器安全功能，可限制从浏览器中运行的脚本发起的 HTTP 请求。构建访问托管在不同域或源上的 API 的 Web 应用程序通常需要 CORS。您可以启用 CORS，以允许来自托管在不同域中的 Web 应用程序对您的 API 的请求。例如，如果您的 API 托管在 https://[api_id].execute-api.[region].amazonaws.com/ 上，并且您想从托管在[bucketname].s3.website-[region] 上的 Web 应用程序调用您的 API，您的 API 必须支持 CORS。 选项 E 需要，要通过网站终端节点提供 HTML 表单 一家公司运行使用 Amazon API Gateway、AWS Lambda 函数、Amazon Cognito 和 Amazon DynamoDB 的无服务器移动应用程序。在流量激增期间，用户会报告间歇性系统故障。API Gateway API终端节点正在向有效请求返回 HTTP 状态代码 502（错误网关）错误。哪种解决方案可以解决此问题？ A 增加 Lambda 函数的并发配额。将 Amazon CloudWatch 配置为在 ConcurrentExecutions 指标接近 额时发送通知提醒。 B 为 API Gateway API 终端节点上的每秒事务配额配置通知提醒。创建一个 Lambda 函数，该函数将在 到配额时增加配额。 C 将用户分片到多个 AWS 地区中的 Amazon Cognito 用户池，以减少用户身份验证延迟。 D 使用 DynamoDB 强一致性读取可确保客户端应用程序始终接收最新数据。 点击查看答案 SAP-CO2样题4：A 如果 AWS Lambda 函数超出其并发配额，Amazon API Gateway 将间歇性地返回 HTTP 状态代码 502（错误网关）错误 选项 B 不正确，API 配额限制将为太多请求返回状态代码是 429 错误。 选项 C 不正确，因为错误发生在调用 API Gateway API 终端节点期间，而不是在身份验证过程中 选项 D 不正确，因为过时的数据不会导致错误网关错误 一家公司正在 Amazon Elastic Container Service (Amazon ECS) 集群上启动一项新的 Web 服务。该集群由 100 个 Amazon EC2 实例组成。公司策略要求集群实例上的安全组阻止除 HTTPS（端口 443）之外的所有入站流量。哪种解决方案将满足这些要求？ A 使用用户数据脚本将集群实例上的 SSH 端口更改为 2222。通过端口 2222 使用 SSH 登录每个实例。 B 使用用户数据脚本将集群实例上的 SSH 端口更改为 2222。使用 AWS Trusted Advisor 通过端口 2222 程管理集群实例。 C 启动没有 SSH 密钥对的集群实例。使用 AWS Systems Manager Run Command 远程管理集群实例。 D 启动没有 SSH 密钥对的集群实例。使用 AWS Trusted Advisor 远程管理集群实例。 点击查看答案 SAP-CO2样题5：C 选项 A 和 B 不正确，因为要求规定唯一应打开的入站端口是 443 选项 D 不正确，因为 AWS Trusted Advisor 用于提供优化建议，不执行此管理函数 选项 C 可行，AWS Systems Manager Run Command不需要打开任何入站端口。Run Command 完全通过出站 HTTPS 运行，默认情况下对安全组开放 一家公司有两个 AWS 账户：一个账户用于生产工作负载，另一个账户用于开发工作负载。开发团队和运营团队负责创建和管理这些工作负载。公司需要满足以下要求的安全策略： 开发人员需要创建和删除开发应用程序基础设施。 操作员需要创建和删除开发和生产应用程序基础设施。 开发人员不能拥有生产基础设施的访问权限。 所有用户都必须拥有一组 AWS 凭证。 哪种策略将满足这些要求？ A 选项 在生产账户中： 创建可创建和删除应用程序基础设施的运营 IAM 组。 为每个操作员创建一个 IAM 用户。将这些用户分配给运营组。 在开发账户中： 创建一个可以创建和删除应用程序基础设施的开发 IAM 组。 为每个操作员和开发人员创建一个 IAM 用户。将这些用户分配给开发组。 B 选项 在生产账户中： 创建可创建和删除应用程序基础设施的运营 IAM 组。 在开发账户中： 创建一个可以创建和删除应用程序基础设","date":"2023-03-28","objectID":"/awsSapC02/:0:0","tags":["sap C02","aws"],"title":"AWS SAP C02 考试样题","uri":"/awsSapC02/"},{"categories":["英语"],"content":" 运行环境： 内容来自以下文档： 百度百科-英语语法：英语语言规则 单词分类英语单词有以下分类： 实词：在语句中是独立的一部分。有以下分类 名词(n)：表示人或事物的名称 数词(num)：表示数量或顺序 形容词(adj)：表示名词(人或物)的特征 代词(pron)：代替名词、形容词或数词 动词(v)：表示动作或心理活动状态 副词(adv)：修饰动词、形容词、其他副词或全句，表示状态特征或行为 虚词：在语句中不能独立担任任何成分 冠词(art)：用在名词前，说明名词所指的人、物 介词(prep)：用在名词、代词前，表示名词、代词等与其它词的关系 连词(conj)：用来连接词与词、短语与短语、句与句 感叹词(int)：表示说话时的感情或口气 语句组成句子成分是句子中起一定功用的组成部分。句子由各个句子成分所构成。句子的组成部分，如下： 主语：是句子陈述的对象，说明是谁或是什么。表示句子说的是“什么人”、“什么事”、“什么东西”、“什么地方”等等 谓语：说明主语所发出的动作或具有的特征或状态。指出“做什么”和“是什么”或“怎么样” 宾语：又称受词，是指一个动作（动词）的对象或接受者 定语：用来修饰、限定、说明名词或代词的品质与特征的成分。汉语中常用“…的”表示 补语：作用对象是主语和宾语，具有鲜明的定语性描写或限制性功能，在句法上是不可或缺的，是起补充说明作用的成分 状语：说明地点、时间、原因、目的、结果、条件、方向、程度、方式和伴随状况等 表语：用来说明主语的身份、性质、品性、特征和状态的 同位语：两个指同一事物的句子成分放在同等位置时，一个句子成分可被用来说明或解释另一个句子成分 独立成分：当一个词、短语或从句用在句子里面，与句子的其他成分只有意义上的联系而没有语法关系时，它就称为独立成分 一个句子未必有主语和宾语，但一定有谓语。句子按其结构可分为简单句、并列句和复合句 简单句：简单句的基本形式是由一个主语加一个谓语构成。其它各种句子形式都是由此句型发展而来，如五大基本句型： 主语+谓语：简称为主谓结构，其谓语一般都是不及物动词 主语+系动词+表语：主系表结构，其实联系动词在形式上也是一种谓语动词，系动词与表语一起构成了复合谓语 主语+谓语+宾语：主谓宾结构，它的谓语一般多是及物动词 主语+谓语+间接宾语+直接宾语 主语+谓语+宾语+宾语补足语 It引导结构，It作引词时，它本身无实义，只起先行引导的作用。 并列句：两个或两个以上的简单句用并列连词连在一起构成的句子，叫做并列句，其基本结构是“简单句+并列连词+简单句”。 复杂句：由一个主句和一个或一个以上的从句组成 ","date":"2023-03-19","objectID":"/english/:0:0","tags":["英语"],"title":"英语语法","uri":"/english/"},{"categories":["linux"],"content":" 运行环境： sort: 8.2 查看帮助 [root@localhost ~]# man sort | cat ... SYNOPSIS sort [OPTION]... [FILE]... sort [OPTION]... --files0-from=F ... OPTION --version # 输出版本并退出 -n, --numeric-sort # 根据值比较 -r, --reverse # 反转比较结果，从升序改为倒序 -c, --check, --check=diagnose-first # 查看是否排序 -u, --unique # 去除重复，如果与 -c 选择同时使用，则先去重，再排序 -k, --key=KEYDEF # 根据 key 排序 # KEYDEF为F[.C][OPTS][,F[.C][OPTS]] 起止位置， # 其中F为字段号，C为字符在字段中的位置； 均为原点 1，停止位置默认为行尾。 # 如果 -t 和 -b 均未生效，则字段中的字符从前面的空白开始计算。 # OPTS 是一个或多个单字母排序选项 [bdfgiMhnRrV]， # 它覆盖该键的全局排序选项。 如果没有给出键，则使用整行作为键。 -t, --field-separator=SEP # 指定字段分隔符，默认为一个或多个空白符（非空白到空白） 示例 [root@localhost ~]# cat txt 192.168.12.49 192.168.12.5 192.168.12.50 192.168.140.49 192.168.140.5 192.168.140.50 [root@localhost ~]# # 等效 sort -t \".\" -k 1n,1 -k 2n,2 -k 3n,3 -k 4n,4 a # 等效 sort -nt. -k3.1,3.3 -k4.1,4.3 txt [root@localhost ~]# sort -nt. -k3,3 -k4,4 txt 192.168.12.5 192.168.12.49 192.168.12.50 192.168.140.5 192.168.140.49 192.168.140.50 ","date":"2023-03-18","objectID":"/linux-cmd-sort/:0:0","tags":["sort","linux","命令"],"title":"sort - 对文本文件行进行排序","uri":"/linux-cmd-sort/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.23 内容来自以下文档： ngx_http_referer_module nginx 防盗链ngx_http_referer_module 可以根据请求头部 Referer 实现一些操作，如防盗链。 配置项：referer_hash_bucket_size size; 默认值：referer_hash_bucket_size 64; 配置域：server, location 模 块：ngx_http_referer_module 配置项：referer_hash_max_size size; 默认值：referer_hash_max_size 2048; 配置域：server, location 模 块：ngx_http_referer_module 配置项：valid_referers none | blocked | server_names | string ...; 默认值：无 配置域：server, location 模 块：ngx_http_referer_module 如果请求头部 referer 值满足该指定定义，则设置 $invalid_referer 变量值为 1 。该配置项有以下值： none: 头部没有 referer blocked: 头部有 referer 但值已被删除（如代理被修改），这类值不以 http 或 https 开头 server_names: 匹配请求头部 referer 中的 server name 字符串: 匹配请求头部 referer 中的字符串，会忽略端口，开关与结尾可以使用 * 以~开头的字符串: 正则表达式 ","date":"2023-02-23","objectID":"/nginx-referer/:0:0","tags":["nginx","防盗链"],"title":"nginx防盗链","uri":"/nginx-referer/"},{"categories":["容器"],"content":" 运行环境： centos: 7 内容来自以下文档： Deprecated Engine Features xfs-filesystem-changing-ftype-0-to-ftype-1 error initializing graphdriver报错信息 failed to start daemon: error initializing graphdriver: prior storage driver devicemapper is deprecated and will be removed in a future release; update the the daemon configuration and explicitly choose this storage driver to continue using it; visit https://docs.docker.com/go/storage-driver/ for more information 解决方法，修改使用的驱动程序 [root@localhost ~]# cat /etc/docker/daemon.json | jq . { \"data-root\": \"/docker/\", # 修改为 overlay2 \"storage-driver\": \"overlay2\" } 原因：docker 使用 overlay2 替代了 devicemapper error initializing graphdriver: overlay2: the backing xfs filesystem is formatted without d_type support报错详情 [root@localhost ~]# journalctl -u docker ... failed to start daemon: error initializing graphdriver: overlay2: the backing xfs filesystem is formatted without d_type support, which leads to incorrect behavior. Reformat the filesystem with ftype=1 to enable d_type support. Backing filesystems without d_type support are not supported. 解决方法，格式化文件系统时指定 ftype=1。新加了一块虚拟磁盘用于 docker-root [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT xvda 202:0 0 10G 0 disk ├─xvda1 202:1 0 500M 0 part /boot └─xvda2 202:2 0 9.5G 0 part ├─centos-root 253:0 0 8.5G 0 lvm / └─centos-swap 253:1 0 1G 0 lvm xvdb 202:16 0 70G 0 disk └─xvdb1 202:17 0 70G 0 part /data xvdc 202:32 0 10G 0 disk └─xvdc1 202:33 0 10G 0 part # -n 选项指定 [root@localhost ~]# mkfs -t xfs -n ftype=1 /dev/xvdc1 meta-data=/dev/xvdc1 isize=512 agcount=4, agsize=655296 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=2621184, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 # 创建挂载点 [root@localhost ~]# mkdir /docker [root@localhost ~]# [root@localhost ~]# mount /dev/xvdc1 /docker [root@localhost ~]# [root@localhost ~]# echo '/dev/xvdc1 /docker xfs defaults 0 0' \u003e\u003e /etc/fstab # 复制原有的 docker 目录文件 [root@localhost ~]# cp -r /var/lib/docker/ / [root@localhost ~]# ls /docker/ buildkit containers devicemapper image network plugins runtimes swarm tmp trust volumes # 修改 /etc/docker/daemon.json 文件 [root@localhost ~]# cat /etc/docker/daemon.json | jq . { # 指定目录 \"data-root\": \"/docker/\", \"storage-driver\": \"overlay2\" } unable to configure the Docker daemon with file /etc/docker/daemon.json: invalid character ‘\"’ after object key:value pair Jan 09 13:28:31 localhost.localdomain systemd[1]: Failed to start Docker Application Container Engine. Jan 09 13:28:31 localhost.localdomain systemd[1]: Unit docker.service entered failed state. Jan 09 13:28:31 localhost.localdomain systemd[1]: docker.service failed. Jan 09 13:28:33 localhost.localdomain systemd[1]: docker.service holdoff time over, scheduling restart. Jan 09 13:28:33 localhost.localdomain systemd[1]: Stopped Docker Application Container Engine. Jan 09 13:28:33 localhost.localdomain systemd[1]: Starting Docker Application Container Engine... Jan 09 13:28:33 localhost.localdomain dockerd[16469]: unable to configure the Docker daemon with file /etc/docker/daemon.json: invalid character '\"' after object key:value pair Jan 09 13:28:33 localhost.localdomain systemd[1]: docker.service: main process exited, code=exited, status=1/FAILURE /etc/docker/daemon.json 文件格式错误，修正文档json格式后重启`docker [root@localhost ~]# systemctl stop docker Warning: Stopping docker.service, but it can still be activated by: docker.socket [root@localhost ~]# systemctl start docker ","date":"2023-02-21","objectID":"/dokcer-error/:0:0","tags":["docker error"],"title":"docker 容器使用中遇到的错误","uri":"/dokcer-error/"},{"categories":["aws"],"content":" 内容来自以下文档： Amazon Virtual Private Cloud 文档 亚马逊云科技白皮书: Amazon VPC Amazon ec2 cli Amazon vpc api VPCvpc（Amazon Virtual Private Cloud） 是可用区级别的网络服务，即内网。用于实现单个可用区内网络隔离。 大部分服务都是在 vpc 网段规划内，aws 默认有个 vpc 可以指定 vpc 网段，网段可以是 ipv6。由于 ipv6 具有全球唯一性，配置后可以选择与公共网络直接链接 可以修改 vpc 路由表 可以用于流量镜像 可以记录流日志 可以用于云服务与本地之间的连接，如 vpn, net 等 多个 vpc 之间可以建立连接 clivpc 相关命令在 aws ec2 子命令内 # vpc 相关 [root@localhost ~]# aws ec2 help | cat | grep vpc accept-transit-gateway-vpc-attachment # 绑定中转网关 --transit-gateway-attachment-id # 指定中转网关 ID accept-vpc-endpoint-connections # 绑定端点 accept-vpc-peering-connection # 对等 associate-vpc-cidr-block # 绑定专有网络 attach-classic-link-vpc # 使用 VPC 替换 EC2-Classic create-default-vpc create-local-gateway-route-table-vpc-association create-transit-gateway-vpc-attachment create-vpc create-vpc-endpoint create-vpc-endpoint-connection-notification create-vpc-endpoint-service-configuration create-vpc-peering-connection delete-local-gateway-route-table-vpc-association delete-transit-gateway-vpc-attachment delete-vpc delete-vpc-endpoint-connection-notifications delete-vpc-endpoint-service-configurations delete-vpc-endpoints delete-vpc-peering-connection describe-local-gateway-route-table-vpc-associations describe-transit-gateway-vpc-attachments # 查看中转网关挂载 describe-vpc-attribute # 查看 vpc 指定字段 --vpc-id # 指定 vpc ID describe-vpc-classic-link describe-vpc-classic-link-dns-support describe-vpc-endpoint-connection-notifications describe-vpc-endpoint-connections describe-vpc-endpoint-service-configurations describe-vpc-endpoint-service-permissions describe-vpc-endpoint-services describe-vpc-endpoints describe-vpc-peering-connections describe-vpcs # 查看 VPC 集合本身，可能会产生多个 API 调用 --filters [ Name=\"filters\",Values=\"value\" [ AND Name=\"filters\",Values=\"value\" ...]] # 指定过滤器，通过过滤器选择 VPC。有以下过滤器（filters） # cidr: CidrBlock 字段地址，即 VPC IP范围 CIDR 块 # cidr-block-association.cidr-block # cidr-block-association.association-id # cidr-block-association.state # dhcp-options-id # is-default # owner-id # state: 值为 pending 或 available # tag:key: 指定标签 # tag-key # vpc-id: vpc ID --vpc-ids # 必选，指定 vpc ID --attribute # 必选，当有多个该选项时，最后一个生效，有以下值 # enableDnsSupport: 是否启用 DNS 解析 # enableDnsHostnames: 是否启用 DNS 解析主机名 # enableNetworkAddressUsageMetrics: 是否启用网络指标 detach-classic-link-vpc disable-vpc-classic-link disable-vpc-classic-link-dns-support disassociate-vpc-cidr-block enable-vpc-classic-link enable-vpc-classic-link-dns-support modify-transit-gateway-vpc-attachment modify-vpc-attribute modify-vpc-endpoint modify-vpc-endpoint-connection-notification modify-vpc-endpoint-service-configuration modify-vpc-endpoint-service-payer-responsibility modify-vpc-endpoint-service-permissions modify-vpc-peering-connection-options modify-vpc-tenancy move-address-to-vpc reject-transit-gateway-vpc-attachment reject-vpc-endpoint-connections reject-vpc-peering-connection start-vpc-endpoint-service-private-dns-verification # 子网相关 [root@localhost ~]# aws ec2 --profile my-hk help | grep subnet associate-subnet-cidr-block create-default-subnet create-subnet create-subnet-cidr-reservation delete-subnet delete-subnet-cidr-reservation describe-subnets # 查看子网 --filters [ Name=\"filters\",Values=\"value\" [ AND Name=\"filters\",Values=\"value\" ...]] # 指定过滤器，通过过滤器选择。有以下过滤器（filters） # availability-zone 或 availabilityZone: 可用区 # availability-zone-id 或 availabilityZoneId: 可用区 ID # available-ip-address-count # cidr-block 或 cidrBlock 或 cidr # customer-owned-ipv4-pool # default-for-az # enable-dns64 # enable-lni-at-device-index # ipv6-cidr-block-association.ipv6-cidr-block # ipv6-cidr-block-association.association-id # ipv6-cidr-block-association.state # ipv6-native # map-customer-owned-ip-on-launch # map-public-ip-on-launch # outpost-arn # owner-id # private-dns-name-options-on-launch.hostname-type # private-dns-name-options-on-launch.enable-resource-name-dns-a-record # private-dns-name-options-on-launch.enable-resource-name-dns-aaaa-record # state # subnet-arn # subnet-id # tag:key: 指定标签 # tag-key # vpc-id: vpc ID disassociate-su","date":"2023-02-20","objectID":"/awsVpc/:0:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 查看所有 VPC 信息 [root@localhost ~]# aws ec2 describe-vpcs --profile my-hk | jq . { \"Vpcs\": [ { \"CidrBlock\": \"10.2.0.0/16\", \"DhcpOptionsId\": \"dopt-002af7335f674750a\", \"State\": \"available\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"InstanceTenancy\": \"default\", \"CidrBlockAssociationSet\": [ { \"AssociationId\": \"vpc-cidr-assoc-051bf1616a88f3784\", \"CidrBlock\": \"10.2.0.0/16\", \"CidrBlockState\": { \"State\": \"associated\" } } ], \"IsDefault\": false, \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-vpc\" } ] }, { \"CidrBlock\": \"172.31.0.0/16\", \"DhcpOptionsId\": \"dopt-002af7335f674750a\", \"State\": \"available\", \"VpcId\": \"vpc-0433cf353b98b77f0\", \"OwnerId\": \"223665515173\", \"InstanceTenancy\": \"default\", \"CidrBlockAssociationSet\": [ { \"AssociationId\": \"vpc-cidr-assoc-0d6af9fcd387e4104\", \"CidrBlock\": \"172.31.0.0/16\", \"CidrBlockState\": { \"State\": \"associated\" } } ], \"IsDefault\": true } ] } ","date":"2023-02-20","objectID":"/awsVpc/:1:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 通过 vpc id 筛选 VPC查找vpc id 为vpc-0e331a9f505c6986d [root@localhost ~]# aws ec2 describe-vpcs --profile my-hk --filters Name=\"vpc-id\",Values=\"vpc-0e331a9f505c6986d\" | jq . { \"Vpcs\": [ { \"CidrBlock\": \"10.2.0.0/16\", \"DhcpOptionsId\": \"dopt-002af7335f674750a\", \"State\": \"available\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"InstanceTenancy\": \"default\", \"CidrBlockAssociationSet\": [ { \"AssociationId\": \"vpc-cidr-assoc-051bf1616a88f3784\", \"CidrBlock\": \"10.2.0.0/16\", \"CidrBlockState\": { \"State\": \"associated\" } } ], \"IsDefault\": false, \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-vpc\" } ] } ] } ","date":"2023-02-20","objectID":"/awsVpc/:2:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据 vpc 状态筛选 VPC状态为available状态查找 [root@localhost ~]# aws ec2 describe-vpcs --profile my-hk --filters Name=\"state\",Values=\"available\" | jq . { \"Vpcs\": [ { .... ","date":"2023-02-20","objectID":"/awsVpc/:3:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据标签值筛选 VPC查找标签为 Name:test-vpc-hk-vpc 的 vpc [root@localhost ~]# aws ec2 describe-vpcs --profile my-hk --filters Name=\"tag:Name\",Values=\"test-vpc-hk-vpc\" | jq . { \"Vpcs\": [ { \"CidrBlock\": \"10.2.0.0/16\", \"DhcpOptionsId\": \"dopt-002af7335f674750a\", \"State\": \"available\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"InstanceTenancy\": \"default\", \"CidrBlockAssociationSet\": [ { \"AssociationId\": \"vpc-cidr-assoc-051bf1616a88f3784\", \"CidrBlock\": \"10.2.0.0/16\", \"CidrBlockState\": { \"State\": \"associated\" } } ], \"IsDefault\": false, \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-vpc\" } ] } ] } ","date":"2023-02-20","objectID":"/awsVpc/:4:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据标签筛选 VPC根据标签key中有 Nmae 的 vpc [root@localhost ~]# aws ec2 describe-vpcs --profile my-hk --filters Name=\"tag-key\",Values=\"Name\" | jq . { \"Vpcs\": [ { \"CidrBlock\": \"10.2.0.0/16\", \"DhcpOptionsId\": \"dopt-002af7335f674750a\", \"State\": \"available\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"InstanceTenancy\": \"default\", \"CidrBlockAssociationSet\": [ { \"AssociationId\": \"vpc-cidr-assoc-051bf1616a88f3784\", \"CidrBlock\": \"10.2.0.0/16\", \"CidrBlockState\": { \"State\": \"associated\" } } ], \"IsDefault\": false, \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-vpc\" } ] } ] } ","date":"2023-02-20","objectID":"/awsVpc/:5:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 查看所有子网信息 [root@localhost ~]# aws ec2 --profile my-hk describe-subnets | jq . { \"Subnets\": [ { \"AvailabilityZone\": \"ap-east-1b\", \"AvailabilityZoneId\": \"ape1-az2\", \"AvailableIpAddressCount\": 4091, \"CidrBlock\": \"10.2.144.0/20\", \"DefaultForAz\": false, \"MapPublicIpOnLaunch\": false, \"MapCustomerOwnedIpOnLaunch\": false, \"State\": \"available\", \"SubnetId\": \"subnet-0f80dc3717d0c1581\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"AssignIpv6AddressOnCreation\": false, \"Ipv6CidrBlockAssociationSet\": [], \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-subnet-private2-ap-east-1b\" } ... ","date":"2023-02-20","objectID":"/awsVpc/:6:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据可用区筛选子网查看 ap-east-1b 可用区所有子网信息 [root@localhost ~]# aws ec2 --profile my-hk describe-subnets --filters Name=\"availabilityZone\",Values=\"ap-east-1b\" | jq . { \"Subnets\": [ { \"AvailabilityZone\": \"ap-east-1b\", \"AvailabilityZoneId\": \"ape1-az2\", \"AvailableIpAddressCount\": 4091, \"CidrBlock\": \"10.2.144.0/20\", \"DefaultForAz\": false, \"MapPublicIpOnLaunch\": false, \"MapCustomerOwnedIpOnLaunch\": false, \"State\": \"available\", \"SubnetId\": \"subnet-0f80dc3717d0c1581\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"AssignIpv6AddressOnCreation\": false, \"Ipv6CidrBlockAssociationSet\": [], \"Tags\": [ ... ","date":"2023-02-20","objectID":"/awsVpc/:7:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据 VPC ID 筛选子网查看以vpc-0e331a9f505c6986d(VPC ID)创建的子网 [root@localhost ~]# aws ec2 --profile my-hk describe-subnets --filters Name=\"vpc-id\",Values=\"vpc-0e331a9f505c6986d\" | jq . { \"Subnets\": [ { \"AvailabilityZone\": \"ap-east-1b\", \"AvailabilityZoneId\": \"ape1-az2\", \"AvailableIpAddressCount\": 4091, \"CidrBlock\": \"10.2.144.0/20\", \"DefaultForAz\": false, \"MapPublicIpOnLaunch\": false, \"MapCustomerOwnedIpOnLaunch\": false, \"State\": \"available\", \"SubnetId\": \"subnet-0f80dc3717d0c1581\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"AssignIpv6AddressOnCreation\": false, \"Ipv6CidrBlockAssociationSet\": [], ... ","date":"2023-02-20","objectID":"/awsVpc/:8:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据子网名称筛选子网查看子网名称为 test-vpc-hk-subnet-private3-ap-east-1c 的子网信息 [root@localhost ~]# aws ec2 --profile my-hk describe-subnets --filters Name=\"tag:Name\",Values=\"test-vpc-hk-subnet-private3-ap-east-1c\" | jq . { \"Subnets\": [ { \"AvailabilityZone\": \"ap-east-1c\", \"AvailabilityZoneId\": \"ape1-az3\", \"AvailableIpAddressCount\": 4091, \"CidrBlock\": \"10.2.160.0/20\", \"DefaultForAz\": false, \"MapPublicIpOnLaunch\": false, \"MapCustomerOwnedIpOnLaunch\": false, \"State\": \"available\", \"SubnetId\": \"subnet-006d2f0faa76dc208\", \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\", \"AssignIpv6AddressOnCreation\": false, \"Ipv6CidrBlockAssociationSet\": [], \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-subnet-private3-ap-east-1c\" } ... ","date":"2023-02-20","objectID":"/awsVpc/:9:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据路由表 ID 筛选路由表查看路由表ID为rtb-0d28f564e75e7045d的路由信息 [root@localhost ~]# aws ec2 --profile my-hk describe-route-tables --filters Name='route-table-id',Values=\"rtb-0d28f564e75e7045d\" | cat { \"RouteTables\": [ { \"Associations\": [ { \"Main\": false, \"RouteTableAssociationId\": \"rtbassoc-0231434852a9438f4\", \"RouteTableId\": \"rtb-0d28f564e75e7045d\", \"SubnetId\": \"subnet-018a516a33179f011\", \"AssociationState\": { \"State\": \"associated\" } }, { \"Main\": false, \"RouteTableAssociationId\": \"rtbassoc-0e1de6ede518e6499\", \"RouteTableId\": \"rtb-0d28f564e75e7045d\", \"SubnetId\": \"subnet-0af62cbcab5871964\", \"AssociationState\": { \"State\": \"associated\" } }, { \"Main\": false, \"RouteTableAssociationId\": \"rtbassoc-0305e4a701d4079f9\", \"RouteTableId\": \"rtb-0d28f564e75e7045d\", \"SubnetId\": \"subnet-08edd77668571001f\", \"AssociationState\": { \"State\": \"associated\" } } ], \"PropagatingVgws\": [], \"RouteTableId\": \"rtb-0d28f564e75e7045d\", \"Routes\": [ { \"DestinationCidrBlock\": \"10.2.0.0/16\", \"GatewayId\": \"local\", \"Origin\": \"CreateRouteTable\", \"State\": \"active\" }, { \"DestinationCidrBlock\": \"0.0.0.0/0\", \"GatewayId\": \"igw-0a180cfb5b33b5e84\", \"Origin\": \"CreateRoute\", \"State\": \"active\" } ], \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-rtb-public\" } ], \"VpcId\": \"vpc-0e331a9f505c6986d\", \"OwnerId\": \"223665515173\" } ] } ","date":"2023-02-20","objectID":"/awsVpc/:10:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" 根据互联网网关ID筛选互联网网关 [root@localhost ~]# aws ec2 --profile my-hk describe-internet-gateways --filters Name=\"internet-gateway-id\",Values=\"igw-0a180cfb5b33b5e84\" | cat { \"InternetGateways\": [ { \"Attachments\": [ { \"State\": \"available\", \"VpcId\": \"vpc-0e331a9f505c6986d\" } ], \"InternetGatewayId\": \"igw-0a180cfb5b33b5e84\", \"OwnerId\": \"223665515173\", \"Tags\": [ { \"Key\": \"Name\", \"Value\": \"test-vpc-hk-igw\" } ] } ] } CloudFormation 创建 VPC","date":"2023-02-20","objectID":"/awsVpc/:11:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["aws"],"content":" AWS::EC2::VPCAWS::EC2::VPC Type: AWS::EC2::VPC Properties: CidrBlock: String EnableDnsHostnames: Boolean EnableDnsSupport: Boolean InstanceTenancy: String Ipv4IpamPoolId: String Ipv4NetmaskLength: Integer Tags: - Tag CidrBlock: 视情况可选字段，重建更新，值为字符串类型（CidrBlock，如 10.0.0.0/16） EnableDnsHostnames: 可选字段，不中断更新，值为布尔类型（true | false）。否获取DNS主机名，如果启用了DNS支持，则只能启用DNS主机名 EnableDnsSupport: 可选字段，不中断更新，值为布尔类型（true | false）。VPC是否支持DNS解析 InstanceTenancy: 可选字段，视情况中断，值为字符串类型。有以下值： default: 共享实例时指定，表示 VPC 启动的实例默认在共享硬件上 dedicated，专用实例时指定，表示 VPC 启动的实例默认为专用实例类型 host: 指定实例 InstanceTenancy: Ipv4IpamPoolId: Ipv4NetmaskLength: Tags: 可选字段，不中断更新，值为键值对列表 下面是 eks 中的 vpc 片段 Resources: VPC: Type: AWS::EC2::VPC Properties: CidrBlock: !Ref VpcBlock EnableDnsSupport: true EnableDnsHostnames: true Tags: - Key: Name Value: !Sub '${AWS::StackName}-VPC' ","date":"2023-02-20","objectID":"/awsVpc/:12:0","tags":["aws","aws vpc"],"title":"AWS VPC","uri":"/awsVpc/"},{"categories":["游戏"],"content":" 运行环境： kof: 15 内容来自以下文档： snk官方文档: KOF XV 用户指南 https://www.yzkof.com/custom-page-kof98-pose.html http://wiki.gotvg.cn/kof/index.php?title=98%E5%87%BA%E6%8B%9B%E8%A1%A8 文档中的按键表示 特殊字符 含义 ⇖ 左上 ⇑ 上 ⇗ 右上 ⇐ 左 ⇒ 右 ⇙ 左下 ⇓ 下 ⇘ 右下 👊🏻 轻拳 👊 重拳 🦶🏻 轻脚 🦶 重脚 ➕ 加号 ","date":"2023-02-16","objectID":"/kof15/:0:0","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 左右移动除了普通的左右缓慢移动，KOF 也支持以下快速移动方式： 奔跑：快速按2次前进方向键可向前奔跑一段距离，第二次按前进方向键长按不放可持续奔跑 后跳：快速按2次后退方向键可向后跳一段距离 ","date":"2023-02-16","objectID":"/kof15/:1:0","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 跳跃KOF 中跳跃大致分为以下几种： 小跳：短暂按1次(⇖/⇑/⇗)键，高度与距离都是最小的 中跳：依次短暂按(⇙/⇓/⇘)(⇖/⇗)键，高度与距离比小跳稍微高些。奔跑过程中使用⇗可触发中跳 普通跳：正常按1次(⇖/⇑/⇗)键，高度与距离都比较大 大跳：短暂按1次(⇙/⇓/⇘)键然后正常按1次(⇖/⇗)键，跳跃距离最远。奔跑过程中使用⇗可触发大跳 ","date":"2023-02-16","objectID":"/kof15/:2:0","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 站斗系统站斗系统可在游戏主页面的练习模式中学习并实验 ","date":"2023-02-16","objectID":"/kof15/:3:0","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 技能官方把角色技能分为以下几类： 通常技：类似其它游戏中的普通攻击（平 A），但在 KOF 有轻拳、重拳、轻脚、重脚，共 4 种。通常轻攻击的距离比重攻击短，前摇、后摇比重攻击小。此外与对手近身的状态下攻击时动作将会发生变化。 特殊技：操作简单的技能 绝招：也成为普通技，通过有序的使用方向键与攻击键即可发动角色独有的绝招。部分技能的性能会根据轻键和重键发生变化。 强化绝招：在绝招使用时多按1次拳或脚（如 ⇓⇘⇒➕🦶🏻 强化版为 ⇓⇘⇒➕🦶🏻➕🦶）。则可以消耗一定能量强化该技能： 在极限模式可以使用多次，但每次会消耗部分极限能量。 非极限模式消耗0.5格能量 超级技能：消耗1格力量槽，或是在极限模式中消耗一定量的极限模式槽即可使出的技能，部分技能的性能会根据轻键和重键发生变化。 极限超级绝招：在超级技使用时多按1次拳或脚。则可以消耗一定能量强化该技能： 极限模式中消耗一定量的极限模式槽。即最终消耗为1格能量+部分限模式槽 非极限模式消耗1格能量。即最终消耗为2格能量 顶点超级绝招：必杀技能。各角色仅有一个必杀技。可以通过消耗3格力量槽或在极限模式中消耗剩余的全部极限模式槽和1格力量槽来发动。 投掷技能：投掷技（抓取效果）能通常需要近身使用，投掷技能无法防御但可以使用投掷技破除。带有投掷效果的却不属于投掷分类的技能无法使用投技能破除。 ","date":"2023-02-16","objectID":"/kof15/:3:1","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 快捷释放在近身时以轻拳开始的4次连击可触发技能（通常是连续使用3次轻拳加最后一击方式使用），该方式根据最后的第4段使用的攻击键会有所不同： 轻拳：会根据当前能量槽资源发动 没有能量：技能 1格能量：超级技能 2格能量：强化的超级技能 3格能量：必杀技能 重拳：消耗1格能量使用超级技能 重脚：消耗2格能量使用强化的超级技能 轻脚：技能 ","date":"2023-02-16","objectID":"/kof15/:3:2","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 判定范围攻击判定与防御方式（无法防御投掷技能）： 上段攻击，需要使用后退防御 下段攻击，需要使用下蹲防御 防御通常技和特殊技时不会受到伤害，防御绝招和超级绝招则会受到部分伤害。此外，如果持续防御对手的攻击，防御瓦解槽就会逐渐减少，变为0时，角色将陷入一定时间内毫无防备的防御瓦解状态（无法移动种防御）。部分攻击动作可被破招，即用攻击打败攻击。具体看攻击判断 ","date":"2023-02-16","objectID":"/kof15/:3:3","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 眩晕在被连续攻击时头像颜色会发生变化（闪烁），如果还继续被攻击则进入眩晕状态，眩晕状态可以通过连按方向键、攻击键减少被眩晕持续时间。 ","date":"2023-02-16","objectID":"/kof15/:3:4","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 吹飞攻击同时按下[⇑]👊🦶即可发动吹飞攻击： 在地面使用的吹飞攻击称为站立吹飞攻击，如果命中地面上的对手会将其击飞至画面边缘。被击飞后对手将处于倒地状态，此时可以进行追击。 在空中使用的吹飞攻击称为空中吹飞攻击，此时对手并不会被击飞至画面边缘，但若造成破招则可以进行追击。 在防御对手攻击时使用(⇑⇙⇖)👊🦶，消耗1格能量即可发动防御取消吹飞攻击。在攻击时会变为无敌状态 ","date":"2023-02-16","objectID":"/kof15/:3:5","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 粉碎打击⇓⇘⇒➕🦶👊 即可消耗1格力量槽来发动粉碎打击。粉碎打击能够在防御对手攻击的同时进行攻击的破招技。如果命中就会恢复一半力量槽，还能让对手在一定时间内处于毫无防备的状态。 ","date":"2023-02-16","objectID":"/kof15/:3:6","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 紧急回避通过向前或向后翻滚(⇐/⇒)👊🏻🦶🏻可以快速向前或向后突进，也可以用于回避对受攻击的动作。 在一定时间内会处于对打击技及飞行工具类技能的无敌状态，但无法回避投技。在防御对手攻击时也可以消耗1格能量使用紧急回避，此时会变为无敌状态。 ","date":"2023-02-16","objectID":"/kof15/:3:7","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 受身受到攻击而被击飞时，如果在倒地之前按👊🦶，角色就能安全落地从而避免倒地。有些技能在对手倒地时可以继续追击，因此最好用受身来回避。但是，根据技能的不同，也存在无法以受身应对的攻击。 ","date":"2023-02-16","objectID":"/kof15/:3:8","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 取消后摇当前攻击动作结束前使用下次攻击方式可以取消当前技能后摇。 ","date":"2023-02-16","objectID":"/kof15/:3:9","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 能量槽与极限模式能量槽：攻击命中及防御时都会积蓄能量，累计到一定量后会以格的单位存储起来。在 3V3 时第1人最多可存储3格，第2人最多可存储4格，第3人最多可存储5格，1V1 时最多可存储5格。 极限能量槽：可以消耗2格力量槽来发动极限模式。在极限模式中，攻击力和防御瓦解值会提高。进入极限模式后，就会出现极限模式槽，槽会随时间推移不断减少。在 3V3 时第1人为1000，第2人为1250，第3人为1500的极限能量值，1V1时为1500 在以下情况可以进入快速极限模式，该模式无法获得数值加成且极限能量比正常发动要少，但可以取消前面技能后摇 通常技命中对方时 特殊技命中对方时 攻击被对方防御时 使用能量槽的情况： 防御时使用紧急回避：消耗1格力量槽或消耗少量极限模式能量 防御吹飞攻击：消耗1格力量槽或消耗少量极限模式能量 粉碎打击：消耗格力量槽或消耗部分极限模式能量 强化绝招：消耗1格力量槽或消耗少量极限模式能量 超级绝招：消耗格力量槽或消耗部分极限模式能量 进入极限模式：消耗2格力量槽 极限超级绝招：消耗2格力量槽或消耗部分极限模式能量+1格力量槽 顶点超级绝招：消耗3格力量槽或消耗全部极限模式能量+1格力量槽 ","date":"2023-02-16","objectID":"/kof15/:3:10","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 角色技能","date":"2023-02-16","objectID":"/kof15/:4:0","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 梁 技能类型 技能名 指令 说明 特殊技 槌 ⇒➕🦶🏻 普通投掷 旋 （近身）(⇐/⇒)➕👊 普通投掷 钓 （近身）(⇐/⇒)➕🦶 绝招 戟（可强化） ⇓⇘⇒➕(👊🏻/👊/🦶🏻) 根据攻击键不同攻击范围不同。长按可保持架势，松开释放；追加🦶原地取消；追加⇒⇒取消并向前突刺 绝招 镰（可强化） （空中）⇓⇙⇐➕(🦶🏻/🦶) 绝招 轮（可强化） ⇓⇙⇐➕(🦶🏻/🦶) 绝招 钩（可强化） ⇓⇙⇐➕(👊🏻/👊) 超级绝招 刀（可极限） ⇓⇘⇒⇓⇘⇒➕(🦶🏻/🦶) 超级绝招 钉（可极限） ⇓⇘⇒⇒⇘⇓⇙⇐➕(🦶🏻/🦶) 顶点超级绝招 鞭 ⇓⇙⇐⇐⇙⇓⇘⇒➕👊🦶 ","date":"2023-02-16","objectID":"/kof15/:4:1","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 莉安娜·哈迪兰 技能类型 技能名 指令 说明 特殊技 攻击之弓 (⇐/⇒)➕🦶🏻 普通投掷 莉安娜粉碎·前方 （近身）(⇐/⇒)➕👊 普通投掷 莉安娜粉碎·后方 （近身）(⇐/⇒)➕🦶 绝招 漩涡发射器（可强化） 长按⇐一定时间松开⇒➕(👊🏻/👊) 绝招 威武军刀（可强化） 长按⇐一定时间松开⇒➕(🦶🏻/🦶)[=\u003e⇒➕🦶] 用🦶才能追加且强化模式不可用 绝招 月光锯（可强化） 长按⇓一定时间松开⇑➕(👊🏻/👊) 绝招 耳环炸弹（可强化） ⇓⇙⇐➕(🦶🏻/🦶) 绝招 耳环炸弹·心脏麻痹（可强化） ⇓⇙⇐➕(👊🏻/👊) 命中后延迟爆炸，可以使用⇓⇙⇐➕(👊🏻/👊) 立即引爆 绝招 交叉神剑（可强化） （空中）⇓⇙⇐➕(👊🏻/👊) 超级绝招 翻折劈砍（可极限） （空中）⇓⇘⇒⇒⇘⇓⇙⇐➕(👊🏻/👊) 超级绝招 砍军刀（可极限） ⇓⇙⇐⇐⇙⇓⇘⇒➕(🦶🏻/🦶) 顶点超级绝招 莉安娜剑 ⇓⇙⇐⇐⇙⇓⇘⇒➕👊🦶 ","date":"2023-02-16","objectID":"/kof15/:4:2","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 坂崎良 技能类型 技能名 指令 说明 特殊技 冰柱割 ⇒➕👊🏻 特殊技 上段受 ⇒➕🦶🏻 纯防御技能，免受上段伤害 特殊技 下段受 ⇘➕🦶 纯防御技能，免受下段伤害 特殊技 刻突 👊🏻➕👊 普通投掷 极限流·三连击 (近身)(⇐/⇒)➕👊 普通投掷 巴投 (近身)(⇐/⇒)➕🦶 绝招 虎咆（可强化） ⇒⇓⇘➕(👊🏻/👊) 绝招 暂烈拳（可强化） ⇒⇐⇒➕(👊🏻/👊) 绝招 虎煌拳（可强化） ⇓⇘⇒➕(👊🏻/👊) 绝招 飞燕疾风脚（可强化） ⇓⇙⇐➕(🦶🏻/🦶) 超级绝招 霸王翔吼拳（可极限） ⇒⇐⇙⇓⇘⇒➕(👊🏻/👊) 超级绝招 龙虎乱舞（可极限） ⇓⇘⇒⇘⇓⇙⇐➕(👊🏻/👊) 顶点超级绝招 真·天地霸煌拳 ⇓⇙⇐⇙⇓⇘⇒➕👊➕🦶 ","date":"2023-02-16","objectID":"/kof15/:4:3","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 安琪尔 技能类型 技能名 指令 说明 特殊技 中旋 ⇒➕🦶🏻 特殊技 重膝攻击 （空中）⇓➕🦶 普通投掷 连击 （近身）(⇐/⇒)➕👊 普通投掷 影枭 （近身）(⇐/⇒)➕🦶 绝招 红色天空（可强化） ⇒⇘⇓⇙⇐➕(🦶🏻/🦶) 绝招 疯狂突袭（可强化） （近身）⇐⇙⇓⇘⇒➕(👊🏻/👊) 绝招 连续连锁 该技能是多种组合技，见表格下方 超级绝招 雷亚尔咆哮（可极限） ⇐⇒⇓⇘➕(👊🏻/👊) 超级绝招 忧郁星期一反击（可极限） （对方攻击时）⇐⇒⇓⇘➕(🦶🏻/🦶) 顶点超级绝招 极乐时间 ⇓⇙⇐⇐⇙⇓⇘⇒➕👊🦶 连续连锁技是多种组合技，大概阶段分为：开始技=\u003e圈技=\u003e结束技，每个阶段选一个技能。圈技与结束技是可选的，但无法跳过圈技阶段直接进入结束技。详细信息如下： 开始技是必须的，有以下连续连锁开始技 解锁·低：⇘➕🦶🏻 解锁·鞋跟：⇘➕🦶 解锁·龙卷风：⇐⇒➕(🦶🏻/🦶) 解锁·殴打（可强化）：⇓⇙⇐➕(👊🏻/👊) 解锁·舞步（可强化）：⇐⇙⇓⇘⇒➕(🦶🏻/🦶) 圈技是在开始技过程中追加的，圈技分为圈技与特殊圈技，普通圈技如下： 圈·上段：⇑➕(👊🏻/👊) 圈·潜流：⇓➕(👊🏻/👊) 圈·锤击：⇒➕(👊🏻/👊) 圈·后踢：⇒➕(🦶🏻/🦶) 圈·高段：⇑➕(🦶🏻/🦶) 圈·突击：⇓➕(🦶🏻/🦶) 在圈技过程中可追加特殊圈技。特殊圈技是可选的，可跳过此阶段直接使用结束技。特殊圈技如下： 圈·声东击西：👊🏻🦶🏻 圈·声东击西（前方）：⇒➕👊🏻🦶🏻 圈·声东击西（后方）：⇐➕👊🏻🦶🏻 在圈技或特殊圈技过程中可追加结束技。有以下结束技： 结束·套索踢：⇒⇒➕👊🏻 结束·直击：⇒⇒➕👊 结束·摇摆：⇒⇒➕(🦶🏻/🦶) 结束·枭刃：⇓⇘⇒➕👊🏻 结束·钩踢：（近身）⇓⇘⇒➕👊 ","date":"2023-02-16","objectID":"/kof15/:4:4","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["游戏"],"content":" 二阶堂红丸 技能类型 技能名 指令 说明 特殊技 杰克小刀踢 6+b 特殊技 飞钻 (空中)2+d 普通投掷 抓击 (近身)(4/6)+c 普通投掷 前后拉抱 (近身)(4/6)+d 普通投掷 旋转膝落 (空中近身)(4/6)+c 绝招 居合踢(可强化) ⇓⇘⇒➕(👊/🦶)[=\u003e28+(b/d)] 绝招 雷鸣刀(可强化) ⇓⇙⇐➕(👊🏻/👊) 绝招 雷韧拳(可强化) [可空中]⇓⇘⇒➕(👊🏻/👊) 绝招 红丸电击(可强化) (近身)632146+(👊🏻/👊) 绝招 超级迅雷踢(可强化) ⇒⇓⇘➕(👊/🦶) 超级绝招 雷光拳(可极限) 236⇓⇘⇒➕(👊🏻/👊) 超级绝招 红丸升击(可极限) 236⇓⇘⇒➕(👊/🦶) 顶点超级绝招 雷波韧皇拳 2141⇓⇘⇒➕👊➕🦶 ","date":"2023-02-16","objectID":"/kof15/:4:5","tags":["kof","kof 15"],"title":"拳皇 15","uri":"/kof15/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.23 内容来自以下文档： PHP星: Nginx优化HTTPS提速30% skyesx: NGINX https 的配置以及使用 KeepAlive 及 SSL Session 提高通讯效率 网络优化","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:0:0","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" 长连接长连接是保持tcp连接，减少同个客户端与服务器之前的三次握手与四次挥手次数。简单说就是让一个连接发送和接收多个请求及其回应 ","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:1:0","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" 代理中长连接数量 keepalive connections; # ngx_http_core_module 配置域：http, server, location # ngx_http_upstream_module 配置域：upstream 默认值：空 限制 nginx 某个 worker 最多空闲连接数，超过时关闭最近最少使用的连接; ","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:1:1","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" 长连接处理请求数量 keepalive_requests number; # ngx_http_core_module 配置域：http, server, location # ngx_http_upstream_module 配置域：upstream 默认值：1000 每个长连接最多处理请求数量，在 v1.19.10 之前，默认值为 100。 ","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:1:2","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" 长连接超时时间 keepalive_time time; # ngx_http_core_module 配置域：http, server, location # ngx_http_upstream_module 配置域：upstream 默认值：1h 每个长连接最多存在时间 ","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:1:3","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" 长连接空闲时间 keepalive_timeout timeout; # ngx_http_upstream_module 配置域：upstream 默认值：60s keepalive_timeout timeout [header_timeout]; # ngx_http_core_module 配置域：http, server, location 默认值：75s 长连接最大空闲时间，超时会关闭。 ","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:1:4","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" ssl","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:2:0","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" SSL 分层值 # ngx_http_ssl_module ssl_buffer_size size; 默认值：16k 配置域：http, server nginx默认的ssl_buffer_size是16K（TLS Record Layer最大的分片），即一个TLS Record的大小，如果HTTP的数据是160K，那么就会被拆分为10个TLS Record（每个TLS Record会被TCP层拆分为多个TCP包传输）发送给客户端。客户端必须等待完整的TLS Record收到才能进行解密。 ","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:2:1","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["nginx"],"content":" SSL 会话缓存 # ngx_http_ssl_module ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; 配置域：http, server 默认值：none # ====================== # ngx_stream_ssl_module ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; 配置域：upstream, server 默认值：none 该参数设置 ssl 会话缓存大小、有效期 off: 严禁使用会话缓存，明确告诉客户端会话不能重用 none: 禁止使用会话缓存，客户端可以重用，实际上不会缓存 builtin: 使用OpenSSL中内置的缓存，仅由一个工作进程使用。 缓存大小在会话中指定。 如果未指定大小，则等于 20480 个会话。 使用内置缓存可能会导致内存碎片。 shared: 所有工作进程之间共享的缓存。 缓存大小以字节为单位指定。1mB 可以存储约 4000 个会话。 ssl 缓存可以减少已建立SSL连接的客户端握手过程，用同一个session建立起ssl连接时（SSL握手过程：客户端请求连接，服务器返回公钥，客户端用公钥加密随机通讯密码，传输加密传到服务器，用私钥解密，并用通讯密码加密返回内容等工作），可以免掉 服务端返回公钥，客户端用公钥加密随机通讯密码 这一次来回产生的通讯延时及计算能力消耗。 ","date":"2023-02-15","objectID":"/nginx%E4%BC%98%E5%8C%96/:2:2","tags":["nginx"],"title":"nginx 优化","uri":"/nginx%E4%BC%98%E5%8C%96/"},{"categories":["windows"],"content":" 运行环境： windows: 10 PowerShell: 6 内容来自以下文档： PowerShell 执行策略 PowerShell 配置文件 PowerShell 更改命令提示符 配置文件PowerShell 支持多个配置文件。 此外，PowerShell 主机程序可以支持自己的特定于主机的配置文件。配置文件按优先顺序列出。 第一个配置文件的优先级最高。（变量 $PSHOME 存储 PowerShell 的安装目录；变量 $HOME 存储当前用户的主目录） 所有用户、所有主机 Windows：$PSHOME\\Profile.ps1 Linux：/usr/local/microsoft/powershell/7/profile.ps1 macOS：/usr/local/microsoft/powershell/7/profile.ps1 所有用户、当前主机 Windows：$PSHOME\\Microsoft.PowerShell_profile.ps1 Linux：/usr/local/microsoft/powershell/7/Microsoft.Powershell_profile.ps1 macOS：/usr/local/microsoft/powershell/7/Microsoft.Powershell_profile.ps1 当前用户、所有主机 Windows：$HOME\\Documents\\PowerShell\\Profile.ps1 Linux：~/.config/powershell/profile.ps1 macOS：~/.config/powershell/profile.ps1 当前用户、当前主机 Windows：$HOME\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1 Linux：~/.config/powershell/Microsoft.Powershell_profile.ps1 macOS：~/.config/powershell/Microsoft.Powershell_profile.ps1 ","date":"2023-02-09","objectID":"/powerShell/:0:0","tags":["powerShell"],"title":"Windows PowerShell","uri":"/powerShell/"},{"categories":["windows"],"content":" 修改默认提示符在配置文件中修改 prompt 函数 PS C:\\Users\\xiaosi\u003e echo $PROFILE C:\\Users\\xiaosi\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 PS:2023/02/09 11:45:23 \u003efunction prompt {\"PS $(Get-Date -Format \"yyyy/MM/dd HH:mm:ss\") \u003e\"} PS:2023/02/09 11:45:23 \u003efunction prompt {\"PS $(Get-Date -Format \"yyyy/MM/dd HH:mm:ss\") \u003e\"} PS 2023/02/09 11:45:31 \u003e 把上面的function prompt {\"PS $(Get-Date -Format \"yyyy/MM/dd HH:mm:ss\") \u003e\"} 加入到配置文件中 error . : 无法加载文件 C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\Microsoft.PowerShell_profile.ps1，因为在此系统上禁止运行脚 本。有关详细信息，请参阅 https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。 所在位置 行:1 字符: 3 + . 'C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\Microsoft.PowerShell_pr ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : SecurityError: (:) []，PSSecurityException + FullyQualifiedErrorId : UnauthorizedAccess PS C:\\Users\\xiaosi\u003e Set-ExecutionPolicy -Scope CurrentUser 位于命令管道位置 1 的 cmdlet Set-ExecutionPolicy 请为以下参数提供值: ExecutionPolicy: RemoteSigned ","date":"2023-02-09","objectID":"/powerShell/:1:0","tags":["powerShell"],"title":"Windows PowerShell","uri":"/powerShell/"},{"categories":["git"],"content":" 运行环境： git: 2.39.1 内容来自以下文档： git book 奔跑吧邓邓子: Git报错git: ‘remote-http‘ is not a git command. See ‘git –help‘ JAVA编程Linux学习：我看谁还不懂 Git ！(万字长文) 快速入门","date":"2023-02-06","objectID":"/git/:0:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 安装windows系统可以从这里下载安装包。lintx可以直接使用安装包 管理工具安装，但部分发行版如centos发行版的版本有些旧， 可以从下载压缩包进行源码编译安装 centos7安装git [root@localhost pak]# wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.37.1.tar.xz ... [root@localhost pak]# tar xJf git-2.37.1.tar.xz [root@localhost pak]# cd git-2.37.1 [root@localhost git-2.37.1]# ./configure ... [root@localhost git-2.37.1]# make \u0026\u0026 make install ... [root@localhost git-2.37.1]# /usr/local/bin/git --version git version 2.37.1 安装后在使用前需要添加以下配置信息 # 指定用户名 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ git config --global user.name \"xiaosi\" # 指定邮箱地址 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ git config --global user.email \"3131516796@qq.com\" # 指定文本编辑器 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ git config --global core.editor vim ","date":"2023-02-06","objectID":"/git/:1:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 初始化本地库开始使用 # 进行工作目录，即代码主目录 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ cd .. # 初始化目录，会创建本地仓库 .git 目录 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ git init . hint: Using 'master' as the name for the initial branch. This default branch name ","date":"2023-02-06","objectID":"/git/:2:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 已跟踪与未跟踪工作目录下的每一个文件都不外乎这两种状态：已跟踪 或 未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后， 它们的状态可能是未修改，已修改或已放入暂存区。简而言之，已跟踪的文件就是 Git 已经知道的文件。未跟踪文件，它们既不存在于上次快照的记录中，也没有被放入暂存区。编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git 将它们标记为已修改文件。 在工作时，可以选择性地将这些修改过的文件放入暂存区，然后提交所有已暂存的修改，如此反复。 untracked: 未跟踪，可以使用 git add 命令加入到暂存区 staged: 已跟踪，即暂存区 unmodified: 未修改，加入到版本库后文件没有被修改 modified: 已修改，加入到版本库后文件被修改，但没有加入到暂不区版本库 # 把当前目录所有文件加入到暂存区，未被 git 跟踪的文件会转换为已跟踪 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ git add . # 查看状态 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git status On branch master No commits yet Changes to be committed: (use \"git rm --cached \u003cfile\u003e...\" to unstage) new file: JsonPath.md ... ","date":"2023-02-06","objectID":"/git/:3:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 忽略文件一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件的模式。 该文件格式如下 以 # 开头表示注释，会被 git 忽略 可以使用标准的 glob 模式匹配，它会递归地应用在整个工作区中 以 / 开头防止递归 以 / 结尾指定目录 以 ! 开头表示取反 在最简单的情况下，一个仓库可能只根目录下有一个 .gitignore 文件，它递归地应用到整个仓库中。 然而，子目录下也可以有额外的 .gitignore 文件。子目录中的 .gitignore 文件中的规则只作用于它所在的目录中。 ","date":"2023-02-06","objectID":"/git/:4:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 提交更新到库只有提交到库的快照才可以在未来回溯。在此之前，请务必确认还有什么已修改或新建的文件还没有 git add 过， 否则提交的时候不会记录这些尚未暂存的变化。 这些已修改但未暂存的文件只会保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，你所需要的文件是不是都已暂存起来了， 然后再运行命令 git commit 提交 # 提交到本地仓库， xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git commit -m '第一次提交' [master (root-commit) 6edbbde] 第一次提交 270 files changed, 60573 insertions(+) ... git commit -m 选项可以在命令行中添加说明，如果未使用 -m 选项，则提交时使用 core.editor 配置项指定的文本编辑器编写说明信息，信息文本中默认添加注释信息（最后一次运行 git status 的输出），注释信息以 # 开头，保存退出时会丢弃注释行 每次提交都会生成 SHA-1 校验和、提交分支等信息，可以使用 git log 查看提交记录信息 xiaosi@DESKTOP-E1ASSM6 MINGW64 /F/xiaosi/hugo/content/archives (git) $ git log commit 920d168b7db009b1f9c834ecb4d84b91b1323866 (HEAD -\u003e git, master) Author: xiaosi \u003c3131516796@qq.com\u003e Date: Tue Feb 7 08:51:25 2023 +0800 第一次提交 git commit -a 选项可以会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤 ","date":"2023-02-06","objectID":"/git/:5:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 移动文件不像其它的 VCS 系统，Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作 # git mv 命令等效执行以下命令集 # mv README.md README # git rm README.md # git add README $ git mv README.md README $ git status On branch master Your branch is up-to-date with 'origin/master'. Changes to be committed: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) renamed: README.md -\u003e README ","date":"2023-02-06","objectID":"/git/:6:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 移除文件使用 git rm 命令可以从 git 与本地磁盘中删除文件，可以使用 git rm --cached 只从 git 中移除跟踪 # 跟踪文件清单和硬盘中移除 $ git rm PROJECTS.md # 移除 git 跟踪 README 文件 # git rm --cached README ","date":"2023-02-06","objectID":"/git/:7:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 提交记录与回滚 # 克隆 vim 项目 [root@localhost /]# git clone https://github.com/vim/vim.git Cloning into 'vim'... remote: Enumerating objects: 165691, done. remote: Counting objects: 100% (26/26), done. remote: Compressing objects: 100% (19/19), done. remote: Total 165691 (delta 13), reused 16 (delta 7), pack-reused 165665 Receiving objects: 100% (165691/165691), 198.99 MiB | 1.54 MiB/s, done. Resolving deltas: 100% (140951/140951), done. Updating files: 100% (4158/4158), done. [root@localhost /]# cd vim/ [root@localhost vim]# git log 可以查看历史的提交记录，不传入任何参数的默认情况下会按时间先后顺序列出所有的提交，最近的更新排在最上面。 这个命令会列出每个提交的 SHA-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。 [root@localhost vim]# git log commit af9e28a5b8f888b79459393ddb26fffe613c3f3c (HEAD -\u003e master, tag: v9.0.1290, origin/master, origin/HEAD) Author: zeertzjq \u003czeertzjq@outlook.com\u003e Date: Mon Feb 6 20:58:09 2023 +0000 patch 9.0.1290: CTRL-N and -P on cmdline don't trigger CmdlineChanged Problem: CTRL-N and -P on cmdline don't trigger CmdlineChanged. Solution: Jump to cmdline_changed instead of cmdline_not_changed. (closes #11956) commit 43e234e8b48caf59d6895a31628dad0bba4fd5c8 (tag: v9.0.1289) Author: Philip H \u003c47042125+pheiduck@users.noreply.github.com\u003e Date: Mon Feb 6 20:22:48 2023 +0000 patch 9.0.1289: a newer version of clang can be used for CI Problem: A newer version of clang can be used for CI. Solution: Switch from clang-15 to clang-16. (closes #11577) ... git log --pretty=format 命令可以以指定方式展示提交记录 [root@localhost vim]# git log --pretty=format:\"%h %s\" --graph * af9e28a5b patch 9.0.1290: CTRL-N and -P on cmdline don't trigger CmdlineChanged * 43e234e8b patch 9.0.1289: a newer version of clang can be used for CI * 91deac453 patch 9.0.1288: FunC files are not recognized * 0261e3978 patch 9.0.1287: with the Kitty key protocl Esc with NumLock cannot be mapped * 546933f49 patch 9.0.1286: Coverity warns for using a NULL pointer * a9a6b0323 patch 9.0.1285: various small problems * 40b487296 patch 9.0.1284: compiler warnings for uninitialized variables * c72078b63 patch 9.0.1283: the code for setting options is too complicated * c8ef30bc2 patch 9.0.1282: Ron files are not recognized * cb626a469 patch 9.0.1281: Cadence files are not recognized * 7a1bdaecf patch 9.0.1280: inssufficient testing for what 9.0.1265 fixes ... 在 Git 中任何已提交(git commit)的东西几乎总是可以恢复的。 甚至那些被删除的分支中的提交或使用 --amend 选项覆盖的提交也可以恢复 （阅读 数据恢复 了解数据恢复） [root@localhost vim]# git reset --hard 7a1bdaecf Updating files: 100% (4158/4158), done. HEAD is now at 7a1bdaecf patch 9.0.1280: inssufficient testing for what 9.0.1265 fixes # 查看最近一次提交 [root@localhost vim]# git log -1 commit 7a1bdaecf2d2a06eb06ed462e6ccae4954939fc9 (HEAD -\u003e master, tag: v9.0.1280) Author: Bram Moolenaar \u003cBram@vim.org\u003e Date: Sat Feb 4 15:45:27 2023 +0000 patch 9.0.1280: inssufficient testing for what 9.0.1265 fixes Problem: Inssufficient testing for what 9.0.1265 fixes. Solution: Add a couple of test cases. (issue #11885) 上面示例使用 git reset --hard 回滚到 haed 为 7a1bdaecf 的提交，工作目录所有的文件也会回到当时提交的状态 分支Git 保存的不是文件的变化或者差异，而是一系列不同时刻的 快照 。在进行提交操作时，Git 会保存一个提交对象（commit object）。该提交对象会包含一个指向暂存内容快照的指针、作者的姓名和邮箱、提交时输入的信息以及指向它的父对象的指针。 首次提交产生的提交对象没有父对象，普通提交操作产生的提交对象有一个父对象， 而由多个分支合并产生的提交对象有多个父对象。 # 创建分支 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git branch git # 查看所有分支，HEAD 指针指向的分支还是初始 master 分支 # HEAD 指针指向当前分支 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git log --oneline --decorate --graph --all * 6edbbde (HEAD -\u003e master, git) 第一次提交 # 切换到 git 分支 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git checkout git Switched to branch 'git' D git/.git.md.swp A git/git.md xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (git) $ git add . # 在 git 分支提交 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (git) $ git commit -m 'git 分支的第一次提交' [git 8b9f426] git 分支的第一次提交 2 files changed, 236 insertions(+) delete mode 100644 git/.git.md.swp create mode 100644 git/git.md # HEAD 指针指向当前分支 xiaosi@DESKTOP-E1ASSM6 MINGW64","date":"2023-02-06","objectID":"/git/:8:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" SHA-1每次提交都会生成一组由 40 个字符组成的完整 SHA-1 散列值，如果前面部分字符串（至少 4 个）具有唯一性，则 git 能确定到是哪次提交， # --abbrev-commit 参数，输出结果里就会显示简短且唯一的值。（至少 7 个字符） PS 2023/02/09 14:44:51 \u003e git log --abbrev-commit --pretty=oneline c138639 (HEAD -\u003e master, tag: git.v1.001) git.md 添加、修改内容 cb460aa 第一次提交 PS 2023/02/09 14:44:55 \u003e git show cb460aa Author: xiaosi \u003c3131516796@qq.com\u003e Date: Tue Feb 7 21:43:57 2023 +0800 ... # 等效 git show cb460aa PS 2023/02/09 14:46:49 \u003e git show cb46 Author: xiaosi \u003c3131516796@qq.com\u003e Date: Tue Feb 7 21:43:57 2023 +0800 ... ","date":"2023-02-06","objectID":"/git/:9:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 引用分支当引用分支时会默认指向最新的提交 # 假设 topic1 分支最后提交为 ca82a6... 则下在 2 条命令等效 $ git show ca82a6dff817ec66f44342007202690a93763949 $ git show topic1 ","date":"2023-02-06","objectID":"/git/:10:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 引用日志Git 会在后台保存一个引用日志。引用日志记录了最近几个月你的 HEAD 和分支引用所指向的历史。引用日志只存在于本地仓库，它只是一个记录你在 自己 的仓库里做过什么的日志。 其他人拷贝的仓库里的引用日志不会和你的相同，而你新克隆一个仓库的时候，引用日志是空的，git reflog 命令可以查看引用日志。 $ git reflog 734713b HEAD@{0}: commit: fixed refs handling, added gc auto, updated d921970 HEAD@{1}: merge phedders/rdocs: Merge made by the 'recursive' strategy. 1c002dd HEAD@{2}: commit: added some blame and merge stuff 1c36188 HEAD@{3}: rebase -i (squash): updating HEAD 95df984 HEAD@{4}: commit: # This is a combination of two commits. 1c36188 HEAD@{5}: rebase -i (squash): updating HEAD 7e05da5 HEAD@{6}: rebase -i (pick): updating HEAD 可以使用 HEAD@{n} 方式指定提交记录 # 查看第五次前的所指向的提交，等效 git show 1c36188 $ git show HEAD@{5} ","date":"2023-02-06","objectID":"/git/:11:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 引用日期如果查引用某分支某个时间的提交可以使用 {branch}@{yesterday} ","date":"2023-02-06","objectID":"/git/:12:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 引用分支历史记录^ 脱字符可以引用上次提交，^ 字符在 windows 系统中是特殊字符（在powerShell中可以正常使用），需要使用 \"{HEAD}^\" 或 {HEAD}^^ 形式 ~ 字符可以回退版本， # 查看上次提交 git show HEAD^ # 查看 d921970^ ","date":"2023-02-06","objectID":"/git/:13:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 提交区间 # 查看不在 master 分支中，但在 experiment 分支中的提交 $ git log experiment..master # 查看被 refA 或 refB 包含的但是不被 refC 包含的提交 $ git log refA refB ^refC $ git log refA refB --not refC # 看 master 或者 experiment 中包含的但不是两者共有的提交 $ git log master...experiment 远程仓库远程仓库实际是也是在本地，是通过网络把对方本地仓库复制到自己主机上，修改后上到对方本地库，对方再合并修改 ","date":"2023-02-06","objectID":"/git/:14:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 克隆远程库 [root@localhost data]# git clone https://github.com/schacon/ticgit Cloning into 'ticgit'... remote: Enumerating objects: 1857, done. remote: Total 1857 (delta 0), reused 0 (delta 0), pack-reused 1857 Receiving objects: 100% (1857/1857), 334.06 KiB | 1.38 MiB/s, done. Resolving deltas: 100% (837/837), done. ","date":"2023-02-06","objectID":"/git/:15:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 查看远程库 # 第一列表示远程库名称 # 第二列表示远程库地址 # -v 选项显示远程库地址 [root@localhost ticgit]# git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) ","date":"2023-02-06","objectID":"/git/:16:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 添加远程库地址再拉取 # 添加远程库，名称为 pb 后面是库地址 $ git remote add pb https://github.com/paulboone/ticgit $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) pb https://github.com/paulboone/ticgit (fetch) pb https://github.com/paulboone/ticgit (push) # git fetch 拉取远程库 $ git fetch pb remote: Counting objects: 43, done. remote: Compressing objects: 100% (36/36), done. remote: Total 43 (delta 10), reused 31 (delta 5) Unpacking objects: 100% (43/43), done. From https://github.com/paulboone/ticgit * [new branch] master -\u003e pb/master * [new branch] ticgit -\u003e pb/ticgit git fetch 命令只会将数据下载到你的本地仓库,它并不会自动合并或修改你当前的工作。当准备好时你必须手动将其合并入你的工作。合并后可以使用 git push 命令上传（称为推送）到对方库 # 把 master 分支推送到 master 分支 $ git push origin master 只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先抓取他们的工作并将其合并进你的工作后才能推送。 git remote show 命令可以查看远程库信息 [root@localhost ticgit]# git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) # 查看远程库 origin 信息 [root@localhost ticgit]# git remote show origin * remote origin Fetch URL: https://github.com/schacon/ticgit Push URL: https://github.com/schacon/ticgit HEAD branch: master Remote branches: master tracked ticgit tracked Local branch configured for 'git pull': master merges with remote master Local ref configured for 'git push': master pushes to master (up to date) ","date":"2023-02-06","objectID":"/git/:17:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 修改远程远程库名称git remote rename 命令可以修改远程库名称 $ git remote rename pb paul $ git remote origin paul ","date":"2023-02-06","objectID":"/git/:18:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 修改远程库地址 PS C:\\Users\\xiaosi\\note\u003e git remote -v origin https://gitlab.xiaosi.host/root/note.git (fetch) origin https://gitlab.xiaosi.host/root/note.git (push) PS C:\\Users\\xiaosi\\note\u003e 使用 git remote set-url 命令修改，把 http 协议改为 ssh 协议 PS C:\\Users\\xiaosi\\note\u003e git remote set-url origin git@gitlab.xiaosi.host:xiaosi/note.git PS C:\\Users\\xiaosi\\note\u003e PS C:\\Users\\xiaosi\\note\u003e git remote -v origin git@gitlab.xiaosi.host:xiaosi/note.git (fetch) origin git@gitlab.xiaosi.host:xiaosi/note.git (push) ","date":"2023-02-06","objectID":"/git/:19:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 删除远程库git remote remove 可以删除一个远程库，只是删除远程库连接方式，不会删除复制到本地的库与文档 $ git remote remove paul $ git remote origin ","date":"2023-02-06","objectID":"/git/:20:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 使用ssh协议搭建一个简单的git仓库 创建用户 [root@localhost data]# useradd -d /data/git -s /sbin/nologin git [root@localhost data]# cd git/ ssh身份验证 # 采用密钥方式验证，减少每次ssh连接时的身份验证 [root@localhost note.git]# cd .. [root@localhost git]# mkdir .ssh # [root@localhost git]# cat id_rsa.pub \u003e .ssh/authorized_keys # 禁用终端分配 [root@localhost git]# sed 's/^/no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty /' .ssh/authorized_keys -i 创建git仓库 [root@localhost git]# cd note.git/ [root@localhost note.git]# [root@localhost note.git]# git init --bare Initialized empty Git repository in /data/git/note.git/ [root@localhost note.git]# pwd /data/git/note.git 此时可以提交或拉取 标签git 以给仓库历史中的某一个提交打上标签，常用于版本标识。使用 git tag 命令可以查看标签 # 查看所有标签，以字符排序 [root@localhost vim]# git tag -l # 查看以 v9.0.003 开头的标签 [root@localhost vim]# git tag -l \"v9.0.003*\" v9.0.0030 v9.0.0031 v9.0.0032 v9.0.0033 v9.0.0034 v9.0.0035 v9.0.0036 v9.0.0037 v9.0.0038 v9.0.0039 git tag -a 命令可以添加标签 # -m 选项添加注释信息，缺省时 Git 会启动编辑器要求你输入信息 [root@localhost vim]# git tag -a \"v9.0.00333\" -m '这是测试' [root@localhost vim]# git tag -l \"v9.0.0033*\" v9.0.0033 v9.0.00333 # 向 SHA-1 值为 9fceb02 开头的提交记录打标签 [root@localhost vim]# git tag -a v1.2 9fceb02 git show 命令可以查看提交内容 查看标签为 v9.0.00333 的提交信息 [root@localhost vim]# git show v9.0.00333 tag v9.0.00333 Tagger: root \u003croot@localhost.localdomain\u003e Date: Wed Feb 8 15:15:22 2023 +0800 这是测试 commit 7a1bdaecf2d2a06eb06ed462e6ccae4954939fc9 (HEAD -\u003e master, tag: v9.0.1280, tag: v9.0.00333) ... 另一种给提交打标签的方式是使用轻量标签。 轻量标签本质上是将提交校验和存储到一个文件中——没有保存任何其他信息。 创建轻量标签，不需要使用 -a、-s 或 -m 选项，只需要提供标签名字。 $ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 v1.4-lw v1.5 当向远程库推送时，默认并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 # 推送，附加 v1.5 的标签 $ git push origin v1.5 # 推送，并附加所有标签 $ git push origin --tags git tag -d 选项删除标签 [root@localhost vim]# git tag -d \"v9.0.00333\" Deleted tag 'v9.0.00333' (was 48f41a722) 想删除远程库的标签要使用以下方式 # 删除远程库 origin 的 v1.4-lw 标签 $ git push origin --delete v1.4-lw # 以下是第二种方式 # 将冒号前面的空值推送到远程标签名，从而高效地删除它。 # 从而实现删除远程库 origin 的 v1.4-lw 标签 $ git push origin :refs/tags/v1.4-lw To /git@github.com:schacon/simplegit.git - [deleted] v1.4-lw 想查看某个标签所指向的文件版本且要修改时，应该先创建分支，否则会产生分离头指针（detached HEAD）状态，在该状态下做了某些更改然后提交它们，标签不会发生变化， 但你的新提交将不属于任何分支，并且只能通过确切的提交哈希才能访问。 # 切换到 tag 为 v2.0.0 的提交并创建分支 version2 $ git checkout -b version2 v2.0.0 Switched to a new branch 'version2' # 切换到 tag 为 v2.0.0 的提交 $ git checkout 2.0.0 命令","date":"2023-02-06","objectID":"/git/:21:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git commit提交记录 git commit [-a | --interactive | --patch] [-s] [-v] [-u\u003cmode\u003e] [--amend] [--dry-run] [(-c | -C | --squash) \u003ccommit\u003e | --fixup [(amend|reword):]\u003ccommit\u003e)] [-F \u003cfile\u003e | -m \u003cmsg\u003e] [--reset-author] [--allow-empty] [--allow-empty-message] [--no-verify] [-e] [--author=\u003cauthor\u003e] [--date=\u003cdate\u003e] [--cleanup=\u003cmode\u003e] [--[no-]status] [-i | -o] [--pathspec-from-file=\u003cfile\u003e [--pathspec-file-nul]] [(--trailer \u003ctoken\u003e[(=|:)\u003cvalue\u003e])…] [-S[\u003ckeyid\u003e]] [--] [\u003cpathspec\u003e…] --amend # 撤消提交操作，用新的提交替换旧的提交 -m \u003cmsg\u003e, --message=\u003cmsg\u003e # 在命令行添加提交说明，缺省时使用 core.editor 配置项指定的文本编辑器编写说明信息 # 不能与 -c, -C, -F 选项同时使用 ","date":"2023-02-06","objectID":"/git/:22:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git branch创建、查看、删除分支 git branch [--color[=\u003cwhen\u003e] | --no-color] [--show-current] [-v [--abbrev=\u003cn\u003e | --no-abbrev]] [--column[=\u003coptions\u003e] | --no-column] [--sort=\u003ckey\u003e] [--merged [\u003ccommit\u003e]] [--no-merged [\u003ccommit\u003e]] [--contains [\u003ccommit\u003e]] [--no-contains [\u003ccommit\u003e]] [--points-at \u003cobject\u003e] [--format=\u003cformat\u003e] [(-r | --remotes) | (-a | --all)] [--list] [\u003cpattern\u003e…] git branch [--track[=(direct|inherit)] | --no-track] [-f] [--recurse-submodules] \u003cbranchname\u003e [\u003cstart-point\u003e] git branch (--set-upstream-to=\u003cupstream\u003e | -u \u003cupstream\u003e) [\u003cbranchname\u003e] git branch --unset-upstream [\u003cbranchname\u003e] git branch (-m | -M) [\u003coldbranch\u003e] \u003cnewbranch\u003e git branch (-c | -C) [\u003coldbranch\u003e] \u003cnewbranch\u003e git branch (-d | -D) [-r] \u003cbranchname\u003e… git branch --edit-description [\u003cbranchname\u003e] ","date":"2023-02-06","objectID":"/git/:23:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git reset将当前 HEAD 重置为指定状态 git reset [-q] [\u003ctree-ish\u003e] [--] \u003cpathspec\u003e… git reset [-q] [--pathspec-from-file=\u003cfile\u003e [--pathspec-file-nul]] [\u003ctree-ish\u003e] git reset (--patch | -p) [\u003ctree-ish\u003e] [--] [\u003cpathspec\u003e…] git reset [--soft | --mixed [-N] | --hard | --merge | --keep] [-q] [\u003ccommit\u003e] DEPRECATED: git reset [-q] [--stdin [-z]] [\u003ctree-ish\u003e] 取消 CONTRIBUTING.md 文件暂存状态 $ git status On branch master Changes to be committed: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) renamed: README.md -\u003e README modified: CONTRIBUTING.md $ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status On branch master Changes to be committed: (use \"git reset HEAD \u003cfile\u003e...\" to unstage) renamed: README.md -\u003e README Changes not staged for commit: (use \"git add \u003cfile\u003e...\" to update what will be committed) (use \"git checkout -- \u003cfile\u003e...\" to discard changes in working directory) modified: CONTRIBUTING.md ","date":"2023-02-06","objectID":"/git/:24:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git checkout切换到指定分支 git checkout [-q] [-f] [-m] [\u003cbranch\u003e] git checkout [-q] [-f] [-m] --detach [\u003cbranch\u003e] git checkout [-q] [-f] [-m] [--detach] \u003ccommit\u003e git checkout [-q] [-f] [-m] [[-b|-B|--orphan] \u003cnew-branch\u003e] [\u003cstart-point\u003e] git checkout [-f|--ours|--theirs|-m|--conflict=\u003cstyle\u003e] [\u003ctree-ish\u003e] [--] \u003cpathspec\u003e… git checkout [-f|--ours|--theirs|-m|--conflict=\u003cstyle\u003e] [\u003ctree-ish\u003e] --pathspec-from-file=\u003cfile\u003e [--pathspec-file-nul] git checkout (-p|--patch) [\u003ctree-ish\u003e] [--] [\u003cpathspec\u003e…] -b \u003cnew-branch\u003e # 创建分支并切换过去 用最近提交的版本覆盖 CONTRIBUTING.md git checkout -- CONTRIBUTING.md ","date":"2023-02-06","objectID":"/git/:25:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git log git log [\u003coptions\u003e] [\u003crevision-range\u003e] [[--] \u003cpath\u003e…] # options -L\u003cstart\u003e,\u003cend\u003e:\u003cfile\u003e, -L:\u003cfuncname\u003e:\u003cfile\u003e --left-right # 查看区间提交时显示提交属于哪边分支 # 查看文件中函数的变更历史。可以与 --no-patch 组和使用不显示补丁 [--] \u003cpath\u003e... # 某些文件或者目录的历史提交，-- 选项是与其它参数区分 --no-merges # 不要打印具有多个父项的提交。这与 --max-parents=1 完全相同 -S\u003cstring\u003e # 仅显示添加或删除内容匹配指定字符串的提交 --author=\u003cpattern\u003e, --committer=\u003cpattern\u003e # 显示指定作者的提交，可以有多个该选项，它们关系是或 --grep=\u003cpattern\u003e # 仅按正则表达式匹配提交说明，可以有多个该选项，它位关系是或 --all-match # 当有多个 --grep 选项时，它们的关系是和 --graph # 在左测基于文本的图形表示形式绘制提交历史记录 # 不能与 `--no-walk` --since=\u003cdate\u003e, --after=\u003cdate\u003e # 只显示晚于指定日期的提交，时间可以是相对日期，绝对日期 --until=\u003cdate\u003e, --before=\u003cdate\u003e # 只显示早于指定日期的提交。时间可以是相对日期，绝对日期 --all # 查看所有提交，不受 HAED 指针影响 --abbrev-commit # 显示唯一的 SHA-1 值前缀 --relative-date # 使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”） --decorate # 查看当前 head 指针所指的对象 --name-only # 仅在提交信息后显示已修改的文件清单 --name-status # 显示新增、修改、删除的文件清单 -\u003cnumber\u003e, -n \u003cnumber\u003e, --max-count=\u003cnumber\u003e # 指定查看当前 head 对象最近提交的次数 -p, -u, --patch # 显示提交所引入的差异，以 diff 方式 --shortstat # 只显示 --stat 中最后的行数修改添加移除统计 --stat[=\u003cwidth\u003e[,\u003cname-width\u003e[,\u003ccount\u003e]]] # 显示修改统计信息 --decorate[=short|full|auto|no], --no-decorate # 打印出显示的任何提交的引用名称 --oneline # --pretty=oneline --abbrev-commit 合用的简写 --pretty[=\u003cformat\u003e], --format=\u003cformat\u003e # 指定显示格式，有以下格式 # oneline: 以行方式显示，会省略很多信息 # short # medium # full # fuller # reference # email # raw # format:\u003cstring\u003e: 按指定修饰格式显示 # tformat:\u003cstring\u003e git log --pretty=format 常用的选项 %H 提交的完整哈希值 %h 提交的简写哈希值 %T 树的完整哈希值 %t 树的简写哈希值 %P 父提交的完整哈希值 %p 父提交的简写哈希值 %an 作者名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 --date=选项 来定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期（距今多长时间） %s 提交说明 ","date":"2023-02-06","objectID":"/git/:26:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 查看最近两周的所有提交： $ git log --since=2.weeks ","date":"2023-02-06","objectID":"/git/:26:1","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" 查看所有提交记录 PS 2023/02/09 13:47:38 \u003e git log --abbrev-commit --pretty=oneline --all c138639 (HEAD -\u003e master, tag: git.v1.001) git.md 添加、修改内容 cb460aa 第一次提交 PS 2023/02/09 13:50:21 \u003e git log --pretty=format:'%h %s' --graph --all * c138639 git.md 添加、修改内容 * cb460aa 第一次提交 ","date":"2023-02-06","objectID":"/git/:26:2","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git tag [root@localhost vim]# git tag -h usage: git tag [-a | -s | -u \u003ckey-id\u003e] [-f] [-m \u003cmsg\u003e | -F \u003cfile\u003e] \u003ctagname\u003e [\u003chead\u003e] or: git tag -d \u003ctagname\u003e... or: git tag -l [-n[\u003cnum\u003e]] [--contains \u003ccommit\u003e] [--no-contains \u003ccommit\u003e] [--points-at \u003cobject\u003e] [--format=\u003cformat\u003e] [--merged \u003ccommit\u003e] [--no-merged \u003ccommit\u003e] [\u003cpattern\u003e...] or: git tag -v [--format=\u003cformat\u003e] \u003ctagname\u003e... -l, --list # 查看标签，可以接表达式缩小范围 -n[\u003cn\u003e] print \u003cn\u003e lines of each tag message -d, --delete delete tags -v, --verify verify tags Tag creation options -a, --annotate annotated tag, needs a message -m, --message \u003cmessage\u003e tag message -F, --file \u003cfile\u003e read message from file -e, --edit force edit of tag message -s, --sign annotated and GPG-signed tag --cleanup \u003cmode\u003e how to strip spaces and #comments from message -u, --local-user \u003ckey-id\u003e use another key to sign the tag -f, --force replace the tag if exists --create-reflog create a reflog Tag listing options --column[=\u003cstyle\u003e] show tag list in columns --contains \u003ccommit\u003e print only tags that contain the commit --no-contains \u003ccommit\u003e print only tags that don't contain the commit --merged \u003ccommit\u003e print only tags that are merged --no-merged \u003ccommit\u003e print only tags that are not merged --sort \u003ckey\u003e field name to sort on --points-at \u003cobject\u003e print only tags of the object --format \u003cformat\u003e format to use for the output --color[=\u003cwhen\u003e] respect format colors -i, --ignore-case sorting and filtering are case insensitive ","date":"2023-02-06","objectID":"/git/:27:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git statusgit status 命令使用 git status [\u003coptions\u003e] [--] [\u003cpathspec\u003e…] # options -s, --short # 简短格式显示 简短格式输出 # X 和 Y 都是状态码， # X 表示暂存区和最近一次提交的差异， # Y 表示工作目录和暂存区的差异。 X Y Meaning ------------------------------------------------- [AMD] not updated M [ MTD] updated in index T [ MTD] type changed in index A [ MTD] added to index D deleted from index R [ MTD] renamed in index C [ MTD] copied in index [MTARC] index and work tree matches [ MTARC] M work tree changed since index [ MTARC] T type changed in work tree since index [ MTARC] D deleted in work tree R renamed in work tree C copied in work tree ------------------------------------------------- D D unmerged, both deleted A U unmerged, added by us U D unmerged, deleted by them U A unmerged, added by them D U unmerged, deleted by us A A unmerged, both added U U unmerged, both modified ------------------------------------------------- ? ? untracked ! ! ignored -------------------------------- ' ' = unmodified M = modified T = file type changed (regular file, symbolic link or submodule) A = added D = deleted R = renamed C = copied (if config option status.renames is set to \"copies\") U = updated but unmerged ","date":"2023-02-06","objectID":"/git/:28:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git grepGit 提供了一个 grep 命令，你可以很方便地从提交历史、工作目录、甚至索引中查找一个字符串或者正则表达式。 以文本行查找 可以搜索任意的 Git 树，而只不是当前检出的版本。 git grep [-a | --text] [-I] [--textconv] [-i | --ignore-case] [-w | --word-regexp] [-v | --invert-match] [-h|-H] [--full-name] [-E | --extended-regexp] [-G | --basic-regexp] [-P | --perl-regexp] [-F | --fixed-strings] [-n | --line-number] [--column] [-l | --files-with-matches] [-L | --files-without-match] [(-O | --open-files-in-pager) [\u003cpager\u003e]] [-z | --null] [ -o | --only-matching ] [-c | --count] [--all-match] [-q | --quiet] [--max-depth \u003cdepth\u003e] [--[no-]recursive] [--color[=\u003cwhen\u003e] | --no-color] [--break] [--heading] [-p | --show-function] [-A \u003cpost-context\u003e] [-B \u003cpre-context\u003e] [-C \u003ccontext\u003e] [-W | --function-context] [(-m | --max-count) \u003cnum\u003e] [--threads \u003cnum\u003e] [-f \u003cfile\u003e] [-e] \u003cpattern\u003e [--and|--or|--not|(|)|-e \u003cpattern\u003e…] [--recurse-submodules] [--parent-basename \u003cbasename\u003e] [ [--[no-]exclude-standard] [--cached | --no-index | --untracked] | \u003ctree\u003e…] [--] [\u003cpathspec\u003e…] -n, --line-number # 显示其行号 -c, --count # 只显示文件名与其统计次数 -p, --show-function # 显示其上下文（字符串所在的方法或函数等） --and # 逻辑和，可以有多个该选项 --or # 逻辑或，可以有多个该选项 --not # 逻辑取反，可以有多个该选项 (...) # 逻辑分组，可以有多个该选项 ","date":"2023-02-06","objectID":"/git/:29:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git config $ git config -h usage: git config [\u003coptions\u003e] # options --global # 修改全局配置项 --system use system config file --local use repository config file --worktree use per-worktree config file -f, --file \u003cfile\u003e use given config file --blob \u003cblob-id\u003e read config from given blob object --get # 查看配置项的值 --get-all get all values: key [value-pattern] --get-regexp get values for regexp: name-regex [value-pattern] --get-urlmatch get value specific for the URL: section[.var] URL --replace-all replace all matching variables: name value [value-pattern] --add add a new variable: name value --unset remove a variable: name [value-pattern] --unset-all remove all matches: name [value-pattern] --rename-section rename section: old-name new-name --remove-section remove a section: name -l, --list # 查看所有配置 --fixed-value use string equality when comparing values to 'value-pattern' -e, --edit open an editor --get-color find the color configured: slot [default] --get-colorbool find the color setting: slot [stdout-is-tty] -t, --type \u003ctype\u003e value is given this type --bool value is \"true\" or \"false\" --int value is decimal number --bool-or-int value is --bool or --int --bool-or-str value is --bool or string --path value is a path (file or directory name) --expiry-date value is an expiry date -z, --null terminate values with NUL byte --includes respect include directives on lookup --show-origin # 显示配置文件 --show-scope show scope of config (worktree, local, global, system, command) --default \u003cvalue\u003e with --get, use default value when missing entry 查看现有配置项与所在文件 [C:\\~]$ git config --list --show-origin file:E:/Git/etc/gitconfig diff.astextplain.textconv=astextplain file:E:/Git/etc/gitconfig http.sslbackend=openssl file:E:/Git/etc/gitconfig http.sslcainfo=e:/Git/mingw64/ssl/certs/ca-bundle.crt file:E:/Git/etc/gitconfig core.autocrlf=input file:E:/Git/etc/gitconfig core.fscache=true file:E:/Git/etc/gitconfig core.symlinks=false file:E:/Git/etc/gitconfig pull.rebase=false file:E:/Git/etc/gitconfig credential.helper=manager-core file:E:/Git/etc/gitconfig credential.https://dev.azure.com.usehttppath=true file:E:/Git/etc/gitconfig init.defaultbranch=master file:E:/Git/etc/gitconfig gui.encoding=utf-8 file:E:/Git/etc/gitconfig i18n.commitencoding=utf-8 file:E:/Git/etc/gitconfig svn.pathnameencoding=utf-8 file:C:/Users/xiaosi/.gitconfig user.name=Xiao Si file:C:/Users/xiaosi/.gitconfig user.email=xiaosi@mail.com 中文乱码解决 $ git config --global core.quotepath false # 设置 git status utf-8编码 $ git config --global gui.encoding utf-8 # 设置Git GUI界面utf-8编码 $ git config --global i18n.commit.encoding utf-8 #设置commit信息utf-8编码 $ git config --global i18n.logoutputencoding utf-8 # 设置输出 log utf-8 编码 把统环境变量 LESSCHARSET并赋值为utf-8。注销重新进入系统 error","date":"2023-02-06","objectID":"/git/:30:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" fatal: detected dubious ownership in repository at… xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ git add * fatal: detected dubious ownership in repository at 'F:/xiaosi/hugo/content/archives' 'F:/xiaosi/hugo/content/archives' is owned by: 'S-1-5-21-3134970382-1526891978-4219715912-1001' but the current user is: 'S-1-5-21-627419753-1426211234-1183549367-1001' To add an exception for this directory, call: git config --global --add safe.directory F:/xiaosi/hugo/content/archives 按照提示修改 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives $ git config --global --add safe.directory F:/xiaosi/hugo/content/archives ","date":"2023-02-06","objectID":"/git/:31:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git bash 显示中文为十六进制 $ git status On branch master No commits yet Untracked files: (use \"git add \u003cfile\u003e...\" to include in what will be committed) ... \"istio-\\347\\237\\245\\350\\257\\206\\346\\236\\266\\346\\236\\204\\345\\233\\276.png\" ... 解决方法 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git config --global core.quotepath false ... ","date":"2023-02-06","objectID":"/git/:32:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" LF will be replaced by CRLF the next time Git touches it xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git add * warning: in the working copy of 'JsonPath.md', LF will be replaced by CRLF the next time Git touches it ... 解决方法 # 提交时转换为LF(\\n)，检出时不转换 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ git config --global core.autocrlf input # 或使用以下方式禁止转换 git config --global core.safecrlf false ","date":"2023-02-06","objectID":"/git/:33:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" does not have a commit checked out $ git add . error: 'vim/vimrc/' does not have a commit checked out fatal: adding files failed 该文件已有本地仓库(.git目录)，解决：删除或省略该目录 xiaosi@DESKTOP-E1ASSM6 MINGW64 /f/xiaosi/hugo/content/archives (master) $ rm -rf vim/vimrc/.git ","date":"2023-02-06","objectID":"/git/:34:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["git"],"content":" git: ‘remote-https’ is not a git command. See ‘git –help’.使用 git clone 报错 [root@localhost themes]# git clone https://github.com/hugo-fixit/FixIt.git Cloning into 'FixIt'... git: 'remote-https' is not a git command. See 'git --help'. 解决方法，安装 libcurl-devel 后重新编译 [root@localhost FixIt]# yum install libcurl-devel -y ... [root@localhost ~]# wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.37.1.tar.xz ... [root@localhost ~]# tar -xJf git-2.37.1.tar.xz [root@localhost ~]# cd git-2.37.1 [root@localhost git-2.37.1]# ./configure ... [root@localhost git-2.37.1]# make \u0026\u0026 make install ... ","date":"2023-02-06","objectID":"/git/:35:0","tags":["git"],"title":"git","uri":"/git/"},{"categories":["文本处理"],"content":" 运行环境： perl: 5 内容来自以下文档： learn.perl.org perldoc.perl.org/perl 介绍Perl 是一种通用编程语言，最初是为文本操作而开发的，现在用于广泛的任务，包括系统管理、Web 开发、网络编程、GUI 开发等。该语言旨在实用（易于使用，高效，完整）而不是美观（微小，优雅，最小）。它的主要特点是易于使用，支持过程和面向对象 （OO） 编程，具有强大的文本处理内置支持 安装perl 下载 Perl 是一种自由格式的语言，也就是缩进与换行多数情况没影响 # linux 中打印 hello, world [root@localhost ~]# perl -e 'print (\"Hello, world\\n\")' Hello, world [root@localhost ~]# [root@localhost ~]# perl -e 'print(\"Hello, world\\n\")' Hello, world [root@localhost ~]# [root@localhost ~]# perl -e 'print \"Hello, world\\n\"' Hello, world # windows 中打印 hello, world PS C:\\Users\\xiaosi\\Desktop\u003e perl -e 'print (\\\"Hello, world\\n\\\");' Hello, world PS C:\\Users\\xiaosi\\Desktop\u003e perl -e 'print( \\\"Hello, world\\n\\\");' Hello, world PS C:\\Users\\xiaosi\\Desktop\u003e perl -e 'print \\\"Hello, world\\n\\\";' Hello, world 选项 PS C:\\Users\\xiaosi\\Desktop\u003e perl -h Usage: perl.exe [switches] [--] [programfile] [arguments] -0[octal] specify record separator (\\0, if no argument) -a # 与 -n 或 -p 一起使用时打开自动拆分模式 -C[number/list] enables the listed Unicode features -c check syntax only (runs BEGIN and CHECK blocks) -d[:debugger] run program under debugger -D[number/list] set debugging flags (argument is a bit mask or alphabets) -e program # 在命令行中使用，可以有多个该选项 -E program # 类似 -e 选项，但隐式启用所有可选功能 -f don't do $sitelib/sitecustomize.pl at startup -F/pattern/ split() pattern for -a switch (//'s are optional) -i[extension] edit \u003c\u003e files in place (makes backup if extension supplied) -Idirectory specify @INC/#include directory (several -I's allowed) -l[octal] # 启用自动行尾处理 -[mM][-]module execute \"use/no module...\" before executing program -n # 假定使用 \"while (\u003c\u003e) { ... }\"， -p assume loop like -n but print line also, like sed -s enable rudimentary parsing for switches after programfile -S look for programfile using PATH environment variable -t enable tainting warnings -T enable tainting checks -u dump core after parsing program -U allow unsafe operations -v print version, patchlevel and license -V[:variable] print configuration summary (or a single Config.pm variable) -w enable many useful warnings -W enable all warnings -x[directory] ignore text before #!perl line (optionally cd to directory) -X disable all warnings Run 'perldoc perl' for more help with Perl. [root@localhost ~]# df -h | perl -nae 'print if $F[-2] \u003e 70' /dev/mapper/centos-root 8.5G 6.5G 2.0G 77% / ","date":"2023-02-05","objectID":"/perl/:0:0","tags":["perl"],"title":"perl","uri":"/perl/"},{"categories":["正则"],"content":" 运行环境： 内容来自以下文档： 正则表达式引擎对比 Zjmainstay: 正则文章合集 chinaunix: 文本处理 示例","date":"2023-02-05","objectID":"/%E6%AD%A3%E5%88%99/:0:0","tags":["正则引擎"],"title":"正则表达式","uri":"/%E6%AD%A3%E5%88%99/"},{"categories":["正则"],"content":" 在josn格式中获取指定的IP地址 nginx 日志记录如下 [root@localhost nginxLog]# head -n 1 2023-02-04-note.xiaosi.host.nginx.access.log { \"responseTime\": \"2023-02-04T00:19:28+08:00\",\"requestIP\": \"207.46.13.103\",\"requestPort\": \"26112\",\"requestScheme\": \"https\",\"requestProtocol\": \"HTTP/1.1\",\"requestMethod\": \"GET\",\"requestDomainName\": \"note.xiaosi.host\",\"requestUri\": \"/vmware/\",\"responseUrl\": \"/vmware/index.html\",\"responseIP\": \"103.106.246.17\",\"responseport\": \"443\",\"responseStatus\": \"200\",\"responseSize\": \"19819B\",\"responseBodySize\": \"19493B\",\"processingConsumeTime\": \"0.000s\",\"processingStatus\": \"OK\"} 想要获取请求IP即requestIP的值 [root@localhost nginxLog]# head -n 1 2023-02-04-note.xiaosi.host.nginx.access.log | grep -oP '(?\u003c=\"requestIP\": \")([0-9]{1,3}\\.){3}[0-9]{1,3}' 207.46.13.103 ","date":"2023-02-05","objectID":"/%E6%AD%A3%E5%88%99/:1:0","tags":["正则引擎"],"title":"正则表达式","uri":"/%E6%AD%A3%E5%88%99/"},{"categories":["正则"],"content":" 对IP进行排序（去重）原文本 [root@localhost ~]# cat txt 192.168.12.49 192.168.12.49 192.168.12.5 192.168.12.50 192.168.12.49 192.168.140.49 192.168.140.5 192.168.12.49 192.168.140.50 awk: [root@localhost ~]# awk '{split($1,i,\".\");n=((i[1]*256+i[2])*256+i[3])*256+i[4];a[n]=$0}END{slen=asorti(a,b);for(j=1;j\u003c=slen;j++)print a[b[j]]}' txt 192.168.12.5 192.168.12.49 192.168.12.50 192.168.140.5 192.168.140.49 192.168.140.50 ","date":"2023-02-05","objectID":"/%E6%AD%A3%E5%88%99/:2:0","tags":["正则引擎"],"title":"正则表达式","uri":"/%E6%AD%A3%E5%88%99/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： [name][url] [url]: 安装 yum install -y iotop 帮助信息 [root@localhost ~]# man iotop | cat ... SYNOPSIS iotop [OPTIONS] ... OPTIONS --version # 查看版本并退出 -h, --help # 查看帮助信息并退出 -o, --only # 只显示正在执行磁盘 I/O 的线程或进程。可在交互中使用 o 切换 -b, --batch # 非交互模式，会持续迭代 -t, --time # 非交互模式，同时显示时间戳 -q, --quiet # 非交互模式，仅在第一次迭代时打印标题字段 -qq # 非交互模式，从不打印标题字段 -qqq # 非交互模式，从不打印 I/O 摘要 -n NUM, --iter=NUM # 迭代次数（默认情况下从不退出） -d SEC, --delay=SEC # 迭代时间（默认为 1 秒），可以是浮点数 -p PID, --pid=PID # 指定进程（默认所有） -u USER, --user=USER # 指定用户（默认所有） -P, --processes # 显示次数，而不是带宽 -a, --accumulated # 以KB为单位，即 1024 byte 输出字段说明 # TID : 进程 ID # PRIO : 优先级 # USER : 用户 # DISK READ : 读取 # DISK WRITE : 写入 # SWAPIN : swap交换百分比 # IO\u003e : IO等待所占用百分比 # COMMAND : 进程或线程名 # Total DISK READ : 磁盘总读取量 # Total DISK WRITE : 磁盘总写入量 # Actual DISK READ : 当前读取量 # Actual DISK WRITE : 当前写入量 Total DISK READ : 0.00 B/s | Total DISK WRITE : 0.00 B/s Actual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO\u003e COMMAND ","date":"2023-02-03","objectID":"/iotop/:0:0","tags":["iotop"],"title":"使用 iotop 查进程或线程使用磁盘 I/O 情况","uri":"/iotop/"},{"categories":["nginx unit"],"content":" 运行环境： 内容来自以下文档： name 安装","date":"2023-01-31","objectID":"/nginx-unit/:0:0","tags":["nginx unit"],"title":"nginx unit","uri":"/nginx-unit/"},{"categories":["nginx unit"],"content":" rpm 安装添加 yum 源 [root@localhost ~]# cat /etc/yum.repos.d/nginx-unit.repo [unit] name=unit repo baseurl=https://packages.nginx.org/unit/rhel/$releasever/$basearch/ gpgcheck=0 enabled=1 安装 nginx unit 及其控制语言 [root@localhost ~]# yum install -y unit unit-devel unit-go ... ","date":"2023-01-31","objectID":"/nginx-unit/:1:0","tags":["nginx unit"],"title":"nginx unit","uri":"/nginx-unit/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： blktrace 帮助手册 LINUXPERFORMANCE: 利用BLKTRACE分析IO性能 blktrace-分析 io 案例 安装 [root@localhost ~]# yum install -y blktrace [root@localhost ~]# rpm -ql blktrace | grep bin /usr/bin/blkiomon /usr/bin/blkparse /usr/bin/blkrawverify /usr/bin/blktrace /usr/bin/bno_plot.py /usr/bin/btrace /usr/bin/btrecord /usr/bin/btreplay /usr/bin/btt /usr/bin/verify_blkparse blktraceblktrace 从内核收集事件跟踪的实用程序 blktrace -d devname [options] -A hex-mask; --set-mask=hex-mask # 设置过滤器器 -a mask; --act-mask=mask # 追加过虑器，该选项可以有多个 -b size; --buffer-size=size # 存储事件缓冲区大小，以 1024 绽放。默认为 512KiB -d dev; --dev=dev # 指定 dev , 可以有多个 -I filel; --input-devs=file # 从文件中读取跟踪的 dev -n num-sub; --num-sub-buffers=num-sub # 缓冲区数量，默认为 4 个 -l; --listen # 以守护进程方式运行 -h hostname; --host=hostname # 以守护进程方式运行时绑定的主机名 -p number; --port=number # 以守护进程方式运行时绑定的端口 -s; --no-sendfile # 使网络客户端不使用 sendfile（） 来传输数据 -o basename; --output=basename # 指定输出文件的基本名称。默认值为 device.blktrace.cpu。 # 指定 -o - 使用 blkparse 在实时模式下运行（将数据写入标准输出） -D dir; --output-dir=dir # 附加输出到其它文件，仅在 -o - 选项时有效 -r rel-path; --relay=rel-path # 指定调试装入点。该文件默认为 /sys/kernel/debug # blktrace 从缓冲区中的内核接收数据，这些缓冲区通过调试文件系统（中继）向上传递。 # 被跟踪的每个设备都有一个在挂载目录中为 debugfs 创建的文件， -v; -V; --version # 打印版本 -w seconds; --stopwatch=seconds # 将运行时间设置为指定的秒数 # 过虑器 barrier: complete: fs: issue: pc: queue: read: requeue: sync: write: notify: drv_data: 数据输出到标准输出 # -o - 输出到标准输出，由 blkparse -i - 从管道符分析 [root@localhost ~]# blktrace -d /dev/mapper/centos-root -o - | blkparse -i - 数据输出到指定文件 [root@localhost ~]# blktrace -d /dev/mapper/centos-root -o bl.txt ^C=== dm-0 === CPU 0: 32 events, 2 KiB data CPU 1: 1 events, 1 KiB data CPU 2: 11 events, 1 KiB data CPU 3: 8 events, 1 KiB data Total: 52 events (dropped 0), 3 KiB data [root@localhost ~]# ls bl.txt* bl.txt.blktrace.0 bl.txt.blktrace.1 bl.txt.blktrace.2 bl.txt.blktrace.3 如果不指定输出，则会保存到当前目录下 [root@localhost ~]# blktrace -d /dev/mapper/centos-root ^C=== dm-0 === CPU 0: 12 events, 1 KiB data CPU 1: 0 events, 0 KiB data CPU 2: 1 events, 1 KiB data CPU 3: 9 events, 1 KiB data Total: 22 events (dropped 0), 2 KiB data [root@localhost ~]# ls | grep blk dm-0.blktrace.0 dm-0.blktrace.1 dm-0.blktrace.2 dm-0.blktrace.3 blkparse格式化 blktrace 收集的跟踪数据的实用程序 blkparse [ options ] -A hex-mask; --set-mask=hex-mask # 设置过滤器器 -a mask; --act-mask=mask # 追加过虑器，该选项可以有多个 -D dir; --input-directory=dir -b batch; --batch={batch} # 标准输入读取批处理 -i file; --input=file # 指定数据源文件 -F typ,fmt; --format=typ,fmt; -f fmt; --format-spec=fmt # 指定输出格式 -M; --no-msgs -h; --hash-by-name # 以进程名做 hash , 默认是以 PID -o file; --no-text-output # 指定输出文件 -O; --no-text-output # 使用 -d 选项时，不生成文本输出 -d file; --dump-binary=file # 以二进制文件方式输出 -q; --quiet # 静默模式 -s; --per-program-stats # 显示按程序排序的数据 -t; --track-ios # 显示每个 IO 的时间增量 -w span; --stopwatch=span # 显示指定范围的跟踪，其中范围可以是： # 开始:结束时间 -- 显示从开始时间(缺省为 0)到结束时间的跟踪（以 ns 为单位）。 -v; --verbose # 显示更详细信息 -V; --version # 显示版本 输出字段 [root@localhost ~]# blktrace -d /dev/mapper/centos-root -o - | blkparse -i - # 第一列：主,次设备号 # 第二列：CPU 序列号（从0开始） # 第三列： # 第四列：时间偏移（Time Stamp） # 第五列：PID # 第六列：I/O 事件 # 第七列：操作类型 # 第八列~第十列：块编号 + 块数 # 进程名 253,0 2 1 0.000000000 22481 Q W 14487928 + 8 [kworker/u8:2] 253,0 0 1 0.063470526 0 C W 14487928 + 8 [0] # 第个 CPU 核心统计 ^CCPU0 (253,0): Reads Queued: 0, 0KiB Writes Queued: 0, 0KiB Read Dispatches: 0, 0KiB Write Dispatches: 0, 0KiB Reads Requeued: 0 Writes Requeued: 0 Reads Completed: 0, 0KiB Writes Completed: 1, 4KiB Read Merges: 0, 0KiB Write Merges: 0, 0KiB Read depth: 0 Write depth: 0 IO unplugs: 0 Timer unplugs: 0 CPU2 (253,0): Reads Queued: 0, 0KiB Writes Queued: 1, 4KiB Read Dispatches: 0, 0KiB Write Dispatches: 0, 0KiB Reads Requeued: 0 Writes Requeued: 0 Reads Completed: 0, 0KiB Writes Completed: 0, 0KiB Read Merges: 0, 0KiB Write Merges: 0, 0KiB Read depth: 0 Write depth: 0 IO unplugs: 0 Timer unplugs: 0 Total (253,0): Reads Queued: 0, 0KiB Writes Queued: 1, 4KiB Read Dispatches: 0, 0KiB Write Dispatches: 0, 0KiB Reads Requeued: 0 Writes Requeued: 0 Reads Completed: 0, 0KiB Writes Completed: 1, ","date":"2023-01-24","objectID":"/blktrace/:0:0","tags":["linux","blktrace"],"title":"blktrace 命令使用","uri":"/blktrace/"},{"categories":["linux"],"content":" 设备号与驱动号 主要设备号（major device number），同一设备驱动程序管理的设备有相同的major device number。这个数字实际是Kernel 中device driver table的索引。这个表保存着不同的设备驱动程序。 次要设备号（minor device number），Kernel根据major device number找到设备驱动程序，然后再从minor device number获得设备位置等属性。 ","date":"2023-01-24","objectID":"/blktrace/:1:0","tags":["linux","blktrace"],"title":"blktrace 命令使用","uri":"/blktrace/"},{"categories":["linux"],"content":" I/O 事件有以下 I/O 事件： A: 表示映射（remap）。进来的 I/O 将被重新映射到 I/O 栈中的具体设备 X: 表示切片（split）。对于做了 Raid 或进行了 device mapper(dm) 的设备,进来的 I/O 可能需要切割,然后发送给不同的设备 Q: 请求队列（queued）。进入 block layer,将要被 request 代码处理（即将生成 I/O 请求） G: 生成请求（get request）。 I/O 请求生成,为 I/O 分配一个请求结构体 M : back merge 之前已经存在的 I/O request 的终止 block 号,和该 I/O 的起始 block 号一致,就会合并,也就是向后合并 F : front merge 之前已经存在的 I/O request 的起始 block 号,和该 I/O 的终止 block 号一致,就会合并,也就是向前合并 I : inserted I/O 请求被插入到 I/O scheduler 队列 S : sleep 没有可用的 request 结构体,也就是 I/O 满了,只能等待有 request 结构体完成释放 P : plug 当一个 I/O 入队一个空队列时,Linux 会锁住这个队列,不处理该 I/O,这样做是为了等待一会,看有没有新的 I/O 进来,可以合并 U : unplug 当队列中已经有 I/O request 时,会放开这个队列,准备向磁盘驱动发送该 I/O.这个动作的触发条件是：超时（plug 的时候,会设置超时时间）;或者是有一些 I/O 在队列中（多于 1 个 I/O） D : issued I/O 将会被传送给磁盘驱动程序处理 C : complete I/O 处理被磁盘处理完成 ","date":"2023-01-24","objectID":"/blktrace/:2:0","tags":["linux","blktrace"],"title":"blktrace 命令使用","uri":"/blktrace/"},{"categories":["linux"],"content":" 操作类型操作类型有以下： R 表示读取， W 表示写入 D 表示块丢弃操作 B 表示barrier（锁定）操作 S 表示同步操作 Debugfs is not mounted at /sys/kernel/debu [root@localhost ~]# blktrace -d /dev/mapper/centos-root -o - | blkparse -i - Debugfs is not mounted at /sys/kernel/debug # 解决方法 [root@localhost ~]# mount -t debugfs debugfs /sys/kernel/debug ","date":"2023-01-24","objectID":"/blktrace/:3:0","tags":["linux","blktrace"],"title":"blktrace 命令使用","uri":"/blktrace/"},{"categories":["linux"],"content":" 运行环境： sysstat: 10.1.5 内容来自以下文档： iostat 帮助手册 yelvlab: iostat详细介绍与基本使用 iostat 安装 yum install -y sysstat 帮助选项 [root@localhost ~]# man iostat | cat ... iostat - Report Central Processing Unit (CPU) statistics and input/output statistics for devices and partitions. # 格式 iostat [options] # 输出字段信息 %user # 显示用户级别进程 CPU 利用率百分比 %nice %system # 显示内核级别进程 CPU 利用率百分比 %iowait # CPU 等待磁盘 IO 反馈时间比 %steal # 虚机等待 CPU 资源的时间(虚机分到的是虚拟 CPU，当需要真实的 CPU 时，可能真实的 CPU 正在运行其它虚机的任务，所以需要等待)。 %idle # CPU 空闲比 Device # 设备名 tps # 每秒发送到设备的 I/O 请求数。多个逻辑请求可以组合成对设备的单个 I/O 请求。 Blk_read (kB_read, MB_read) # 读取的块的总数 Blk_wrtn (kB_wrtn, MB_wrtn) # 写入的块的总数 rrqm/s # 每秒合并到设备的读取请求数 wrqm/s # 每秒合并到设备的写入请求数。 r/s # 设备每秒完成的读请求数(合并后) w/s # 设备每秒完成的写请求数(合并后) Blk_read/s (kB_read/s, MB_read/s) # 每秒读取的磁盘块的大小 Blk_wrtn/s (kB_wrtn/s, MB_wrtn/s) # 每秒写入的磁盘块的大小 rsec/s (rkB/s, rMB/s) # 每秒从设备读取的扇区数（千字节、兆字节） wsec/s (wkB/s, wMB/s) # 每秒写入设备的扇区数（千字节、兆字节） avgrq-sz # 向设备发出的请求的平均大小（以扇区为单位）。 avgqu-sz # 向设备发出的请求的平均队列长度 await # 向要处理的设备发出的 I/O 请求的平均时间（以毫秒为单位） # 这包括队列中的请求所花费的时间以及处理这些请求所花费的时间 r_await # 向要处理的设备发出的读取请求的平均时间（以毫秒为单位） # 这包括队列中的请求所花费的时间以及处理这些请求所花费的时间 w_await # 向要处理的设备发出的写入请求的平均时间（以毫秒为单位） # 这包括队列中的请求所花费的时间以及处理这些请求所花费的时间 svctm # 向设备发出的 I/O 请求的平均服务时间（以毫秒为单位）。 # 由于 I/O 统计信息现在是在块级别计算的， # 不知道磁盘驱动程序何时开始处理。因此该字段不可信， # 后续会被删除 %util # 向设备发出 I/O 请求的运行时间百分比(设备的带宽利用率)， # 换句话说就是一秒中有百分之多少的时间用于 I/O 操作。 # 选项 -c # 显示 cpu 信息，缺省值 -d # 显示 dev 信息，缺省值 -g group_name { device [...] | ALL } # 显示 dev 设备统计信息 -h # 换行显示结果 -j { ID | LABEL | PATH | UUID | ... } [ device [...] | ALL ] # 显示设备的持久化名称 -k # 以 KB/s 为单位，即 1024 bit -m # 以 MB/s 为单位，即 1024x1024B -N # 显示注册 dev ，如 lvm container 注册的 -p [ { device [,...] | ALL } ] # 显示分区 -T # This option must be used with option -g and indicates # that only global statistics for the group are to be # displayed, and not statistics for individual devices in the group. -t # 显示时间，格式为 S_TIME_FORMAT 变量 -V # 显示版本后退出 -x # 显示更多的指标 -y # 指定频率显示多少报告时，则省略自系统启动以来的第一个带有统计信息 -z # 省略没有活动的 dev [ interval [ count ] ] # interval 指定显示频率，count 指定次数，count 忽略时表示一直到进程结束 BUGS /proc filesystem must be mounted for iostat to work. Kernels older than 2.6.x are no longer supported. FILES /proc/stat contains system statistics. /proc/uptime contains system uptime. /proc/diskstats contains disks statistics. /sys contains statistics for block devices. /proc/self/mountstats contains statistics for network filesystems. /dev/disk contains persistent device names. [root@localhost ~]# iostat -x Linux 4.18.0-348.7.1.el8_5.x86_64 (localhost.localdomain) 01/23/2022 _x86_64_ (4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.18 0.00 0.57 0.04 0.00 99.21 Device r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util sda 10.70 1.52 390.47 96.40 0.05 0.44 0.51 22.65 0.49 1.02 0.01 36.48 63.52 0.46 0.56 scd0 0.04 0.00 1.12 0.00 0.00 0.00 0.00 0.00 2.10 0.00 0.00 26.04 0.00 2.37 0.01 dm-0 10.22 1.92 334.96 94.18 0.00 0.00 0.00 0.00 0.51 1.16 0.01 32.79 49.16 0.45 0.54 dm-1 0.11 0.00 2.38 0.00 0.00 0.00 0.00 0.00 0.23 0.00 0.00 22.65 0.00 0.27 0.00 avgqu-s：发送给设备 I/O 请求的等待队列平均长度，对于单个磁盘如果值\u003e1表明设备饱和，对于多个磁盘阵列的逻辑磁盘情况除外 await(r_await、w_await)：平均每次设备 I/O 请求操作的等待时间(ms)，包含请求排列在队列中和被服务的时间之和； svctm：发送给设备 I/O 请求的平均服务时间(ms)，如果 svctm 与 await 很接近，表示几乎没有 I/O 等待，磁盘性能很好，否则磁盘队列等待时间较长，磁盘响应较差； %util：设备的使用率，表明每秒中用于 I/O 工作时间的占比，单个磁盘当 %util\u003e60% 的时候性能就会下降(体现在 await 也会增加)，当接近100%时候就设备饱和了，但对于有多个磁盘阵列的逻辑磁盘情况除外； 还有，虽然监测到的磁盘性能比较差，但是不一定会对应用程序的响应造成影响，内核通常使用 I/O asynchronously 技术，使用读写缓存技术来改善性能，不过这又跟上面的物理内存的限制相制约了。 磁盘 I/O 性能不佳不一定是应用程序问题。许多技术通常用于异步执行 I/O，以便应用程序不会阻塞并直接遭受延迟（例如，读取时预读，写入时缓冲）。 ","date":"2023-01-23","objectID":"/linuxCmdIostat/:0:0","tags":["linux","iostat","命令"],"title":"iostat — 报告中央处理单元(CPU)的统计信息以及块设备和分区的输入/输出统计信息。","uri":"/linuxCmdIostat/"},{"categories":["linux"],"content":" 运行环境： centos: 7 ulimitulimit 命令限制进程可用的资源 ulimit [-HSTabcdefilmnpqrstuvx [limit]] -a # 显示所有限制 limit # 修改其限制值，可指定为 unlimited 表示不限制,缺省时只查看值 -H # 硬限制 -S # 软限制 -n # 文件句柄数 -u # 进程数量 [root@localhost ~]# ulimit -a core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 15742 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 65536 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 15742 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 永久修改需要修改 pam_limits 配置文件： /etc/security/limits.d 目录 /etc/security/limits.conf 配置格式如下 \u003cdomain\u003e\u003ctype\u003e\u003citem\u003e\u003cvalue\u003e \u003cdomain\u003e 用户部分 - 可以是用户名 - * 表示所有用户 - % 表示仅适用于 maxlogins 限制，用户组 - \u003cmin_uid\u003e:\u003cmax_uid\u003e uid 范围 - @\u003cmin_gid\u003e:\u003cmax_gid\u003e. 用户组范围 \u003ctype\u003e 限制类型 - hard 表示硬限制由超级用户设置，内核强制执行 - soft 表示软限制，弹性范围 - - 表示 hard 与 soft \u003citem\u003e 限制资源 nice # 进程优先级值，[-20,19] cpu # cpu 最长占用时间，单位分钟 nofile # 文件描述符数量 core data fsize rss stack nproc # 进程数量 as maxlogins maxsyslogins priority locks sigpending msgqueue rtprio \u003cvalue\u003e 值 ","date":"2023-01-14","objectID":"/linux-limit/:0:0","tags":["linux"],"title":"进程可用资源限制","uri":"/linux-limit/"},{"categories":["linux"],"content":" 运行环境： centos: 7 帮助信息man ss 输出有以下信息 -H, --no-header # 不显示标题行 -r, --resolve # 解析端口与 ip -a, --all # 显示所有连接 -l, --listening # 仅显示侦听套接字 -o, --options # 显示计时器信息 -e, --extended # 显示详细的套接字信息 -m, --memory # 显示 socket 占用内存情况 -p, --processes # 显示进程信息 -i, --info # 显示 TCP 内部信息 -K, --kill # 尝试强行关闭套接字。它支持 IPv4 和 IPv6 -s, --summary # 打印汇总统计信息。此选项不会分析从各种源获取摘要的套接字列表。 -z, --contexts # 类似 -p 选项，但显示进程安全上下文 -N NSNAME, --net=NSNAME # 切换到指定的网络命名空间名称。 -f FAMILY, --family=FAMILY # 显示指定套接字类型，FAMILY 有 unix, inet, inet6, link, netlink, vsock -A QUERY, --query=QUERY, --socket=QUERY # 要转储的套接字表列表，以逗号分隔。 # all, inet, tcp, udp, raw, unix, packet, netlink, unix_dgram, unix_stream, # unix_seqpacket, packet_raw, packet_dgram, dccp, sctp, # vsock_stream, vsock_dgram. -b, --bpf # 显示套接字 BPF 筛选器（仅允许管理员获取这些信息）。 -4, --ipv4 # 显示 ipv4 等效 -f inet -6, --ipv6 # 显示 ipv6 等效 -f inet6 -0, --packet # 显示 ESTAB 状态的连接，等效 -f link -t, --tcp # 显示 TCP 套接字 -u, --udp # 显示 UDP 套接字 -d, --dccp # 显示 DDCP 套接字 -w, --raw # 显示 RAW 套接字 -x, --unix # 显示 unix 套接字，等效 -f unix -S, --sctp # 显示 SCTP 套接字 --vsock # 显示 vsock 套接字，等效 -f vscol -D FILE, --diag=FILE # 输入到文件或标准输入 -F FILE, --filter=FILE # 从文件读取 state STATE-FILTER # 指定 TCP 状态 # STATE-FILTER 取值为 {all|connected|synchronized|bucket|big|TCP-STATES} # TCP-STATES 取值为 {established|syn-sent|syn-recv|fin-wait-{1,2}|time-wait|closed|close-wait|last-ack|listen|closing} # all: 所有 TCP 状态 # connected: 比 all 少 listen, closed, closing # synchronized: 比 all 少 syn-sent, listen, closed, closing # big: 比 all 少 syn-recv, time-wait # bucket: syn-recv 或 time-wait EXPRESSION # 表达式 # dport: 目标端口 # sport: 源端口 # dst: 目标 ip ... tcp 状态说明tcp 状态信息 closed: 关闭状态 listen: 等待连接状态 syn-sent: 请求连接状态，即开始第一次握手：发送 SYN 后的状态 syn-recv(SYN-RCVD): 收到请求连接状态。即开始第二次握手：收到请求后发送 SYN+ACK 后的状态 established: 完成三次握手后数据传输状态 fin-wait-1: 请求断开连接状态，即开始第一次分手。发送 FIN 后进入的状态 closing(close-wait): 完成第一次分手。即收到FIN 后发送 ACK 后进入的状态 fin-wait-2: 断开连接第二阶段收到 FIN，即完成第二次分手，开始第三次分手阶段 time-wait: 第四次分手，等待2MSL后进入closed状态 示例 查看所有 http 或 https 连接 [root@localhost ~]# ss '( sport = :http or sport = :https )' Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port 查看 193.233.7.9 的 ssh 连接 [root@localhost ~]# ss dst 193.233.7.9:ssh Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port ","date":"2023-01-09","objectID":"/ss/:0:0","tags":[null],"title":"ss 命令使用帮助","uri":"/ss/"},{"categories":["网络通信"],"content":" 运行环境： centos: 7 内容来自以下文档： RFC 9293 tcp 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | |C|E|U|A|P|R|S|F| | | Offset| Rsrvd |W|C|R|C|S|S|Y|I| Window | | | |R|E|G|K|H|T|N|N| | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | [Options] | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | : : Data : : | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Note that one tick mark represents one bit position. tcp 状态变迁 问题","date":"2023-01-08","objectID":"/tcp/:0:0","tags":["tcp"],"title":"tcp 协议","uri":"/tcp/"},{"categories":["网络通信"],"content":" tcp长连接处于什么状态","date":"2023-01-08","objectID":"/tcp/:1:0","tags":["tcp"],"title":"tcp 协议","uri":"/tcp/"},{"categories":["网络通信"],"content":" 运行环境： centos: 7 内容来自以下文档： RFC 791 RFC 1349 RFC 6864 RFC RFC 791: 1981年定义了 TCP 协议 RFC 1349: 2013年修改了 TCP 头部的 IPv4 Identification 字段 TPC 头部报文格式 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |Version| IHL |Type of Service| Total Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Identification |Flags| Fragment Offset | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Time to Live | Protocol | Header Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Destination Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Example Internet Datagram Header ","date":"2023-01-07","objectID":"/ipv4/:0:0","tags":["ip"],"title":"ipv4 协议","uri":"/ipv4/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： pcap-filter 超详细的网络抓包神器 Tcpdump 使用指南 tcpdumptcpdump是一款强大的网络抓包工具，它使用libpcap库来抓取网络数据包 安装 # 安装 [root@localhost ~]# yum install -y tcpdump Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile ... 选项 # 常用选项 -i # 选择要捕获的网络接口 -n[n] # 单个 n 表示不解析域名，直接显示 IP；两个 n 表示不解析域名和端口 -s{n} # n 表示想要截取的报文字节数。缺省选项时只截取前 96 字节的内容； # n 为 0 表示截取报文全部内容 -v[vv] # 显示更多的详细信息。v的数量越多越详细，最多用 3 个 v -p # 不让网络接口进入混杂模式。此时网卡只接受来自网络端口的目的地址指向 # 自己的数据（当网卡工作在混杂模式下时，网卡将来自接口的所有数据都捕获 # 并交给相应的驱动程序） -e # 显示数据链路层信息。可以显示源和目的 MAC 地址，以及 VLAN tag 信息 -A # 表示使用 ASCII 字符串打印报文的全部数据。不能与 -X 同时使用 -w filename # 把数据报文输出到文件 filename -l # 行缓冲模式，可以实时将抓取到的数据通过管道传递给其他命令 -c n # 抓取 n 个数据包后退出 -S # 打印TCP 数据包的顺序号时, 使用绝对的顺序号, 而不是相对的顺序号. # 相对顺序号可理解为, 相对第一个TCP 包顺序号的差距。如 # 接受方收到第一个数据包的绝对顺序号为232323, 对于后来接收到的第2个,第3个数据包, # tcpdump会打印其序列号为1, 2分别表示与第一个数据包的差距为1 和 2 prot # 端口号 udp|protocol 17 # UDP 协议 TCP|protocol 6 # TCP 协议，可缺省 host [ip] # 抓取特定目的地和源 IP 地址的流量 src [ip] # 源地址 dst [ip] # 目标地址 net [cidrIP] # 使用CIDR[2]模式，可以指定某个网段，如 a.b.c 或 a.b 或 a and 或 \u0026\u0026 # 逻辑或 or 或 || # 逻辑或 not 或 ! # 逻辑非 (...) # 分组 ","date":"2023-01-06","objectID":"/linux-tcpdump/:0:0","tags":["linux","tcpdump 命令"],"title":"tcpdump 命令","uri":"/linux-tcpdump/"},{"categories":["linux"],"content":" 示例 查看版本 [root@localhost ~]# tcpdump --version tcpdump version 4.9.2 libpcap version 1.5.3 OpenSSL 1.0.2k-fips 26 Jan 2017 抓取 eth0 网卡 8209/tcp 的信息 [root@localhost ~]# tcpdump -i eth0 -nn -v port 8209 tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 13:57:45.815037 IP (tos 0x0, ttl 64, id 52824, offset 0, flags [DF], proto TCP (6), length 333) 103.106.244.101.8209 \u003e 120.239.7.124.8466: Flags [P.], cksum 0xdd7a (incorrect -\u003e 0x6442), seq 4212787207:4212787500, ack 1652759749, win 631, length 293 13:57:45.851363 IP (tos 0x0, ttl 49, id 22972, offset 0, flags [DF], proto TCP (6), length 569) 120.239.7.124.8466 \u003e 103.106.244.101.8209: Flags [P.], cksum 0xaed4 (correct), seq 1:530, ack 293, win 509, length 529 从 HTTP 请求头中提取 HTTP 用户代理： $ tcpdump -nn -A -s1500 -l | grep \"User-Agent:\" 同时提取用户代理和主机名 $ tcpdump -nn -A -s1500 -l | egrep -i 'User-Agent:|Host:' 抓取 HTTP GET 流量 tcpdump -s 0 -A -vv 'tcp[((tcp[12:1] \u0026 0xf0) \u003e\u003e 2):4] = 0x47455420' 抓取 HTTP POST 请求流量 # 该方法不能保证抓取到 HTTP POST 有效数据流量， # 因为一个 POST 请求会被分割为多个 TCP 数据包 tcpdump -s 0 -A -vv 'tcp[((tcp[12:1] \u0026 0xf0) \u003e\u003e 2):4] = 0x504f5354' 提取 HTTP 请求的主机名和路径 $ tcpdump -s 0 -v -n -l | egrep -i \"POST /|GET /|Host:\" tcpdump: listening on enp7s0, link-type EN10MB (Ethernet), capture size 262144 bytes POST /wp-login.php HTTP/1.1 Host: dev.example.com GET /wp-login.php HTTP/1.1 Host: dev.example.com GET /favicon.ico HTTP/1.1 Host: dev.example.com GET / HTTP/1.1 Host: dev.example.com 从 HTTP POST 请求中提取密码和主机名 $ tcpdump -s 0 -A -n -l | egrep -i \"POST /|pwd=|passwd=|password=|Host:\" tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on enp7s0, link-type EN10MB (Ethernet), capture size 262144 bytes 11:25:54.799014 IP 10.10.1.30.39224 \u003e 10.10.1.125.80: Flags [P.], seq 1458768667:1458770008, ack 2440130792, win 704, options [nop,nop,TS val 461552632 ecr 208900561], length 1341: HTTP: POST /wp-login.php HTTP/1.1 .....s..POST /wp-login.php HTTP/1.1 Host: dev.example.com .....s..log=admin\u0026pwd=notmypassword\u0026wp-submit=Log+In\u0026redirect_to=http%3A%2F%2Fdev.example.com%2Fwp-admin%2F\u0026testcookie=1 提取 Set-Cookie（服务端的 Cookie）和 Cookie（客户端的 Cookie） $ tcpdump -nn -A -s0 -l | egrep -i 'Set-Cookie|Host:|Cookie:' tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on wlp58s0, link-type EN10MB (Ethernet), capture size 262144 bytes Host: dev.example.com Cookie: wordpress_86be02xxxxxxxxxxxxxxxxxxxc 抓取 ICMP 数据包 $ tcpdump -n icmp tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on enp7s0, link-type EN10MB (Ethernet), capture size 262144 bytes 11:34:21.590380 IP 10.10.1.217 \u003e 10.10.1.30: ICMP echo request, id 27948, seq 1, length 64 11:34:21.590434 IP 10.10.1.30 \u003e 10.10.1.217: ICMP echo reply, id 27948, seq 1, length 64 11:34:27.680307 IP 10.10.1.159 \u003e 10.10.1.1: ICMP 10.10.1.189 udp port 59619 unreachable, length 115 通过排除 echo 和 reply 类型的数据包使抓取到的数据包不包括标准的 ping 包 tcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply' tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on enp7s0, link-type EN10MB (Ethernet), capture size 262144 bytes 11:37:04.041037 IP 10.10.1.189 \u003e 10.10.1.20: ICMP 10.10.1.189 udp port 36078 unreachable, length 156 可以提取电子邮件的正文和其他数据。例如，只提取电子邮件的收件人 $ tcpdump -nn -l port 25 | grep -i 'MAIL FROM\\|RCPT TO' 抓取 NTP 服务的查询和响应 $ tcpdump dst port 123 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes 21:02:19.112502 IP test33.ntp \u003e 199.30.140.74.ntp: NTPv4, Client, length 48 21:02:19.113888 IP 216.239.35.0.ntp \u003e test33.ntp: NTPv4, Server, length 48 21:02:20.150347 IP test33.ntp \u003e 216.239.35.0.ntp: NTPv4, Client, length 48 21:02:20.150991 IP 216.239.35.0.ntp \u003e test33.ntp: NTPv4, Server, length 48 抓取 SNMP 服务的查询和响应 # 通过 SNMP 服务，渗透测试人员可以获取大量的设备和系统信息 $ tcpdump -n -s0 port 161 and udp tcpdump: verbose output suppressed, use -v or -vv for full protocol d","date":"2023-01-06","objectID":"/linux-tcpdump/:1:0","tags":["linux","tcpdump 命令"],"title":"tcpdump 命令","uri":"/linux-tcpdump/"},{"categories":["golang"],"content":" 运行环境： go: 1.15 内容来自以下文档： WiseAdministrator-go语言基础(流程控制语句) if 条件判断语句if 语句会从上往下判断表达式，如果某个表达式为 true 则执行相应的操作 并跳过后续的条件判断，语法如下： if 表达式1 { 执行操作1 } else if 表达式2 { 执行操作2 ... } else{ 所有表达式不满足时执行的操作 } else 和 else if 部分都是可选的，其中 else if 结构可以有多个。 左大括号{必须和 if，else , else if 格式保持在同一行； 执行操作语句和右大括号} 没有硬性规定位置 下面代码输出结果为 A，虽然后续也有表达式满足，但不会被执行 package main import \"fmt\" func main() { score := 110 if score \u003e= 90 { fmt.Println(\"A\") } else if score \u003e 100 { fmt.Println(\"B\") } else if score \u003c 100 { fmt.Println(\"B\") } else { fmt.Println(\"C\") } } 可以把执行语句放在第一个表达式的前面，用; 分隔，如 if score := 110; score \u003e= 90 { fmt.Println(\"A\") } else if score \u003e 100 { fmt.Println(\"B\") } else { fmt.Println(\"C\") } for 循环语句Go 语言中只有 for 循环这一种循环语句，语法格式如下： for 初始语句; 条件表达式; 结束语句 { 循环体语句 } 初始语句部分是可选的，如果没有省略必须是一条简短的语句（短变量声明，自增语句，赋值语句，函数调用）。条件表达式部分也是可选的，表达式成立(为true)时执行循环体语句；不成立(为 false)时，结束循环。结束语句是可选的，如果存在则每次循环之后都要运行一次结束语句，再对条件表达式进行判断，表达式成立则继续执行循环体语句；表达式不成立则结束循环。下面代码打印斐波那契数列，循环9次之后变量x值为34 package main import \"fmt\" func main() { x, y, n := 0, 1, 9 for i := 0; i \u003c n; i++ { x, y = y, x+y } fmt.Println(x) } 如果同时缺省初始语句和结束语句，也就是只有条件表达式，则可以缺省分号 ; package main import \"fmt\" func main() { n := 0 for 4 \u003e n { n = n + 1 } // 最终打印结果为 4 fmt.Println(n) } 如果同时缺省初始语句、结束语句、条件表达式、则是无限循环执行循环语句 package main import \"fmt\" func main() { for { fmt.Println(\"爱你\") } } 上面代码就是一直输出爱你，直到计算机撑不住 switch 条件判断语句switch 语句类似 if 语句，对某个值进行判断，成立则执行相应语句。语法结构如下： switch 条件表达式 { case 值或值列表或表达式之一: 执行语句 fallthrough ... default 执行语句 如果 switch 后面的条件表达式缺省，则表示为 true;可以有多个 case 分支，从上往下执行，当满足某个 case 语句时，执行相应语句， 退出循环; 多个case语句的情况下，它们的表达式或值都是相同数据类型依次做条件判断 age := 1 switch age { case 1: age = age + 10 case 2: age = age + 20 default: age = age - age } // 输出结果为 11 fmt.Println(age) 和 if 语句一样，可以把执行语句放在 switch 之后，但该变量只能在 whitch 语句内有效 switch age := 1; age { case 1: age = age + 10 fmt.Println(age) case 2: age = age + 20 fmt.Println(age) default: age = age - age fmt.Println(age) } case 语句可以同时判断多个值，满足其中一个就执行相应语句 // 输出结果为奇数 switch n := 7; n { case 1, 3, 5, 7, 9: fmt.Println(\"奇数\") case 2, 4, 6, 8: fmt.Println(\"偶数\") default: fmt.Println(n) } case 语句可以使用表达式 age := 30 switch { case age \u003c 25: fmt.Println(\"好好学习吧\") case age \u003e 25 \u0026\u0026 age \u003c 35: fmt.Println(\"好好工作吧\") case age \u003e 60: fmt.Println(\"好好享受吧\") default: fmt.Println(\"活着真好\") } case 语句中的fallthrough 语句是可选的，它会继续执行下一个 case 语句之后再退出，如下面代码输出结果为 31 age := 1 switch age { case 1: age = age + 10 fallthrough case 2: age = age + 20 default: age = age - age } // age = age + 10 + 20 fmt.Println(age) goto 跳转到指定标签goto 语句可以跳转到当前区域之内的指定标签 // 输出结果中没有第二步 func main() { fmt.Println(\"第一步\") // 跳转到 a 标签 goto a // 被忽略 fmt.Println(\"第二步\") // 设置 a 标签 a: fmt.Println(\"第三步\") } goto 跳转到标签处的缩进是没有用的，下面代码输出结果为第一步和第四步 func main() { fmt.Println(\"第一步\") a: fmt.Println(\"第四步\") goto b fmt.Println(\"第二步\") fmt.Println(\"第三步\") goto a b: } break 终止循环break 语句可以终止当前循环语句，可以在 for. switch, select 控制流语句中使用 下面代码中当变量 n 值为 3 时，跳出for循环 func main() { n := 1 for { n = n + 1 fmt.Println(n) if n == 3 { break } } } break 可以指定退出标签的for, select, switch 控制流语句，但好像只能退出第一个语句 // 输出结果为: // 2 // 3 // s // 退出循环 func main() { a: for { n := 1 for { n = n + 1 fmt.Println(n) if n == 3 { break a } } } for { fmt.Println(\"s\") break } fmt.Println(\"退出循环\") } continue 忽略当前循环continue 语句可以忽略当前循环，继续后续的循环，只能在 for 循环语句中使用 // 输出结果为： // 0 // 1 // 3 func main() { for i := 0; i \u003c4 ; i++ { if i == 2 { continue } fmt.Println(i) } } continue 语句指定标签时，忽略标签标签对应的当前循环 func main() { var a, b , c int for ; a \u003c 2 ; a++ { a: for ; b \u003c 3 ; b++ { for ; c \u003c 2; c++ { if c == 1 { continue a } fmt.Println(\"c:\", c) } fmt.Println(\"b:\", b) } fmt.Println(\"a:\", a) } } 上面代码输出结果为： // 三个 for 语句都满足，先循环执行 for c 语句，打印 c c: 0 // for c 循环语句满足 c=1，忽略标签a对应的 for b 当前循环，打印 a a: 0 // a=1 时，进入 b 循环，b 循环进入 c 循环， // 此时 c 还是 1 满足 if 条件，忽略标签a对应的 for b 当前循环b, 打印 a a: 1 // 后续 1+1 不满足条件退出循环 ","date":"0001-01-01","objectID":"/go-Control-flow-statements/:0:0","tags":[null],"title":"go 控制流语句","uri":"/go-Control-flow-statements/"},{"categories":["golang"],"content":" 运行环境： 内容来自以下文档： Nick Coghlan: Go 系列教程 —— 4. 类型【Noluye 译】 Nick Coghlan: Go 系列教程 —— 11. 数组和切片【Dingo1991 译】 Nick Coghlan: Go 系列教程 —— 16. 结构体【Noluye 译】 Nick Coghlan: Go 系列教程 —— 13. Maps【ArisAries 译】 Go语言圣经-4.4 基础数据类型","date":"2023-01-03","objectID":"/go-date-type/:0:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" boolbool 类型表示一个布尔值，值为 true 或者 false 。 func main() { a := true b := false fmt.Println(\"a:\", a, \"b:\", b) // c 赋值为 a \u0026\u0026 b。仅当 a 和 b 都为 true 时，操作符 \u0026\u0026 才返回 true c := a \u0026\u0026 b fmt.Println(\"c:\", c) // 当 a 或者 b 为 true 时，操作符 || 返回 true d := a || b fmt.Println(\"d:\", d) } a: true b: false c: false d: true ","date":"2023-01-03","objectID":"/go-date-type/:1:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 整数整数分为无符号（0与正整数）与有符号整数（正数、负数、0） int8：表示 8 位有符号整数型。范围是：-128～127 int16：表示 16 位有符号整数型。范围是：-32768～32767 int32：表示 32 位有符号整数型。范围是：-2147483648～2147483647 int64：表示 64 位有符号整数型。范围是：-9223372036854775808～9223372036854775807 int：根据底层平台决定，在 32 位系统下是 int32，而在 64 位系统下是 int64 位 uint8：表示 8 位无符号整数型。范围：0～255 uint16：表示 16 位无符号整数型。范围：0～65535 uint32：表示 32 位无符号整数型。范围：0～4294967295 uint64：表示 64 位无符号整数型。范围：0～18446744073709551615 uint：根据底层平台决定，在 32 位系统下是 uint32，而在 64 位系统下是 uint64 ","date":"2023-01-03","objectID":"/go-date-type/:2:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 浮点数浮点数即带小数点的数字，算术规范由IEEE754浮点数国际标准定义。有以下分类 float32 float64 ","date":"2023-01-03","objectID":"/go-date-type/:3:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 复数复数与浮点数相关： complex64: 实部和虚部都是 float32 类型的的复数 complex128: 实部和虚部都是 float64 类型的的复数 ","date":"2023-01-03","objectID":"/go-date-type/:4:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 字符串Go 语言中的字符串是一个字节切片。Go 语言中字符串是兼容 Unicode 编码的，并且使用 UTF-8 进行编码。创建一个字符串需要使用引号 func main() { // 字符串 Hello World fmt.Println(\"Hello World\") } ","date":"2023-01-03","objectID":"/go-date-type/:5:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 获取字符串的元素由于字符串是一个字节切片，所以我们可以获取字符串的每一个字节。但由于一个字符可能占用多个字节，使用 fmt.Printf(\"%c\") 输出字符时不是正常的结果，可以使用 rune类型解决 func printBytes(s string) { for i := 0; i \u003c len(s); i++ { // %x 以 16 进制方式输出 // 48 65 6c 6c 6f 20 57 6f 72 6c 64 fmt.Printf(\"%x \", s[i]) } } func printChars(s string) { for i := 0; i \u003c len(s); i++ { // %c 以字符串方式输出 fmt.Printf(\"%c \", s[i]) } } func main() { name := \"Hello World\" printBytes(name) fmt.Printf(\"\\n\") printChars(name) } ","date":"2023-01-03","objectID":"/go-date-type/:5:1","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 借助 rune 类型打印字符rune 是 Go 语言的内建类型，它也是 int32 的别称。在 Go 语言中，rune 表示一个代码点。代码点无论占用多少个字节，都可以用一个 rune 来表示。 func printBytes(s string) { for i:= 0; i \u003c len(s); i++ { fmt.Printf(\"%x \", s[i]) } } func printChars(s string) { runes := []rune(s) for i:= 0; i \u003c len(runes); i++ { fmt.Printf(\"%c \",runes[i]) } } func main() { name := \"Hello World\" printBytes(name) fmt.Printf(\"\\n\") printChars(name) fmt.Printf(\"\\n\") name = \"Señor\" printBytes(name) fmt.Printf(\"\\n\") printChars(name) } ","date":"2023-01-03","objectID":"/go-date-type/:5:2","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 字符串的 for range 循环使用 for range 循环遍历了字符串 func printCharsAndBytes(s string) { for index, rune := range s { fmt.Printf(\"%c starts at byte %d\\n\", rune, index) } } func main() { name := \"Señor\" printCharsAndBytes(name) } ","date":"2023-01-03","objectID":"/go-date-type/:5:3","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 字符串的长度utf8 package 包中的 func RuneCountInString(s string) (n int) 方法用来获取字符串的长度。这个方法传入一个字符串参数然后返回字符串中的 rune 的数量。 ","date":"2023-01-03","objectID":"/go-date-type/:5:4","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 基础数据类型转换","date":"2023-01-03","objectID":"/go-date-type/:6:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 使用 string 函数转换为字符串 func main() { // 16 进制 byteSlice1 := []byte{0x43, 0x61, 0x66, 0xC3, 0xA9} // 10 进制 byteSlice2 := []byte{67, 97, 102, 195, 169} fmt.Println(string(byteSlice1)) fmt.Println(string(byteSlice2)) } 复合数据类型","date":"2023-01-03","objectID":"/go-date-type/:6:1","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 数组数组是同一类型元素的有序序列集合，该单一类型称为元素类型。元素的个数被称为数组长度，并且不能为负值。长度是数组类型的一部分；它必须为一个可以被 int 类型的值所代表的非负常量。。例如，整数集合 5,8,9,79,76 形成一个数组。Go 语言中不允许混合不同类型的元素，例如包含字符串和整数的数组。如果是 interface{} 类型数组，可以包含任意类型。一个数组的表示形式为 [n]T 。 n 表示数组中元素的数量， T 代表每个元素的类型。元素的数量 n 也是该类型的一部分。数组中的所有元素都被自动赋值为数组类型的零值 func main() { var a [3]int // 声明了一个长度为 3 的整型数组 // 输出 [0 0 0] fmt.Println(a) } 数组的索引从 0 开始到 length - 1 结束。可以通过数组索引给数组赋值。 func main() { var a [3]int //int array with length 3 a[0] = 12 // array index starts at 0 a[1] = 78 a[2] = 50 // [12 78 50] fmt.Println(a) } 也可以使用简略声明来创建相同的数组。可以忽略元素中的值，被忽略的元素会被自动赋值为数组元素的零值。可以使用 ... 代替数组长度，编译器会根据元素数量计算出长度。 func main() { a := [3]int{12, 78, 50} fmt.Println(a) // [12 78 50] b := [3]int{12} fmt.Println(b) // [12 0 0] , 第2、3个元素自动赋值 c := [...]int{12, 78, 50} fmt.Println(c) // [12 78 50] } ","date":"2023-01-03","objectID":"/go-date-type/:7:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 特殊的初始化根据Go 编程语言规范Composite literals 部分对数组和切片的字面值初始化进行了规定： 数组中的每个元素有一个关联的标记其位置的整数索引 带键的元素使用该键作为其索引。这个键必须是可被类型 int 所表示的一个非负常量；而且如果其被赋予了类型的话则必须是整数类型 不带键的元素使用之前元素的索引加一。如果第一个元素没有键，则其索引为零 func main() { var x = []int{22, 5: 44, 55, 66, 3: 77, 88} // 22 没有指定索引，因此索引为 0 // 如果第一个元素没有键，则其索引为零 // 索引为 5 的值为 44 , 不带键的元素使用之前元素的索引加一 // 因此 55 的索引为 6，以此类推，66 的索引为 7 // 88 的索引为 4 （前面一个值的索引为 5） // 综上，输出为：[22 0 0 77 88 44 55 66] fmt.Println(x) // 8 0 println(len(x), x[2]) } ","date":"2023-01-03","objectID":"/go-date-type/:7:1","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 数组是值类型Go 中的数组是值类型而不是引用类型。这意味着当数组赋值给一个新的变量时，该变量会得到一个原始数组的一个副本。如果对新变量进行更改，则不会影响原始数组。 func main() { a := [...]string{\"USA\", \"China\", \"India\", \"Germany\", \"France\"} b := a b[0] = \"Singapore\" // a is [USA China India Germany France] fmt.Println(\"a is \", a) // b is [Singapore China India Germany France] fmt.Println(\"b is \", b) } 同样，当数组作为参数传递给函数时，它们是按值传递，而原始数组保持不变 func changeLocal(num [5]int) { num[0] = 55 // inside function [55 6 7 8 8] fmt.Println(\"inside function \", num) } func main() { num := [...]int{5, 6, 7, 8, 8} // before passing to function [5 6 7 8 8] fmt.Println(\"before passing to function \", num) changeLocal(num) //num is passed by value // after passing to function [5 6 7 8 8] fmt.Println(\"after passing to function \", num) } ","date":"2023-01-03","objectID":"/go-date-type/:7:2","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 数组长度通过将数组作为参数传递给 len 函数，可以得到数组的长度。 func main() { a := [...]float64{67.7, 89.8, 21, 78} fmt.Println(\"length of a is\",len(a)) } 数组的长度是数组类型的一部分。因此 [5]int 和 [25]int 是不同类型。数组不能调整大小 func main() { a := [3]int{5, 78, 8} var b [5]int b = a // main.go:6: cannot use a (type [3]int) as type [5]int in assignment。 } ","date":"2023-01-03","objectID":"/go-date-type/:7:3","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 迭代数组元素for 循环可用于遍历数组中的元素。 func main() { a := [...]float64{67.7, 89.8, 21, 78} for i := 0; i \u003c len(a); i++ { // looping from 0 to the length of the array fmt.Printf(\"%d th element of a is %.2f\\n\", i, a[i]) } } Go 提供了一种更好、更简洁的方法，通过使用 for 循环的 range 方法来遍历数组。range 返回索引和该索引处的值。 func main() { a := [...]float64{67.7, 89.8, 21, 78} sum := float64(0) for i, v := range a {//range returns both the index and value fmt.Printf(\"%d the element of a is %.2f\\n\", i, v) sum += v } fmt.Println(\"\\nsum of all elements of a\",sum) } 如果只需要值并希望忽略索引，则可以通过用 _ 空白标识符替换索引来执行。 for _, v := range a { // ignores index } ","date":"2023-01-03","objectID":"/go-date-type/:7:4","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 多维数组Go 语言可以创建多维数组。 func main() { a := [3][2]string{ {\"lion\", \"tiger\"}, {\"cat\", \"dog\"}, {\"pigeon\", \"peacock\"}, } printarray(a) var b [3][2]string b[0][0] = \"apple\" b[0][1] = \"samsung\" b[1][0] = \"microsoft\" b[1][1] = \"google\" b[2][0] = \"AT\u0026T\" b[2][1] = \"T-Mobile\" fmt.Printf(\"\\n\") printarray(b) } 输出结果如下 lion tiger cat dog pigeon peacock apple samsung microsoft google AT\u0026T T-Mobile ","date":"2023-01-03","objectID":"/go-date-type/:7:5","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 切片切片是由数组建立的一种方便、灵活且功能强大的包装（Wrapper）。切片本身不拥有任何数据。它们只是对现有数组的引用。带有 T 类型元素的切片由 []T 表示 切片是针对一个底层数组的连续段的描述符，它提供了对该数组内有序序列元素的访问。切片类型表示其元素类型的数组的所有切片的集合。元素的数量被称为切片长度，且不能为负。未初始化的切片的值为 nil func main() { // 数组 a a := [5]int{76, 77, 78, 79, 80} // 切片 b，对引用数组 a 的值（从索引1到索引4） var b []int = a[1:4] // creates a slice from a[1] to a[3] // [77 78 79] fmt.Println(b) } 另一种创建切片的方法 func main() { // 创建一个有 3 个整型元素的数组，并被切片 c 引用 c := []int{6, 7, 8} fmt.Println(c) } ","date":"2023-01-03","objectID":"/go-date-type/:8:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 切片的长度和容量 // slice 表示数组对象名称，字符串、数组都可以 // i 表示起始元素的下标 // j 表示结束元素的下标-1 slice[i;j] 切片的长度是切片中的元素数。切片的容量是从创建切片索引开始的底层数组中元素数。切片可以重置其容量。任何超出这一点将导致程序运行时抛出错误。 func main() { fruitarray := [...]string{\"apple\", \"orange\", \"grape\", \"mango\", \"water melon\", \"pine apple\", \"chikoo\"} fruitslice := fruitarray[1:3] // lan 函数返回长度，即现有元素个数。cap 反回容量，即最多元素个数 // length of slice 2 capacity 6 fmt.Printf(\"length of slice %d capacity %d\", len(fruitslice), cap(fruitslice)) // 重制 fruitslice 容量 fruitslice = fruitslice[:cap(fruitslice)] // After re-slicing length is 6 and capacity is 6 fmt.Println(\"After re-slicing length is\",len(fruitslice), \"and capacity is\",cap(fruitslice)) } ","date":"2023-01-03","objectID":"/go-date-type/:8:1","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" make 创建切片func make（[]T，len，cap）[]T 通过传递类型，长度和容量来创建切片。容量是可选参数, 默认值为切片长度。make 函数创建一个数组，并返回引用该数组的切片。使用 make 创建切片时默认情况下这些值为零。下面程序的输出为 [0 0 0 0 0]。 func main() { i := make([]int, 5, 5) fmt.Println(i) } ","date":"2023-01-03","objectID":"/go-date-type/:8:2","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 切片的修改切片自己不拥有任何数据。它只是底层数组的一种表示。对切片所做的任何修改都会反映在底层数组中。 func main() { darr := [...]int{57, 89, 90, 82, 100, 78, 67, 69, 59} dslice := darr[2:5] // array before [57 89 90 82 100 78 67 69 59] fmt.Println(\"array before\", darr) for i := range dslice { dslice[i]++ } // array after [57 89 91 83 101 78 67 69 59] fmt.Println(\"array after\", darr) } 当多个切片共用相同的底层数组时，每个切片所做的更改将反映在数组中。 func main() { numa := [3]int{78, 79 ,80} // [:] 缺省开始和结束值，表示引用所有值 nums1 := numa[:] nums2 := numa[:] // array before change 1 [78 79 80] fmt.Println(\"array before change 1\", numa) // 对 nums1 切片修改 nums1[0] = 100 // array after modification to slice nums1 [100 79 80] fmt.Println(\"array after modification to slice nums1\", numa) // 对 nums2 切片修改 nums2[1] = 101 // array after modification to slice nums2 [100 101 80] fmt.Println(\"array after modification to slice nums2\", numa) } ","date":"2023-01-03","objectID":"/go-date-type/:8:3","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 追加切片元素数组的长度是固定的，它的长度不能增加。 切片是动态的，使用 append 可以将新元素追加到切片上。当超过最大长度时会创建一个新的数组（容量通常是翻倍）。现有数组的元素被复制到这个新数组中，并返回这个新数组的新切片引用。 func SliceRise(s []int) { // 当 s1 切片传入函数时，切片 s1 s 引用同一个数组（原始数组 []int{1,2}）。 // 使用 append 函数时也触发扩展，新建数组并被 s 切片引用，后续for循环对s切片追加元素不会对 s1 造成影响 // 当 s2 切片传入函数时，切片 s s2 引用同一个数组（数组 [1 2 3 0] ），元素都是 [1 2 3] // 此时它们的长度一样，当对 s 切片使用 append 函数追加元素后它们长度不一样， // s 元素为：[1 2 3 0]， s2 元素为：[1 2 3] // for 循环把每个元素值+1，结果： s 元素是 [2 3 4 1], s2 元素是 [2 3 4] s = append(s, 0) for i := range s { s[i]++ } } func main() { // s1 s2 都引用同一个数组 [1,2], 该数组大小与容量都为 2 s1 := []int{1, 2} s2 := s1 // 使用 append 函数追加一个值后，原数据容量不够，会新建一个容量为 4（原容量x2）的数组，并把旧的元素复制到新的数组 // s2引用新的数组，新的数组为 [1 2 3 0]，s2 切片长度为3，即元素是 [1 2 3]，最后面的0没有引用 s2 = append(s2, 3) SliceRise(s1) SliceRise(s2) // [1 2] [2 3 4] fmt.Println(s1, s2) } append() 函数还支持使用...运算符将一个切片添加到另一个切片 func main() { veggies := []string{\"potatoes\", \"tomatoes\", \"brinjal\"} fruits := []string{\"oranges\", \"apples\"} food := append(veggies, fruits...) // food: [potatoes tomatoes brinjal oranges apples] fmt.Println(\"food:\", food) } ","date":"2023-01-03","objectID":"/go-date-type/:8:4","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 多维切片类似于数组，切片可以有多个维度。 func main() { pls := [][]string{ {\"C\", \"C++\"}, {\"JavaScript\"}, {\"Go\", \"Rust\"}, } for _, v1 := range pls { for _, v2 := range v1 { fmt.Printf(\"%s \", v2) } // C C++ // JavaScript // Go Rust fmt.Printf(\"\\n\") } } ","date":"2023-01-03","objectID":"/go-date-type/:8:5","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 数组回收切片持有对底层数组的引用。只要切片在内存中，数组就不能被垃圾回收。在内存管理方面，这是需要注意的。让我们假设我们有一个非常大的数组，我们只想处理它的一小部分。然后，我们由这个数组创建一个切片，并开始处理切片。这里需要重点注意的是，在切片引用时数组仍然存在内存中。 一种解决方法是使用 copy 函数 func copy(dst，src[]T)int 来生成一个切片的副本。这样我们可以使用新的切片，原始数组可以被垃圾回收。 func countries() []string { countries := []string{\"USA\", \"Singapore\", \"Germany\", \"India\", \"Australia\"} // 创建一个去掉尾部 2 个元素的切片 countries neededCountries := countries[:len(countries)-2] countriesCpy := make([]string, len(neededCountries)) // 将 neededCountries 复制到 countriesCpy copy(countriesCpy, neededCountries) // 返回 countriesCpy。现在 countries 数组不再被引用，可以被垃圾回收 return countriesCpy } func main() { countriesNeeded := countries() fmt.Println(countriesNeeded) } ","date":"2023-01-03","objectID":"/go-date-type/:8:6","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 结构体结构体是一种聚合的数据类型。是由任意个类型组成的实体，每个值称为结构体的成员。语法如下： // 命名的结构体 type 结构体名称 struct { 成员名称 成员数据类型 .... } 声明结构体时也可以不用声明一个新类型，这样的结构体类型称为 匿名结构体。 // 匿名结构体 var employee struct { firstName, lastName string age int } 命名结构体示例 type Employee struct { // firstName 和 lastName 属于相同的 string 类型，可以写成一行 firstName, lastName string age int salary int } func main() { // 定义变量 emp1 值是结构值类型 // 赋值时如果指定结构体中的字段，可以不按顺序赋值 emp1 := Employee{ firstName: \"Sam\", age: 25, salary: 500, lastName: \"Anderson\", } // 没有指定字段时必须按结构体定义字段顺序赋值 emp2 := Employee{\"Thomas\", \"Paul\", 29, 800} // Employee 1 {Sam Anderson 25 500} fmt.Println(\"Employee 1\", emp1) // Employee 2 {Thomas Paul 29 800} fmt.Println(\"Employee 2\", emp2) } ","date":"2023-01-03","objectID":"/go-date-type/:9:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 结构体的零值当定义好的结构体并没有被显式地初始化时，该结构体的字段将默认赋为零值。 type Employee struct { firstName, lastName string age, salary int } func main() { emp5 := Employee{ firstName: \"John\", age: 22, } // lastName 与 salary 字段没有赋值时将根据类型赋为零值 // Employee 5 {John 22 0} fmt.Println(\"Employee 5\", emp5) } ","date":"2023-01-03","objectID":"/go-date-type/:9:1","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 访问结构体的字段点号操作符 . 用于访问结构体的字段 type Employee struct { firstName, lastName string age, salary int } func main() { emp6 := Employee{\"Sam\", \"Anderson\", 55, 6000} // First Name: Sam fmt.Println(\"First Name:\", emp6.firstName) // Last Name: Anderson fmt.Println(\"Last Name:\", emp6.lastName) // Age: 55 fmt.Println(\"Age:\", emp6.age) // Salary: $6000 fmt.Printf(\"Salary: $%d\", emp6.salary) } 还可以创建零值的结构体，以后再给各个字段赋值。 type Employee struct { firstName, lastName string age, salary int } func main() { var emp7 Employee emp7.firstName = \"Jack\" emp7.lastName = \"Adams\" fmt.Println(\"Employee 7:\", emp7) } ","date":"2023-01-03","objectID":"/go-date-type/:9:2","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 结构体的指针还可以创建指向结构体的指针 type Employee struct { firstName, lastName string age, salary int } func main() { emp8 := \u0026Employee{\"Sam\", \"Anderson\", 55, 6000} // First Name: Sam // 可以使用 emp8.firstName 来代替显式的解引用 (*emp8).firstName fmt.Println(\"First Name:\", (*emp8).firstName) // Age: 55 fmt.Println(\"Age:\", (*emp8).age) } ","date":"2023-01-03","objectID":"/go-date-type/:9:3","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 匿名字段当创建结构体时，字段可以只有类型，而没有字段名。这样的字段称为匿名字段。虽然匿名字段没有名称，但其实匿名字段的名称就默认为它的类型 type Person struct { // 字段名与字段类型都是 string string int } func main() { p := Person{\"Naveen\", 50} fmt.Println(p) } ","date":"2023-01-03","objectID":"/go-date-type/:9:4","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 嵌套结构体结构体的字段有可能也是一个结构体。这样的结构体称为嵌套结构体。 type Address struct { city, state string } type Person struct { name string age int // address 字段的类型是 Address 结构体 address Address } func main() { var p Person p.name = \"Naveen\" p.age = 50 p.address = Address { city: \"Chicago\", state: \"Illinois\", } fmt.Println(\"Name:\", p.name) fmt.Println(\"Age:\",p.age) fmt.Println(\"City:\",p.address.city) fmt.Println(\"State:\",p.address.state) } 如果是结构体中有匿名的结构体类型字段，则该匿名结构体里的字段就称为提升字段。这是因为提升字段就像是属于外部结构体一样，可以用外部结构体直接访问。 type Address struct { city, state string } type Person struct { name string age int // 字段名称与结构体名称相同，称为提升字段 Address } func main() { var p Person p.name = \"Naveen\" p.age = 50 p.Address = Address{ city: \"Chicago\", state: \"Illinois\", } fmt.Println(\"Name:\", p.name) fmt.Println(\"Age:\", p.age) // 提升字段可以直接通过结构体引用 fmt.Println(\"City:\", p.city) //city is promoted field fmt.Println(\"State:\", p.state) //state is promoted field } ","date":"2023-01-03","objectID":"/go-date-type/:9:5","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 导出结构体和字段如果结构体名称以大写字母开头，则它是其他包可以访问的导出类型。同样，如果结构体里的字段首字母大写，它也能被其他包访问到 // computer/spec.go # computer 目录与 man.go 同级 package computer type Spec struct { // Maker string //exported field model string // 无法被其它包引用 Price int //exported field } // man.go func main() { var spec computer.Spec spec.Maker = \"apple\" spec.Price = 50000 // Spec: {apple 50000} fmt.Println(\"Spec:\", spec) // spec.model undefined (cannot refer to unexported field or method model)。 spec.model = \"Mac Mini\" fmt.Println(\"Spec:\", spec) } ","date":"2023-01-03","objectID":"/go-date-type/:9:6","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 结构体相等性结构体是值类型。如果它的每一个字段都是可比较的，则该结构体也是可比较的。如果两个结构体变量的对应字段相等，则这两个变量也是相等的。如果结构体包含不可比较的字段，则结构体变量也不可比较。 // 结构体类型 name 包含两个 string 类型。 type name struct { firstName string lastName string } func main() { name1 := name{\"Steve\", \"Jobs\"} name2 := name{\"Steve\", \"Jobs\"} // 由于字符串是可比较的，因此可以比较两个 name 类型的结构体变量。 if name1 == name2 { fmt.Println(\"name1 and name2 are equal\") } else { fmt.Println(\"name1 and name2 are not equal\") } name3 := name{firstName:\"Steve\", lastName:\"Jobs\"} name4 := name{} name4.firstName = \"Steve\" if name3 == name4 { fmt.Println(\"name3 and name4 are equal\") } else { fmt.Println(\"name3 and name4 are not equal\") } } 示例2 // 结构体类型 image 包含一个 map 类型的字段。 type image struct { data map[int]int } func main() { image1 := image{data: map[int]int{ 0: 155, }} image2 := image{data: map[int]int{ 0: 155, }} // 由于 map 类型是不可比较的，因此 image1 和 image2 也不可比较。 if image1 == image2 { fmt.Println(\"image1 and image2 are equal\") } } ","date":"2023-01-03","objectID":"/go-date-type/:9:7","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" mapmap 是在 Go 中将值（value）与键（key）关联的内置类型。通过相应的键可以获取到值。通过向 make 函数传入键和值的类型，可以创建 map。语法为 make(map[type of key]type of value) personSalary := make(map[string]int) // 创建了一个名为 personSalary 的 map，其中键是 string 类型，而值是 int 类型。 personSalary := make(map[string]int) map 的零值是 nil。如果你想添加元素到 nil map 中，会触发运行时 panic。因此 map 必须使用 make 函数初始化。 func main() { var personSalary map[string]int if personSalary == nil { fmt.Println(\"map is nil. Going to make one.\") personSalary = make(map[string]int) } } ","date":"2023-01-03","objectID":"/go-date-type/:10:0","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 给 map 添加元素给 map 添加新元素的语法和数组相同。下面的程序给 personSalary map 添加了几个新元素。 func main() { personSalary := make(map[string]int) personSalary[\"steve\"] = 12000 personSalary[\"jamie\"] = 15000 personSalary[\"mike\"] = 9000 fmt.Println(\"personSalary map contents:\", personSalary) } 也可以在声明的时候初始化 map。 func main() { // 声明了 personSalary，并在声明的同时添加两个元素 personSalary := map[string]int { \"steve\": 12000, \"jamie\": 15000, } // 添加了键 mike personSalary[\"mike\"] = 9000 fmt.Println(\"personSalary map contents:\", personSalary) } ","date":"2023-01-03","objectID":"/go-date-type/:10:1","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 获取 map 中元素可以通过 key 获取 value func main() { personSalary := map[string]int{ \"steve\": 12000, \"jamie\": 15000, } employee := \"jamie\" fmt.Println(\"Salary of\", employee, \"is\", personSalary[employee]) fmt.Println(\"Salary of steve is\", personSalary[\"steve\"]) } 可以通过 value, ok := map[key] 判断一个 key 是否存在，如果 ok 为真表示 key 存在 func main() { personSalary := map[string]int{ \"steve\": 12000, \"jamie\": 15000, } newEmp := \"joe\" value, ok := personSalary[newEmp] if ok == true { fmt.Println(\"Salary of\", newEmp, \"is\", value) } else { fmt.Println(newEmp,\"not found\") } } 可以使用 form range 循环遍历 map ，但 map 是无序的，不保证每次执行程序获取的元素顺序相同。 func main() { personSalary := map[string]int{ \"mike1\": 270001, \"mike2\": 270002, \"mike3\": 270003, \"mike4\": 270004, \"mike5\": 270005, \"mike6\": 270005, \"mike7\": 270006, } fmt.Println(\"All items of a map\") for key, value := range personSalary { fmt.Printf(\"personSalary[%s] = %d\\n\", key, value) } } ","date":"2023-01-03","objectID":"/go-date-type/:10:2","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 删除 map 中元素使用 delete 函数可以删除 map 中的元素 func main() { personSalary := map[string]int{ \"steve\": 12000, \"jamie\": 15000, } fmt.Println(\"map: \", personSalary) // 删除 personSalary 中 key 为 steve 的元素 delete(personSalary, \"steve\") fmt.Println(\"map: \", personSalary) } ","date":"2023-01-03","objectID":"/go-date-type/:10:3","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 获取 map 长度使用 len 函数可获得 map 元素数量 func main() { personSalary := map[string]int{ \"steve\": 12000, \"jamie\": 15000, } // length is 2 fmt.Println(\"length is\", len(personSalary)) } ","date":"2023-01-03","objectID":"/go-date-type/:10:4","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" map 是引用类型当 map 被赋值为一个新变量的时候，它们指向同一个内部数据结构。因此，改变其中一个变量，就会影响到另一变量。当 map 作为函数参数传递时也会发生同样的情况。函数中对 map 的任何修改，对于外部的调用都是可见的。 func main() { personSalary := map[string]int{ \"steve\": 12000, \"jamie\": 15000, } // personSalary: map[jamie:15000 steve:12000] fmt.Println(\"personSalary: \", personSalary) newPersonSalary := personSalary newPersonSalary[\"jamie\"] = 18000 // newPersonSalary: map[jamie:18000 steve:12000] fmt.Println(\"newPersonSalary: \", personSalary) } ","date":"2023-01-03","objectID":"/go-date-type/:10:5","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" map 的相等性map 之间不能使用 == 操作符判断，== 只能用来检查 map 是否为 nil。 func main() { map1 := map[string]int{ \"one\": 1, \"two\": 2, } map2 := map1 // invalid operation: map1 == map2 (map can only be compared to nil) if map1 == map2 { fmt.Println(\"ok\" } } ","date":"2023-01-03","objectID":"/go-date-type/:10:6","tags":["数据类型","golang"],"title":"go 数据类型","uri":"/go-date-type/"},{"categories":["golang"],"content":" 运行环境： go: 1.19 内容来自以下文档： Nick Coghlan: Go 系列教程 —— 3. 变量【Noluye 译】 Go语言圣经-程序结构：变量 Go语言圣经-基础数据类型：常量 变量变量指定了某存储单元（Memory Location）的名称，该存储单元会存储特定类型的值。在Go中，有多种语法用于声明变量。 ","date":"2023-01-03","objectID":"/go-variable-constant/:0:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 声明变量var 声明语句会创建一个特定数据类型的变量，然后给变量附加一个名称， 并设置变量的初始值。语法通常如下： var 变量名称 数据类型 = 表达式 其中，变量值类型或表达式可以省略其中一个： 如果是省略数据类型，那么更据初始化表达式来推导变量的数据类型 如果是省略表达式，那么更据数据类型对应的零值初始化变量 数值类型零值为：0 布尔值类型零值为：false 字符串类型零值为：\"\"（空字符串） 接口或引用类型零值为：nil var形式的声明语句往往是用于需要显式指定变量类型的地方，或者因为变量稍后会被重新赋值而初始值无关紧要的地方。零值初始化及其可以确保每个变量都有一个值，这个特性可以简化很多代码，如下面代码输出结果为0 // int 表示数据类型 var s int fmt.Println(s) Go 是强类型（Strongly Typed）语言，因此不允许某一类型的变量赋值为其他类型的值。下面的程序会抛出错误 cannot use \"naveen\" (type string) as type int in assignment，这是因为 age 本来声明为 int 类型，却给它赋字符串类型的值。 func main() { age := 29 // age是int类型 age = \"naveen\" // 错误，尝试赋值一个字符串给int类型变量 } ","date":"2023-01-03","objectID":"/go-variable-constant/:1:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 声明一组变量可以在一个声明语句中同时声明一组变量，或用一组初始化表达式声明并初始化一组变量。如果省略每个变量的类型，将可以声明多个类型不同的变量 // d, e, f 三个变量没有声明数值类型，会更据值推导的数值类型 // 变量 d 布尔型，值为 true // 变量 e 浮点数型, 值为 5.5 // 变量 f 字符串型， 值为 hello var d, e, f = true, 2.3+3.2, \"hello\" // 这三个变量都没有声明数值，会初始化为数值 0 var i, j, k int fmt.Println(d, e, f) fmt.Println(i, j, k) ","date":"2023-01-03","objectID":"/go-variable-constant/:2:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 简短声明简短声明是在函数内部的一种声明方式，用于声明和初始化局部变量。变量类型是由表达式字段推导，语法如下： 变量名称 := 表达式 这种方式和var语句声明的变量几乎没有区别，如果变量在同级语法区域已经声明过了，那么简短变量声明会变成赋值行为；如果变量在外部语法区域声明的，那么加简短变量会在当前语法区域声明一个新的变量 package main import \"fmt\" func main() { name, age := \"naveen\", 29 // 简短声明 fmt.Println(\"my name is\", name, \"age is\", age) } 简短声明要求 := 操作符左边的所有变量都有初始值。下面程序将会抛出错误 cannot assign 1 values to 2 variables，这是因为 age 没有被赋值。 package main import \"fmt\" func main() { name, age := \"naveen\" //error fmt.Println(\"my name is\", name, \"age is\", age) } 简短声明的语法要求 := 操作符的左边至少有一个变量是尚未声明的。否则会报错：no new variables on left side of := func main() { a, b := 20, 30 // 声明a和b fmt.Println(\"a is\", a, \"b is\", b) a, b := 40, 50 // 错误，没有尚未声明的变量 } ","date":"2023-01-03","objectID":"/go-variable-constant/:3:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 指针变量在声明时把内存空间中的值绑定到一个变量名，因此一个变量可以看由以下部分组成： 变量名 变量类型 变量值 存储变量值的内存地址 如果变量的值是另一个变量值的内存地址，那么该变量称为指针，如下代码，变量c可以称为c指针指向变量a指向 // 字符串类型变量 a a := \"hello\" // 字符串类型变量 b b := \"hi\" // 字符串类型指针变量 c // \u0026a 表示获取变量值的内存地址 c := \u0026a // 得到变量值 ,内存地址, 变量类型 fmt.Println(a, \u0026a ,reflect.TypeOf(a) ) fmt.Println(b, \u0026b ,reflect.TypeOf(b) ) fmt.Println(c, \u0026c ,reflect.TypeOf(c) ) 上面代码的示意图： go-指针1 如果一个变量的值是另一个变量的指针，则可以用通过 *变量名 去修改或获取该指针的值，如以下代码 // 字符串类型变量 a a := \"hello\" // 字符串类型指针变量 c // \u0026a 表示获取变量值的内存地址 c := \u0026a // 输出结果为 hello fmt.Println(*c) // 对 c 变量值所指的指针重新赋值 *c = \"hi\" // 输出结果为 hi hi fmt.Println(*c, a) 任何类型的指针的零值都是nil。指针之间也是可以进行相等测试的，只有当它们指向同一个变量或全部是nil时才相等 a, b := \"\", \"\" // 输出为 true false false // 原因是变量的指针不同 // \u0026a 为什么不喝 nil 相等？ fmt.Println(\u0026a == \u0026a, \u0026a == \u0026b, \u0026a == nil) 在Go语言中，返回函数中局部变量的地址也是安全的。例如下面的代码，调用f函数时创建局部变量v，在局部变量地址被返回之后依然有效，因为指针p依然引用这个变量 var p = f() func f() *int { v := 1 return \u0026v } ","date":"2023-01-03","objectID":"/go-variable-constant/:4:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 指向指针的指针指针可以嵌套一级，最多一级 ","date":"2023-01-03","objectID":"/go-variable-constant/:5:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 变量声明周期变量的生命周期指的是在程序运行期间变量有效存在的时间段： 对于在包一级声明的变量来说，它们的生命周期和整个程序的运行周期是一致的 对于局部变量的生命周期则是动态的，每次从创建一个新变量的声明语句开始，直到该变量不再被引用为止，然后变量的存储空间可能被回收 Go 语言的自动垃圾收集器的基本思路是：从每个包级的变量和每个当前运行函数的每一个局部变量开始，通过指针或引用的访问路径遍历，是否可以找到该变量。如果不存在这样的访问路径，那么说明该变量是不可达的，也就是说它是否存在并不会影响程序后续的计算结果 因为一个变量的有效周期只取决于是否可达，因此一个循环迭代内部的局部变量的生命周期可能超出其局部作用域。同时，局部变量可能在函数返回之后依然存在 ","date":"2023-01-03","objectID":"/go-variable-constant/:6:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 变量初始化在包级别声明的变量会在main入口函数执行前完成初始化，局部变量将在声明语句被执行时完成初始化 ","date":"2023-01-03","objectID":"/go-variable-constant/:7:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 栈堆编译器会自动选择在栈上还是在堆上分配局部变量的存储空间，与变量声明方式无关 常量常量表达式的值在编译期计算，而不是在运行期。每种常量的潜在类型都是基础类型。一个常量的声明语句定义了常量的名字，和变量的声明语法类似，常量的值不可修改，这样可以防止在运行期被意外或恶意的修改 const pi = 3.14159 // 定义常量 pi 值为圆周率 pi = 3.14159265359 // error：cannot assign to a. 原因 不允许重新赋值 和变量声明一样，可以批量声明多个常量；这比较适合声明一组相关的常量 const ( e = 2.7182818284590 pi = 3.14159265358979323846264338327950288419716939937510582097494459 ) 所有常量的运算都可以在编译期完成，这样可以减少运行时的工作，也方便其他编译优化，当操作数是常量时，一些运行时的错误也可以在编译时被发现，例如整数除零、字符串索引越界、任何导致无效浮点数的操作。常量间的所有算术运算、逻辑运算和比较运算的结果也是常量，对常量的类型转换操作或以下函数调用都是返回常量结果： len cap real imag complex unsafe.Sizeof func main() { fmt.Println(\"Hello, playground\") var a = math.Sqrt(4) // 允许 // 不允许， 是一个常量，它的值需要在编译的时候就确定。函数 math.Sqrt(4) 只会在运行的时候计算， // error main.go:11: const initializer math.Sqrt(4) is not a constant) const b = math.Sqrt(4) } 因为它们的值是在编译期就确定的，因此常量可以是构成类型的一部分，例如用于指定数组类型的长度 const IPv4Len = 4 // parseIPv4 parses an IPv4 address (d.d.d.d). func parseIPv4(s string) IP { var p [IPv4Len]byte // ... } 一个常量的声明也可以包含一个类型和一个值，但是如果没有显式指明类型，那么将从右边的表达式推断类型 func main() { const timeout = 5 * time.Minute // 输出:time.Duration 5m0s // %T 打印类型 fmt.Printf(\"%T %[1]v\\n\", timeout) } 如果是批量声明的常量，除了第一个外其它的常量右边的初始化表达式都可以省略，如果省 略初始化表达式，则使用前面常量的表达式的写法，对应类型也是一样 func main() { const ( a = 1 b c = 2 d ) // 1 1 2 2 fmt.Println(a, b, c, d) } ","date":"2023-01-03","objectID":"/go-variable-constant/:8:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" iota 常量生成器常量声明可以使用iota常量生成器初始化，它用于生成一组以相似规则初始化的常量，但 是不用每行都写一遍初始化表达式。在一个const声明语句中，在第一个声明的常量所在 的行，iota将会被置为0，然后在每一个有常量声明的行加一 func main() { const ( a int = iota b c d ) // 输出： 0 1 2 3 fmt.Println(a, b, c, d) } 可以在iota部分使用表达式，会自动套用该表达式 func main() { const ( // \u003c\u003c 表示2次幂 a int = 1 \u003c\u003c iota b c d ) // 输出： 1 2 4 8 fmt.Println(a, b, c, d) } 下面示例中，每个常量都是1024的幂 const ( _ = 1 \u003c\u003c (10 * iota) KiB // 1024 MiB // 1048576 GiB // 1073741824 TiB // 1099511627776 (exceeds 1 \u003c\u003c 32) PiB // 1125899906842624 EiB // 1152921504606846976 ZiB // 1180591620717411303424 (exceeds 1 \u003c\u003c 64) YiB // 1208925819614629174706176 ) 不过iota常量生成规则也有其局限性。例如，它并不能用于产生1000的幂,，因为Go语言并没有计算幂的运算符 ","date":"2023-01-03","objectID":"/go-variable-constant/:9:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 字符串常量双引号中的任何值都是 Go 中的字符串常量。 const typedhello string = \"Hello World\" ","date":"2023-01-03","objectID":"/go-variable-constant/:10:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 布尔常量布尔值常量与字符串常量相似 func main() { const trueConst = true type myBool bool var defaultBool = trueConst // 允许 var customBool myBool = trueConst // 允许 defaultBool = customBool // 不允许 } ","date":"2023-01-03","objectID":"/go-variable-constant/:11:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 数字常量数字常量包含整数、浮点数和复数的常量。数字常量中有一些微妙之处。 func main() { const a = 5 var intVar int = a fmt.Printf(\"type %T value %v\\n\", intVar, intVar) var int32Var int32 = a fmt.Printf(\"type %T value %v\\n\", int32Var, int32Var) var float64Var float64 = a fmt.Printf(\"type %T value %v\\n\", float64Var, float64Var) var complex64Var complex64 = a fmt.Printf(\"type %T value %v\\n\", complex64Var, complex64Var) } 数字常量可以在表达式中自由混合和匹配，只有当它们被分配给变量或者在需要类型的代码中的任何地方使用时，才需要类型。 func main() { const a = 5.9 / 8 fmt.Printf(\"a's type %T value %v\", a, a) } ","date":"2023-01-03","objectID":"/go-variable-constant/:12:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 无类型常量许多常量并没有一个明确的数据类型，编译器为这些没有明确基础类型的数字常量提供比基础类型更高精度的算术运算，可以认为至少有256bit的运算精度。有以下几种未明确的常量类型： 无类型的布尔型 无类型的整数 无类型的字符 无类型的浮点数 无类型的复数 无类型的字符 Go 是一门强类型语言，所有的变量必须有明确的类型。无类型的常量有一个与它们相关联的默认类型，并且当且仅当一行代码需要时才提供它。 func main() { // 无类型常量 name var name = \"Sam\" // 转换为 字符串类型常量 fmt.Printf(\"type %T value %v\", name, name) } func main() { const a = 0 var b = 0 var f1 float64 = a // 可以正常赋值，转换为 float64 类型 var f2 float64 = b // b 变量是 int 类型，无法赋值给 float64 类型的 f2 变量 fmt.Println(f1, f2) } 通过延迟明确常量的具体类型，无类型的常量不仅可以提供更高的运算精度，而且可以直接用于更多的表达式而不需要显式的类型转换。如下面是示例中，ZiB和YiB已经超过了任何Go语言中的整数范围，但依然是合法的常量，且常量表达式依旧有效 func main() { const ( _ = 1 \u003c\u003c (10 * iota) KiB // 1024 MiB // 1048576 GiB // 1073741824 TiB // 1099511627776 (exceeds 1 \u003c\u003c 32) PiB // 1125899906842624 EiB // 1152921504606846976 ZiB // 1180591620717411303424 (exceeds 1 \u003c\u003c 64) YiB // 1208925819614629174706176 ) fmt.Println(YiB/ZiB) // \"1024\" } 注意有一点不同：无类型整数常量转换为int，它的内存大小是不确定的，但是无类型浮点数和复数常量则转换为内存大小明确的float64和complex128。 如果不知道浮点数类型的内存大小是很难写出正确的数值算法，因此Go语言不存在整型类似的不确定内存大小的浮点数和复数类型 ","date":"2023-01-03","objectID":"/go-variable-constant/:13:0","tags":["变量","常量"],"title":"go 语言中变量与常量","uri":"/go-variable-constant/"},{"categories":["golang"],"content":" 运行环境： 内容来自以下文档： go编程语言规范 cwittlut: Go 编程语言规范【译】 go编程语言补充：有效执行 go编程语言有效执行补充1：风格指南 go编程语言有效执行补充2：注释 ","date":"2023-01-03","objectID":"/go-spec/:0:0","tags":["书写规范"],"title":"go 语言书写规范","uri":"/go-spec/"},{"categories":["redis"],"content":" 运行环境： redis: 7.0.7 内容来自以下文档： redis官方文档: ACL redis官方文档: commands redis ACLACL 是访问控制列表的缩写，是允许在可以执行的命令和可以访问的密钥方面限制某些连接的功能。它的工作方式是，连接后，客户端需要提供用户名和有效密码进行身份验证。如果身份验证成功，则连接与给定用户及其用户的限制相关联。 可以使用以下方式为用户配置规则 使用 ACL SETUSER 指令 使用 ACL LOAD 导入 ACL 配置文件 规则由用户、密码、指令权限、kye 操作权限、Pub/Sub权限组成 ACL SETUSER ACL SETUSER username [rule [rule ...]] 可用版本: 6.0.0 时间复杂度: O(N) # N 为规则数量 ACL 分类: @admin, @slow, @dangerous ACL SETUSER 可以创建用户并设置规则 103.106.246.17:6973\u003e ACL SETUSER redis01 OK 默认情况下，未指定规则几乎没有任何权限，从 redis 6.2 开始 pub/sub 的默认权限为 allchannels 该值可以通过 acl-pubsub-default 修改，但从 redis 7.0 开始为了安全又把该权限改为 resetchannels 可以使用 ACL GETUSER 或 ACL LIST 查看权限 103.106.246.17:6973\u003e ACL LIST 1) \"user alice off resetchannels -@all\" 2) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 3) \"user redis01 off resetchannels -@all\" 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e ACL GETUSER redis01 1) \"flags\" 2) 1) \"off\" 3) \"passwords\" 4) (empty array) 5) \"commands\" 6) \"-@all\" 7) \"keys\" 8) \"\" 9) \"channels\" 10) \"\" 11) \"selectors\" 12) (empty array) 103.106.246.17:6973\u003e ACL LIST 1) \"user alice off resetchannels -@all\" 2) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" ACL SETUSER 是以增量的方式修改用户，并不会直接覆盖，如下面 redis01 用户最终拥有使用 GET 与 SET 指令权限，如果规则冲突则以最后的为准（依次修改的） 103.106.246.17:6973\u003e ACL LIST ... 3) \"user redis01 off resetchannels -@all\" 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e ACL SETUSER redis01 on OK 103.106.246.17:6973\u003e ACL SETUSER redis01 +set OK 103.106.246.17:6973\u003e ACL SETUSER redis01 +get OK 103.106.246.17:6973\u003e ACL LIST ... 3) \"user redis01 on resetchannels -@all +set +get\" 103.106.246.17:6973\u003e ACL SETUSER redis01 -get OK 103.106.246.17:6973\u003e ACL LIST ... 3) \"user redis01 off resetchannels -@all +set\" ","date":"2023-01-02","objectID":"/redis-acl/:0:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["redis"],"content":" 启用或禁用用户 103.106.246.17:6973\u003e ACL LIST 3) \"user redis01 off resetchannels -@all +set 103.106.246.17:6973\u003e ACL SETUSER redis01 on OK 103.106.246.17:6973\u003e ACL LIST 3) \"user redis01 on resetchannels -@all +set\" ","date":"2023-01-02","objectID":"/redis-acl/:1:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["redis"],"content":" 设置密码可以通过以下前缀设置密码： 以\u003e开头: 表示添加密码 以\u003c开头: 表示移除密码 以#开头: 表示以 64 位的 SHA-256 哈希值（只包含0-9a-f），可以存放在 acl.conf 中 以!开头: 表示移除哈希密码 nopass: 不设置密码 resetpass: 先连接再设置密码，设置密码后才会进行权限验证。这是默认值 # 为 redis01 用户设置密码 103.106.246.17:6973\u003e ACL SETUSER redis01 \u003eoVAmLz9DXZ28uZ4OAiwZnN OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 off #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 resetchannels -@all\" 103.106.246.17:6973\u003e # 为 redis01 用户设置密码（hash） 103.106.246.17:6973\u003e ACL SETUSER redis01 #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 off #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 resetchannels -@all\" 103.106.246.17:6973\u003e # 移除指定的 hash 密码 103.106.246.17:6973\u003e ACL SETUSER redis01 !a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 off #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 resetchannels -@all\" 103.106.246.17:6973\u003e # 不设置密码 103.106.246.17:6973\u003e ACL SETUSER redis01 nopass OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 off nopass resetchannels -@all\" 当连接 redis 时是使用 AUTH 指令进行的身份验证（类似 linux 中的 ssh） AUTH [username] password 可用版本: 1.0.0 时间复杂度: O(N) # N 为密码长度 ACL 分类: @fast, @connection 在 redis 6.0 之前是只有 default 用户，因此没有 username 部分 default 用户的密码也可以在配置文件中使用 requirepass 配置项指定，由于 redis 性能很高，可以在短时间内处理大量密码，因此密码必须要尽可能的复杂。redis 提供了 ACL GENPASS 命令生成随机密码 ACL GENPASS [bits] 可用版本: 6.0.0 时间复杂度: O(1) ACL 分类: @slow bits 表示密码大小，默认情况下，64 字节字符串表示 256 位伪随机数据。 如果指定的 bit 无法被4整除，则向上取整。如 5 bit 的密码长度为 2 ","date":"2023-01-02","objectID":"/redis-acl/:2:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["redis"],"content":" 设置使用指令权限可以通过以下方式指定权限 以+开头：表示可以使用该命令。子命令使用| 表示，从redis 7.0 开始如想增加 ACL SETUSER权限可写为 +ACL|SETUESR，在此之前必须写为-ACL +ACL|SETUSER (先禁止再允许) 以-开头：表示禁止使用该命令 以+@ 开关：表示可以使用指定的 ACL 类别命令，@all 表示所有类别 以-@ 开关：表示禁止使用指定的 ACL 类别命令，@all 表示所有类别 allcommands: 表示允许使用所有命令，等效 +@all nocommands: 表示禁止使用所有命令，这是默认值，等效 -@all # 允许除 ACL SETUSER 以外的所有命令 103.106.246.17:6973\u003e ACL SETUSER redis01 on \u003eoVAmLz9DXZ28uZ4OAiwZnN allcommands -ACL|SETUSER OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 resetchannels +@all -acl|setuser\" # 验证 [root@localhost ~]# redis-cli -h 103.106.246.17 -p 6973 103.106.246.17:6973\u003e AUTH redis01 oVAmLz9DXZ28uZ4OAiwZnN OK 103.106.246.17:6973\u003e ACL SETUSER user01 on (error) NOPERM this user has no permissions to run the 'acl|setuser' command 再次提示，ACL SETUSER 是增量方式增加的，权限顺序很重要 # 由于 -ACL|SETUSER 与 allcommands 有冲突，后者覆盖前者 103.106.246.17:6973\u003e ACL SETUSER redis01 on \u003eoVAmLz9DXZ28uZ4OAiwZnN -ACL|SETUSER allcommands OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 resetchannels +@all\" redis 的指令很多，依次添加非常麻烦，redis 把命令进行归类，ACL CAT 命令可以查看所有分类与某类所包含的指令 103.106.246.17:6973\u003e ACL CAT 1) \"keyspace\" # key 管理，但不涉及值。如删除 key，查看 key 列表等 2) \"read\" # 对 key 的值有查询权限 3) \"write\" # 对 key 的值有写入权限 4) \"set\" # set 数据类型相关 5) \"sortedset\" # sorted sets related 数据类型相关 6) \"list\" # list 数据类型相关 7) \"hash\" # hash 数据类型相关 8) \"string\" # sreing 数据类型相关 9) \"bitmap\" # bitmap 数据类型相关 10) \"hyperloglog\" # hyperloglog 数据类型相关 11) \"geo\" # geospatial indexes related 数据类型相关 12) \"stream\" # stream 数据类型相关 13) \"pubsub\" # pub/sub 数据类型相关 14) \"admin\" # 管理 redis 相关命令，如 配置、调试、ACL 等等 15) \"fast\" # 时间复杂度为 O(1) 的指令 16) \"slow\" # 时间复杂度不为 O(1) 的指令 17) \"blocking\" # 有关锁相关的指令（要等等另一方释放） 18) \"dangerous\" # 有危险的指令 19) \"connection\" # 连接相关的命令，如 PING ECHO 20) \"transaction\" # 事务相关 21) \"scripting\" # 脚本相关 # 查看 read 类有哪些指令 103.106.246.17:6973\u003e ACL CAT read 1) \"srandmember\" 2) \"geopos\" 3) \"mget\" ... 下面示例将为 redis01 用户允许使用 string 数据类型相关的所有指令 103.106.246.17:6973\u003e ACL DELUSER redis01 (integer) 1 103.106.246.17:6973\u003e ACL SETUSER redis01 on \u003eoVAmLz9DXZ28uZ4OAiwZnN +@string OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 resetchannels -@all +@string\" ","date":"2023-01-02","objectID":"/redis-acl/:3:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["redis"],"content":" 设置使用 key 的权限有以使用以下方式为用户增加对 key 的操作权限 以~或%RW~开头：表示允许使用指定 key 的读写，可以使用 go 匹配模式，如 ~* 允许所有的 key 读写权限 以%R~开头：表示允许修改指定 key，需要 redis 6.2 起 以%W~开头：表示允许读取指定 key，需要 redis 6.2 起 allkeys: 表示对所有 key 有读写权限，等效 ~* resetkeys: 移除对 key 的权限，默认值为 resetkeys allkeys。可以使用 go 匹配模式 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 resetchannels -@all +@string\" 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e ACL SETUSER redis01 allkeys OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 ~* resetchannels -@all +@string\" # 等效 resetkeys allkeys 103.106.246.17:6973\u003e ACL SETUSER redis01 resetkeys OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 resetchannels -@all +@string\" ","date":"2023-01-02","objectID":"/redis-acl/:4:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["redis"],"content":" 设置使用 pub/sub 权限可以通过以下方式为用户提供访问 pub/sub 权限 allchannels: 可访问所有 pub/sub 信道 以\u0026开头：可访问 go 匹配模式匹配到的 pub/sub 信道 resetchannels: 取消可访问的信道，可使用 go 匹配模式。缺省值为取消所有 pub/sub 信道 ","date":"2023-01-02","objectID":"/redis-acl/:5:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["redis"],"content":" 权限组从 redis 7.0 可以使用括号添加一组权限，这样可以更灵活的配置权限。 103.106.246.17:6973\u003e ACL DELUSER redis01 (integer) 1 103.106.246.17:6973\u003e # redis01 用户只可以使用 SET key1、SET key2、GET key1 权限 103.106.246.17:6973\u003e ACL SETUSER redis01 on \u003eoVAmLz9DXZ28uZ4OAiwZnN +GET ~key1 (+SET ~key[12]) OK 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 ~key1 resetchannels -@all +get (~key[12] resetchannels -@all +set)\" # 测试 [root@localhost ~]# redis-cli -h 103.106.246.17 -p 6973 103.106.246.17:6973\u003e AUTH redis01 oVAmLz9DXZ28uZ4OAiwZnN OK 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e SET key1 haha OK 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e SET key2 haha OK 103.106.246.17:6973\u003e # 没有 GET key2 的权限 103.106.246.17:6973\u003e GET key2 (error) NOPERM this user has no permissions to access one of the keys used as arguments 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e GET key1 \"haha\" 权限组无法修改，可以通过 clearselectors 关键字移除所有附加组权限 # 移除所有附加权限 103.106.246.17:6973\u003e ACL SETUSER redis01 clearselectors OK 103.106.246.17:6973\u003e 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 ~key1 resetchannels -@all +get\" 103.106.246.17:6973\u003e ","date":"2023-01-02","objectID":"/redis-acl/:6:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["redis"],"content":" 重置所有权限reset 关键字可重置默认权限（一无所有） 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 on #e3609173108c06fb81458d7b4148c1ae807f9460d6b31678a39ff8db1894f3c5 ~* resetchannels -@all +@string\" 103.106.246.17:6973\u003e ACL SETUSER redis01 reset OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user redis01 off sanitize-payload resetchannels -@all\" acl 配置文件可以在 redis 配置文件中添加 aclfile 配置项目指定 acl 规则文件，该文件每一行指定一个用户的规则。规则与 ACL SETUSER 指令定义一样 [root@localhost ~]# echo 'aclfile /data/redis/acl.conf' \u003e\u003e /data/redis/redis.conf [root@localhost ~]# cat /data/redis/acl.conf user worker +@list +@connection ~jobs:* on \u003effa9203c493aa99 user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all [root@localhost ~]# chown redis:redis /data/redis/acl.conf [root@localhost ~]# redis-cli -h 103.106.246.17 -p 6973 103.106.246.17:6973\u003e AUTH default redisAsd123 OK 103.106.246.17:6973\u003e ACL LIST 1) \"user default on #a468529ac9108f5483e0956ca9a601241a82149ef107864dafaddb1279ce63c8 ~* \u0026* +@all\" 2) \"user worker on #2288ec82bc090b36a7ebee6c750e541c3d3594a17917e6aa275340c77226e883 ~jobs:* resetchannels -@all +@connection +@list\" ACL SAVE 可以把内存的中 ACL 规则写入 aclfile 配置项指定的文件中，ACL LOAD 相反，是加载 ACL 规则文件 ","date":"2023-01-02","objectID":"/redis-acl/:7:0","tags":["redis","ACL"],"title":"redis 访问控制列表","uri":"/redis-acl/"},{"categories":["golang"],"content":" 运行环境： go: 1.19.4 内容来自以下文档： 林猛男: 解决Goland错误：$GOPATH/go.mod exists but should not 下载与激活点击下载 goland即可从 jiebrains 官网下载 goland。激活方式参考该网站：http://jets.idejihuo.com/ 使用 goroot 是指 golang sdk 目录 gopath 是指 golang 工作目录，新版本不用配置，会与 go mod 冲突 error","date":"2023-01-01","objectID":"/goland/:0:0","tags":["go"],"title":"jetbrains goland","uri":"/goland/"},{"categories":["golang"],"content":" $GOPATH/go.mod exists but should not错误详情 原因:开启Go module模块支持后，并不能与$GOPATH共存,所以把项目从$GOPATH中移出或者不要使用Go module模块即可 方法1：删除 gopath 方法2：删除 go.mod 文件 ","date":"2023-01-01","objectID":"/goland/:1:0","tags":["go"],"title":"jetbrains goland","uri":"/goland/"},{"categories":["redis"],"content":" ","date":"2022-12-31","objectID":"/redis-data-teype/","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 运行环境： redis: 7.0.7 内容来自以下文档： 一洺：一文搞懂redis redis官方文档：Redis data types redis官方文档：Commands 肉眼品世界公号：一文深入了解 Redis 内存模型，Redis 的快是有原因的！ 业余草：从根上理解，一个 Redis 字符串为什么要设计的这么复杂！ Mr于：Redis数据结构——快速列表(quicklist) redis 整体的存储结构redis内部整体的存储结构是一个大的hashmap，内部是数组实现的hash，key冲突通过挂链表去实现，每个dictEntry为一个key/value对象，value为定义的redisObject。 其中dictEntry是存储key/value的地主，以下是dictEntry结构体 /* * 字典 */ typedef struct dictEntry { // 键 void *key; // 值 union { // 指向具体redisObject void *val; // uint64_t u64; int64_t s64; } v; // 指向下个哈希表节点，形成链表 struct dictEntry *next; } dictEntry; redisObject 结构体如下： /* * Redis 对象 */ typedef struct redisObject { // 类型 4bits unsigned type:4; // 编码方式 4bits unsigned encoding:4; // LRU 时间（相对于 server.lruclock） 24bits unsigned lru:22; // 引用计数 Redis里面的数据可以通过引用计数进行共享 32bits int refcount; // 指向对象的值 64bits void *ptr; } robj; *ptr 指向具体的数据结构的地址 type 表示redis对象类型（数据类型）。如 string、list 等 encoding 表示对象底层使用的编码。为了提高存储效率与程序执行效率，每种数据类型的底层数据结构实现都可能不止一种。redis 对象底层有以下几种数据结构 -REDIS_ENCODING_INT：long 类型的整数 -REDIS_ENCODING_EMBSTR：embstr编码的简单动态字符串 -REDIS_ENCODING_RAW：简单动态字符串 -REDIS_ENCODING_HT：字典 -REDIS_ENCODING_LINKEDLIST：双端链表 -REDIS_ENCODING_ZIPLIST：压缩列表 -REDIS_ENCODING_INTSET：整数集合 -REDIS_ENCODING_SKIPLIST：跳跃表和字典 下图是每种数据类型使用的数据结构 ","date":"2022-12-31","objectID":"/redis-data-teype/:0:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" sds以下是 sds 结构体 /* 针对不同长度整形做了相应的数据结构 * Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 使用 sds 实现 string 相比 c 语言的 string 有以下好处： 低复杂度获取字符串长度：由于 len 存在，可以直接查出字符串长度，复杂度O(1)；如果用c语言字符串，查询字符串长度需要遍历整个字符串，复杂度为O(n)； 避免缓冲区溢出：进行两个字符串拼接 c 语言可使用 strcat 函数，但如果没有足够的内存空间。就会造成缓冲区溢出；而用 sds 在进行合并时会先用 len 检查内存空间是否满足需求，如果不满足，进行空间扩展，不会造成缓冲区溢出； 减少修改字符串的内存重新分配次数： c 语言字符串不记录字符串长度，如果要修改字符串要重新分配内存，如果不进行重新分配会造成内存缓冲区泄露； redis sds 实现了空间预分配和惰性空间释放两种策略： 如果 sds 修改后， sds 长度（ len 的值）将于 1mb ，那么会分配与 len 相同大小的未使用空间，此时 len 与 free 值相同。例如，修改之后字符串长度为 100 字节，那么会给分配 100 字节的未使用空间。最终 sds 空间实际为 100+100+1 (保存空字符’\\0') 如果大于等于 1mb ，每次给分配 1mb 未使用空间 对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，等待后续使用（ sds 也提供 api ，我们可以手动触发字符串缩短）； 因为 C 字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此 C 字符串无法正确存取；而所有 SDS 的 API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束； ","date":"2022-12-31","objectID":"/redis-data-teype/:1:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" ziplistziplist 是一种压缩链表，它最大的优点是能节省内存空间，它所存储的内容都是连续的内存区域中，当 list 元素过大时就不好用了。这是由于保证他存储内容在内存中的连续性，插入的时间复杂度是O(N)，即每次插入都会重新进行realloc 做内存扩展。如果超过 ziplist 的内存大小还会重新分配内存空间。并把内容复制到新的内存空间。如果数量大的话，重新分配内存与拷贝数据会消耗大量时间。因此不适合存储过多元素。 ziplist 结构有以下组成： zlbytes: 用于记录整个压缩列表占用的内存字节数 zltail: 记录要列表尾节点距离压缩列表的起始地址有多少字节 zllen: 记录了压缩列表包含的节点数量 entry: 列表包含的节点，可能存在多个节点 zlend: 于标记压缩列表的末端 当 zset 数据类型使用 ziplist 存储时会对 ziplist 进行排序：每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（ member ），而第二个元素则保存元素的分值（ score ）。如下图 ","date":"2022-12-31","objectID":"/redis-data-teype/:2:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" linkedlistlinkedlist 的附加空间相对太高，prev 和 netx 指针要占用 16 个字节，而且每一个结点都是单独分配，会加剧内存的碎片化，影响内存管理效率。因此使用 quickList 替换它。quicklist 是 ziplist 和 linkedlist 的混合体，是将 linkedlist 按段切分，每段用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针链接。以下是 quicklist 结构图 以下是 quicklist 结构定义 typedef struct quicklist { // 指向quicklist的头部 quicklistNode *head; // 指向quicklist的尾部 quicklistNode *tail; unsigned long count; unsigned int len; // ziplist大小限定，由list-max-ziplist-size给定 int fill : 16; // 节点压缩深度设置，由list-compress-depth给定 unsigned int compress : 16; } quicklist; typedef struct quicklistNode { // 指向上一个ziplist节点 struct quicklistNode *prev; // 指向下一个ziplist节点 struct quicklistNode *next; // 数据指针，如果没有被压缩，就指向ziplist结构，反之指向quicklistLZF结构 unsigned char *zl; // 表示指向ziplist结构的总长度(内存占用长度) unsigned int sz; // ziplist数量 unsigned int count : 16; /* count of items in ziplist */ unsigned int encoding : 2; /* RAW==1 or LZF==2 */ // 预留字段，存放数据的方式，1--NONE，2--ziplist unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */ // 解压标记，当查看一个被压缩的数据时，需要暂时解压，标记此参数为1，之后再重新进行压缩 unsigned int recompress : 1; /* was this node previous compressed? */ unsigned int attempted_compress : 1; /* node can't compress; too small */ // 扩展字段 unsigned int extra : 10; /* more bits to steal for future usage */ } quicklistNode; typedef struct quicklistLZF { // LZF压缩后占用的字节数 unsigned int sz; /* LZF size in bytes*/ // 柔性数组，存放压缩后的ziplist字节数组 char compressed[]; } quicklistLZF; quicklist 内部单个 ziplist长度由 list-max-ziplist-siz 配置项设置。默认为 8k 字节，超过该值时会新建一个 ziplist。为了进一歩节约空间，redis 还会对 ziplist 使用 LZF 算法进行压缩。压缩深度由 list-compress-depth 配置项设置，默认值为 0。为了支持快速 push/pop 操作，quicklist 首尾两个 ziplist 不进行压缩，即深度为 1。如果深度为 2 表示首尾两个 ziplist 都不压缩 ","date":"2022-12-31","objectID":"/redis-data-teype/:3:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" intsetintset 数据结构体如下 typedef struct intset { uint32_t encoding; // length就是数组的实际长度 uint32_t length; // contents 数组是实际保存元素的地方，数组中的元素有以下两个特性： // 1.没有重复元素 // 2.元素在数组中从小到大排列 int8_t contents[]; } intset; // encoding 的值可以是以下三个常量的其中一个 #define INTSET_ENC_INT16 (sizeof(int16_t)) #define INTSET_ENC_INT32 (sizeof(int32_t)) #define INTSET_ENC_INT64 (sizeof(int64_t)) intset 是一个有序的集合（只是单纯的对整数进行升序）。查找元素的时间复杂度为 O(logN)（采用二分法），但插入时不一定。这是因为有可能涉及到升级操作。比如当集合里全是 int16_t 型的整数，这时要插入一个 int32_t ，那么为了维持集合中数据类型的一致，那么所有的数据都会被转换成 int32_t 类型，涉及到内存的重新分配，这时插入的复杂度就为 O(N) 了。 intset 不支持降级操作。 ","date":"2022-12-31","objectID":"/redis-data-teype/:4:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" dict以下是 dict 结构体定义 typedef struct dict { dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ int iterators; /* number of iterators currently running */ } dict; typedef struct dictht { //指针数组，这个hash的桶 dictEntry **table; //元素个数 unsigned long size; unsigned long sizemask; unsigned long used; } dictht; dictEntry 在上面有讲，使用来真正存储key-\u003evalue的地方 typedef struct dictEntry { // 键 void *key; // 值 union { // 指向具体redisObject void *val; // uint64_t u64; int64_t s64; } v; // 指向下个哈希表节点，形成链表 struct dictEntry *next; } dictEntry; 结构图如下 每个 dict 中都有两个 hashtable，虽然 dict 结构有两个 hashtable ，但是通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容的时候，需要分配新的 hashtable ，然后进行渐近式搬迁，这时候两个 hashtable 存储的旧的 hashtable 和新的 hashtable 。搬迁结束后，旧 hashtable 删除，新的取而代之。 渐进式 rehash 是指我们的大字典的扩容是比较消耗时间的，需要重新申请新的数组，然后将旧字典所有链表的元素重新挂接到新的数组下面，是一个 O(n) 的操作。但是因为我们的 redis 是单线程的，无法承受这样的耗时过程，所以采用了渐进式 rehash 小步搬迁，虽然慢一点，但是可以搬迁完毕。由于它采取分而治之的方式，避免了集中式 rehash 带来的庞大计算量。特别的在进行 rehash 时只能对 h[0] 元素减少的操作，如查询和删除；而查询是在两个哈希表中查找的，而插入只能在 ht[1] 中进行， ht[1] 也可以查询和删除 扩容一般会在 Hash 表中的元素个数等于第一维数组的长度的时候，就会开始扩容。扩容的大小是原数组的两倍。不过在 redis 在做 bgsave （ RDB 持久化操作的过程），为了减少内存页的过多分离（Copy On Write）， redis 不会去扩容。不扩容主要是为了尽可能减少内存页过多分离，系统需要更多的开销去回收内存。但是如果 hash 表的元素个数已经到达了第一维数组长度的 5 倍的时候，就会强制扩容，不管你是否在持久化。 hash 表元素逐渐删除的越来越少的时候。 redis 于是就会对 hash 表进行缩容来减少第一维数组长度的空间占用。缩容的条件是元素个数低于数组长度的 10% ，并且缩容不考虑是否在做 redis 持久化。不用考虑 bgsave 主要是因为我们的缩容的内存都是已经使用过的，缩容的时候可以直接置空，而且由于申请的内存比较小，同时会释放掉一些已经使用的内存，不会增大系统的压力。 rehash 过程如下图 步骤如下： 为 ht[1] 分配空间，让字典同时持有 ht[0] 和 hy[1] 两个 hashtabe 定时维持一个索引计数器变量 rehashidx ，并将它的值设置为 0 ，表示 rehash 开始 在 rehash 进行期间，每次对字典执行 CRUD 操作时，程序除了执行指定的操作以外，还会将 ht[0] 中的数据 rehash 迁移到 ht[1] 表中，并且将 rehashidx 加 1 当 ht[0] 中所有数据转移到 ht[1] 中时，将 rehashidx 设置成- 1 ，表示 rehash 结束 将 ht[0] 释放，然后将 ht[1] 设置成 ht[0] ，最后为 ht[1] 分配一个空白哈希表 ","date":"2022-12-31","objectID":"/redis-data-teype/:5:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" skiplistskiplist 是与 dict 结合来使用的，结构体如下 /* * 跳跃表 */ typedef struct zskiplist { // 头节点，尾节点 struct zskiplistNode *header, *tail; // 节点数量 unsigned long length; // 目前表内节点的最大层数 int level; } zskiplist; /* * 跳跃表节点 */ typedef struct zskiplistNode { // member 对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 这个层跨越的节点数量 unsigned int span; } level[]; } zskiplistNode; 如下图 header: 指向跳跃表的表头节点，通过这个指针程序定位表头节点的时间复杂度就为 O(1) tail: 指向跳跃表的表尾节点,通过这个指针程序定位表尾节点的时间复杂度就为 O(1) level: 记录目前跳跃表内,层数最大的那个节点的层数(表头节点的层数不计算在内)，通过这个属性可以在 O(1) 的时间复杂度内获取层高最好的节点的层数 length: 记录跳跃表的长度,也即是,跳跃表目前包含节点的数量(表头节点不计算在内)，通过这个属性，程序可以在 O(1) 的时间复杂度内返回跳跃表的长度 Ln: 节点中用 L1 、 L2 、 L3 等字样标记节点的各个层, L1 代表第一层, L2 代表第二层,以此类推。每次创建一个新跳跃表节点的时候,程序都根据幂次定律( powerlaw ,越大的数出现的概率越小)随机生成一个介于 1 和 32 之间的值作为 level 数组的大小,这个大小就是层的高度。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点,而跨度则记录了前进指针所指向节点和当前节点的距离(跨度越大、距离越远)。在上图中,连线上带有数字的箭头就代表前进指针,而那个数字就是跨度。当程序从表头向表尾进行遍历时,访问会沿着层的前进指针进行。 后退(backward)指针: 节点中用 BW 字样标记节点的后退指针,它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。与前进指针所不同的是每个节点只有一个后退指针，因此每次只能后退一个节点。 分值( score ): 各个节点中的 1.0 、 2.0 和 3.0 是节点所保存的分值。在跳跃表中,节点按各自所保存的分值从小到大排列。多个节点保存的分值却可以是相同的:分值相同的节点将按照成员对象在字典序中的大小来进行排序,成员对象较小的节点会排在前面(靠近表头的方向),而成员对象较大的节点则会排在后面(靠近表尾的方向)。 成员对象( oj ): 各个节点中的 o1 、 o2 和 o3 是节点所保存的成员对象。在同一个跳跃表中,各个节点保存的成员对象必须是唯一的 数据类型","date":"2022-12-31","objectID":"/redis-data-teype/:6:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" string 类型Redis 字符串存储字节序列，包括文本、序列化对象和二进制数组。因此，字符串是最基本的 Redis 数据类型。通常用于缓存，但也支持其他功能，这些功能也可能实现计数器并执行按位运算。默认情况下，单个 Redis 字符串的最大大小为 512 MB。 string 类型的底层数据结构转换顺序： 当值为整数且值的大小不超过long的范围，使用int编码 当字符串长度不超过44字节时，使用EMBSTR 编码 分配空间 - redisObject占用空间 - sdshdr8占用空间 redisObject：type + encoding + lru + refcount + *ptr=16字节 sdshdr8：1（uint8_t） + 1（uint8_t）+ 1 （unsigned char）+ 1（buf[]中结尾的'\\0'字符）= 4字节 64-16-4=44 字节 在 3.2 版本之前存储 embstr 需要 8 字节，因此 3.2 版本之前只有 39 字节 大于44字节时，使用raw编码 embstr与raw都使用redisObject和sds保存数据，区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。因此与raw相比，embstr的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。而embstr的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，因此redis中的embstr实现为只读。在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象不管是否超过44字节一定是raw的 103.106.246.17:6973\u003e SET key1 hello OK 103.106.246.17:6973\u003e OBJECT ENCODING key1 \"embstr\" 103.106.246.17:6973\u003e APPEND key1 ' world' (integer) 11 103.106.246.17:6973\u003e OBJECT ENCODING key1 \"raw\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 创建字符串类型 key SET key value [NX | XX] [GET] [EX seconds | PX milliseconds | EXAT unix-time-seconds | PXAT unix-time-milliseconds | KEEPTTL] 可用版本: 1.0.0 时间复杂度: O(1) ACL 分类: @write, @string, @slow # 从 2.6.12 开始加入以下选项 - EX # 设置 key 有效时间 seconds (秒) - PX # 设置 key 有效时间 milliseconds (毫秒) - NX # 当 key 不存在时才创建。从 7.0.0 版本开始可以与 GET 选项同时使用 - XX # 当 key 存在时才创建 # 从 6.0.0 开始加入以下选项 - KEEPTTL # 保留 key 的有效时间 # 从 6.2.0 开始加入以下选项 - GET # 同时返回旧的值，如果没有旧的值，则返回(nil) 从 7.0.0 版本开始可以与 GET 选项同时使用 - EXAT # 设置 key 有效 Unix 时间。单位为秒 - PXAT # 设置 key 有效 Unix 时间。单位为豪秒 该指令有以下返回值： ok：SET 命令执行成功 nil: NX 或 XX 条件不满足。或 GET 没有旧的值 字符串: GET 选项返回旧的值 如果 key 已经存在则替换 103.106.246.17:6973\u003e SET key1 1 OK 103.106.246.17:6973\u003e SET key1 2 OK 103.106.246.17:6973\u003e GET key1 \"2\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:1","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 创建多个字符串类型的 key MSET key value [key value ...] 可用版本: 1.0.1 时间复杂度: O(N) # N 为 key 的数量 ACL 分类: @write, @string, @slow 如果 key 已经存在则替换。操作是原子的，即所有的 key 都是一次设置。客户端无法查看哪些 key 是修改，哪些是新建 redis\u003e MSET key1 \"Hello\" key2 \"World\" \"OK\" redis\u003e GET key1 \"Hello\" redis\u003e GET key2 \"World\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:2","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 新建多个字符串类型的 key MSETNX key value [key value ...] 可用版本: 1.0.1 时间复杂度: O(N) # N 为 key 的数量 ACL 分类: @write, @string, @slow 只能新建字符串类型的 key ，如果 key 已存在则忽略 103.106.246.17:6973\u003e MGET keya keyb keyc 1) (nil) 2) (nil) 3) (nil) 103.106.246.17:6973\u003e MSETNX keya 1 keyb 2 keyc 3 (integer) 1 103.106.246.17:6973\u003e MSETNX keya a keyb b keyc c (integer) 0 103.106.246.17:6973\u003e MGET keya keyb keyc 1) \"1\" 2) \"2\" 3) \"3\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:3","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 获取字符串的长度 STRLEN key 可用版本: 2.2.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 返回存储在键的字符串值的长度。如果键保存非字符串值时返回错误；key 不存在时返回 0 redis\u003e SET mykey \"Hello world\" \"OK\" redis\u003e STRLEN mykey (integer) 11 redis\u003e STRLEN nonexisting (integer) 0 ","date":"2022-12-31","objectID":"/redis-data-teype/:7:4","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 获取字符串类型的值 GET key 可用版本: 1.0.0 时间复杂度: O(1) ACL 分类: @read, @string, @fast 该指令有以下返回值： nil: 指定的 key 不存在 err: 指定的 key 不是字符串类型 字符串: 指定的字符串类型 key 的值 ","date":"2022-12-31","objectID":"/redis-data-teype/:7:5","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 获取多个字符串类型的值 MGET key [key ...] 可用版本: 1.0.0 时间复杂度: O(N) # N 为 key 的数量 ACL 分类: @read, @string, @fast 同时查看多个字符串类型的值 redis\u003e SET key1 \"Hello\" \"OK\" redis\u003e SET key2 \"World\" \"OK\" redis\u003e MGET key1 key2 nonexisting 1) \"Hello\" 2) \"World\" 3) (nil) ","date":"2022-12-31","objectID":"/redis-data-teype/:7:6","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 获取字符串类型的值后删除 key GETDEL key 可用版本: 6.2.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 返回字符串类型的值后删除 key 103.106.246.17:6973\u003e SET key1 1 OK 103.106.246.17:6973\u003e GETDEL key1 \"1\" 103.106.246.17:6973\u003e GET key1 (nil) 103.106.246.17:6973\u003e GETDEL key1 (nil) ","date":"2022-12-31","objectID":"/redis-data-teype/:7:7","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 获取字符串类型的值后设置 key 的有效期 GETEX key [EX seconds | PX milliseconds | EXAT unix-time-seconds | PXAT unix-time-milliseconds | PERSIST] 可用版本: 6.2.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 有以下选项 - EX # 设置 key 有效时间 seconds (秒) - PX # 设置 key 有效时间 milliseconds (毫秒) - EXAT # 设置 key 有效 Unix 时间。单位为秒 - PXAT # 设置 key 有效 Unix 时间。单位为豪秒 - PERSIST # 删除为 key 设置的有效期 获取字符串类型的值后可以设置 key 的有效期 103.106.246.17:6973\u003e GETEX key1 EX 20 (nil) 103.106.246.17:6973\u003e GET key1 (nil) 103.106.246.17:6973\u003e SET key1 1 OK 103.106.246.17:6973\u003e GETEX key1 EX 20 \"1\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:8","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 获取字符串的子串 GETRANGE key start end 可用版本: 2.4.0 时间复杂度: O(N) # N 为返回字符串的长度 ACL 分类: @read, @string, @slow 根据下标获取字符串的子串 redis\u003e SET mykey \"This is a string\" \"OK\" redis\u003e GETRANGE mykey 0 3 \"This\" redis\u003e GETRANGE mykey -3 -1 \"ing\" redis\u003e GETRANGE mykey 0 -1 \"This is a string\" redis\u003e GETRANGE mykey 10 100 \"string\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:9","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 追加字符串 APPEND key value 可用版本: 2.0.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 如果 key 已存在并且是字符串，则此命令会将值追加到字符串的末尾。如果 key 不存在，则会将其创建并设置为空字符串再追加 103.106.246.17:6973\u003e GET key2 (nil) 103.106.246.17:6973\u003e APPEND key2 'heloo' (integer) 5 103.106.246.17:6973\u003e GET key2 \"heloo\" 103.106.246.17:6973\u003e APPEND key2 'heloo' (integer) 10 103.106.246.17:6973\u003e GET key2 \"helooheloo\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:10","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 整数减一 DECR key 可用版本: 1.0.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 把字符串类型值减一（范围： 64 位有符号整数）。如果 key 不存在则会将其创建并设置为 0 再减一。如果 key 不是字符串类型或值超过 64 位有符号整数范围则返回错误 103.106.246.17:6973\u003e GET key3 (nil) 103.106.246.17:6973\u003e DECR key3 (integer) -1 103.106.246.17:6973\u003e GET key3 \"-1\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:11","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 整数做减法 DECRBY key decrement 可用版本: 1.0.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 把字符串类型做减法（范围： 64 位有符号整数）。如果 key 不存在则会将其创建并设置为 0 再做减法。如果 key 不是字符串类型或值超过 64 位有符号整数范围则返回错误 103.106.246.17:6973\u003e GET decrby (nil) 103.106.246.17:6973\u003e DECRBY decrby 99 (integer) -99 103.106.246.17:6973\u003e GET decrby \"-99\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:12","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 整数加一 INCR key 可用版本: 1.0.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 把字符串类型值加一（范围： 64 位有符号整数）。如果 key 不存在则会将其创建并设置为 0 再加一。如果 key 不是字符串类型或值超过 64 位有符号整数范围则返回错误 redis\u003e SET mykey \"10\" \"OK\" redis\u003e INCR mykey (integer) 11 redis\u003e GET mykey \"11\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:13","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 整数做加法 INCRBY key increment 可用版本: 1.0.0 时间复杂度: O(1) ACL 分类: @write, @string, @fast 把字符串类型做加法（范围： 64 位有符号整数）。如果 key 不存在则会将其创建并设置为 0 再做加法。如果 key 不是字符串类型或值超过 64 位有符号整数范围则返回错误 103.106.246.17:6973\u003e SET mykey \"10\" OK 103.106.246.17:6973\u003e INCRBY mykey 5 (integer) 15 103.106.246.17:6973\u003e GET mykey \"15\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:14","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 浮点数加法与减法运算 INCRBYFLOAT key increment 时间复杂度: O(1) ACL 分类: @write, @string, @fast 把浮点数做加法或减法运算，如果 key 不存在则会将其创建并设置为 0 再做加法或减法。如果 key 不是字符串类型或值超过 64 位有符号整数范围则返回错误。输出的精度固定在小数点后 17 位。 103.106.246.17:6973\u003e SET mykey 11.11 OK 103.106.246.17:6973\u003e INCRBYFLOAT mykey 22.33 \"33.44\" 103.106.246.17:6973\u003e INCRBYFLOAT mykey -0.4 \"33.04\" 103.106.246.17:6973\u003e GET mykey \"33.04\" redis\u003e SET mykey 5.0e3 \"OK\" redis\u003e INCRBYFLOAT mykey 2.0e2 \"5200\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:15","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 获取两个字符串类型的公共子序列 LCS key1 key2 [LEN] [IDX] [MINMATCHLEN len] [WITHMATCHLEN] 可用版本: 7.0.0 时间复杂度: O(N*M) # N 表示 key1 值的长度，M 表示 key2 值的长度，* 表示乘法 ACL 分类: @read, @string, @slow 有以下可选项 - LEN # 只获取总长度 - IDX # 显示其中公共子字串的位置 - MINMATCHLEN # 指定最小长度的公共子串，与 IDX 选项使用才有实际效果 - WITHMATCHLEN # 分别统计公共子字串长度，与 IDX 选项使用才有实际效果 简单说就是对比两个字符串共同使用的子字串，判断2个字符串的相似度 103.106.246.17:6973\u003e MSET key1 ohmytext key2 mynewtext OK # 公共子字串其实分别为 my 与 text , redis 没加分隔符 103.106.246.17:6973\u003e LCS key1 key2 \"mytext\" 103.106.246.17:6973\u003e LCS key1 key2 LEN (integer) 6 # 匹配方式从后往前，因此先匹配 text 再匹配 my 103.106.246.17:6973\u003e LCS key1 key2 IDX 1) \"matches\" # 第二列表示对比组，1) 表示最后一组相同的公共子串，2) 表示倒数第二组 # 第三列表示 key 的顺序，1) 表示第一个 key , 2) 表示第二个 key # 第四列与最后的值： 1) 表示公共子串的起始下标，2) 表示结束下标 2) 1) 1) 1) (integer) 4 2) (integer) 7 # 结合上下文表示 key1 从下标4到7，即 text 2) 1) (integer) 5 # 结合上下文表示 key2 从下标5到8，即 text 2) (integer) 8 2) 1) 1) (integer) 2 # 第二对比组 2) (integer) 3 # 结合上下文表示 key1 从下标2到3，即 my 2) 1) (integer) 0 # 结合上下文表示 key2 从下标0到1，即 my 2) (integer) 1 3) \"len\" 4) (integer) 6 103.106.246.17:6973\u003e LCS key1 key2 IDX MINMATCHLEN 3 1) \"matches\" 2) 1) 1) 1) (integer) 4 2) (integer) 7 2) 1) (integer) 5 2) (integer) 8 3) \"len\" 4) (integer) 6 103.106.246.17:6973\u003e LCS key1 key2 WITHMATCHLEN IDX MINMATCHLEN 3 1) \"matches\" 2) 1) 1) 1) (integer) 4 2) (integer) 7 2) 1) (integer) 5 2) (integer) 8 3) (integer) 4 3) \"len\" 4) (integer) 6 ","date":"2022-12-31","objectID":"/redis-data-teype/:7:16","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" 修改字符串的中子串 SETRANGE key offset value 可用版本: 2.2.0 时间复杂度: O(M) # M 为参数长度 ACL 分类: @write, @string, @slow 从指定下标开始修改子串，如果下标值超过字符串长度则以零值填充；如果 key 不存在则先创建。 103.106.246.17:6973\u003e SET key1 \"Hello World\" OK 103.106.246.17:6973\u003e SETRANGE key1 6 \"Redis\" (integer) 11 103.106.246.17:6973\u003e GET key1 \"Hello Redis\" 103.106.246.17:6973\u003e GET key2 (nil) 103.106.246.17:6973\u003e SETRANGE key2 6 \"Redis\" (integer) 11 # \\x00 为16进制，表示 Null 103.106.246.17:6973\u003e GET key2 \"\\x00\\x00\\x00\\x00\\x00\\x00Redis\" ","date":"2022-12-31","objectID":"/redis-data-teype/:7:17","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" list 类型在 reids 3.2 版本之前 list 底层实现方式为：压缩列表(ziplist)或双向循环链表(linkedlist)。从 redis 3.2 版本开始 list 底层实现方式为 quicklist。它是一个基于 ziplist 的双向链表，quicklist 每个节点都是一个 ziplist。结合了双向链表和 ziplist 的优点 当list同时满足以下条件时使用 ziplist 存储数据： list 中保存的每个元素长度小于 64 字节 list 中数据个数少于 512个 ","date":"2022-12-31","objectID":"/redis-data-teype/:8:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" hash 类型hash 满足以下条件时使用 ziplist 存储数据，随着数据的增加，底层的 ziplist 就可能会转成 dict 每个元素的长度小于 64 字节。可以使用 hash-max-ziplist-entries 配置项修改 元素个数少于 512 个。可以使用 hash-max-ziplist-value 配置项修改 ","date":"2022-12-31","objectID":"/redis-data-teype/:9:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" set 类型redis set（集合）的 key/value 是无序的、唯一的。内部实现相当于一个特殊的字典，字典所有的 value 都是一个值 NULL。 当存储数据满足以下所有条件时，redis 使用 intset 结构，否则使用 hashtable 结构存储 存储的数据都是整数 存储的元素个数小于 512 个 ","date":"2022-12-31","objectID":"/redis-data-teype/:10:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" zset 类型zset （有序集合）保留了 set （集合）不能有重复成员的特性，但不同的是，有序集合中的元素是可以排序的，但是它和列表的使用索引下标作为排序依据不同的是，它给每个元素设置一个分数，作为排序的依据。 zet 的底层编码有两种数据结构，一个 ziplist ，一个是 skiplist 。当zset同时满足以下条件时使用 ziplist 存储数据： 每个元素的长度小于 64 字节 元素个数少于 512 个 error","date":"2022-12-31","objectID":"/redis-data-teype/:11:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["redis"],"content":" (error) DENIED Redis is running in protected [root@localhost redis]# redis-cli -h 103.106.246.17 -p 6973 103.106.246.17:6973\u003e SET key1 hello (error) DENIED Redis is running in protected mode because protected mode is enabled and no password is set for the default user. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a an authentication password for the default user. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside. 根据提示有以下方法 protected-mode 配置项修改值为 no 为默认用户设置身份验证密码 [root@localhost redis]# grep '^requirepass' redis.conf requirepass 123456 ","date":"2022-12-31","objectID":"/redis-data-teype/:12:0","tags":["redis","数据类型"],"title":"redis数据类型","uri":"/redis-data-teype/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： 廖雪峰：3分钟安装配置Postfix邮件服务器 Postfix配置通过远程SMTP服务器发送邮件 所以怎样：503 5.5.1 Error: authentication not enabled postfix官方文档 Debian 管理员手册：邮件服务器 Red Hat Enterprise Linux 9 产品文档：部署邮件服务器 https://docs.gitlab.cn/jh/administration/reply_by_email_postfix_setup.html https://docs.gitlab.cn/omnibus/settings/smtp.html https://docs.gitlab.cn/jh/administration/incoming_email.html 安装","date":"2022-12-28","objectID":"/postfix/:0:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" yum 安装默认是有的，如果没有使用以下命令安装 下载源码 [root@localhost etc]# yum install -y postfix Loaded plugins: fastestmirror [root@localhost ~]# tar zxf postfix-3.7.2.tar.gz [root@localhost ~]# cd postfix-3.7.2/ ","date":"2022-12-28","objectID":"/postfix/:1:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 源码安装 [root@localhost ~]# wget http://mirror.postfix.jp/postfix-release/official/postfix-3.7.2.tar.gz 地址类 http://www.postfix.org/ADDRESS_CLASS_README.html Postfix 2.0 版引入了地址类的概念。这是一种按收件人地址的递送方法对收件人地址进行分组的方法，决定接受哪些邮件以及如何发送邮件的方式（域可理解为邮地址@后面域名部分）。 默认域类，代表授权客户将邮件转发到互联网 邮件传送传输由 default_transport 配置项指定（默认值为smtp） 更多信息参考：Postfix基本配置 本地域类：最终传递传统UNIX系统帐户和传统Sendmail风格的别名，通常是：user@localhost.localdomain（这里user特指系统用户名）。 域名由mydestination 配置项指定，当inet_interfaces 配置项或proxy_interfaces 配置项时，邮件形式包含user@[ipaddress] 允许收件从由local_recipient_maps 配置项指定（默认值为local:$myhostname），如果为空，则接受所有本地域类地址 邮件传送传输由local_transport 配置项指定，由local代理交付 中继域类，将邮件发送到其它邮件服务端 域名由relay_domains 配置项指定 允许收件人由relay_recipient_maps 配置项指定，如果值为空，则只接受由relay_domains 配置项列出的域做为收件人。 邮件传送传输由relay_transport 配置项指定 更多信息参考：Postfix基本配置。 虚拟邮箱域类 虚拟别名域类 基础配置大至分为以下步骤 接收哪些IP地址的邮件，接收哪些邮件域？ 允许哪些邮件域通过什么方式发送到哪里去 # 接收客户端IP列表有以下方式。选其中一个 mynetworks_style = class # 指定网络接口 mynetworks_style = subnet # IP class A/B/C mynetworks_style = host # 当前主机 mynetworks = 127.0.0.0/8 168.100.189.2/32 # 指定客户端IP列表 # 接收邮件域，以空格为分隔 mydestination= $myhostname localhost.$mydomain localhost $mydomain # 允许发送的邮件域 relay_domains = $mydestination # 出站时使用的域名 myorigin = notify.xiaosi.host # 方式到哪里去 relayhost = # 为空表示直接发送到目标，可以指定到其它中继服务器地址 配置项配置目录为 /etc/postfix/，其中 main.cf 作为进程配置文件。可以使用 postconf 命令修改配置，也可以直接编辑配置文件 myhostname = smtp.xiaosi.host mydomain = xiaosi.host myhostname 参数指定主机名，在配置文件中它的值可以被 $myhostname 引用。mydomain 参数指定主机名。可以被 $mydomain 引用 myorigin = $mydomain 发件地址 mydestination = $myhostname, localhost.$mydomain, localhost 收件地址 inet_interfaces = localhost inet_protocols = all # 其它可选值有 IPv4、IPv6 默认只监听本地， # 出站使用的域名，即发件人地址或代发件人地址 # 它不是强制的，可以被邮箱中 FORM 覆盖 myorigin = gitlab.xiaosi.host # 接收邮件的域名，值可以有多个，用逗号分开 mydestination = gitlab.xiaosi.host, localhost.localdomain, localhost # 发送中继的客户端网段，即哪些网段可以发送邮件 mynetworks = 103.106.246.103/24, 127.0.0.0/8 # 禁止中继 relay_domains = # 间接或直接发送，取决于网络环境，如果是内网，则要指定中继（SMTP） # 为空表示直接发送 relayhost = # 监听地址，可以是网卡接口 inet_interfaces = localhost, 103.106.246.103 # IP 协议 # 其它可选值有 IPv4、IPv6、all # Enable IPv4, and IPv6 if supported inet_protocols = ipv4 # 邮件服务器使用的域 mydomain = gitlab.xiaosi.host sendmail 可以直接使用 -r xxx@xxx.xxx 参数来以任意源地址发送邮件，但目前主流的邮箱都会将源地址和反向解析 IP 进行比较，如果解析不到或是解析的 IP 不匹配，轻则将邮件直接归为垃圾邮件，严重的就直接拒绝接收。 测试 [root@localhost ~]# cat mail.txt From:note管理员 \u003cnote@xiaosi.host\u003e To:3023465141@qq.com Subject: 这是标题 这是内容 [root@localhost ~]# cat mail.txt | sendmail 3023465141@qq.com SMTP 服务端配置修改配置文件：/etc/postfix/main.cf 以下是基础配置 # 邮件服务器主机名，影响邮件头部和 SMTP 问候消息 # 也就是说，也是 SMTP 地址，并不是邮件域 [root@localhost ~]# postconf -e 'myhostname = mail-cow.xiaosi.host' [root@localhost ~]# # 邮件服务器监听地址 [root@localhost ~]# postconf -e 'inet_interfaces = $myhostname, localhost' [root@localhost ~]# # 邮件服务器监听IP地址类型 # 值有：ipv4, ipv6, all [root@localhost ~]# postconf -e 'inet_protocols = ipv4' [root@localhost ~]# # 允许以下客户端地址连接 [root@localhost ~]# postconf -e 'mynetworks = $myhostname' [root@localhost ~]# # 允许发送的邮件域 [root@localhost ~]# postconf -e 'relay_domains = notify.xiaosi.host' ","date":"2022-12-28","objectID":"/postfix/:2:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 基于客户端地址限制smtpd_client_restrictions有以下值： permit_mynetworks: 允许mynetworks 网络列表地址连接 reject_unknown_client_hostname: 拒绝IP无法反向解析DNS的域名，有部分邮件服务器无法满足，因此可以使用 warn_if_reject 修饰符改为警告而不是直接拒绝 check_client_access: 根据网络地址文件的策略决定，是hash 表 reject_rhsbl_reverse_client: 指定一个域名，如果域名A记录解析出的IP地址在黑名单上则拒绝。黑名单列表由rbl_reply_map配置项定义，该参数可以使用多个 reject_rbl_client: 指定一个域名，如果域名在黑名单上，则拒绝。黑名单列表由rbl_reply_maps配置项定义，该参数可以使用多少 ","date":"2022-12-28","objectID":"/postfix/:3:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 基于 EHLO 或 HELO 命令的合法性在配置之前使用配置（smtpd_helo_required = yes）强制客户端使用 HELO 或 EHLO smtpd_helo_restrictions 指令检查 EHLO 或 HELO 命令的合法性： permit_mynetworks: 允许mynetworks 网络列表地址连接 reject_invalid_helo_hostname: 当HELO或EHLO主机名语法错误时拒绝请求 reject_non_fqdn_helo_hostname: 当HELO或EHLO主机名不是RFC要求的完全限定域或地址文字形式时，拒绝请求 reject_unknown_helo_hostname: 当HELO或EHLO主机名没有DNS A或MX记录时，拒绝请求 check_helo_access: 值为hash 表，如果匹配HELO或EHLO中域名，则拒绝 reject_rhsbl_helo: 指定一个域名，如果HELO的域名A记录在黑名单中，则拒绝 ","date":"2022-12-28","objectID":"/postfix/:4:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 基于FORM做限制smtpd_sender_restrictions 限制发件人，有以下参数 check_sender_access: 值为hash 表文件，该文件定义的规则表决定允许还是拒绝 reject_unknown_sender_domain： FORM域名满足以下条件之一则拒绝： DNS无法解析出A记录和MAX记录 MAX记录不正常，如MAX长度为0 reject_unlisted_sender: 拒绝满足以下条件之一的邮件域 不是virtual 配置项定义别名 不是canonical配置项定义的映射 不是postfix 地址类 reject_non_fqdn_sender：拒绝非全限定域名（FQDN）地址 reject_rhsbl_sender: 如果发件域DNS A记录解析出的IP地址在黑名单上则拒绝。黑名单列表由rbl_reply_map配置项定义，该参数可以使用多个 permit： 允许所有发送方地址发送邮件，没有限制。 reject： 拒绝所有发送方地址发送邮件，没有例外。 check_sender_mx_access： 检查发送方地址的 MX 记录，以确定是否允许发送邮件。 check_sender_ns_access： 检查发送方地址的 NS 记录，以确定是否允许发送邮件。 check_sender_domain_access： 检查发送方地址的域名是否在访问控制列表中。 reject_authenticated_sender_login_mismatch： 拒绝发送方地址与已验证的登录不匹配的邮件。 reject_sender_login_mismatch： 拒绝发送方地址与登录不匹配的邮件。 permit_sasl_authenticated： 仅允许经过 SASL 验证的用户发送邮件。 reject_unauthenticated_sender_login_mismatch： 拒绝未验证的发送方地址与登录不匹配的邮件。 ","date":"2022-12-28","objectID":"/postfix/:5:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 基于RCPT TO地址限制垃圾邮件smtpd_recipient_restrictions 可以对收件地址检查： reject_unauth_destination: 拒绝想向不服务的地址发送，需要满足以下条件之一 Postfix is a mail forwarder: the resolved RCPT TO domain matches $relay_domains or a subdomain thereof, and contains no sender-specified routing (user@elsewhere@domain), Postfix is the final destination: the resolved RCPT TO domain matches $mydestination, $inet_interfaces, $proxy_interfaces, $virtual_alias_domains, or $virtual_mailbox_domains, and contains no sender-specified routing (user@elsewhere@domain). reject_unlisted_recipient: 拒绝将消息发送给不存在的本地用户 reject_non_fqdn_recipient: 规则拒绝非完全合格的地址 permit: 允许 ","date":"2022-12-28","objectID":"/postfix/:6:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 基于RCPT TO地址判断中继在Postfix 2.10之前中继权限判断是由smtpd_recipient_restrictions配置项指定，此后由smtpd_relay_restrictions指定，部分以下值： permit_mynetworks: 允许mynetworks 网络列表地址连接 permit_sasl_authenticated: 允许经过 SASL 验证的用户发送邮件 defer_unauth_destination: 满意以下条件之一则请允许 目标地址匹配relay_domains配置项（如果发件人指定的域除外，如user@elsewhere@domain） 目标地址匹配$inet_interfaces,$proxy_interfaces, $mydestination, $virtual_alias_domains, $virtual_mailbox_domains ","date":"2022-12-28","objectID":"/postfix/:7:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 对 DATA 部分限制 smtpd_data_restrictions = reject_unauth_pipelining ","date":"2022-12-28","objectID":"/postfix/:8:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 基于内容的筛选 header_checks = regexp:/etc/postfix/header_checks body_checks = regexp:/etc/postfix/body_checks ","date":"2022-12-28","objectID":"/postfix/:9:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" 灰名单使用外部程序判断 smtpd_recipient_restrictions = permit_mynetworks, [...] check_policy_service inet:127.0.0.1:10023 ","date":"2022-12-28","objectID":"/postfix/:10:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" SASL 身份验证 https://www.postfix.org/SASL_README.html 可以使用以下命令查看哪些SASL实现被编译集成Postfix # SMTP server [root@localhost ~]# postconf -A cyrus # SMTP+LMTP client [root@localhost ~]# postconf -a cyrus dovecot 连接到 dovecot 启用SASL: smtpd_sasl_auth_enable = yes 指定使用身份认证系统：smtpd_sasl_type = dovecot 连接到身份认证系统： # 通过 UNIX-domain socket 连接 smtpd_sasl_path = private/auth # 通TCP连接 smtpd_sasl_path = inet:127.0.0.1:12345 ","date":"2022-12-28","objectID":"/postfix/:11:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" cyrus sasldb 存储用户密码 安装 [root@localhost ~]# yum install -y cyrus-sasl-* Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile epel/x86_64/metalink ... 配置SASL认证 ### sasldb2建立smtp用户和密码 # 创建用户，用户必须指定username@example.com 为登录名，而不是username。 [root@localhost ~]# saslpasswd2 -c -u notify.xiaosi.host prometheus Password: Again (for verification): [root@localhost ~]# gFAFPdIQpFhoWh9HYYJHIV # 查看用户列表 [root@localhost ~]# sasldblistusers2 prometheus@notify.xiaosi.host: userPassword # 删除用户 # [root@localhost ~]# saslpasswd2 -d prometheus@notify.xiaosi.host 修改smtpd.conf文件 [root@localhost ~]# cat /etc/sasl2/smtpd.conf Pwcheck_method: auxprop Auxprop_plugin: sasldb Mech_list: PLAIN LOGIN CRAM-MD5 DIGEST-MD5 NTLM 修改 /etc/postfix/main.cf 文件 [root@localhost ~]# cat /etc/postfix/main.cf ###################################################SASL ## 启用身份认证 smtpd_sasl_auth_enable = yes ## 身份认证方式 ##smtpd_sasl_type = dovecot smtpd_sasl_type = cyrus ## 是否支持像outlook、foxmail等非标准协议认证 broken_sasl_auth_clients = yes ## 不支持匿名 smtpd_sasl_security_options = noanonymous ## 使用 Cyrus SASL 的服务器组件 smtpd_sasl_path = smtpd cyrus_sasl_config_path=/etc/sasl2/ ## 是否强制使用TLS连接到身份认证服务 ##smtpd_tls_auth_only = yes # 限制只允许经过身份认证才能转发邮件 smtpd_relay_restrictions = # permit_mynetworks, permit_sasl_authenticated, defer_unauth_destination ","date":"2022-12-28","objectID":"/postfix/:11:1","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" Postfix TLS https://www.postfix.org/TLS_README.html SMTP 客户端Postfix SMTP/LMTP client是一种用于发送电子邮件的客户端程序，会连接到其它SMTPD 服务器 # 发件人邮件地址 邮件账号:邮件密码 [root@localhost postfix]# echo 'test@notify.xiaosi.host prometheus@notify.xiaosi.host:gFAFPdIQpFhoWh9HYYJHIVAs' \u003e sasl_passwd [root@localhost postfix]# postmap sasl_passwd # 发件人邮件地址 SMTP 服务器地址 [root@localhost postfix]# echo 'test@notify.xiaosi.host [mail-notify.xiaosi.host]:25' \u003e sender_relay [root@localhost postfix]# postmap sender_relay /etc/postfix/main.cf: smtp_sasl_auth_enable = yes smtp_tls_security_level = encrypt smtp_sasl_tls_security_options = noanonymous relayhost = [mail.isp.example] # Alternative form: # relayhost = [mail.isp.example]:submission smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd 747 #smtp_sender_dependent_authentication = yes 748 #smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd 749 #sender_dependent_relayhost_maps = hash:/etc/postfix/sender_relay 命令行工具postfix check 检查配置文档 postfix 连接到 dovecotDovecot 是一个高性能邮件发送代理(MDA)，专注于安全性。您可以使用 IMAP 或 POP3 兼容电子邮件客户端连接到 Dovecot 服务器，并读取或下载电子邮件。 安装 [root@localhost ~]# yum install postfix dovecot -y 创建用户用于接收电子邮件 [root@localhost ~]# mkdir -p /data/mail [root@localhost ~]# useradd --home-dir /data/mail/ --shell /usr/sbin/nologin vmail 如果家目录不是/var/mail/，则修改SELinux 安全上下文 semanage fcontext -a -t mail_spool_t \"\u003cpath\u003e(/.*)?\" restorecon -Rv \u003cpath\u003e 修改家目录权限 [root@localhost ~]# chown vmail:vmail /data/mail/ [root@localhost ~]# chmod 700 /data/mail/ 修改/etc/dovecot/conf.d/10-mail.conf文件以下配置 # 保存邮件格式 mail_location = sdbox:/data/mail/%n/ # 可以验证到 Dovecot 的最低用户 ID (UID) first_valid_uid = 1000 修改 /etc/dovecot/conf.d/auth-system.conf.ext # System users (NSS, /etc/passwd, or similiar). In many systems nowadays this # uses Name Service Switch, which is configured in /etc/nsswitch.conf. userdb { # \u003cdoc/wiki/AuthDatabase.Passwd.txt\u003e driver = passwd # 用户信息 override_fields = uid=vmail gid=vmail home=/data/mail/ # [blocking=no] #args = # Override fields from passwd #override_fields = home=/home/virtual/%u } 编辑/etc/dovecot/conf.d/10-master.conf service auth { # 指定运行postfix进程用户信息 unix_listener auth-userdb { mode = 0666 user = postfix group = postfix } # Postfix unix socket unix_listener /var/spool/postfix/private/auth { mode = 0666 } # Auth process is run as this user. #user = $default_internal_user } 编辑/etc/dovecot/conf.d/10-auth.conf auth_mechanisms = plain login 启用服务并开机启动 [root@localhost ~]# systemctl enable --now dovecot Created symlink from /etc/systemd/system/multi-user.target.wants/dovecot.service to /usr/lib/systemd/system/dovecot.service. [root@localhost ~]# [root@localhost ~]# systemctl status dovecot ● dovecot.service - Dovecot IMAP/POP3 email server Loaded: loaded (/usr/lib/systemd/system/dovecot.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2024-02-15 00:43:09 CST; 12s ago Docs: man:dovecot(1) http://wiki2.dovecot.org/ ... 修改/etc/postfix/main.cf # 指定 dovecot smtpd_sasl_type = dovecot # 指定连接地址 smtpd_sasl_path = /var/spool/postfix/private/auth # 是否强制使用TLS连接到身份认证服务 smtpd_tls_auth_only = yes # 限制只允许经过身份认证才能转发邮件 smtpd_relay_restrictions = permit_mynetworks, permit_sasl_authenticated, defer_unauth_destination 重新载入 postfix 服务以应用更改 并测试 error","date":"2022-12-28","objectID":"/postfix/:12:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" smtp-server: 503 5.5.1 Error: authentication not enabled [root@localhost ~]# echo \"test\" | mail -s \"主题\" 3023465141@qq.com [root@localhost ~]# smtp-server: 503 5.5.1 Error: authentication not enabled \"/root/dead.letter\" 11/304 . . . message not sent. ^C 解决方法： [root@localhost postfix]# postconf -e 'smtpd_sasl_auth_enable = yes' [root@localhost postfix]# postfix check \u0026\u0026 systemctl restart postfix ; ss -lantpd | grep master tcp LISTEN 0 100 103.106.246.17:587 *:* users:((\"master\",pid=8839,fd=14)) tcp LISTEN 0 100 127.0.0.1:587 *:* users:((\"master\",pid=8839,fd=13)) 原因：main.cf 配置文件没有启动身份验证 ","date":"2022-12-28","objectID":"/postfix/:13:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" no SASL authentication mechanisms [root@localhost ~]# tail -n 30 /var/log/maillog Dec 29 10:49:33 localhost postfix/smtpd[11171]: error: open database /etc/postfix/recipient_access.db: No such file or directory Dec 29 10:49:33 localhost postfix/smtpd[11171]: connect from unknown[103.106.246.17] Dec 29 10:49:33 localhost postfix/smtpd[11171]: warning: SASL authentication failure: Internal Error -4 in server.c near line 1757 Dec 29 10:49:33 localhost postfix/smtpd[11171]: warning: SASL authentication failure: Internal Error -4 in server.c near line 1757 Dec 29 10:49:33 localhost postfix/smtpd[11171]: warning: SASL authentication failure: Internal Error -4 in server.c near line 1757 Dec 29 10:49:33 localhost postfix/smtpd[11171]: warning: xsasl_cyrus_server_get_mechanism_list: no mechanism available Dec 29 10:49:33 localhost postfix/smtpd[11171]: fatal: no SASL authentication mechanisms Dec 29 10:49:34 localhost postfix/master[11077]: warning: process /usr/libexec/postfix/smtpd pid 11171 exit status 1 Dec 29 10:49:34 localhost postfix/master[11077]: warning: /usr/libexec/postfix/smtpd: bad command startup -- throttling 解决方法 [root@localhost ~]# yum install cyrus-sasl-plain -y ","date":"2022-12-28","objectID":"/postfix/:14:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" NOQUEUE: reject: RCPT from … Relay access denied使用 smtp 时邮件发送不出去，出现以下提示 Dec 30 10:15:03 localhost postfix/smtpd[8642]: connect from 172-11-1-11.lightspeed.jcvlfl.sbcglobal.net[172.11.1.11] Dec 30 10:15:04 localhost postfix/smtpd[8642]: NOQUEUE: reject: RCPT from 172-11-1-11.lightspeed.jcvlfl.sbcglobal.net[172.11.1.11]: 454 4.7.1 \u003cxq4096@163.com\u003e: Relay access denied; from=\u003cxiaosi@xiaosi.host\u003e to=\u003cxq4096@163.com\u003e proto=ESMTP helo=\u003clocalhost\u003e Dec 30 10:15:04 localhost postfix/smtpd[8642]: disconnect from 172-11-1-11.lightspeed.jcvlfl.sbcglobal.net[172.11.1.11] 出现原因：发件地址没有在 smtp 中过白明单 解决方法：修改规则，使其能使用 smtp 发送邮件 # 172.11.1.0/24 是机器内部 IP，就直接加入 mynetworks 中 mynetworks = 103.106.246.17 172.11.1.0/24 smtpd_relay_restrictions = permit_mynetworks,permit_sasl_authenticated,defer_unauth_destination ","date":"2022-12-28","objectID":"/postfix/:15:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["linux"],"content":" smtp-server: 503 5.5.1 Error: authentication not enabled [root@localhost ~]# smtp-server: 503 5.5.1 Error: authentication not enabled \"/root/dead.letter\" 11/306 . . . message not sent. ^C ","date":"2022-12-28","objectID":"/postfix/:16:0","tags":["linux","mail"],"title":"postfix","uri":"/postfix/"},{"categories":["容器"],"content":" ","date":"2022-12-26","objectID":"/docker-network/","tags":["docker","linux","网络"],"title":"docker网络","uri":"/docker-network/"},{"categories":["容器"],"content":" 运行环境： docker-ce: 20.10 内容来自以下文档： docker 官方文档：网络概述 docker 网络驱动程序Docker 的网络子系统是可插拔的，使用驱动程序。几个驱动程序 默认存在，并提供核心网络功能： bridge: 默认网络驱动程序。如果未指定驱动程序，则为 您正在创建的网络类型。桥接网络通常用于以下情况 您的应用程序在需要通信的独立容器中运行。 host: 对于独立容器，直接使用主机的网络。 overlay: 覆盖网络将多个 Docker 守护进程连接在一起，并且使群服务能够相互通信。 ipvlan: IPvlan 网络使用户能够完全控制 IPv4 和 IPv6 寻址 macvlan: 为容器分配 MAC 地址，使其显示为网络上的物理设备。 none: 对于此容器，禁用所有网络。 除了官方默认自带的网络驱动程序，可以添加第三方网络驱动程度 管理网络使用 docker network 管理网络 ","date":"2022-12-26","objectID":"/docker-network/:0:0","tags":["docker","linux","网络"],"title":"docker网络","uri":"/docker-network/"},{"categories":["容器"],"content":" 创建网络 docker network create [OPTIONS] NETWORK Options --driver , -d # 指定网络驱动程序，默认为 bridge --subnet # 指定网段 ","date":"2022-12-26","objectID":"/docker-network/:1:0","tags":["docker","linux","网络"],"title":"docker网络","uri":"/docker-network/"},{"categories":["linux"],"content":" ","date":"2022-12-25","objectID":"/lvm/","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 运行环境： lvm: 2 内容来自以下文档： 百度百科: LVM 扩展逻辑分区","date":"2022-12-25","objectID":"/lvm/:0:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 查看现有磁盘 [root@xiaosi ~]# ls /dev/sd sda sda1 sda2 sdb ","date":"2022-12-25","objectID":"/lvm/:1:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 创建物理卷 [root@xiaosi ~]# pvcreate /dev/sdb WARNING: xfs signature detected on /dev/sdb at offset 0. Wipe it? [y/n]: y Wiping xfs signature on /dev/sdb. Physical volume \"/dev/sdb\" successfully created. ","date":"2022-12-25","objectID":"/lvm/:2:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 查看创建的物理卷 [root@xiaosi ~]# pvdisplay --- Physical volume --- PV Name /dev/sda2 VG Name centos_xiaosi PV Size \u003c39.00 GiB / not usable 3.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 9983 Free PE 1 Allocated PE 9982 PV UUID Vw1WQS-lT7o-P59j-1cmC-pTUF-s89r-moSsgI \"/dev/sdb\" is a new physical volume of \"10.00 GiB\" --- NEW Physical volume --- PV Name /dev/sdb VG Name PV Size 10.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID R3hP7K-bAOR-TnMg-W1iT-5UuW-jzsy-uWk1x5 ","date":"2022-12-25","objectID":"/lvm/:3:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 查看现有卷组 [root@xiaosi ~]# vgdisplay --- Volume group --- VG Name centos_xiaosi System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c39.00 GiB PE Size 4.00 MiB Total PE 9983 Alloc PE / Size 9982 / 38.99 GiB Free PE / Size 1 / 4.00 MiB VG UUID Yd1smr-6TaB-Xye2-F11m-4WQP-BOj9-DEepuJ ","date":"2022-12-25","objectID":"/lvm/:4:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 将新建的物理卷添加到卷组 [root@xiaosi ~]# vgextend centos_xiaosi /dev/sdb Volume group \"centos_xiaosi\" successfully extended [root@xiaosi ~]# vgdisplay --- Volume group --- VG Name centos_xiaosi System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 48.99 GiB PE Size 4.00 MiB Total PE 12542 Alloc PE / Size 9982 / 38.99 GiB Free PE / Size 2560 / 10.00 GiB VG UUID Yd1smr-6TaB-Xye2-F11m-4WQP-BOj9-DEepuJ ","date":"2022-12-25","objectID":"/lvm/:5:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 扩展逻辑卷 [root@xiaosi ~]# lvextend -l +100%FREE /dev/mapper/centos_xiaosi- centos_xiaosi-root centos_xiaosi-swap [root@xiaosi ~]# lvextend -l +100%FREE /dev/mapper/centos_xiaosi-root Size of logical volume centos_xiaosi/root changed from \u003c35.12 GiB (8990 extents) to \u003c45.12 GiB (11550 extents). Logical volume centos_xiaosi/root successfully resized. ","date":"2022-12-25","objectID":"/lvm/:6:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 扩展 xfs 文件系统 [root@xiaosi ~]# xfs_growfs /dev/mapper/centos_xiaosi-root meta-data=/dev/mapper/centos_xiaosi-root isize=512 agcount=4, agsize=2301440 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=9205760, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=4495, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 9205760 to 11827200 ","date":"2022-12-25","objectID":"/lvm/:7:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["linux"],"content":" 检验 [root@xiaosi ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/mapper/centos_xiaosi-root xfs 46G 1004M 45G 3% / devtmpfs devtmpfs 1.9G 0 1.9G 0% /dev tmpfs tmpfs 1.9G 0 1.9G 0% /dev/shm tmpfs tmpfs 1.9G 12M 1.9G 1% /run tmpfs tmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup /dev/sda1 xfs 1014M 146M 869M 15% /boot tmpfs tmpfs 378M 0 378M 0% /run/user/0 挂载旧的lvm 查看vg id [root@localhost ~]# vgdisplay --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c222.57 GiB PE Size 4.00 MiB Total PE 56977 Alloc PE / Size 56976 / 222.56 GiB Free PE / Size 1 / 4.00 MiB VG UUID vLM4Iq-jnpK-LSlw-Jzmo-WF8y-SORg-X914OK --- Volume group --- VG Name centos System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 6 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size \u003c222.57 GiB PE Size 4.00 MiB Total PE 56977 Alloc PE / Size 56977 / \u003c222.57 GiB Free PE / Size 0 / 0 VG UUID EqO9L7-5zzD-00Zg-yc7W-2GjY-3CC4-lrbXHk [root@localhost ~]# 重命令一个vg [root@localhost ~]# vgrename EqO9L7-5zzD-00Zg-yc7W-2GjY-3CC4-lrbXHk centos-1 Processing VG centos because of matching UUID EqO9L7-5zzD-00Zg-yc7W-2GjY-3CC4-lrbXHk Volume group \"EqO9L7-5zzD-00Zg-yc7W-2GjY-3CC4-lrbXHk\" successfully renamed to \"centos-1\" [root@localhost ~]# [root@localhost ~]# lvscan ACTIVE '/dev/centos/root' [214.81 GiB] inherit ACTIVE '/dev/centos/swap' [7.75 GiB] inherit inactive '/dev/centos-1/swap' [7.75 GiB] inherit inactive '/dev/centos-1/root' [\u003c214.82 GiB] inherit [root@localhost ~]# [root@localhost ~]# [root@localhost ~]# lvdisplay --- Logical volume --- LV Path /dev/centos/root LV Name root VG Name centos LV UUID Xmdgbc-M2ZL-oxdW-Z97f-uCwL-gSAG-Rrfymi LV Write Access read/write LV Creation host, time localhost, 2023-12-11 21:46:15 +0800 LV Status available # open 1 LV Size 214.81 GiB Current LE 54992 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:0 --- Logical volume --- LV Path /dev/centos/swap LV Name swap VG Name centos LV UUID jV5m9f-gYxT-N5ev-CcCw-Kzi4-p6wt-df7AKR LV Write Access read/write LV Creation host, time localhost, 2023-12-11 21:46:16 +0800 LV Status available # open 2 LV Size 7.75 GiB Current LE 1984 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:1 --- Logical volume --- LV Path /dev/centos-1/swap LV Name swap VG Name centos-1 LV UUID hcTlpv-aJiu-lVrN-u1PQ-VXXH-i7SS-Mnk5H2 LV Write Access read/write LV Creation host, time localhost, 2023-11-14 13:33:04 +0800 LV Status NOT available LV Size 7.75 GiB Current LE 1984 Segments 1 Allocation inherit Read ahead sectors auto --- Logical volume --- LV Path /dev/centos-1/root LV Name root VG Name centos-1 LV UUID RwHnYR-FbsX-4mQH-s7Ns-POrK-V2of-YixC42 LV Write Access read/write LV Creation host, time localhost, 2023-11-14 13:33:05 +0800 LV Status NOT available LV Size \u003c214.82 GiB Current LE 54993 Segments 2 Allocation inherit Read ahead sectors auto 激活 [root@localhost ~]# vgchange -ay /dev/centos-1 2 logical volume(s) in volume group \"centos-1\" now active [root@localhost ~]# [root@localhost ~]# lvdisplay --- Logical volume --- LV Path /dev/centos/root LV Name root VG Name centos LV UUID Xmdgbc-M2ZL-oxdW-Z97f-uCwL-gSAG-Rrfymi LV Write Access read/write LV Creation host, time localhost, 2023-12-11 21:46:15 +0800 LV Status available # open 1 LV Size 214.81 GiB Current LE 54992 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:0 --- Logical volume --- LV Path /dev/centos/swap LV Name swap VG Name centos LV UUID jV5m9f-gYxT-N5ev-CcCw-Kzi4-p6wt-df7AKR LV Write Access read/write LV Creation host, time localhost, 2023-12-11 21:46:16 +0800 LV Status available # open 2 LV Size 7.75 GiB Current LE 1984 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 253:1 --- Logica","date":"2022-12-25","objectID":"/lvm/:8:0","tags":["lvm"],"title":"逻辑卷管理器","uri":"/lvm/"},{"categories":["nginx"],"content":" ","date":"2022-12-19","objectID":"/nginxLog/","tags":["日志","nginx"],"title":"nginx日志","uri":"/nginxLog/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.23.0 内容来自以下文档： 陶辉：nginx 核心知识100讲 赵安家: nginx日志中$request_body 十六进制字符(x22x9Bx5Cx09x08…)完美解决方案 访问日志访问日志记录由 ngx_http_log_module 模块提供 # 处于处理HTTP请求的第11个（LOG）阶段 log_format name [escape=default|json|none] string ...; 配置域：http 默认值：combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $status $bytes_sent ' '\"$http_referer\" \"$http_user_agent\" \"$gzip_ratio\"' 该指令指定 access_log 指令记录格式，格式必须在引用之前定义。可以多次使用该指令配置多个格式 # 处于处理HTTP请求的第11个（LOG）阶段 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 默认值：logs/access.log combined; 配置域：http，server，location，if in location，limit_except 该指令指定记录访问日志位置。可以在同一配置级别指定多个日志。有以下参数： path 代指保存路径，可以包含变量 buffer 指定缓存空间大小，默认为 64k。超过时将定入磁盘 gzip 指定压缩内存中的日志级别，减少缓存空间占用。默认压缩级别为1（1-9，级别越大压缩率越高但压缩越慢）。该功能依赖于 zlib 库 flush 指定日志缓存时间。超时将写入磁盘 if 用于满足指定条件才写入磁盘 off 表示不记录访问日志 此外，worker 进程正在被关闭或执行 reopen 命令时也会把日志写入文件 示例 # 日志压缩级别为 1，每隔1分钟或超过缓存空间限值时写入磁盘 access_log logs/note.xiaosi.host.nginx.access.log note gzip flush=1m; # 处于处理HTTP请求的第11个（LOG）阶段 open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 默认值：off 配置域：http，server，location 该指令配置缓存日志文件句柄。当没用开启时每次记录日志都需要打开和关闭日志文件。有以下参数： max 指定缓存数量，如果缓存数量已满，则使用淘汰关闭最近最少（LRU）使用的文件句柄 inactive 指定缓存时间，默认为 10s min_uses 指定在 inactive 时间内活跃次数。默认为 1 小于该值时将关闭文件句柄 valid 指定检测缓存时间间隔。默认为 60s off 关闭该功能 示例 # 缓存 3 个日志文件句柄，10秒内没有写入1次日志将关闭该文件句柄 open_log_file_cache max=3 ; ","date":"2022-12-19","objectID":"/nginxLog/:0:0","tags":["日志","nginx"],"title":"nginx日志","uri":"/nginxLog/"},{"categories":["nginx"],"content":" 日志格式该日志记录了客户端与服务端基本信息 log_format note escape=json '{' '\"responseTime\": \"$time_iso8601\",' '\"requestIP\": \"$remote_addr\",' '\"requestPort\": \"$remote_port\",' '\"requestScheme\": \"$scheme\",' '\"requestProtocol\": \"$server_protocol\",' '\"requestMethod\": \"$request_method\",' '\"requestDomainName\": \"$host\",' '\"requestUri\": \"$request_uri\",' '\"responseUrl\": \"$uri\",' '\"responseIP\": \"$server_addr\",' '\"responseport\": \"$server_port\",' '\"responseStatus\": \"$status\",' \"\\\"responseSize\\\": \" \"\\\"$bytes_sent\" \"B\\\",\" \"\\\"responseBodySize\\\": \" \"\\\"$body_bytes_sent\" \"B\\\",\" \"\\\"processingConsumeTime\\\": \" \"\\\"$request_time\" \"s\\\",\" '\"processingStatus\": \"$request_completion\"' '}'; 输出结果 {\"responseTime\": \"2022-12-19T16:19:48+08:00\",\"requestIP\": \"40.77.167.8\",\"requestPort\": \"49024\",\"requestScheme\": \"https\",\"requestProtocol\": \"HTTP/1.1\",\"requestMethod\": \"GET\",\"requestDomainName\": \"103.106.246.17\",\"requestUri\": \"/categories/windows\",\"responseUrl\": \"/categories/windows\",\"responseIP\": \"103.106.246.17\",\"responseport\": \"443\",\"responseStatus\": \"301\",\"responseSize\": \"456B\",\"responseBodySize\": \"169B\",\"processingConsumeTime\": \"0.000s\",\"processingStatus\": \"OK\"} 常用正则 # 查看访问 IP grep -oPh '(?\u003c=\"requestIP\": \")([0-9]{1,3}\\.){3}[0-9]{1,3}' ","date":"2022-12-19","objectID":"/nginxLog/:1:0","tags":["日志","nginx"],"title":"nginx日志","uri":"/nginxLog/"},{"categories":["nginx"],"content":" 访问日志中文变成16进制 http { ... log_format access1 '$remote_addr:$remote_port \u003e $uri ' \"$status $connection $request_time\" \"s \" \"$time_iso8601 $request_completion\"; ... [root@localhost nginx]# cat logs/8023.FixIt.nginx.access.log 119.123.151.155:13621 \u003e /posts/k8s/k8s\\xE5\\x9E\\x83\\xE5\\x9C\\xBE\\xE6\\x94\\xB6\\xE9\\x9B\\x86/index.html 200 228 0.000s 2022-07-26T04:19:36+08:00 OK 以josn格式记录，可以绕过 [root@localhost nginx]# cat conf/nginx.conf ... http { log_format access1 escape=json '$remote_addr:$remote_port \u003e $uri ' \"$status $connection $request_time\" \"s \" \"$time_iso8601 $request_completion\"; ... [root@localhost nginx]# cat logs/8023.FixIt.nginx.access.log 119.123.151.155:13621 \u003e /posts/k8s/k8s\\xE5\\x9E\\x83\\xE5\\x9C\\xBE\\xE6\\x94\\xB6\\xE9\\x9B\\x86/index.html 200 228 0.000s 2022-07-26T04:19:36+08:00 OK 119.123.151.155:15380 \u003e /posts/k8s/k8s控制器/index.html 200 232 0.000s 2022-07-26T04:27:15+08:00 OK 错误日志 error_log file [level]; 默认值：logs/error.log error; 配置域：main, http, mail, stream, server, location 该指令指定错误日志与记录级别，可以在同一配置级别上指定多个 errir_log。记录级别由高到低为：debug, info, notice, warn, error, crit, alert, emerg。级别越高优先级越大，记录也越详细。debug 级别需要 nginx 编译时指定 --with-debug 选项 日志切割 定义脚本 #!/bin/bash # 按日期切割nginx日志 # centos:7 # 时间变量 date=$(date +%F -d 'yesterday') # 源日志文件目录变量 log_file=$(ls /usr/local/nginx/logs/*.log) # 备份目录变量 backup_dir=\"/data/nginx/logs\" # 创建备份目录 if [[ ! -d ${backup_dir} ]]; then mkdir -p ${backup_dir} fi # 备份日志文件 for i in ${log_file}; do # 排除空日志文件 if [[ -s ${i} ]]; then mv ${i} ${backup_dir}/${date}-${i##*/} fi done # 日志切割，可以使用 nginx -s reopen kill -USR1 $(cat /usr/local/nginx/logs/nginx.pid) 定义定时任务 # 每天23:59:59秒执行 [root@localhost ~]# grep 'nginx' /etc/crontab 59 23 * * * root sleep 59; bash /data/download/nginx_logs_day.sh ","date":"2022-12-19","objectID":"/nginxLog/:2:0","tags":["日志","nginx"],"title":"nginx日志","uri":"/nginxLog/"},{"categories":["linux"],"content":" ","date":"2022-12-17","objectID":"/linux-disk/","tags":["linux","磁盘管理"],"title":"linux系统中磁盘管理","uri":"/linux-disk/"},{"categories":["linux"],"content":" 运行环境： centos: 7 kernel: 5.4.227 内容来自以下文档： linux内核文档：I/O 统计信息字段 wshenJin：/proc/diskstats 文件内容记录 proc 文件以下 /proc 文件可查看磁盘文件 /proc/diskstats: 此文件包含每个磁盘设备的磁盘 I/O 统计信息 /sys/block/*/stat : 此文件包含指定磁盘（*）设备的磁盘 I/O 统计信息 ","date":"2022-12-17","objectID":"/linux-disk/:0:0","tags":["linux","磁盘管理"],"title":"linux系统中磁盘管理","uri":"/linux-disk/"},{"categories":["linux"],"content":" 磁盘I/O磁盘 I/O 信息可以从以下文件获取 /proc/diskstats: 此文件包含每个磁盘设备的磁盘 I/O 统计信息 /sys/block/*/stat : 此文件包含指定磁盘（*）设备的磁盘 I/O 统计信息 /proc/diskstats 文件比 /sys/block/*/stat 多了三个字段。从左至右分别对应主设备号，次设备号和设备名称。 [root@localhost hugo]# cat /proc/diskstats | column -t 202 0 xvda 22206 41 985763 62090 145665 17906 3643071 371719 0 146840 361102 0 0 0 0 202 1 xvda1 660 0 13182 408 519 0 4120 156 0 390 297 0 0 0 0 202 2 xvda2 21494 41 969493 61561 130046 17906 3638951 365444 0 146141 356438 0 0 0 0 202 16 xvdb 3444 7 233055 29457 4280 467 122794 13100 0 9846 39035 0 0 0 0 202 17 xvdb1 3391 7 229959 29292 4267 467 122794 13099 0 9787 38898 0 0 0 0 253 0 dm-0 13069 0 961109 13712 143305 0 3859453 360743 0 142829 374455 0 0 0 0 253 1 dm-1 86 0 4144 27 0 0 0 0 0 27 27 0 0 0 0 [root@localhost hugo]# cat /sys/block/xvda/stat | column -t 22206 41 985763 62090 145665 17906 3643071 371719 0 146840 361102 0 0 0 0 字段信息如下（这些值都是近似值，这是由于磁盘多个分区的I/O、从 kernel v:2.6+ 每个 CPU 都有计数器，避免引入性能瓶颈，并没锁定计数器导致的）： 第一列：从系统启动后成功已完成的读取次数。 第二列：从系统启动后已合并读取完成次数。为了提高效率，合并彼此相邻的读取和写入。 第三列：从系统启动后成功读取扇区总数。 第四列：从系统启动后所有读取花费的时间（毫秒）。 第五列：从系统启动后成功已完成的写入次数。 第六列：从系统启动后已合并写入完成次数。为了提高效率，合并彼此相邻的读取和写入。 第七列：从系统启动后成功写入扇区总数。 第八列：从系统启动后所有写入花费的时间（毫秒）。 第九列：当前正在进行 I/O 数量（队列数量） 第十列：从系统启动后执行所有 I/O 花费的时间（毫秒）。 第十一列：执行 I/O 所花费的毫秒数加权数。此字段在每次 I/O 启动、I/O 完成、I/O 合并或读取这些统计信息时按正在进行的 I/O 数（字段 9）乘以自上次更新此字段以来执行 I/O 所花费的毫秒数。这可以轻松衡量 I/O 完成时间和可能累积的积压工作。 第十二列：从系统启动后成功完成的丢弃总数。 第十三列：同第二例 第十四列：从系统启用后成功丢弃的扇区总数。 第十五列：从系统启用后丢弃所花费的总毫秒数。 iostat 查看磁盘总体信息 # 安装 yum install -y sysstat # -z 省略没有活动的设备 # -y 指定频率显示多少报告时，则省略自系统启动以来的第一个带有统计信息 # -x 显示更多指标 # -N 显示注册 dev ，如 lvm container 注册的 # 1 每隔 1 秒频率显示，直到手动结束进程 [root@localhost ~]# iostat -zyxN 1 Linux 5.4.227-1.el7.elrepo.x86_64 (localhost.localdomain) 02/03/2023 _x86_64_ (4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.25 0.00 0.25 0.00 0.00 99.50 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util xvda 0.00 0.00 0.00 1.00 0.00 4.00 8.00 0.00 0.00 0.00 0.00 1.00 0.10 centos-root 0.00 0.00 0.00 1.00 0.00 4.00 8.00 0.00 0.00 0.00 0.00 1.00 0.10 .... 输出字段说明 %user # 显示用户级别进程 CPU 利用率百分比 %nice %system # 显示内核级别进程 CPU 利用率百分比 %iowait # CPU 等待磁盘 IO 反馈时间比 %steal # 虚机等待 CPU 资源的时间(虚机分到的是虚拟 CPU，当需要真实的 CPU 时，可能真实的 CPU 正在运行其它虚机的任务，所以需要等待)。 %idle # CPU 空闲比 Device # 设备名 tps # 每秒发送到设备的 I/O 请求数。多个逻辑请求可以组合成对设备的单个 I/O 请求。 Blk_read (kB_read, MB_read) # 读取的块的总数 Blk_wrtn (kB_wrtn, MB_wrtn) # 写入的块的总数 rrqm/s # 每秒合并到设备的读取请求数 wrqm/s # 每秒合并到设备的写入请求数。 r/s # 设备每秒完成的读请求数(合并后) w/s # 设备每秒完成的写请求数(合并后) Blk_read/s (kB_read/s, MB_read/s) # 每秒读取的磁盘块的大小 Blk_wrtn/s (kB_wrtn/s, MB_wrtn/s) # 每秒写入的磁盘块的大小 rsec/s (rkB/s, rMB/s) # 每秒从设备读取的扇区数（千字节、兆字节） wsec/s (wkB/s, wMB/s) # 每秒写入设备的扇区数（千字节、兆字节） avgrq-sz # 向设备发出的请求的平均大小（以扇区为单位）。 avgqu-sz # 向设备发出的请求的平均队列长度 await # 向要处理的设备发出的 I/O 请求的平均时间（以毫秒为单位） # 这包括队列中的请求所花费的时间以及处理这些请求所花费的时间 r_await # 向要处理的设备发出的读取请求的平均时间（以毫秒为单位） # 这包括队列中的请求所花费的时间以及处理这些请求所花费的时间 w_await # 向要处理的设备发出的写入请求的平均时间（以毫秒为单位） # 这包括队列中的请求所花费的时间以及处理这些请求所花费的时间 svctm # 向设备发出的 I/O 请求的平均服务时间（以毫秒为单位）。 # 由于 I/O 统计信息现在是在块级别计算的， # 不知道磁盘驱动程序何时开始处理。因此该字段不可信， # 后续会被删除 %util # 向设备发出 I/O 请求的运行时间百分比(设备的带宽利用率)， # 换句话说就是一秒中有百分之多少的时间用于 I/O 操作。 查看进程或线程磁盘 IO # 安装 yum install -y iotop [root@localhost ~]# iotop -o ... 输出字段说明 # TID : 进程 ID # PRIO : 优先级 # USER : 用户 # DISK READ : 读取 # DISK WRITE : 写入 # SWAPIN : swap交换百分比 # IO\u003e : IO等待所占用百分比 # COMMAND : 进程或线程名 # Total DISK READ : 磁盘总读取量 # Total DISK WRITE : 磁盘总写入量 # Actual DISK READ : 当前读取量 # Actual DISK WRITE : 当前写入量 Total DISK READ : 0.00 B/s | Total DISK WRITE : 0.00 B/s Actual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO\u003e COMMAND 查看磁盘 IO 进度 [root@localhost ~]# yum install -y blktrace 实时查看 xvda I/O 进度 # -d 指定跟踪磁盘 # -o 输出到 - （标准输出） # -i 从 - （标准输入中）读取 [root@localhost ~]# blktrace -d /dev/xvda -o - | blkparse -i - 202,0 0 1 0.000000000 767 A W 3856336 + 8 \u003c- (253,0) 1757136 202,0 0 2 0.000000760 767 A W 4882384 + 8 \u003c- (202,2) 3856336 202,0 0 3 0.000001471 767 Q W 4882384 + 8 [kworker/u8:0] 202,0 0 4 0.000014815 767 G W 48","date":"2022-12-17","objectID":"/linux-disk/:1:0","tags":["linux","磁盘管理"],"title":"linux系统中磁盘管理","uri":"/linux-disk/"},{"categories":["vim"],"content":" 运行环境： vim: 8 vim: 9 内容来自以下文档： Vim 中文文档计划 vim官方文档英文版 vim官方文档其它语言版本 Willis翻译的中文文档 插入模式以下命令可以在缓冲区插入文本。这些命令可以被撤消，可以被重复 操作指令 说明 a 在光标后附加文本 [count] 次 A 在行尾附加文本 [count] 次，可在可视列块中使用 i 或 \u003cinsert\u003e 在光标前插入文本 [count] 次 I 在本行第一个非空白字符之前插入文本 [count] 次。受 cpoptions 选项影响 gI 在第一列插入文本 [count] 次 gi 在当前缓冲区最近一次插入模式停止的位置继续插入文本。 该位置记在 '^ 位置标记里。如果标记在行末之后，和 `^i 有所差异。 该位置在插入/删除行时会自动修正。但不在插入/删除字符时被修正。使用 keepjumps 命令修饰符时，不改变'^ 位置标记。 o 在光标下方开启新行，并插入文本，重复 [count] 次。受 cpoptions 选项影响 O 在光标上方开启新行，并插入文本，重复 [count] 次。受 cpoptions 选项影响 使用这些命令后进入插入械（可直接插入文本），可以使用 \u003cESC\u003e 退出插入模式。自动缩进配置会影响插入位置 ","date":"2022-12-13","objectID":"/vim-insert/:0:0","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["vim"],"content":" 插入模式中的特殊按键当进入插入模式后以下按键有特殊含义，无法直接插入。想要插入这些字符可以在前面加上 \u003cCtrl+v\u003e 特殊按键 说明 \u003cEsc\u003e 或 \u003cCtrl+[\u003e 结束插入或替换模式，回到普通模式。结束缩写。 \u003cInsert\u003e 在插入和替换模式间切换 \u003cCtrl+v\u003e 如果下一个是非数字，按本义插入。对特殊键而言，插入其终端代码 \u003cCtrl+c\u003e 退出插入模式，回到普通模式。不检查缩写。不激活 InsertLeave 自动命令事件 \u003cCtrl+@\u003e 插入最近插入的文本，并停止插入 \u003cCtrl+a\u003e 插入最近插入的文本 \u003cBackspace\u003e 或 \u003cCtrl+h\u003e 删除光标前的字符 \u003cDelete\u003e 删除光标下的字符。如果光标在行尾。受 backspace 选项影响 \u003cCtrl+w\u003e 删除光标前的单词。 \u003cCtrl+u\u003e 删除当前行上光标前的所有输入字符 \u003cCtrl+i\u003e 或 \u003cTab\u003e 插入制表。受 autoindent 选项影响 \u003cCtrl+j\u003e 或 \u003cCtrl+m\u003e 或 \u003cEnter\u003e 开始新行（换行） \u003cCtrl+k\u003e {char1} [char2] 输入二合字母 \u003cCtrl+r\u003e {register} 插入寄存器内容。在输入 \u003cCtrl+r\u003e 后会显示 \" ，以提示你需要输入寄存器的名字。文本插入方式和直接输入相同，但不使用映射和缩写。 受 textwidth、formatoptions、autoindent 这些选项影响 \u003cCtrl+r\u003e \u003cCtrl+r\u003e {register} 文本按本义插入寄存器内容。特殊字符也会插入 \u003cCtrl+r\u003e \u003cCtrl+o\u003e {register} 按本义插入寄存器内容，并且不进行自动缩进。 \u003cCtrl+r\u003e \u003cCtrl+p\u003e {register} 按本义插入寄存器内容，修正缩进 \u003cCtrl+t\u003e 在当前行开始处插入一个缩进。受 shiftwidth 选项影响 \u003cCtrl+d\u003e 在当前行开始处删除一个缩进。受 shiftwidth 选项影响 0 \u003cCtrl+d\u003e 删除所有当前行的缩进 ^ \u003cCtrl+d\u003e 删除所有当前行的缩进。缩进在下一行上恢复 \u003cCtrl+e\u003e 插入光标下面的字符 \u003cCtrl+y\u003e 插入光标上面的字符 \u003cCtrl+x\u003e \u003cCtrl+e\u003e 窗口滚动上移一行 \u003cCtrl+x\u003e \u003cCtrl+y\u003e 窗口滚动下移一行 ","date":"2022-12-13","objectID":"/vim-insert/:1:0","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["vim"],"content":" 插入模式中移动光标以下按键是特殊的，使用会退出插入模式执行操作后再进入插入模式。 操作 说明 \u003cUp\u003e 光标上移一行 \u003cDown\u003e 光标下移一行 \u003cCtrl+g\u003e k 或 \u003cCtrl+g\u003e \u003cCtrl+k\u003e 或 \u003cCtrl+g\u003e \u003cUp\u003e 光标上移一行，到插入开始时所在的列 \u003cCtrl+g\u003e j 或 \u003cCtrl+g\u003e \u003cCtrl+j\u003e 或 \u003cCtrl+g\u003e \u003cDown\u003e 光标下移一行，到插入开始时所在的列 \u003cLeft\u003e 光标左移一个字符 \u003cRight\u003e 光标右移一个字符 \u003cShitf\u003e+\u003cRight\u003e \u003cShitf\u003e+\u003cRight\u003e 光标正向一个单词 \u003cShitf\u003e+\u003cLeft\u003e \u003cCtrl\u003e+\u003cLeft\u003e 光标反向一个单词 \u003cHome\u003e 光标移到该行首个字符 \u003cEnd\u003e 光标移到该行末个字符之后 \u003cCtrl\u003e+\u003cHome\u003e 光标移到该文件首个字符 \u003cCtrl\u003e+\u003cEnd\u003e 光标移到该文件末尾字符之后 鼠标左键 光标移动鼠标点击处 \u003cPageUp\u003e 或 \u003cShitf\u003e+\u003cUp\u003e 上翻窗口一页 \u003cPageDown\u003e 或 \u003cShift\u003e+Down\u003e 下翻窗口一页 鼠标滚轮向上 窗口向上滚动三行 鼠标滚轮向下 窗口向下滚动三行 \u003cShift\u003e + 鼠标滚轮向上 窗口向上滚动一个整页 \u003cShift\u003e + 鼠标滚轮向下 窗口向下滚动一个整页 \u003cCtrl+o\u003e 执行命令，然后返回到插入模式。 如果光标在行尾之外，它会先被移动该行最后一个字符上。 会忽略进入插入模式命令之前的计数器。如 3i 会等效 i 。 插入模式通常不会嵌套，如 i \u003cCtrl+o\u003e i 再次进入插入模式使用 \u003cEsc\u003e 后立即回到普通模式。但执行映射或执行脚本时，嵌套仍然会发生（这是合理的） \u003cCtrl+\\\u003e \u003cCtrl+o\u003e 执行命令，然后返回到插入模式。基本不会移动光标，除非使用移动光标相关命令 \u003cCtrl+g\u003e u 打断撤销序列，开始新的改变 \u003cCtrl+g\u003e U 只要光标停在同一行，就不会打断撤销序列 ","date":"2022-12-13","objectID":"/vim-insert/:2:0","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["vim"],"content":" 插入模式补全在插入和替换模式下，有若干命令可以补全输入的部分关键字或者行。可以补全以下信息： 整行 字符串 标签 文件名 宏 vim 命令 拼写建议 ","date":"2022-12-13","objectID":"/vim-insert/:3:0","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["vim"],"content":" 整行补全\u003cCtrl+x\u003e \u003cCtrl+l\u003e 反向搜索和当前行光标前字符序列完全相同的行。忽略缩进。反向搜索和当前行光标前字符序列完全相同的行。忽略缩进。complete 选项决定匹配在哪个缓冲区里搜索。当有多个可选结果时使用以下操作选中补全的行： \u003cCtlr+l\u003e 或 \u003cCtrl+p\u003e: 反向搜索前一个匹配行，替换上一次匹配的行。 \u003cCtlr+n\u003e: 正向搜索下一个匹配行，替换上一次匹配的行。 在补全一行以后，可以通过接着输入 \u003cCtrl+x\u003e \u003cCtrl+l\u003e 接着匹配行进行补全 ","date":"2022-12-13","objectID":"/vim-insert/:3:1","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["vim"],"content":" 补全当前文件内的关键字补全列表选择操作： \u003cCtrl+x\u003e \u003cCtrl+N\u003e 正向搜索下一个匹配的关键字，替换上一次匹配的关键字 \u003cCtrl+x\u003e \u003cCtrl+P\u003e 反向搜索前一个匹配的关键字，替换上一次匹配的关键字 在替换模式下，替换的字符数目决定于匹配字符串的长度。 ","date":"2022-12-13","objectID":"/vim-insert/:3:2","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["vim"],"content":" 根据字典文件补全可以通过字典文件进行补全： \u003cCtrl+x\u003e \u003cCtrl+k\u003e: 根据 dictionary 选项指定的字典文件进行补全。当有多个可选结果时可以使用以下操作选择： \u003cCtrl+n\u003e 或 \u003cCtrl+k\u003e: 正向搜索下一个匹配的关键字，替换前次匹配的关键字。 \u003cCtrl+p\u003e: 反向搜索下一个匹配的关键字，替换前次匹配的关键字。 \u003cCtrl+x\u003e \u003cCtrl+t\u003e: 根据 thesaurus 选项指定的字典文件进行补全 \u003cCtrl+n\u003e 或 \u003cCtrl+t\u003e: 正向搜索下一个匹配的关键字，替换前次匹配的关键字。 \u003cCtrl+p\u003e: 反向搜索下一个匹配的关键字，替换前次匹配的关键字。 dictionary 选项默认值为空，逗号分隔的文件名列表。字典文件每行可以有多个关键字，关键字之间使用非关键字字符分隔（如空格），行最大长度为 510 个字节 thesaurus 选项默认值为空，逗号分隔的文件名列表，用于为同义词替换。相同行的关键字视为同义词，即能够进行替换。 ","date":"2022-12-13","objectID":"/vim-insert/:3:3","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["vim"],"content":" 取消补全当使用 \u003cCtrl+x\u003e 后可以使用 \u003cCtrl+z\u003e 退出补全，使用 \u003cCtrl+n\u003e 或 \u003cCtrl+p\u003e 这类选择补全时可以使用 \u003cCtrl+e\u003e 退出补全 ","date":"2022-12-13","objectID":"/vim-insert/:3:4","tags":["插入文本","vim"],"title":"vim中插入文本","uri":"/vim-insert/"},{"categories":["linux","windows"],"content":" ","date":"2022-12-11","objectID":"/mtr/","tags":["mtr","windows","linux"],"title":"mtr使用方法","uri":"/mtr/"},{"categories":["linux","windows"],"content":" 内容来自以下文档： 阿里云帮助文档: MTR工具使用说明与结果分析 mtrMTR工具将ping和traceroute命令的功能并入了同一个工具中，实现更强大的功能。 linux 系统使用 [root@localhost ~]# yum install -y mtr Loaded plugins: fastestmirror Determining fastest mirrors epel/x86_64/metalink ... ","date":"2022-12-11","objectID":"/mtr/:0:0","tags":["mtr","windows","linux"],"title":"mtr使用方法","uri":"/mtr/"},{"categories":["linux","windows"],"content":" 使用帮助 [root@localhost ~]# mtr -h usage: mtr [-BfhvrwctglxspQomniuT46] [--help] [--version] [--report] [--report-wide] [--report-cycles=COUNT] [--curses] [--gtk] [--csv|-C] [--raw] [--xml] [--split] [--mpls] [--no-dns] [--show-ips] [--address interface] [--filename=FILE|-F] [--ipinfo=item_no|-y item_no] [--aslookup|-z] [--psize=bytes/-s bytes] [--order fields] [--report-wide|-w] [--inet] [--inet6] [--max-ttl=NUM] [--first-ttl=NUM] [--bitpattern=NUM] [--tos=NUM] [--udp] [--tcp] [--port=PORT] [--timeout=SECONDS] [--interval=SECONDS] HOSTNAME -h, --help # 显示帮助菜单。 -r, -report # 以报告模式显示输出。 -p, -split # 将每次追踪的结果分别列出来。 -s, -psize # 指定ping数据包的大小。 -n, -no-dns # 不对IP地址做域名反解析。 -a, -address # 设置发送数据包的IP地址。用于主机有多个IP时。 -4： # 只使用IPv4协议。 -6： # 只使用IPv6协议 -n, --no-dns # 不解析主机名 --tcp # 使用 tcp --udp # 使用 udp ","date":"2022-12-11","objectID":"/mtr/:1:0","tags":["mtr","windows","linux"],"title":"mtr使用方法","uri":"/mtr/"},{"categories":["linux","windows"],"content":" 输出说明 My traceroute [v0.85] localhost.localdomain (0.0.0.0) Sun Dec 11 16:48:40 2022 Keys: Help Display mode Restart statistics Order of fields quit Packets Pings Host Loss% Snt Last Avg Best Wrst StDev 1. 103.106.244.3 0.0% 10 0.8 1.4 0.6 5.9 1.5 2. ??? 3. ??? 4. 103.106.248.5 0.0% 9 1.8 1.8 1.6 2.0 0.0 5. 223.118.2.177 0.0% 9 3.6 3.6 1.6 5.1 0.9 6. 223.120.22.106 0.0% 9 27.8 28.1 27.8 28.9 0.0 7. 221.183.89.174 0.0% 9 29.9 30.7 29.7 38.3 2.8 8. 221.183.89.69 0.0% 9 29.2 29.4 29.2 30.3 0.0 9. 221.183.89.46 55.6% 9 30.0 30.2 30.0 30.4 0.0 10. 221.183.37.133 75.0% 9 55.7 55.6 55.4 55.7 0.0 11. ??? 12. 111.13.188.38 0.0% 9 56.2 56.1 55.9 56.6 0.0 13. 39.156.27.1 0.0% 9 55.7 55.9 55.5 57.1 0.4 14. ??? Host: 节点地址，在运行中可使用 n 开启或关闭解析主机名 Loss%: 节点丢包率 Snt: 每秒发送的数据包数量，默认值为 10，可使用 -c 指定 Last: 最近一次的探测延迟值 Avg: 探测延迟平均值 Best: 探测延迟最小值 Wrst: 探测延迟最大值 StDev: 标准偏差。越大说明相应节点越不稳定 windows 中使用 mtrWinMTR 是 windows 版本的 MTR 工具，MTR 工具将 ping 和 traceroute 命令的功能并入了同一个工具中，实现更强大的功能。可以从以下方式获取 BestTrace 中带有 WinMTR 从sourceforge 中下载 从官网 winmtr.net 中获取 ","date":"2022-12-11","objectID":"/mtr/:2:0","tags":["mtr","windows","linux"],"title":"mtr使用方法","uri":"/mtr/"},{"categories":["linux","windows"],"content":" 输出信息 开始与停止：输入目标地址后单击 Start 开始测试，开始测试后，相应按钮变成了 Stop。运行一段时间后，单击 Stop 停止测试 选项说明：点击 Options 可修改以下参数 Interval (sec): 每次探测间隔时间与过期时间。默认为 1 秒 Ping size (bytes): 每次探测所使用的数据包大小。默认为 64 字节 Max hosts in LRU list: LRU 列表支持的最大主机数，默认值为 128 Resolve names: 通过反查IP以域名方式显示相关节点 Exit: 退出 Copy Text to clipboard: 将测试结果以文本格式复制到粘贴板 Copy HTML to clipboard: 将测试结果以 HTML 格式复制到粘贴板 Export TEXT: 将测试结果以文本格式导出到指定文件 Export HTML: 将测试结果以 HTML 格式导出到指定文件 HostName: 节点地址 Nr: 节点编号 Loss%: 节点丢包率 Snt: 每秒发送的数据包数量 Recv: 已成功接收的数据包数量 Best: 探测延迟最小值 Avrg: 探测延迟平均值 Worst: 探测延迟最大值 Last: 最近一次的探测延迟值 StDev: 标准偏差。越大说明相应节点越不稳定 ","date":"2022-12-11","objectID":"/mtr/:3:0","tags":["mtr","windows","linux"],"title":"mtr使用方法","uri":"/mtr/"},{"categories":["linux"],"content":" 网卡激活失败No suitable device found for this connection Failed to start LSB: Bring up/down networking. 详情 [root@master ~]# systemctl status network ● network.service - LSB: Bring up/down networking Loaded: loaded (/etc/rc.d/init.d/network; bad; vendor preset: disabled) Active: failed (Result: exit-code) since Thu 2020-03-19 10:17:37 CST; 5min ago Docs: man:systemd-sysv-generator(8) Process: 870 ExecStart=/etc/rc.d/init.d/network start (code=exited, status=1/FAILURE) Mar 19 10:17:37 master.xiaosi.com systemd[1]: Starting LSB: Bring up/down networking... Mar 19 10:17:37 master.xiaosi.com network[870]: Bringing up loopback interface: [ OK ] Mar 19 10:17:37 master.xiaosi.com network[870]: Bringing up interface ens33: Error: Connection activation failed: No suitable device found for this connection (device lo not available because device is strictly unmanaged). Mar 19 10:17:37 master.xiaosi.com network[870]: [FAILED] Mar 19 10:17:37 master.xiaosi.com systemd[1]: network.service: control process exited, code=exited status=1 Mar 19 10:17:37 master.xiaosi.com systemd[1]: Failed to start LSB: Bring up/down networking. Mar 19 10:17:37 master.xiaosi.com systemd[1]: Unit network.service entered failed state. Mar 19 10:17:37 master.xiaosi.com systemd[1]: network.service failed. ","date":"2022-12-11","objectID":"/linux-error/:0:0","tags":["linux","error"],"title":"linux 使用过程中遇到的错误","uri":"/linux-error/"},{"categories":["linux"],"content":" 解决方法重启 NetworkManager 服务之后再修改该服务 [root@master ~]# systemctl restart NetworkManager ","date":"2022-12-11","objectID":"/linux-error/:1:0","tags":["linux","error"],"title":"linux 使用过程中遇到的错误","uri":"/linux-error/"},{"categories":["linux"],"content":" 原因NetworkManager 服务和 Network 服务配置发送冲突 code=exited, status=203/EXEC 详情 [root@node01 ~]# systemctl status docker.service ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: activating (auto-restart) (Result: exit-code) since Wed 2020-04-29 16:06:29 CST; 990ms ago Docs: https://docs.docker.com Process: 1259 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock (code=exited, status=203/EXEC) Main PID: 1259 (code=exited, status=203/EXEC) Apr 29 16:06:29 node01.xiaosi.com systemd[1]: Failed to start Docker Application Container Engine. Apr 29 16:06:29 node01.xiaosi.com systemd[1]: Unit docker.service entered failed state. Apr 29 16:06:29 node01.xiaosi.com systemd[1]: docker.service failed. 解决方法：从其他地方复制一份 dockerd 命令文件 或重装 dockers服务 原因：命令不存在 [root@node01 ~]# journalctl -xe ... -- Unit docker.service has begun starting up. Apr 29 16:10:01 node01.xiaosi.com systemd[1392]: Failed at step EXEC spawning /usr/bin/dockerd: No such file or directory -- Subject: Process /usr/bin/dockerd could not be executed -- Defined-By: systemd -- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel -- -- The process /usr/bin/dockerd could not be executed and failed. -- -- The error number returned by this process is 2. Apr 29 16:10:01 node01.xiaosi.com systemd[1]: docker.service: main process exited, code=exited, status=203/EXEC Apr 29 16:10:01 node01.xiaosi.com systemd[1]: Failed to start Docker Application Container Engine. -- Subject: Unit docker.service has failed -- Defined-By: systemd -- Support: http://lists.freedesktop.org/mailman/listinfo/systemd-devel ... error while loading shared libraries: libc.so.6: cannot open shared object file: No such file or directory想替换libc库，直接删除软件链接造成的 [root@localhost lib64]# ll /usr/lib64/libc.so.6 lrwxrwxrwx. 1 root root 12 Jun 23 08:52 /usr/lib64/libc.so.6 -\u003e libc-2.17.so [root@localhost lib64]# rm -rf /usr/lib64/libc.so.6 [root@localhost lib64]# ln -s /usr/lib64/libc.so.6 /usr/lib64/libc.musl-x86_64.so.1 ln: error while loading shared libraries: libc.so.6: cannot open shared object file: No such file or directory 解决方法: [root@localhost next]# export LD_PRELOAD=\"/lib64/libc-2.17.so\" [root@localhost next]# ln -s /lib64/libc-2.17.so /lib64/libc.so.6 /lib64/libstdc++.so.6: no version information available [root@localhost ~]# cmake -version cmake: /lib64/libstdc++.so.6: no version information available (required by cmake) cmake: /lib64/libstdc++.so.6: no version information available (required by cmake) cmake: /lib64/libstdc++.so.6: no version information available (required by cmake) cmake: /lib64/libstdc++.so.6: no version information available (required by cmake) cmake: /lib64/libstdc++.so.6: no version information available (required by cmake) [root@localhost lib64]# ll libstdc++.so.6* lrwxrwxrwx. 1 root root 19 Jul 4 22:03 libstdc++.so.6 -\u003e libstdc++.so.6.0.29 -rwxr-xr-x. 1 root root 995840 Sep 30 2020 libstdc++.so.6.0.19 -rwxr-xr-x. 1 root root 1915480 Jul 4 21:18 libstdc++.so.6.0.29 [root@localhost lib64]# strings libstdc++.so.6.0.29 | grep GLIBC GLIBCXX_FORCE_NEW GLIBCXX_DEBUG_MESSAGE_LENGTH [root@localhost lib64]# strings libstdc++.so.6.0.19 | grep GLIBC GLIBCXX_FORCE_NEW GLIBCXX_DEBUG_MESSAGE_LENGTH # 重新安装libstdc [root@localhost lib64]# libgcc libstdc++ libstdc++-devel [root@localhost lib64]# strings libstdc++.so.6.0.19 | grep GLIBC GLIBCXX_3.4 GLIBCXX_3.4.1 GLIBCXX_3.4.2 .... [root@localhost lib64]# rm -rf libstdc++.so.6 [root@localhost lib64]# ln -s libstdc++.so.6.0.19 libstdc++.so.6 [root@localhost lib64]# rm -rf libstdc++.so.6.0.29 ","date":"2022-12-11","objectID":"/linux-error/:2:0","tags":["linux","error"],"title":"linux 使用过程中遇到的错误","uri":"/linux-error/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： [name][url] [url]: perf 命令 # Listing all currently known events: perf list # Listing sched tracepoints: perf list 'sched:*' # Listing sched tracepoints (older syntax): perf list -e 'sched:*' # CPU counter statistics for the specified command: perf stat command # Detailed CPU counter statistics (includes extras) for the specified command: perf stat -d command # CPU counter statistics for the specified PID, until Ctrl-C: perf stat -p PID # CPU counter statistics for the entire system, for 5 seconds: perf stat -a sleep 5 # Various basic CPU statistics, system wide, for 10 seconds: perf stat -e cycles,instructions,cache-references,cache-misses,bus-cycles -a sleep 10 # Various CPU level 1 data cache statistics for the specified command: perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores command # Various CPU data TLB statistics for the specified command: perf stat -e dTLB-loads,dTLB-load-misses,dTLB-prefetch-misses command # Various CPU last level cache statistics for the specified command: perf stat -e LLC-loads,LLC-load-misses,LLC-stores,LLC-prefetches command # Using raw PMC counters, eg, unhalted core cycles: perf stat -e r003c -a sleep 5 # Count system calls for the specified PID, until Ctrl-C: perf stat -e 'syscalls:sys_enter_*' -p PID # Count system calls for the entire system, for 5 seconds: perf stat -e 'syscalls:sys_enter_*' -a sleep 5 # Count scheduler events for the specified PID, until Ctrl-C: perf stat -e 'sched:*' -p PID # Count scheduler events for the specified PID, for 10 seconds: perf stat -e 'sched:*' -p PID sleep 10 # Count ext4 events for the entire system, for 10 seconds: perf stat -e 'ext4:*' -a sleep 10 # Count block device I/O events for the entire system, for 10 seconds: perf stat -e 'block:*' -a sleep 10 # Show system calls by process, refreshing every 2 seconds: perf top -e raw_syscalls:sys_enter -ns comm # Sample on-CPU functions for the specified command, at 99 Hertz: perf record -F 99 command # Sample on-CPU functions for the specified PID, at 99 Hertz, until Ctrl-C: perf record -F 99 -p PID # Sample on-CPU functions for the specified PID, at 99 Hertz, for 10 seconds: perf record -F 99 -p PID sleep 10 # Sample CPU stack traces for the specified PID, at 99 Hertz, for 10 seconds: perf record -F 99 -p PID -g -- sleep 10 # Sample CPU stack traces for the PID, using dwarf to unwind stacks, at 99 Hertz, for 10 seconds: perf record -F 99 -p PID -g dwarf sleep 10 # Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds: perf record -F 99 -ag -- sleep 10 # If the previous command didn't work, try forcing perf to use the cpu-clock event: perf record -F 99 -e cpu-clock -ag -- sleep 10 # Sample CPU stack traces for the entire system, with dwarf stacks, at 99 Hertz, for 10 seconds: perf record -F 99 -ag dwarf sleep 10 # Sample CPU stack traces, once every 10,000 Level 1 data cache misses, for 5 seconds: perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5 # Sample CPU stack traces, once every 100 last level cache misses, for 5 seconds: perf record -e LLC-load-misses -c 100 -ag -- sleep 5 # Sample on-CPU kernel instructions, for 5 seconds: perf record -e cycles:k -a -- sleep 5 # Sample on-CPU user instructions, for 5 seconds: perf record -e cycles:u -a -- sleep 5 # Sample on-CPU instructions precisely (using PEBS), for 5 seconds: perf record -e cycles:p -a -- sleep 5 # Perform branch tracing (needs HW support), for 1 second: perf record -b -a sleep 1 # Trace new processes, until Ctrl-C: perf record -e sched:sched_process_exec -a # Trace all context-switches, until Ctrl-C: perf record -e context-switches -a # Trace all context-switches with stack traces, until Ctrl-C: perf record -e context-switches -ag # Trace all context-switches with stack traces, for 10 seconds: perf record -e context-switches -ag -- sleep 10 # Trace CPU migrations, for 10 seconds: perf record -e migrations -a -- sleep 10 # Trace all connect()s with stack traces (outbound c","date":"2022-12-11","objectID":"/perf/:0:0","tags":["命令","linux"],"title":"perf命令","uri":"/perf/"},{"categories":["linux"],"content":" 运行环境： centos: 7 安装相关的软件包避免出现编译出错，无法编译，升级之后无法使用等情况 [root@master ~]# yum install -y zlib* readline* gcc* libffi-devel 从Python官网下载python3.7.3的安装包 [root@master ~]# wget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz 解压安装 [root@master ~]# tar xf Python-3.7.3.tgz [root@master ~]# cd Python-3.7.3 [root@master Python-3.7.3]# mkdir /usr/local/python3.7.3 [root@master Python-3.7.3]# ./configure --prefix=/usr/local/python3.7.3 [root@master Python-3.7.3]# make [root@master Python-3.7.3]# make install 创建软连接 [root@master Python-3.7.3]# mv /usr/bin/python /usr/bin/python_2.7.5 [root@master Python-3.7.3]# ln -s /usr/local/python3.7.3/bin/python3.7 /usr/bin/python [root@master Python-3.7.3]# python -V Python 3.7.3 还原到原版本 [root@master ~]# mv /usr/bin/python /usr/bin/python_3.7 [root@master ~]# mv /usr/bin/python_2.7.5 /usr/bin/python [root@master ~]# python -V Python 2.7.5 解决升级之后python之后yum无法使用问题将 /usr/bin/yum 和 /usr/libexec/urlgrabber-ext-down 这2个文件的第一行指向 /usr/bin/python_2.7.5 ","date":"2022-12-11","objectID":"/updatePython/:0:0","tags":["python"],"title":"更新与降级 python","uri":"/updatePython/"},{"categories":["linux"],"content":" 批量修改文件名称rename 可以替换指定文件名称中的字符串 格式：rename 替换之前字符串 替换之后字符串 文件名称 示例：将 centos 替换为 centos7 centos7-升级与降级python.md centos-firewalld.md centos-samba.md centos-开机流程.md centos-正则表达式.md centos7-扩展根分区.md centos-ftp.md centos-sed.md centos-快捷键.md centos-环境变量.md centos7-配置ss客户端.md centos-grep.md centos-ssh.md centos-文件系统层次结构.md centos-用户和组.md centos-awk.md centos-iptables.md centos-vim.md centos-日志.md centos-磁盘管理.md centos-bash特性.md centos-nfs.md centos-压缩打包.md centos-时间任务.md centos-网络配置.md centos-curl.md centos-pxe.md centos-命令使用帮助.md centos-时间服务.md centos-访问控制.md centos-dhcp.md centos-rpm包管理.md centos-命令历史.md centos-服务管理.md centos-进程管理.md centos-find.md centos-rsync.md centos-基础命令.md centos-权限.md centos-通配符.md [root@master centos7]# rename centos centos7 * [root@master centos7]# ls centos77-升级与降级python.md centos7-firewalld.md centos7-samba.md centos7-开机流程.md centos7-正则表达式.md centos77-扩展根分区.md centos7-ftp.md centos7-sed.md centos7-快捷键.md centos7-环境变量.md centos77-配置ss客户端.md centos7-grep.md centos7-ssh.md centos7-文件系统层次结构.md centos7-用户和组.md centos7-awk.md centos7-iptables.md centos7-vim.md centos7-日志.md centos7-磁盘管理.md centos7-bash特性.md centos7-nfs.md centos7-压缩打包.md centos7-时间任务.md centos7-网络配置.md centos7-curl.md centos7-pxe.md centos7-命令使用帮助.md centos7-时间服务.md centos7-访问控制.md centos7-dhcp.md centos7-rpm包管理.md centos7-命令历史.md centos7-服务管理.md centos7-进程管理.md centos7-find.md centos7-rsync.md centos7-基础命令.md centos7-权限.md centos7-通配符.md ","date":"2022-12-11","objectID":"/%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%90%8D/:0:0","tags":["linux","命令","rename"],"title":"批量修改文件名","uri":"/%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%90%8D/"},{"categories":["游戏"],"content":" ","date":"2022-11-25","objectID":"/kof98c/","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 内容来自以下文档： https://www.yzkof.com/custom-page-kof98-pose.html http://kof98.gotvg.com/caozuo/ http://kof98.gotvg.com/ http://wiki.gotvg.cn/kof/index.php?title=98%E5%87%BA%E6%8B%9B%E8%A1%A8 文档中的按键表示 特殊字符 含义 ⇖ 左上 ⇑ 上 ⇗ 右上 ⇐ 左 ⇒ 右 ⇙ 左下 ⇓ 下 ⇘ 右下 👊🏻 轻拳 👊 重拳 🦶🏻 轻脚 🦶 重脚 ➕ 加号 ","date":"2022-11-25","objectID":"/kof98c/:0:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 左右移动除了普通的左右缓慢移动，KOF 也支持以下快速移动方式： 奔跑：快速按2次前进方向键可向前奔跑一段距离，第二次按前进方向键长按不放可持续奔跑 后跳：快速按2次后退方向键可向后跳一段距离 ","date":"2022-11-25","objectID":"/kof98c/:1:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 跳跃KOF 中跳跃大致分为以下几种： 小跳：短暂按1次(⇖/⇑/⇗)键，高度与距离都是最小的 中跳：依次短暂按(⇙/⇓/⇘)(⇖/⇗)键，高度与距离比小跳稍微高些。奔跑过程中使用⇗可触发中跳 普通跳：正常按1次(⇖/⇑/⇗)键，高度与距离都比较大 大跳：短暂按1次(⇙/⇓/⇘)键然后正常按1次(⇖/⇗)键，跳跃距离最远。奔跑过程中使用⇗可触发大跳 ","date":"2022-11-25","objectID":"/kof98c/:2:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 通用操作 操作 按键 轻拳 A键 轻脚 B键 重拳 C键 重脚 D键 后跃 ←← 挑衅或切换为Ex状态 Start键，2边都是Ex模式且对手在集气时可以减少对方的气 超重击 _(跳跃中)CD 倒地回避 倒地瞬间输入AB,角色就会向后滚,不会倒在地上 空中防御 (垂直跳跃/向后跳跃中)↖/←/↙ 援助攻击 满足以下条件的情况下，同时按ABC： 1. 昏迷或受到对手擒拿攻击 2. 在画面中看到尚未败阵的同伴,且尚未败阵的同伴的相性与自己的相性不相克。角色间存在三种相性,分别为： - 良好：必定会出手相助 - 普通：只有一半机会出手相助 - 恶劣：一定不会出手相助 3. 体力少于对方 防御破坏 每个角色都有一定的防御耐久值,受对手连续攻击时防御耐久值便会减低,当超过极限后(8次吹飞攻击，或是共格挡了9次重攻击),就出现角色防御不能状态.而当出现防御破坏时,不仅防御状态被强制解除,原来若具有MAX状态的能量也要被解除. Counter Hit Counter Hit是击溃对手特殊技、必杀技、超必杀技、MAXIMUM状态下的通常技和奔跑(Advanced模式),除攻击力加强之外,对手在倒地前会再次出现被攻击判定,此时能以任何方法作跳跃中追打攻击. Critical Hit Critical Hit是以特定必杀技、其特定的动作击中对手及随机的情况下便会出现Critical Hit,它除了将必杀技的攻击力加强之外,更会令对手出现瞬间硬直状态和被攻击判定,能于此时出招作追打攻击. Advantage System - Advanced模式下为第一个人最多可以储三个能量珠,第二位出场角色可储四个能量珠,第三位则可以储五个能量珠 - Extra模式下为越后出场角色的能量棒会越短,换言之也就是储气的时间大大缩短了. Feeling Variation System 游戏中每一位角色,在每一天也会有不同的心情(选人后在决定出场次序时可按住Start键查看角色心情). ","date":"2022-11-25","objectID":"/kof98c/:3:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" Advanced 模式操作 操作 按键 前冲 →→/按住→不放 前紧急回避 ←AB/→ AB 后紧急回避 ← AB 取消前紧急回避 防御中,AB/→ AB(消耗一个能量珠) 取消后紧急回避 防御中,← AB(消耗一个能量珠) 取消吹飞攻击 防御中,CD(消耗一个能量珠) 小跳跃 ↖/↑/↗ 中跳跃 长按↖or↗ 大跳跃 短按↓+长按↖or↗ 小影跳 短按↓+短按↖or↗ 解拆投技 普通投技判定成立瞬间,同时按A B/↓ A/B/C/D Maximum发动 同时按ABC,消耗一个能量珠 超必杀技 消耗一个能量珠 Maximum超必杀技 Maximum发动状态,再消耗一个能量珠,发动后强制终结Maximum状态 ","date":"2022-11-25","objectID":"/kof98c/:4:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" Extra 模式操作 操作 按键 前冲 →→(向前跳一步)/←←(向后跳一步,有极为短暂的无敌时间) 小跳跃 瞬间输入↖/↑/↗ 中跳跃 瞬间输入↙/↓/↘/奔跑中,再瞬间输入↖/↑/↗ 大跳跃 瞬间输入↙/↓/↘/奔跑中,再瞬间输入↖/↑/↗ 攻击回避 AB同,可避开对手近身投技以及震地技能除外的任何攻击 Counter攻击 “攻击回避”中 A/B/C/D 取消前紧急回避 能量槽全满状态,防御中,AB/→ AB 取消后紧急回避 能量槽全满状态,防御中,← AB 取消吹飞攻击 能量槽全满状态,防御中,CD 蓄气 按住ABC不放 无限次使用超必杀技 当角色的体力低于八分之一,体力的显示便会不停闪烁,在这种状态下角色可无限次使用超必杀技. Maxium状态 当角色的能量槽储满时,角色便进入Maxium状态.这时攻击力可提升1.5倍,并可使用超必杀技,如果同时体力低于八分之一,那么便可使用Maxium超必杀技. ","date":"2022-11-25","objectID":"/kof98c/:5:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 安迪·博加德/Andy Bogard衣服颜色：A(白)、B(黑)、C(粉)、D(红) 各类 招式名称 出招详细 投技 刚临改 (近身)← or → + C 投技 抱入投 (近身)← or → + D 特殊技 上鳄 →+B 特殊技 下面 ↘+A 必杀技 幻影不知火 (空中)↓↘→+B或D 必杀技 幻影不知火·上颚 幻影不知火着地中→+B或D 必杀技 幻影不知火·下颚 幻影不知火着地中→+A或C 必杀技 飞翔拳 ↓↙←+A或C 必杀技 斩影拳 ←→+A或C 必杀技 我弹幸 斩影拳击中后↓↘→+A或C 必杀技 空破弹 ←↙↓↘→+B或D 必杀技 击臂背水掌 (近身)←↙↓↘→+A或C 必杀技 升龙拳(可空中) →↓↘+A或C 超必杀 超裂破弹 ↓↙←↙↓↘→+B或D 超必杀 飞翔流星拳 ↓↘→↓↘→+A或C ","date":"2022-11-25","objectID":"/kof98c/:6:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 夏尔米/Shermie衣服颜色： A(粉)， B(绿)， C(白)， D(红) 种类 招式名称 出招详细 普通投 闪光 近敌时 ←/→ C 普通投 后拱投 近敌时 ←/→ D 特殊技 站立 → B 必杀技 鞭答 ↓↙← A/C(近身命中) 必杀技 螺旋打(可空中) (近身)←↙↓↘→ A/C 必杀技 叠加(可空中) →↓↘ B/D(只能对空) 必杀技 天真 必杀投动作中↓↘→·B或D 必杀技 旋转踢 ↓↙← B/D 必杀技 重炮 ←↙↓↘→ B/D 超必杀技 狂欢 (近身)←↙↓↘→←↙↓↘→ A/C 超必杀技 闪耀 (近身)→↘↓↙←→↘↓↙← A/C ","date":"2022-11-25","objectID":"/kof98c/:7:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 雷光·夏尔米(Ex)/Shermie衣服颜色： A(红)， B(蓝)， C(黑)， D(黄) 种类 招式名称 出招详细 普通投 爆雷 近敌时 ←/→ C 普通投 影雷 近敌时 ←/→ D 特殊技 钩雷 → B 必杀技 无月之雷云 ←↙↓↘→ A/B/C/D 必杀技 八咫薙之鞭 ↓↙← A/C 必杀技 斜日之舞 ↓↙← B/D 必杀技 叠加(投,空中) →↓↘ B/D 超必杀技 暗黑雷光拳 ↓↘→↓↘→ A/C 超必杀技 宿命幻影振子 ↓↘→↓↘→ B/D ","date":"2022-11-25","objectID":"/kof98c/:8:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 二阶堂红丸 种类 招式名称 出招详细 普通投 居合投 近敌时 ←/→ C 普通投 背倒摔 近敌时 ←/→ D 普通投 旋转膝落 跳跃中近敌时 ↑ 以外方向 C/D 特殊技 杰克小刀踢 → B 特殊技 飞之技巧 跳跃中 ↓ D 必杀技 雷刃拳 ↓↘→ A/C(跳跃中可) 必杀技 真空片手驹 ↓↙← A/C 必杀技 红丸投 近敌时 →↘↓↙←→ A/C 必杀技 居合蹴 ↓↘→ B/D 必杀技 超级闪电踢 →↓↘ B/D 必杀技 反动三段蹴 →↘↓↙← B/D 超必杀技 雷光拳 ↓↘→↓↘→ A/C 超必杀技 大发电者 近敌时 →↘↓↙←→↘↓↙← A/C ","date":"2022-11-25","objectID":"/kof98c/:9:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 七枷社衣服颜色： A(红)， B(蓝)， C(青)， D(绿) 种类 招式名称 出招详细 普通投 抓击 近敌时 ←/→ C 普通投 抓掷 近敌时 ←/→ D 特殊技 标准大锤 → A 特殊技 滑步踢 → B 必杀技 升龙决斗 →↓↘ A/C 必杀技 喷气反击 ←↙↓↘→ A/C 必杀技 喷气反击.钢 喷气反击+↓↘→ A/C 必杀技 飞弹强力锤 →↘↓↙← A/C 必杀技 敲大锤 ↓↙← B/D 超必杀技 最终冲击 ↓↘→↓↘→ A/C(可蓄力) 超必杀技 百万大锤蒸汽 ↓↙←↙↓↘→ A/C·A/C ","date":"2022-11-25","objectID":"/kof98c/:10:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 大地·七枷社(Ex)衣服颜色： A(红)， B(蓝)， C(灰)， D(黄) 种类 招式名称 出招详细 普通投 缚 近敌时 ←/→ C 普通投 幕 近敌时 ←/→ D 特殊技 裂 → A 特殊技 武 → B 必杀技 挫大地 ↓↙← A/C 必杀技 淬大地 近敌时 ←↙↓↘→ A/C 必杀技 哽大地 近敌时 →↘↓↙←→ A/C 必杀技 耀大地 ←↙↓↘→ B/D 超必杀技 吼大地 ↓↘→↓↘→ A/C(可蓄力) 超必杀技 暗黑地狱极乐落 近敌时 →↘↓↙←→↘↓↙← A/C 超必杀技 荒大地 ↓↘→↓↘→ B/D ","date":"2022-11-25","objectID":"/kof98c/:11:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 神乐千鹤/Chizuru Kagura衣服颜色：A白、B紫、C黄、D粉 种类 招式名称 出招详细 普通投 令月 近敌时 ←/→ C 普通投 回天 近敌时 ←/→ D 特殊技 除活·铮铮 → A 特殊技 除活·瑜瑜 → B 特殊技 除活·淙淙 ↘ B 必杀技 百八活·玉响之瑟音 ↓↘→ A/C 必杀技 百活·天神之理 →↓↘ A/C 必杀技 二百十二活·神速之祝词 →↘↓↙← A/B/C/D(AB为分身，CD为实体) 必杀技 二百十二活·神速之祝词·天瑞 神速之祝词动作中↓↙← A/B/C/D(分身转换为实体) 必杀技 二百十二活·乙式·顶门之一针 ↓↓ A/B/C/D(AC为分身,BD为实体) 超必杀技 里面八十伍活·零技之础 ↓↙←↙↓↘→ A/C 超必杀技 里面一活·三籁之布阵 ↓↘→↓↘→ B/D ","date":"2022-11-25","objectID":"/kof98c/:12:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 麦卓衣服颜色： A(白)， B(紫)， C(蓝)， D(黑) 种类 招式名称 出招详细 普通投 颈向转动 近敌时 ←/→ C 普通投 穿透 近敌时 ←/→ D 特殊技 侧踢 → B 必杀技 绝望之手 ↓↘→ A/C 必杀技 死亡坠落 ↓↙← A/C ×3 必杀技 钢铁屠杀 ↓↙← B/D 必杀技 天堂旋转 →↓↘ A/C 必杀技 决择摔击 ←↙↓↘→ B/D 必杀技 晶莹的眼泪 ↓↘→↘↓↙← A/C 超必杀技 死亡之光 ↓↘→↓↘→ A/C 超必杀技 天国滑行 ↓↙←↙↓↘→ B/D ","date":"2022-11-25","objectID":"/kof98c/:13:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 草薙京/Kyo Kusanagi衣服颜色：A(黑)、B(红)、C(蓝)、D(灰) 种类 招式名称 出招详细 投技 扒铁 (近身)← or → + C 投技 一剎背負投 (近身)← or → + D 特殊技 外式·轰斧阳 →+B 特殊技 外式·奈落落 (空中)↓+C 特殊技 八十八式 ↘+D 必杀技 百式·鬼燃烧 →↓↘+A或C 必杀技 七百七式·独乐屠 ←↓↙+B或D 必杀技 二百十二式·琴月阳 →↘↓↙←+B或D 必杀技 七十五式·改 ↓↘→B+B或D+D 必杀技 百十四式·荒咬 ↓↘→+A 必杀技 百二十八式·九伤 荒咬动作中↓↘→+A或C 必杀技 百二十五式·七濑 九伤动作中B或D 必杀技 百二十七式·八锖 荒咬动作中→↘↓↙←+A或C/九伤动作中A或C 必杀技 外式·砌穿 八锖动作中A或C 必杀技 百十五式·毒咬 ↓↘→+C 必杀技 四百一式·罪咏 毒咬动作中→↘↓↙←+A或C 必杀技 四百二式·罚咏 罪咏动作中→A或C 必杀技 九百十式·鹤摘(外式+虎伏/龙射) ↓↙←+A或C 超必杀 里百八式·大蛇雉 ↓↙←↙↓↘→+A或C 超必杀 最终决战奥义·无式 ↓↘→↓↘→+A或C ","date":"2022-11-25","objectID":"/kof98c/:14:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 克里斯/Chris衣服颜色： A(绿)， B(红)， C(蓝)， D(灰) 种类 招式名称 出招详细 普通投 旋转踩踏 近敌时 ←/→ C 普通投 滑步投掷 近敌时 ←/→ D 特殊技 针刺 → A 特殊技 颠倒混乱踢 → B 特殊技 卸下踢 ↘ B 必杀技 滑触 ↓↘→ A/C 必杀技 乱冲 ↓↘→ B/D 必杀技 方向变换 →↓↘ A/C 必杀技 猎杀的空气 →↓↘ B/D 必杀技 射杀舞者突刺 →↘↓↙← A/C 必杀技 射杀舞者舞步 →↘↓↙← B/D 必杀技 舞者之章 (空中)↓↘→ B/D 超必杀技 连续滑触 ↓↘→↓↘→ A/C 超必杀技 滑行者的踩踏(可空中) ↓↙←↓↙← B/D ","date":"2022-11-25","objectID":"/kof98c/:15:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 火炎·克里斯(Ex)/Chris 种类 招式名称 出招详细 普通投 血之罚 近敌时 ←/→ C 普通投 天之罪 近敌时 ←/→ D 特殊技 无用之斧 → A 特殊技 受刑之鬼 → B 特殊技 截断之琴 ↘ B 必杀技 射日之炎(可空中) ↓↘→ A/C 必杀技 屠镜之炎 ↓↙← A/C 必杀技 摘月之炎 →↓↘ A/C 必杀技 狮咬之炎 ←↙↓↘→ A/B/C/D 必杀技 齿四肢之炎 (近身)←↙↓↘→+B或D 超必杀技 拂大地之禁果(可空中) ↓↘→↓↘→ A/C 超必杀技 暗黑大蛇薙(可蓄力) ↓↙←↙↓↘→ A/C ","date":"2022-11-25","objectID":"/kof98c/:16:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 麻宫雅典娜/Athena Asamiya 种类 招式名称 出招详细 投技 位投 (近身)←或→+C 投技 精神力投 (近身)←或→+D 投技 精神射击 (空中↑以外)+C或D 特殊技 连环腿 →+B 特殊技 凤凰弹 (空中)↓+B 特殊技 三角跳 (墙角)↗ 必杀技 精神力球 ↓↙←·A或C 必杀技 心灵传送术 ↓↘→·B或D 必杀技 凤凰箭 (空中)↓↙←·B或D 必杀技 精神力反射波 ↓↙←+B 必杀技 伽玛精神反射 ↓↙←+D 必杀技 划空光剑 →↓↘·A或C(可空中) 必杀技 超级精神穿透 (近身) ←↙↓↘→ A/C 超必杀技 闪光水晶波(可空中) →↘↓↙←→↘↓↙←+A或C 超必杀技 水晶射杀 (闪光水晶波中)↓↙←+A或C 超必杀技 凤凰FANG箭 (空中)↓↘→↓↘→+B或D 超必杀技 乱舞 ↓↘→↘↓↙←B或D ","date":"2022-11-25","objectID":"/kof98c/:17:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 布鲁·玛丽/Bule Mary衣服颜色： A(红)， B(黄)， C(灰)， D(紫) 种类 招式名称 出招详细 普通投 胜利投掷 近敌时 ←/→ C 普通投 头摔击 近敌时 ←/→ D 特殊技 铁锤击 → A 特殊技 双滚 → B 特殊技 上升之箭 ↘ B 必杀技 玛莉蜘蛛固 ↓↘→ A/C 必杀技 旋转下落 ↓↘→ B/D 必杀技 玛莉翻脸 对中段攻击时 ↓↙← B 必杀技 头部飞弹 对上段攻击时 ↓↙← D 必杀技 垂直之箭 →↓↘ B/D (可空中) 必杀技 玛莉掠夺 垂直之箭+ →↓↘ B/D 必杀技 指天回旋脚 ←→ B/D 必杀技 转踵落脚 指天回旋脚+ ↓↘→ B/D 必杀技 回身真落 (近敌时命中)→↘↓↙←→ A/C 超必杀技 玛莉野玫瑰 (近敌时命中)→↘↓↙←→↘↓↙← B/D 超必杀技 玛莉电闪光(可空中) ↓↘→↘↓↙← A/C 超必杀技 玛莉台风(可空中) ↓↘→↓↘→ B/D ","date":"2022-11-25","objectID":"/kof98c/:18:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 大门五郎/Goro Daimon衣服颜色：A(黑)、B(红)、C(蓝)、D(灰) 种类 招式名称 出招详细 投技 十字缔 (近身)← or → + C 投技 掴扣付 (近身)← or → + D 特殊技 玉溃 →+A 特殊技 头上拂 ↘+C 必杀技 根返 ↓↘→+B或D 必杀技 超受身 ↓↙←+B或D 必杀技 地雷震 →↓↘+A或C 必杀技 超大外割 (近身)→↓↘+B或D 必杀技 出云投 ←↙↓↘→+A 必杀技 切株返 ←↙↓↘→+C 必杀技 天地返 (近身)→↘↓↙←→+A或C 必杀技 里投 →↘↓↙←→+B或D 超必杀 地狱极乐落 (近身)→↘↓↙←→↘↓↙←+A或C 超必杀 岚之山 (近身)←↙↓↘→←↙↓↘→+B或D 超必杀 续·切株返 岚之山中←↙↓↘→+B或D 超必杀 根拔里投 续·切株返中→↓↘+B或D ","date":"2022-11-25","objectID":"/kof98c/:19:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 坂崎琢磨/Takuma Sakazaki衣服颜色： 白、红、黄、黑 种类 招式名称 出招详细 投技 大外割 近身← or → + C 投技 一本背负投 近身← or → + D 特殊技 鬼车 →+A 特殊技 瓦割 →+B 必杀技 虎煌拳 ↓↘→+A或C 必杀技 暂烈拳 →←→+A或C 必杀技 飞燕疾风脚(可空中) ←→+B或D 必杀技 翔乱脚 →↘↓↙←+B或D 必杀技 猛虎无赖岩 ↓↙←+A或C 超必杀 真·鬼神击 近身↓↘→↓↘→+A或C 超必杀 龙虎乱舞 ↓↘→↘↓↙←+A或C 超必杀 霸王至高拳 →←↙↓↘→+A或C ","date":"2022-11-25","objectID":"/kof98c/:20:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["游戏"],"content":" 莉安娜·哈迪兰/Leona Heidern 种类 招式名称 出招详细 普通投 杀手钻 近敌时 ←/→ C 普通投 背袭 近敌时 ←/→ D 普通投 黑登摔 跳跃中近敌时 ↑ 以外方向 C/D 特殊技 打击(可空中) → B 必杀技 眼之斩 ↓↙← A/C 必杀技 耳环炸弹 ↓↙← B/D 必杀技 月光锯 →↓↘ A/C 必杀技 →↓↘ B/D 必杀技 涡旋发射器 ←↙↓↘→+A/C 必杀技 威武军刀 ←↙↓↘→+B/D 必杀技 粉碎者 威武军刀+D 必杀技 X口径炮 ↓↑ B/D 超必杀技 重力风暴 ↓↘→↓↘→ A/C 超必杀技 V字金锯 跳跃中 ↓↘→↘↓↙← A/C 超必杀技 旋转的火花 ↓↘→↘↓↙← B/D ","date":"2022-11-25","objectID":"/kof98c/:21:0","tags":["kof","kof 98c"],"title":"拳皇98c","uri":"/kof98c/"},{"categories":["windows"],"content":" 运行环境： vmware: 16 内容来自以下文档： 浪漫歌 VMware虚拟机共享目录普通用户无法访问 vmware 密钥vmware 15： CG392-4PX5J-H816Z-HYZNG-PQRG2 vmware 16： ZF3R0-FHED2-M80TY-8QYGC-NPKYF vmware 17: MC60H-DWHD5-H80U9-6V85M-8280D 共享主机目录虚拟机关机状态下执行以下操作 选择使用共享文件的虚拟机 编辑虚拟机设置 选项卡 共享文件夹 总是启用 添加 安照引导添加共享的文件夹 保存 在虚拟机器中安装 open-vm-tools [root@master ~]# yum install -y open-vm-tools Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * epel: my.mirrors.thegigabit.com ... 检查是否识别到共享的本地文件夹 [root@master ~]# vmware-hgfsclient note 创建挂载目录，如果该目录可能已经存在，不用重新创建 [root@master ~]# mkdir /mnt/hgfs/ 挂载共享文件夹 [root@master ~]# vmhgfs-fuse .host:/ /mnt/hgfs -o uid=0 -o gid=0 -o umask=022 -o allow_other .host:/ ：表示本地共享文件的更目录 /note ： 表示虚拟机的挂载点 查看挂载 [root@master ~]# ls /mnt/hgfs/ note 开机自动挂载 [root@master ~]# chmod +x /etc/rc.d/rc.local [root@localhost ~]# echo 'vmhgfs-fuse .host:/ /mnt/hgfs -o uid=0 -o gid=0 -o umask=022 -o allow_other' \u003e\u003e /etc/rc.d/rc.local ","date":"2022-11-20","objectID":"/vmware/:0:0","tags":["vmware"],"title":"windows中vmware使用","uri":"/vmware/"},{"categories":["windows"],"content":" docker无法挂载vmware共享目录挂载时加-o allow_other（允许其它用户访问） 克隆注意事项 修改主机名 修改网卡的 UUID 与 IP 地址（如果冲突） ","date":"2022-11-20","objectID":"/vmware/:1:0","tags":["vmware"],"title":"windows中vmware使用","uri":"/vmware/"},{"categories":["linux"],"content":" 运行环境： rocky: 8 查看当前语言环境 [root@node01 ~]# echo $LANG zh_CN.UTF-8 临时修改只需要修改变量值即可，如果要永久修改则要修改 /etc/locale.conf 配置文件 [root@node01 ~]# echo 'LANG=\"en_US.UTF-8\"' \u003e/etc/locale.conf ","date":"2022-11-20","objectID":"/linux%E7%B3%BB%E7%BB%9F%E8%AF%AD%E8%A8%80%E7%8E%AF%E5%A2%83/:0:0","tags":[null],"title":"修改linux系统语言环境","uri":"/linux%E7%B3%BB%E7%BB%9F%E8%AF%AD%E8%A8%80%E7%8E%AF%E5%A2%83/"},{"categories":["windows"],"content":" 运行环境： windows: 11 内容来自以下文档： 右键开始菜单，点击搜索 在搜索框中输入变量，点击第编辑系统环境变量 点击高级选项卡中的环境变量 点击用户变量中 Path 行，选择编辑 点击新建，在新行中添加路径 保存 ","date":"2022-11-16","objectID":"/windows-path/:0:0","tags":["windows path"],"title":"windows 系统中添加 PATH 环境变量","uri":"/windows-path/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： redhat5 官方文档：Pluggable Authentication Modules (PAM) WeiyiGeek: Linux之PAM系统模块详解说明 Susan Lauber: An introduction to Pluggable Authentication Modules (PAM) in Linux PAM可插拔认证模块（Pluggable Authentication Modules）简称 PAM。在 linux 是一种安全验证方式是基于模块化设计、具有可插入功能的一种独立于应用程序之外的用户验证方式；设计的初衷是将不同的底层认证机制集中到一个高层次的 API 中，从而省去开发人员自己去设计和实现各种繁杂的认证机制的麻烦。 如果应用程序或服务支持 PAM 验证功能，就可以通过修改其相应的 PAM 配置文件（所有验证功能都是通过一些库文件来提供的）来实现用户验证方式，当重新启用些服务或应用程序时 PAM 模块就会通过其专用 API 来读取它的配置文件，根据配置文件中的内容来提供相应的验证功能 使用 ldd 命令查看进程是否支持 PAM 验证方式，如果有 libpam.so.0 输出则表示支持。如果能够得到一个应用程序的原代码，也可以自行将支持 PAM 的功能代码加入其中。 [root@localhost ~]# ldd $(which sshd) | grep \"libpam\" libpam.so.0 =\u003e /lib64/libpam.so.0 (0x00007f24209e1000) 使用 man 手册可以获取帮助 # 介绍 pam [root@localhost ~]# man pam # pam 配置文件使用帮助 [root@localhost ~]# man pam.conf # 查看已安装的 pam 模块 [root@localhost ~]# man -k pam_ group.conf (5) - configuration file for the pam_group module limits.conf (5) - configuration file for the pam_limits module pam_access (8) - PAM module for logdaemon style login access control pam_console (8) - determine user owning the system console pam_console_apply (8) - set or revoke permissions for users at the system console ... 配置文件配置文件用于调用库文件实现用户身份验证。位于： /etc/pam.conf 文件 /etc/pam.d/ 目录下，当该目录存在时会忽略 /etc/pam.conf 文件 配置文件语法为：“进程名称 工作类别 控制模式 模块路径 模块参数”。每行记录一条规则。如果使用 /etc/pam.d 配置目录则使用进程名作为配置文件名，配置文件中不用指定进程名。 在配置文件中添加注释信息有以下方法： 以 # 开头的行 在配置记录后面添加 \\ 用于分割注释信息 ","date":"2022-11-07","objectID":"/pam/:0:0","tags":[null],"title":"linux中的可插拔式认证模块","uri":"/pam/"},{"categories":["linux"],"content":" 工作类别工作类别用于指定需要验证的类型： auth: 主要负责验证使用者身份以及用户权限授予; 例如你的验证方式有很多比如一次性密码、指纹、虹膜等等，都应该添加在 auth 下以及比如赋给用户某个组的组员身份等等 account: 主要负责在用户能不能使用某服务上具有发言权，但不负责身份认证; 例如验证帐户的此操作是否已经过期,权限多大,拥有此权限的时间期限是否已经过期等等 password: 主要负责和密码有关的工作; 例如控制密码的使用期限，重复输入的次数，密码锁定后的解禁时限以及保存密码的加密放方式等 session: 主要负责对每个会话进行跟踪和记录，例如记录的内容包括登录的用户名及登录的时间和次数等等 ","date":"2022-11-07","objectID":"/pam/:1:0","tags":[null],"title":"linux中的可插拔式认证模块","uri":"/pam/"},{"categories":["linux"],"content":" 控制模式控制模式主要用来控制在验证过程中动作和返回结果的方式, 简单的说用于定义各个认证模块在给出各种结果时 PAM 的行为，或者调用在别的配置文件中定义的认证流程栈。它有以下两种表达方式： 简单控制标志 复杂控制标志 关键字模式。有以下控制字段： required: 当使用此控制标志时，当验证失败时仍然会继续进行其下的验证过程，它会返回一个错误信息，但是由于它不会由于验证失败而停止继续验证过程，因此用户不会知道是哪个规则项验证失败 requisite: 当使用此控制标志时，当验证失败时立即结束整个验证过程，并返回一个错误信息。使用此关键字可以防止一些通过暴力猜解密码的攻击，但是由于它会返回信息给用户，因此它也有可能将系统的用户结构信息透露给攻击者 sufficien: 只要有此控制标志的一个规则项验证成功，那么 PAM 构架将会立即终止其后所有的验证，并且不论其前面的 required 标志的项没有成功验证，它依然将被忽略然后验证通过 optional: 表明对验证的成功或失败都是可有可无的，所有的都会被忽略。通常用于 session 类型 include: 加载其它配置文件 substack: 运行其他配置文件中的流程，并将整个运行结果作为该行的结果进行输出。该模式和 include 的不同点在于认证结果的作用域：如果某个流程栈 include 了一个带 requisite 的栈，这个 requisite 失败将直接导致认证失败同时退出栈；而某个流程栈 substack 了同样的栈时，requisite 的失败只会导致这个子栈返回失败信号，母栈并不会在此退出 复杂的控制标志能够让管理员可以指定在验证过程中发生某种事件时可以执行的动作。格式为 [value1=action1 value2=action2 ...]。其中 value 字段有以下： success open_err symbol_err service_err system_err buf_err perm_denied auth_err cred_insufficient authinfo_unavail user_unknown maxtries new_authtok_reqd acct_expired session_err cred_unavail cred_expired cred_err no_module_data conv_err authtok_err authtok_recover_err authtok_lock_busy authtok_disable_aging try_again ignore abort authtok_expired module_unknown bad_item conv_again incomplete default action 有以下值： ignore: 在一个栈中有多个认证条目的情况下，如果标记 ignore 的返回值被命中，那么这条返回值不会对最终的认证结果产生影响 bad: 标记 bad 的返回值被命中时，最终的认证结果注定会失败。此外，如果这条 bad 的返回值是整个栈的第一个失败项，那么整个栈的返回值一定是这个返回值，后面的认证无论结果怎样都改变不了现状了 die: 标记 die 的返回值被命中时，马上退出栈并宣告失败。整个返回值为这个 die 的返回值 ok: 在一个栈的运行过程中，如果 ok 前面没有返回值，或者前面的返回值为 PAM_SUCCESS，那么这个标记了 ok 的返回值将覆盖前面的返回值。但如果前面执行过的验证中有最终将导致失败的返回值，那 ok 标记的值将不会起作用 done: 在前面没有 bad 值被命中的情况下，done 值被命中之后将马上被返回，并退出整个栈 N: 与 ok 类似，但会跳过接下来的 N 个验证步骤。如果 N = 0 则和 ok 完全相同 reset: 清空之前生效的返回值，并且从下面的验证起重新开始 可以查看 /usr/include/security/_pam_types.h 了解更多详情（我看不懂）。如果没有这个文件则要安装 pam-devel 包 [root@localhost ~]# yum install -y pam-devel ","date":"2022-11-07","objectID":"/pam/:2:0","tags":[null],"title":"linux中的可插拔式认证模块","uri":"/pam/"},{"categories":["linux"],"content":" 模块模块文件（动态库文件）默认在以下目录，如果不是就必需在模块的完整名称前加上完整的模块路径名。 32 位操作系统：/lib/security/ 64 位操作系统：/lib64/security/ 可以使用 man 命令查看相关模块帮助信息 [root@localhost ~]# man -k pam_ group.conf (5) - configuration file for the pam_group module limits.conf (5) - configuration file for the pam_limits module pam_access (8) - PAM module for logdaemon style login access control pam_console (8) - determine user owning the system console pam_console_apply (8) - set or revoke permissions for users at the system console ... 有些模块后面可指定参数，如果需要在单个参数中使用空格可以将整个参数用方括号 [] 包裹起来, 当选项超过一行时用 \\ 符号连接下一行。如下面示例 squid auth required pam_mysql.so user=passwd_query passwd=mada \\ db=eminence [query=select user_name from internet_service \\ where user_name='%u' and password=PASSWORD('%p') and \\ service='web_proxy'] ","date":"2022-11-07","objectID":"/pam/:3:0","tags":[null],"title":"linux中的可插拔式认证模块","uri":"/pam/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： man 手册 ps 命令ps 命令可以查看当前进程信息快照。该命令选项有以下几种格式： UNIX 格式：以 - 开头。如 ps -e。可以合并同格式选项 GUN 格式：以 -- 开头。如 ps --deselect。可以合并同格式选项 BSD 格式：没有破折号，如 ps a。不能合并选项 选择当前会话以外的进程ps 命令默认只显示当前会话相关联进程的信息，以下这些选项可以打破限制 a # 与 tty 相关联的进程信息 x # 与 a 选项同时使用时，取消 tty 关联限制，即查看所有进程信息 -A,-e # 查看所有进程信息 -r # 只查看运行状态的进程信息 --deselect, -N # 运行结果取反 指定进程列表以下选项可以指定多次，且单个选项可以指定多个值，这些值使用（带引号）空格或逗号分隔 n, -n, p n, -p n, --pid n # 查看指定进程号信息，其中 n 为进程号 -C cmdlist # 指定进程名列表（不含路径） --ppid # 指定父进程号，列出其子进程信息 --quick-pid, q, -q # 只显示简要信息 -s,--sid # 查看会话进程信息 -t, t, --tty # 查看当前 tty 相关进程信息，如果指定 - 为值则查看所有进行信息 U, -u, --user # 查看指定 EUID 运行的进程，EUID 可以是用户名 -U, --User # 查看指定 RUID 运行的进程，RUID 可以是用户名 输出格式 -o, o # 指定输出字段，格式：-o 字段[:宽度][=字段名]。 # 字段宽度必须是正整数，宽度小于信息值时只显示前面部分 # 字段名用于显示标题行，可以为空，当所有字段名为空时不显示标题行 -O # 指定输出字段，比 -o 选项默认增加 pid,tname,time,args 字段 O # 指定输出字段，比 -o 选项默认增加 pid,tname,time,fname 字段 -j # 等效 -o pid,pgid,sid,tname,cputime,comm j # 等效 -o ppid,pid,pgid,sid,tname,tpgid,s,uid,bsdtime,args s # 等效 -o uid,pid,pending,blocked,ignored,caught,s,tname,bsdtime,args u # 等效 -o user,pid,pcpu,pmem,vsz,rss,tname,s,start_time,bsdtime,args v # 等效 -o pid,tname,s,bsdtime,maj_flt,trs,drs,rss,pmem,args X # 等效 -o pid,stackp,esp,eip,tmout,alarm,s,tname,bsdtime,args -l # 等效 -o f,s,uid,pid,ppid,c,pri,nice,sz,wchan,tname,cputime,cmd # ADDR 字段没找到 -y # 只能与 -l 选项同时使用，把 -l 输出字段中 ADDR 字段替换为 RSS 字段 --context # 查看 selinux 上下文 -M # 曾加 LABEL 字段（显示 SELINUX 上下文） Z # 安全相关字段，如果是 SELINUX 则与 -M 相同 H # 像进程那样显示线程 输出修饰符 e # 查看进程指定的环境变量 f # 以 ACSII 码展示进程关系树 --forest # 类似 f 选项，但只有进程文件名，没有路径与参数 H # 类似 --forest，但没有 ACSII 码，以缩进表示 h # 不展示标题行 k,--sort # 指定字段排序，如 ps -ef --sort ppid。部分字段不支持用于排序 # 指定排序方式格式为：[+|-]key[,[+|-]key[,...]] 其中： # k表示字段名 # -表示降序 # +表示升序 输出字段表ps -o 选项有字段表： 字段 默认字段名 说明 %cpu 或 pcpu %CPU 进程的CPU利用率。计算方式：使用的CPU时间除以进程已经运行的时间 x 100% c C 类似 %cpu 字段，但只显示整数 cp CP 同 c 字段 %mem 或 pmem %MEM 进程使用内存占比。计算方式：进程占用内存除以物理内存 x 100% args 或 command COMMAND 进程运行的参数，包含进程路径。值可以会超过默认宽度 cmd CMD 同 args comm 或fname 或ucomm COMMAND 进程名称，不含路径与参数 cputime 或 time TIME [DD-]HH:MM:SS 时间格式 bsdtime TIME 进程利用CPU时间，时间格式为 MMM:SS bsdstart START 进程启动时间，24小时以内时间格式为 HH:MM，大于24小时时间格式为 Mmm:SS start_time START 进程启动时间或日期，根据执行ps命令时机显示不同格式： 同一天格式为：HH:MM 同一年格式为：MmmDD 不同年格式为：Y cputimes 或times TIME 利用cpu时间，单位秒 etime ELAPSED 进程已启动时间，时间格式为 [DD-]HH:MM:SS etimes ELAPSED 进程已启动时间，时间单位为秒 lstart STARTED 进程启动时间，时间格式为 “周 月 日 时:分:秒 年” start STARTED 进程启动时间，时间格式为 HH:MM:SS blocked 或 sigmask BLOCKED blocked 信号掩码 ignored 或 sigignore IGNORED ignored 信号掩码 pending 或 sig PENDING pending 信号掩码 caught 或 sigcatch CAUGHT caught 信号掩码 cgroup CGROUP 进程控制组 cgname CGNAME 进程控制组名称 class 或 cls CLS 进程调度类别，有以下值： -: 未报告 ? 表示: 未知 B 表示: SCHED_BATCH TS 表示: SCHED_OTHER FF 表示: SCHED_FIFO RR 表示: SCHED_RR ISO 表示: SCHED_ISO IDL 表示: SCHED_IDLE DLN 表示: SCHED_DEADLINE policy POL 同 class 字段 sched SCH 进程调度策略，有以下值： 0: 表示 SCHED_OTHER (SCHED_NORMAL) 1: 表示 SCHED_FIFO 2: 表示 SCHED_RR 3: 表示 SCHED_BATCH 4: 表示 SCHED_ISO 5: 表示 SCHED_IDLE 6: 表示 SCHED_DEADLINE drs DRS 数据驻留集大小，即用于除可执行代码以外的其他物理内存量 egid EGID 进程组ID gid GID 同 egid egroup EGROUP 进程组名 grop GROUP 进程组名 ipcns IPCNS 名称空间中进程 inode 号 eip EIP instruction pointer(存放执行中的函数对应的栈帧的栈底地址) esp ESP stack pointer(存放执行中的函数对应的栈帧的栈顶地址) euid EUID 运行进程用户 id 号 uid UID 同 euid 字段 euser EUSER 运行进程用户名 user 或uname USER 同 euser 字段 f 或flag 或flags F 标志，值为1表示有分支，值为4表示使用超级用户权限 fgid FGID filesystem access group ID fgroup FGROUP filesystem access group name fuid FUID filesystem access user ID fuser FUSER filesystem access user name label LABEL 安全标签，通常是 SELINUX 上下文 lsession SESSION 进程登陆会话标识符，需要systemd支持 luid LUID 进程相关登录ID lwp LWP 线程 ID maj_flt MAJFL 表示程序的页请求错误次数。内存中没有缓存有进程所需要的页面数据。内核必需要通知CPU从磁盘中把页面数据加载到内存中来。 min_flt MINFLT 表示程序的页请求错误次数.内存中已经缓存有进程所需要的页面数据。只要把该页面数据与进程的虚拟地址空间建立映射关系就可以 ni 或 nice NI 进程nice值 nlwp NLWP 进程中线程数量 numa NUMA nwchan WCHAN 进程休眠的内核函数的WCHAN地址 pid PID 进程号 ppid PPID 父进程号 pgid PGID 进程组号 pgrp PGRP 同 pgid 字段 pri PRI 进程优先级，数字越大，优先级越低 psr PSR 进程当前被分配给的处理器 sz SZ tgid TGID rss 或rssize RSS 常驻集大小，即任务使用的非交换物理内存 rsz RSZ 同 rss 字段 rtprio RTPRIO 进程实时优先级 ruid RUID 真实用户ID s S 进程状态，","date":"2022-11-02","objectID":"/linuxCmdPs/:0:0","tags":["linux","ps","命令"],"title":"ps - 查看进程信息快照","uri":"/linuxCmdPs/"},{"categories":["linux"],"content":" 运行环境： centos: 8 centos: 7 内容来自以下文档： OpenSSH 官方文档 sshdsshd 是服务端守护进程。 相关文件","date":"2022-10-25","objectID":"/openSSH/:0:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 服务端配置文件","date":"2022-10-25","objectID":"/openSSH/:1:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" known_hosts 文件服务端 /etc/ssh/ssh_host*.pub 文件保存了公钥，当客户端第一次远程时会保存在客户端 ~/.ssh/known_hosts 文件中。客户端下次远程内容与服务端不一样时，则阻止远程。需要删除相关记录 ","date":"2022-10-25","objectID":"/openSSH/:2:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" authorized_keys 文件服务端~/.ssh/authorized_keys 文件保存了公钥，客户端使用对应密钥可远程该主机。客户端的密钥保存在 ~/.ssh/ 中 ","date":"2022-10-25","objectID":"/openSSH/:3:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 服务端配置文件选项 centos7 ssh配置文件：(#+空格才表示注释) /etc/ssh/sshd_config Port 22 #端口号 ListenAddress #监听的IP Protocol #SSH协议 HostKey #主机密钥路径 KeyRegenerationInterval #重新生成密钥倒计时 ServerKeyBits #密钥长度 LogLevel #日志级别 LoginGraceTime #登陆连接中切断连接倒计时 PermitRootLogin #是否允许超级用户ssh 登陆 StrictModes #ssh接收登陆请求之前是否坚持用户根目录和rhosts权限 MaxAuthTries #指定每个连接允许的最大身份验证尝试次数 MaxSessions #指定每个网络允许的最大打开shell MaxStartups：x:y:z, #同一地址的并发连接数量为z，则拒绝这个地址所有连接 RSAAuthentication #是个开启RAS密钥验证 PubkeyAuthentication #是否开启公钥验证 AuthorizedKeysFile #公钥验证文件路径 PasswordAuthentication #是否开启密码验证登录 PrintMotd #登陆时是否显示/etc/motd中的消息 Subsystem #是否支持sft子系统 X11Forwarding # 是否开启图形化程序 UseDNS yes #是否反检查DNS PidFile #父进程号保存的文件 #登陆请求记录文件 /var/log/secure 限制登陆名单，只能是用户名 且以空格分开 黑名单：DenyUsers 黑名单用户组：DenyGroups 白名单：AllowUsers 白名单用户组： AllowGroups ","date":"2022-10-25","objectID":"/openSSH/:4:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 基于用户名方式远程 #远程目标与当前同名的用户 [root@yh ~]# ssh 192.168.157.21 #远程 192.168.157.21的user1用户 [root@yh ~]# ssh user1@192.168.157.21 #在 192.168.157.21 上用user1用户执行ls / 返回结果 [root@yh ~]# ssh user1@192.168.157.21 \"ls /\" #ssh -p 指定远程端口 [root@yh ~]# ssh 192.168.157.130 -p 22 ","date":"2022-10-25","objectID":"/openSSH/:5:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 基于密钥方式远程(用自己的私钥连接对方，前提是对方有自己的公钥) 生成密钥对 交互式生成密钥对方式 # 生成密钥，-t选择加密方式 [root@localhost ~]# ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): #密钥保存位置 Created directory '/root/.ssh'. Enter passphrase (empty for no passphrase): # 密钥密码 Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. # 密钥文件 Your public key has been saved in /root/.ssh/id_rsa.pub. # 公钥文件 The key fingerprint is: SHA256:jQZ27QOYwjt+VUaqCZlXQd3QpYMNXLLhh18nTDTnHDU root@localhost.localdomain The key's randomart image is: +---[RSA 2048]----+ | .++*=.o=E+| | . o + =oOo+ =o| | * * + O = + +| | * = B o o o | | o o S + . | | . . o . | | . . | | . | | | +----[SHA256]-----+ 非交互式生成密钥对方式 # -P 指定密码 -f 指定保存私钥文件 ssh-keygen -t rsa -P \"\" -f \"/root/.ssh/ssh.rsa\" 把公钥文发给对方 #把公钥文件发给131 -p 指定对方远程端口 [root@localhost ~]# ssh-copy-id -i .ssh/id_rsa.pub -p 22 root@192.168.157.131 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@192.168.157.131's password: #输入192.168.157.131密码 Number of key(s) added: 1 Now try logging into the machine, with: \"ssh '192.168.157.131'\" and check to make sure that only the key(s) you wanted were added. ","date":"2022-10-25","objectID":"/openSSH/:6:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 文件说明 # 查看公钥文件位置 [root@localhost ~]# grep \"AuthorizedKeysFile\" /etc/ssh/sshd_config [root@yh ~]# ls .ssh/ id_rsa id_rsa.pub known_hosts # rsa：私钥 # rsa.pub：公钥 # known_hosts：服务端保存的客户端的信息， # 若果没有相关客户端信息 远程时则会咨询是否连接客户端 # authorized_keys：客户端保存的服务器信息(内容与服务端生成的公钥相同) # 如果没有相关服务端信息，则不能通过密钥连接 ","date":"2022-10-25","objectID":"/openSSH/:7:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 日志登录成功的日志会记录在/var/run/utmp文件，失败记录是 /var/log/btmp 文件。需要使用 last -f 命令查看 ","date":"2022-10-25","objectID":"/openSSH/:8:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 安全建议 修改默认端口 使用安全的连接方式 设置登陆用户列表（白名单） 设置空闲超时时长 防火墙访问策略 监听特定的IP 尽量使用密钥对验证 密码复杂度高 禁止管理员用户远程 ","date":"2022-10-25","objectID":"/openSSH/:9:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 修改端口 [root@localhost ~]# grep \"Port\" /etc/ssh/sshd_config #Port 22 #GatewayPorts no # 添加端口 [root@localhost ~]# echo \"Port 2882\" \u003e\u003e/etc/ssh/sshd_config [root@localhost ~]# echo 'IPQoS=throughput' \u003e\u003e/etc/ssh/sshd_config # 在selinux中添加sshd注册端口 [root@localhost ~]# semanage port -a -t ssh_port_t -p tcp 2882 [root@localhost ~]# semanage port -l | grep ssh ssh_port_t tcp 2882, 22 # 添加端口到防火墙 [root@localhost ~]# firewall-cmd --get-zone-of-interface=eno1 public [root@localhost ~]# firewall-cmd --zone=public --add-port=2882/tcp \u0026\u0026 firewall-cmd --runtime-to-permanent success success # 重启ssh服务 [root@localhost ~]# systemctl restart sshd [root@localhost ~]# [root@localhost ~]# ss -anltpd | grep ssh tcp LISTEN 0 128 0.0.0.0:2882 0.0.0.0:* users:((\"sshd\",pid=77582,fd=4)) tcp LISTEN 0 128 [::]:2882 [::]:* users:((\"sshd\",pid=77582,fd=6)) ","date":"2022-10-25","objectID":"/openSSH/:10:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" 安全防护 修改默认端口号减少被扫描风险 密码要有随机性、复杂性或禁用密码使用秘钥对 配置防火墙限制IP远程 ","date":"2022-10-25","objectID":"/openSSH/:11:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" centos7 使用PAM机制防暴力破解sshd服务使用以下方式锁定账号 # even_deny_root 也限制root用户； # deny 设置普通用户和root用户连续错误登陆的最大次数，超过最大次数，则锁定该用户 # unlock_time 设定普通用户锁定后，多少时间后解锁，单位是秒； # root_unlock_time 设定root用户锁定后，多少时间后解锁，单位是秒； [root@localhost ~]# echo 'auth required pam_tally2.so deny=3 unlock_time=999999 even_deny_root root_unlock_time=10800' \u003e\u003e /etc/pam.d/sshd 使用 pam_tally2 查看登录失败的次数，-u选项可以指定具体的用户；-r选项可以清空统计次数 [root@localhost ~]# pam_tally2 Login Failures Latest failure From root 212 11/06/22 19:38:48 61.177.172.76 git 2 11/06/22 19:18:18 43.134.4.104 [root@localhost ~]# pam_tally2 -u root Login Failures Latest failure From root 213 11/06/22 19:40:15 129.146.90.109 ","date":"2022-10-25","objectID":"/openSSH/:11:1","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" centos8 使用PAM机制防暴力破解sshd服务centos8 使用 pam_faillock 替换 pam_tally2 模块。 在 /etc/pam.d/system-auth 与 /etc/pam.d/password-auth 文件添加以下行（注意模块类型、控制标记顺序） # 模块类型 控制标记 模块路径及参数 auth required pam_faillock.so even_deny_root preauth silent audit deny=3 unlock_time=300 auth sufficient pam_unix.so nullok try_first_pass auth [default=die] pam_faillock.so even_deny_root authfail audit deny=3 unlock_time=300 # 这行在 accpunt 块最片 account required pam_faillock.so 使用 faillock 查看登录失败的次数，-u选项可以指定具体的用户；-r选项可以清空统计次数 错误处理","date":"2022-10-25","objectID":"/openSSH/:11:2","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" ssh_exchange_identification: Connection closed by remote host [root@localhost ~]# ssh root@192.168.245.210 -p 2551 ssh_exchange_identification: Connection closed by remote host 解决方法：在 known_hosts 中删除该主机中的记录 [root@localhost ~]# echo \u003e.ssh/known_hosts ... [root@localhost ~]# ssh root@192.168.245.210 -p 2551 The authenticity of host '[192.168.245.210]:2551 ([192.168.245.210]:2551)' can't be established. ECDSA key fingerprint is SHA256:uzWQ3DhjrQwC5FsV+NFYa1GNcziBr/YK+TtGAut0qys. ECDSA key fingerprint is MD5:4b:9f:39:3b:d5:71:00:ee:ab:b5:29:1d:a1:90:0d:64. Are you sure you want to continue connecting (yes/no)? yes ... ","date":"2022-10-25","objectID":"/openSSH/:12:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" client_loop: send disconnect: Connection reset PS E:\\\u003e ssh root@154.55.134.82 -p 18671 root@154.55.134.82's password: client_loop: send disconnect: Connection reset Nov 19 09:13:00 HK02-5037MR-006-08 systemd[1]: Stopping OpenSSH server daemon... Nov 19 09:13:00 HK02-5037MR-006-08 sshd[32010]: Received signal 15; terminating. Nov 19 09:13:00 HK02-5037MR-006-08 systemd[1]: Stopped OpenSSH server daemon. Nov 19 09:13:00 HK02-5037MR-006-08 systemd[1]: Starting OpenSSH server daemon... Nov 19 09:13:00 HK02-5037MR-006-08 sshd[32045]: Server listening on 0.0.0.0 port 18671. Nov 19 09:13:00 HK02-5037MR-006-08 sshd[32045]: Server listening on :: port 18671. Nov 19 09:13:00 HK02-5037MR-006-08 systemd[1]: Started OpenSSH server daemon. Nov 19 09:13:06 HK02-5037MR-006-08 sshd[32048]: Accepted publickey for root from 119.123.152.249 port 25367 ssh2: RSA SHA256:TzjxAthsEdqCvbFk5VTlmRgVfB9bOxPHJTL0/OBNfhs Nov 19 09:13:06 HK02-5037MR-006-08 sshd[32048]: pam_unix(sshd:session): session opened for user root by (uid=0) [root@HK02-5037MR-006-04 ~]# echo 'IPQoS=throughput' \u003e\u003e/etc/ssh/sshd_config [root@HK02-5037MR-006-04 ~]# systemctl restart sshd ","date":"2022-10-25","objectID":"/openSSH/:13:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" error: Bind to port failed: Permission denied修改sshd端口后无法重启 [root@localhost ssh]# journalctl -xe ... -- Unit sshd.service has begun starting up. Jan 18 14:11:58 localhost.localdomain sshd[1741]: error: Bind to port 838 on 0.0.0.0 failed: Permission denied. Jan 18 14:11:58 localhost.localdomain sshd[1741]: error: Bind to port 838 on :: failed: Permission denied. Jan 18 14:11:58 localhost.localdomain systemd[1]: sshd.service: Main process exited, code=exited, status=255/n/a Jan 18 14:11:58 localhost.localdomain sshd[1741]: fatal: Cannot bind any address. Jan 18 14:11:58 localhost.localdomain systemd[1]: sshd.service: Failed with result 'exit-code'. -- Subject: Unit failed -- Defined-By: systemd -- Support: https://access.redhat.com/support selinux造成的 方法1：改变selinux ## 在selinux中添加sshd注册端口 [root@localhost ssh]# semanage port -a -t ssh_port_t -p tcp 838 [root@localhost ssh]# ## 查看selinux中sshd当前的注册端口 [root@localhost ssh]# semanage port -l | grep ssh ssh_port_t tcp 838, 22 # 方法2：关闭selinux ## 临时关闭，立即生效 [root@localhost ssh]# setenforce 0 [root@localhost ssh]# getenforce Permissive ## 永久关闭，重启服务器后生效 [root@localhost ssh]# sed -i '/^SELINUX=/ s/enforcing/disabled/g' /etc/selinux/config [root@localhost ssh]# systemctl restart sshd [root@localhost ssh]# [root@localhost ssh]# ss -altpdn | grep \"ssh\" tcp LISTEN 0 128 0.0.0.0:838 0.0.0.0:* users:((\"sshd\",pid=1818,fd=4)) tcp LISTEN 0 128 [::]:838 [::]:* users:((\"sshd\",pid=1818,fd=6)) ","date":"2022-10-25","objectID":"/openSSH/:14:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" Load key “/root/.ssh/id_rsa”: bad permissions/root/.ssh/id_rsa的权限错误，应该为600 [root@xiaosi ~]# ll .ssh/id_rsa -rwxr-xr-x. 1 root root 1675 Apr 23 17:36 .ssh/id_rsa [root@xiaosi ~]# [root@xiaosi ~]# chmod 600 .ssh/id_rsa [root@xiaosi ~]# [root@xiaosi ~]# ll .ssh/id_rsa -rw-------. 1 root root 1675 Apr 23 17:36 .ssh/id_rsa ","date":"2022-10-25","objectID":"/openSSH/:15:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["linux"],"content":" Did not receive identification string from [root@localhost ~]# systemctl -l status sshd ● sshd.service - OpenSSH server daemon ... May 12 19:03:58 localhost.localdomain sshd[3377]: Did not receive identification string from x.x.x.x port 33503 ... scp scp ：基于ssh复制文件 -r：递归复制 -p：保持文件属性 -P：指定端口 -q：静默模式 #本地复制到对方 scp 本地文件路径 用户名@ip:保存路径 #远程复制到本地 scp 用户名@ip:保存路径 本地文件路径 ","date":"2022-10-25","objectID":"/openSSH/:16:0","tags":["ssh"],"title":"OpenSSH - SSH 协议远程登录连接工具","uri":"/openSSH/"},{"categories":["五笔"],"content":" 内容来自以下文档： 五笔练习 五笔学习视频 五笔字根查询1 五笔字根查询2 百度汉语 五笔简介五笔输入法日前已被智能拼音输入法淘汰 五笔：所有的汉字基础笔画，共5个：一(横)、|(竖)、丿(撇)、丶(捺)、乙(折) 字根：由汉字基础笔画组成的汉字或汉字的某个部分，共128个 五笔输入法：利用字根组成的汉字，共6300+个 五笔的学习基础 熟悉汉字的书写顺序（为了正确的拆字） 熟悉键盘分布（为了快速的输入） 熟悉常用汉字（汉字都不知道长什么样是不可能用五笔的） 五笔字根分布规则五笔字根分布规则： 字根按照起笔划分为5个区域，每个区有单独的编号，每个区域都有5个键，每个键有单独的编号。如横区第二个键表示12 每个字根的第一笔定区，第二笔定位。如字根“王”，第一笔的是横，第二笔是横，所以字根“王”所在的键的11 重复笔画的字根按照重复次数分别位在12345号位。如第一个点在Y键，第二个点在U键，第四个点在O键 相似字根有时会无视原则跳到有相似字根的按键去，如：“卜”应该在L，但是因为形似一竖一横所以放在H 五笔输入法与版本五笔输入法（五笔字型输入法）有以下版本： 86版：日前使用人数最多的版本，也是大部分输入法支持的版本，但字根分部不是很合理。 98版：86版的改进，优化了字根。只有少数输入法支持 新世纪版：最终版本，优化了字根。少数版本支持。随着智能拼音输入法的算法越来越精准，加上五笔学习难度高，导致使用人群减少，后续不会再有更新了 输入法推荐： 搜狗五笔输入法：免费、没有广告、支持全部版本、有免费皮肤、能自定义词库但不能修改原本词库。推荐使用的 ","date":"2022-10-23","objectID":"/%E4%BA%94%E7%AC%94/:0:0","tags":["五笔"],"title":"五笔输入法","uri":"/%E4%BA%94%E7%AC%94/"},{"categories":["五笔"],"content":" 86版五笔字根分布与助记词助记词只是记忆字根方法的一种，不是记口诀，而是记口诀中关联的字根。死记口诀是没用的。配合字根拆分原则能加强记忆 ","date":"2022-10-23","objectID":"/%E4%BA%94%E7%AC%94/:1:0","tags":["五笔"],"title":"五笔输入法","uri":"/%E4%BA%94%E7%AC%94/"},{"categories":["五笔"],"content":" 新世纪版本字根分布与助记词助记词只是记忆字根方法的一种，不是记口诀，而是记口诀中关联的字根。死记口诀是没用的。配合字根拆分原则能加强记忆 五笔拆分原则汉字按照以下拆分原则进行拆分。优先级:散\u003e连\u003e交 书写顺序：要求正确的书写顺序。正确：新=立 木 斤 取大优先：按照书写顺序为汉字编码时，拆出来的字根要尽可能大(能用2个字根组成就不用3个字根即减少拆分字根数量)。正确：世=廿 乙 兼顾直观：在确认字根时，为了使字根的特征明显易辩，有时就要牺牲书写顺序和取大优先的原则。正确：国=口 王 丶 能连不交：当一个字可以视作相连的几个字根，也可视作相交的几个字根时，我们认为，相连的情况是可取的。正确：天=一 大 能散不连：如果一个结构可以视为几个基本字根的散的关系，就不要认为是连的关系。正确：占=卜 口 ","date":"2022-10-23","objectID":"/%E4%BA%94%E7%AC%94/:2:0","tags":["五笔"],"title":"五笔输入法","uri":"/%E4%BA%94%E7%AC%94/"},{"categories":["五笔"],"content":" 键内字与键外字五笔分为键内字和键外字： 键内字是拆分的字根中，本身就是汉字。它是键码是特殊的，有以下情况： 键名字：每个按键连续敲4下所打印的字。如：工:AAAA、田:LLLL 单笔画：即横竖撇捺折，连续2个首键+LL。如：丨:HHLL、一:GGLL 其他字根：所在键+首笔画+次笔画+末笔画。如：五:GGHG 键外字：字根之外的字,分为以下几种情况 键少于4个：依次打完字根+识别码。如：草:AJJ 键刚好4个：依次打第一、第二、第三、第四字根。如：罪:LDJD 键大于4个：依次打第一、第二、第三、最后字根。如：舞:RLGH ","date":"2022-10-23","objectID":"/%E4%BA%94%E7%AC%94/:3:0","tags":["五笔"],"title":"五笔输入法","uri":"/%E4%BA%94%E7%AC%94/"},{"categories":["五笔"],"content":" 五笔识别码某些汉字字根拆分数量少于4个，这类汉字会造成大量重码，识别码是为了减少这类汉字重码而设定的，组成方式：最后一笔编号+字形编号=识别码，如下图 下面是几个示例： 如：拍:RRG(最后一笔是横，编号为1；字形是左右型，编号为1。识别码为：11 即G键) 如：草:AJJ(最后一笔是竖，编号为2；字形是上下型，编号为2。识别码为：22 即J键) 如：万:DNV(最后一笔是折，编号为5；字形是杂合型，编号为3。识别码为：53 即V键) 识别码的特殊规定： 半包围或包围结构的汉字取未包围的最后一笔： 如：连:LPK(未包围的最后一笔是竖，编号为2；字形是杂合型，编号为3。识别码为：23 即K键) 包含字根“九、刀、力、匕”的汉字最后一笔认定为折： 如：仑:WBB(包含匕字认定最后一笔是折，编号为5；字形是上下型，编号为2。识别码为：52 即B键) 单笔画是字根的一部分认定为杂合型： 如：歹:GQI(最后一笔点，编号为4；也是字Q键上字根的一部分，认定是杂合型，编号为3。识别码为：43 即I键) 五笔简码简码是打出部分字根之后输入法展示出的第一个汉字： 一级简码：第一个字根+空格所打印的汉字，共25个 二级简码：第一个字根+第二个字根+空格所打印的汉字，小于625个 三级简码：第一个字根+第二个字根+第三个字根+空格所打印的汉字，小于4400+个 以下是一级简码，在任何五笔输入法基本是固定的 横区：G:一、F:地、D:在、S:要、A:工 竖区：H:上、J:是、K:中、L:国、M:同 撇区：T:和、R:的、E:有、W:人、Q:我 捺区：Y:主、U:产、I:不、O:为、P:这 折区：N:民、B:了、V:发、C:以、X:经 五笔词组词组是至少一个汉字的词语： 双字词组：第1个汉字的前2个字根+第2个汉字的前2个字根，如：你好（wqvb） 三字词组：第1个汉字的前1个字根+第2个汉字的前1个字根+第3个汉字的前2个字根。如：中国人（klww） 四字词组：第1个汉字的前1个字根+第2个汉字的前1个字根+第3个汉字的前1个字根+第4个汉字的前1个字根。 多字词组：第1个汉字的前1个字根+第2个汉字的前1个字根+第3个汉字的前1个字根+最后1个汉字的前1个字根 提高五笔打字速度单个汉字（优先级从上往下）： 简码 键内字 键外字 多个汉字（视情况而定）： 双字词组 三字词组 多字词组 五笔练习和查询以下是我个人常用练习和查询网页 五笔练习 五笔学习视频 五笔字根查询1 五笔字根查询2 百度汉语 ","date":"2022-10-23","objectID":"/%E4%BA%94%E7%AC%94/:4:0","tags":["五笔"],"title":"五笔输入法","uri":"/%E4%BA%94%E7%AC%94/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 内容来自以下文档： k8s 官方文档: 存储 pod 中的存储卷k8s volume (卷)这个概念是为了解决以下问题： 容器中的文件是临时放在磁盘上的，当容器崩溃、删除、重启时会默认会丢失所有文件恢复到容器最初状态。 多个 pod 中共享数据 在 pod..spec.containers[*].volumeMounts 字段中声明存储卷，在 pod.spec.volumes 字指定挂载的存储卷 [root@node1 ~]# kubectl -n note get pod artalk-deployment-56cb487c89-c5rzk -o yaml apiVersion: v1 kind: Pod ... spec: containers: volumeMounts: - mountPath: /etc/localtime name: mysql-localtime - mountPath: /etc/mysql name: mysql-conf - mountPath: /var/log/mysql name: mysql-log - mountPath: /var/lib/mysql name: mysql-data - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-wk8d7 readOnly: true volumes: - hostPath: path: /root/note/artalk type: \"\" name: artalk-data - hostPath: path: /etc/localtime type: \"\" name: mysql-localtime - hostPath: path: /root/note/mysql/data type: \"\" name: mysql-data - hostPath: path: /root/note/mysql/conf type: \"\" name: mysql-conf - hostPath: path: /root/note/mysql/log type: \"\" name: mysql-log ... 持久卷为了将存储如何制备的细节从其如何被使用中抽象出来，k8s 引入了两个新的 API 卷资源： PersistentVolume: 持久卷，简称 PV。 持久卷是集群资源，与普通卷一样， 也是使用卷插件来实现的，只是它们拥有独立于任何使用它的 pod 的生命周期。 PersistentVolumeClaim: 持久卷申领，简称 PVC。用户对存储的请求。概念上与 Pod 类似。PVC 申领会耗用 PV 资源。 持久卷是用插件的形式实现的，k8s 支持以下插件： cephfs: cephfs 文件系统 csi: csi 容器存储接口（CSI） fc: Fibre Channel 存储 hostPath: 节点文件系统上的文件或目录 iscsi: SCSI over IP 存储 local: 节点上挂载的本地存储设备 nfs: 网络文件系统（NFS）存储 [rbd][rbd]: Rados 块设备 (RBD) 卷 awsElasticBlockStore: v1.17 弃用 azureDisk: v1.19 弃用 azureFile: v1.21 弃用 cinder: v1.18 弃用 flexVolume: v1.23 gcePersistentDisk: v1.17 弃用 glusterfs: v1.25 弃用 portworxVolume: v1.25 弃用 vsphereVolume: v1.19 弃用 photonPersistentDisk: v1.15 弃用 scaleIO: v1.21 之后弃用 flocker: v1.25 之后弃用 quobyte: v1.25 之后弃用 storageos: v1.25 之后弃用 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:0:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" PV 创建与绑定 PVCPV 卷的制备有两种方式： 静态制备：集群管理员创建若干 PV 卷用于消费 动态制备：如果现有 PV 无法满足 PVC 申领需求，则集群可以尝试动态制备一个存储卷。动态制备由 StorageClass 实现的，因此必须满足以下条件： PVC 申领必须请求某个 StorageClass，如果申领指定存储类为 \"\"，则相当于为自身禁止使用动态制备的卷 StorageClass 在事先已创建 在 API 服务器上启用 DefaultStorageClass 准入控制器 用户创建一个带有特定存储容量和特定访问模式需求的 PersistentVolumeClaim 对象，该对象绑定 PV 顺序如下： 现用 PV 刚好能满足 PVC 申领，则把它们绑定在一起 使用动态制备创建卷 绑定满足 PVC 申领的 PV，这种情况会超出所请求的配置 以上都不满足时，PVC 申领会无限期地处于未绑定状态。当与之匹配的 PV 卷可用时，PVC 申领会被绑定。 绑定操作会检查存储类、 访问模式和所请求的存储尺寸都是否合法，不会某些卷匹配条件是否满足，包括节点亲和性等等。一旦绑定关系建立，则 PVC 绑定就是排他性的， 无论该 PVC 申领是如何与 PV 卷建立的绑定关系。 PVC 申领与 PV 卷之间的绑定是一种一对一的映射（使用 ClaimRef 来记述 PV 卷与 PVC 申领间的双向绑定关系） pod 将 PVC 当成存储卷来使用。集群会检视 PVC 申领，找到所绑定的卷， 并为 Pod 挂载该卷。一旦用户有了申领对象并且该申领已经被绑定， 则所绑定的 PV 卷在用户仍然需要它期间一直属于该用户。 用户通过在 Pod 的 volumes 块中包含 persistentVolumeClaim 节区来调度 Pod 这是示例 [root@node01 note]# cat nginxPod.yaml --- apiVersion: v1 kind: PersistentVolume metadata: name: local-pv-node04-nginx-config spec: capacity: storage: 30Mi volumeMode: Filesystem accessModes: - ReadOnlyMany persistentVolumeReclaimPolicy: Delete local: path: /note/nginx/html nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node04.localhost.com --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: note-pvc-nginx-config namespace: note spec: accessModes: - ReadOnlyMany volumeMode: Filesystem resources: requests: storage: 30Mi --- apiVersion: v1 kind: Pod metadata: name: note-nginx namespace: note spec: containers: - name: note-nginx image: nginx ports: - name: http-port containerPort: 80 volumeMounts: - name: nginx-config mountPath: \"/usr/share/nginx/html\" volumes: - name: nginx-config persistentVolumeClaim: claimName: note-pvc-nginx-config [root@node01 note]# kubectl create ns note \u0026\u0026 kubectl apply -f nginxPod.yaml persistentvolume/local-pv-node04-nginx-config unchanged persistentvolumeclaim/note-pvc-nginx-config unchanged pod/note-nginx configured [root@node01 note]# kubectl --namespace note get pod note-nginx -o=jsonpath='{.status.podIP}{\"\\n\"}' 100.95.190.7 [root@node01 note]# [root@node01 note]# curl 100.95.190.7 \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003cmeta name=\"generator\" content=\"Hugo 0.102.0-DEV\" /\u003e ... ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:1:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 名称PV 与 PVC 对象名称必须是合法的 DNS 子域名，即必须满足如下规则： 不能超过 253 个字符 只能包含小写字母、数字，以及 - 和 . 必须以字母数字开头 必须以字母数字结尾 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:2:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 容量通常每个 PV 卷都会使用 PV.spec.capacity.storage 明确存储容量。PVC.spec.resources 字段申领容量值，有以下字段： limits.storage: 申领使用最大值，缺省为不限制 requests.storage: 申领使用最小值，如果 PV 不满足此条件，则无法绑定 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:3:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 挂载模式PV.spec.volumeMode 可选字段可以指定以哪种方式被 pod 使用，有以下值： Filesystem: 表示文件系统，也是默认值 Block: 表示以块设备给 pod 使用，没有文件系统，因此 pod 中的应用必须知道该如何使用块设备 PVC.sepc.volumeModes 字段使用与 PV.sepc.volumeModes相同的约定来表明是将卷作为文件系统还是块设备来使用。 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:4:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 卷访问模式PV 卷可以用资源提供者所支持的任何方式挂载到宿主系统上。提供者（驱动）的能力不同，每个 PV 卷的访问模式都会设置为对应卷所支持的模式值。每个卷同一时刻只能以一种访问模式挂载，即使该卷能够支持多种访问模式。 访问模式由 PV.spec.accessModes 字段指定（值为列表类型）。有以下值： ReadWriteOnce: 卷可以被一个 PVC 以读写方式挂载。也允许运行在同一节点上的多个 Pod 访问卷。在命令行中以 RWO 展示 ReadOnlyMany: 卷可以被多个 PVC 以只读方式挂载。在命令行接口中以 ROX 展示 ReadWriteMany: 卷可以被多个 PVC 以读写方式挂载。在命令行接口中以RWX 展示 ReadWriteOncePod: 卷可以被单个 Pod 以读写方式挂载。命令行接口中以 RWOP 展示 PVC 申领在请求具有特定访问模式的存储时，挂载模式（PVC.spec.accessModes 字段）与 PV 相同才能绑定 k8s 使用卷访问模式来匹配 PVC 和 PV。在某些场合下，卷访问模式也会限制 PV 可以挂载的位置。 卷访问模式并不会在存储已经被挂载的情况下为其实施写保护。例如，即使某个卷创建时设置为 ReadOnlyMany，也无法保证该卷是只读的。 如果访问模式设置为 ReadWriteOncePod，则卷会被限制起来并且只能挂载到一个 Pod 上。 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:5:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 挂载选项k8s 管理员可以指定持久卷被挂载到节点上时使用的附加挂载选项。并非所有持久卷类型都支持挂载选项。早期是使用注解 PV.metadata.annotations: volume.beta.kubernetes.io/mount-options，目前及其以后使用 PV.spec.mountOptions 字段 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:6:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 节点亲和性每个 PV 卷可以通过设置节点亲和性（PV.spec.nodeAffinity 字段）来定义一些约束，进而限制从哪些节点上可以访问此卷。 使用这些卷的 Pod 只会被调度到节点亲和性规则所选择的节点上执行。 PVC 也可以通过标签选择算符来过滤 PV，只有标签与选择算符相匹配的卷能够绑定到申领上。PVC.sepc.selector 字段定义此功能，有以下字段，如果同时定义则都要满足才能绑定到 PV： matchLabels: PV 必须含有此标签才能绑定 matchExpressions: 通过键值对列表与操作符组（In、NotIn、Exists、DoesNotExist）成过滤条件 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:7:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 预留 PVPV.spec.claimRef 字段可以声明把指定的 PVC 与 PV 绑定。该绑定操作不会考虑某些卷匹配条件是否满足，包括节点亲和性等。但控制面依旧会检查存储类、访问模式、请求大小等 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: foo-pvc namespace: foo spec: storageClassName: \"\" # 此处须显式设置空字符串，否则会被设置为默认的 StorageClass volumeName: foo-pv ... --- apiVersion: v1 kind: PersistentVolume metadata: name: foo-pv spec: storageClassName: \"\" claimRef: name: foo-pvc # 指定 PVC 名称 namespace: foo # 指定 PVC 所在名称空间 ... ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:8:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 名称空间由于 PV 具有绑定后是有排它性的，且 PVC 是名称空间作用域的对象，因此 ReadWriteMany 与 ReadOnlyMany 访问模式只能在同一名称空间内进行 ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:9:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" PV 删除当用户不再使用其存储卷时，他们可以从 API 中将 PVC 对象删除， 从而允许该资源被回收再利用。PV 对象的回收策略告诉集群， 当其被从申领中释放时如何处理该数据卷： Retain(保留): PV 卷仍然存在且被标识为 released （已释放）。由于卷上仍然存在这前一申领人的数据，该卷还不能用于其他申领。如果重用该存储资产，可以基于存储资产的定义创建新的 PV 与 PVC 对象并绑定。 想要彻底回收时需要通过以下步骤操作： 删除 PV 对象及其相关的外部存储资产 根据情况，手动清除所关联的存储资产上的数据 删除存储资产 Delete(删除): 移除 PV 对象与其所关联的存储资产。动态制备的卷会继承 StorageClass 回收策略 Recycle(回收): 只删除 PV 上的数据，不删除对象，可以把 PV 重新与 PVC 绑定。该策略已废弃。可以使用动态制备实现（StorageClass 回收策略）。 当使用某 PVC 的 Pod 对象仍然存在时，认为该 PVC 仍被此 Pod 使用。如果用户删除被某 Pod 使用的 PVC 对象，该 PVC 申领不会被立即移除。 PVC 对象的移除会被推迟，直至其不再被任何 Pod 使用。 此外，如果管理员删除已绑定到某 PVC 申领的 PV 卷，该 PV 卷也不会被立即移除。 PV 对象的移除也要推迟到该 PV 不再绑定到 PVC。这一功能特性的目的是确保仍被 Pod 使用的 PVC 对象及其所绑定的 PV 被删除造成的数据丢失 PVC 对象是处于被保护状态时，Status 值为 Terminating；Finalizers 值包含 kubernetes.io/pvc-protection kubectl describe pvc hostpath ... Name: hostpath Namespace: default StorageClass: example-hostpath Status: Terminating Volume: Labels: \u003cnone\u003e Annotations: volume.beta.kubernetes.io/storage-class=example-hostpath volume.beta.kubernetes.io/storage-provisioner=example.com/hostpath Finalizers: [kubernetes.io/pvc-protection] ... PV 对象是处于被保护状态时，Status 值为 Terminating；Finalizers 值包含 kubernetes.io/pv-protection kubectl describe pv task-pv-volume ... Name: task-pv-volume Labels: type=local Annotations: \u003cnone\u003e Finalizers: [kubernetes.io/pv-protection] StorageClass: standard Status: Terminating Claim: Reclaim Policy: Delete ... ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:10:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 阶段每个 PVC 会处于以下阶段之一： Available: 表示可用，是空闲资源，没有绑定到 PVC Bound: 表示已绑定到 PVC Released: 表示可释放，PVC 已被删除 Failed: PV 自动回收操作失败 Pending: 等待。没有满足条件的 PV ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:11:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["k8s"],"content":" 存储类可以使用 StorageClass 资源对这些类统一的配置。该资源为管理员提供了描述存储类的配置文件。相同为类才能绑定，缺省时会指定默认的类。示例 apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: standard provisioner: kubernetes.io/aws-ebs parameters: type: gp2 reclaimPolicy: Retain allowVolumeExpansion: true mountOptions: - debug volumeBindingMode: Immediate StorageClass.metadata.name 字段声明名称，且必须是 DNS 子域名 StorageClass.provisioner 字段是必须的，它声明使用哪个卷插件创建 PV StorageClass.reclaimPolicy 字段指定默认回收策略，缺省时为 Delete StorageClass.allowVolumeExpansion 字段声明允许（值为：true）或拒绝（值为：false）用户通过编辑 PVC 对象来扩容卷 StorageClass.mountOptions 字段声明挂载选项。如果卷插件不支持声明的挂载选项则则制备操作会失败 StorageClass.volumeBindingMode 字段声明卷动态制备与绑定。有以下值 Immediate 表示 PVC 创建后立即创建相当的 PV 并与之绑定。由于拓扑限制而非集群所有节点可达的存储后端，PV 可能会在不知道 pod 调度要求下可能完成了绑定 。该场景应该使用 WaitForFirstConsumer 值 WaitForFirstConsumer 表示根据使用该 PVC 的 pod 调度情况制备 PV 再绑定 从 k6s:1.6 起使用 PVC.spec.storageClassName 字段声明使用的 StorageClass 资源。在 k8s:1.6 以前是给 pod 添加注解 volume.beta.kubernetes.io/storage-class 使用动态卷。该方法到 k8s:1.9 彻底废弃。以下是示例 --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: fast provisioner: kubernetes.io/gce-pd parameters: type: pd-ssd --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: claim1 spec: accessModes: - ReadWriteOnce storageClassName: fast resources: requests: storage: 30Gi hostPathhostPath 类型的存储卷能把主机节点文件系统上的文件或目录挂载到 pod 中，这种方式存在许多风险，尽可能避免使用，使用时应当以只读方式挂载。 hostPath 类型可以指定以下 type 属性（可选的 pod.sepc,volumes.hostPath.type 字段） type 取值 说明 缺省 缺省时安装 hostPath 卷之前不会执行任何检查 DirectoryOrCreate 如果在给定路径上什么都不存在，那么将根据需要创建空目录，权限设置为 0755，具有与 kubelet 相同的组和属主信息 FileOrCreate 如果在给定路径上什么都不存在，那么将在那里根据需要创建空文件，权限设置为 0644，具有与 kubelet 相同的组和所有权 Directory 在给定路径上必须存在的目录 File 在给定路径上必须存在的文件 Socket 在给定路径上必须存在的 UNIX 套接字 CharDevice 在给定路径上必须存在的字符设备 BlockDevice 在给定路径上必须存在的块设备 emptyDir对于定义了 emptyDir 卷的 Pod，在 Pod 被指派到某节点时此卷会被创建。 就像其名称所表示的那样，emptyDir 卷最初是空的。尽管 Pod 中的容器挂载 emptyDir 卷的路径可能相同也可能不同，但这些容器都可以读写 emptyDir 卷中相同的文件。 当 Pod 因为某些原因被从节点上删除时，emptyDir 卷中的数据也会被永久删除。 volumes: - emptyDir: name: # 挂载点名称 medium: # 存储介质，缺省或为空时，使用节点默认存储介质，如硬盘、网络挂载 # 可以指定为Memory，表示使用内存，k8s 会挂载基于 RAM 的tmpfs文件系统 sizeLimit: # 限制存储大小，如果是内存介质需要开启 SizeMemoryBackedVolumes 控制特性 locallocal 类型与 hostPath 类似。local 卷无需手动将 Pod 调度到节点。系统通过查看 PersistentVolume 的节点亲和性配置，就能了解卷的节点约束。使用 local 卷作为 PV 时必须显式使用 PV.sepc.nodeAffinity 字段指定节点。当节点变得不健康，那么 local 卷也将变得不可被 Pod 访问。使用它的 Pod 将不能运行。 更多信息可以查看local 卷驱动用户指 示例 --- apiVersion: v1 kind: PersistentVolume metadata: name: local-pv-node1 spec: capacity: storage: 4Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local local: path: /pv nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - node01.localhost.com --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: node-pvc spec: accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 1Gi storageClassName: local [root@node01 ~]# kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE local-pv-node1 4Gi RWO Delete Bound default/node-pvc local 44s [root@node01 ~]# [root@node01 ~]# kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE node-pvc Bound local-pv-node1 4Gi RWO local 46s IOMeshhttps://docs.iomesh.com/next/about-iomesh/introduction ","date":"2022-10-07","objectID":"/k8s%E5%AD%98%E5%82%A8/:12:0","tags":["k8s 存储卷"],"title":"k8s 存储卷","uri":"/k8s%E5%AD%98%E5%82%A8/"},{"categories":["linux"],"content":" 运行环境： centos: 8 内容来自以下文档： [Linux命令行与shell脚本编程大全第3版][] linux安全基线配置全解析 google开源项目风格指南-shell风格指南 Shell_HAT: bash中字符串的处理 琴酒网络-linux BASH shell下设置字体及背景颜色 bash 与父子进程当 bash 进程执行一个非内置命令时，会产生一个子进程去执行该命令，命令执行结束后，回收子进程。如果是 bash 脚本，则会产生 bash 子进程，由 bash 子进程执行脚本 当前 bash 执行命令时进程树状图 [root@localhost ~]# pstree -p systemd(1)─┬─NetworkManager(2256)─┬─{NetworkManager}(2257) ├─sshd(2466)─┬─sshd(13287)───bash(13289)───ping(17747) │ └─sshd(17752)───bash(17756)───pstree(17825) 上述示例中，终端1的bash 进程（13289） 在运行 ping 命令产生了一个进程 ping (17747)，bash 进程（17756）运行当前 pstree 命令也产生一个进程 （17825） 当 bash 运行脚本时，产生的进程树状图 # 终端1 [root@localhost ~]# cat ping.sh #!/bin/bash ping baidu.com [root@localhost ~]# ./ping.sh PING baidu.com (39.156.69.79) 56(84) bytes of data. 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=48 time=43.7 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=2 ttl=48 time=44.3 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=3 ttl=48 time=44.1 ms # 终端2 [root@localhost ~]# pstree -p systemd(1)─┬─NetworkManager(2256)─┬─{NetworkManager}(2257) │ └─{NetworkManager}(2259) ├─sshd(2466)─┬─sshd(13287)───bash(13289)───ping.sh(19530)───ping(19531) │ ├─sshd(17752)───bash(17756)───pstree(19536) 上述示例中，终端1 运行一个脚之所以产生一个子shell （bash）类型，是因为运行 bash 命令的效果，每执行一次 bash 命令就会产生并进入 bash 子进程，当进程命令结束运行时回收子进程 示例：运行 bash 命令产生进程以及回收 # 终端1 [root@localhost ~]# bash [root@localhost ~]# bash [root@localhost ~]# bash [root@localhost ~]# bash ping.sh PING baidu.com (39.156.69.79) 56(84) bytes of data. 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=48 time=43.8 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=2 ttl=48 time=44.0 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=3 ttl=48 time=44.3 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=4 ttl=48 time=43.9 ms # 终端2 [root@localhost ~]# pstree -p systemd(1)─┬─NetworkManager(2256)─┬─{NetworkManager}(2257) │ └─{NetworkManager}(2259) ├─sshd(2466)─┬─sshd(13287)───bash(13289)───bash(19763)───bash(19774)───bash(19783)───bash(19894)───ping(19895) │ ├─sshd(17752)───bash(17756)───pstree(19901) # 结束终端1之后，终端2查看进程树效果 [root@localhost ~]# pstree -p systemd(1)─┬─NetworkManager(2256)─┬─{NetworkManager}(2257) │ └─{NetworkManager}(2259) ├─sshd(2466)─┬─sshd(13287)───bash(13289)───bash(19763)───bash(19774)───bash(19783) │ ├─sshd(17752)───bash(17756)───pstree(20125) bash 命令常见选项 使用方式：bash [GNU long option] [option] script-file ... 常见选项： -c string 从字符串中读取命令 -s 从标准输入中读取命令 -i 交互式 -l 以登陆 shell 方式启动 -r 受限制在家目录中 -x 查看执行的命令和参数，set 命令的效果，可以有 bash -x 直接运行 -v 查看执行时输入的行，set 命令的效果，可以用 bash -v 直接运行 -n 读取命令但不执行 变量变量：表示表示某段内存空间的值 。变量名是标识内存空间的名称 数据存储方式：ASCII码 存储数据类型：字符，且不支持浮点数（不同解释器有所不同） 查看变量值方式： 使用 set 命令查看 使用 printenv 变量名 ，仅限于环境变量 使用 echo ${变量名} 使用 unset 变量名 可以删除某个变量 变量按照环境有以下分类： 环境变量：shell 工作环境相关的变量，变量名通常全是大写字母 用户变量：只在某个用户生效的变量，变量名通常全是小写字母 以下表格是常见变量 变量名 变量简介 $$ 当前进程PID $? 上一条命令的退出状态码 $! 上一条运行后台进程的PID $PWD 当前目录 $LANG 默认语言 $USER 当前用户名 $HOME 当前用户家目录 $PATH 默认可执行程序路径 $SHELL 默认 shell $HOSTNAME 主机名 $# 脚本参数数量 $* 脚本所有参数（当成整体） $0 脚本名称（包含执行时的路径） $n n 为 1 到 8 的正整数，脚本参数 $@ 脚本所有参数（每个参数当成单个个体） 自定义变的方法：变量名=变量值，其中变量名可以是任何由字母、数字或下划线组成的文本字符串。长度不超过20个，区分大小写。定义变量时： 如果是原有文件，保持之前的格式 定义变量时，变量名尽量是单词，多个单词使用下划线分割，如 bash_shell 定义环境变量和常用变量时：名称全部使用大写，且声明在文件脚本注释下面 引用变量时，容易引起争议的单个字符变量和多字符变量使用 ${var} 格式；单个字符变量和脚本参数变量使用 $var 格式 引用变量时，尽量使用 $@ ，有必要才使用 $* 引用变量时，使用 [[ ]] 匹配规则，不要使用 [] 只读变量应该使用 readonly 或 declare -r 明确定义 本地变量（常见于函数）需要使用 local 命令明确定义，当赋值的值由命令替换提供时，声明和赋值必须分开。因为内建的 local 不会从命令替换中传递退出码 子进程被创建时会继承父进程的环境变量，但父进程不会引用子进程的变量，因此，如果是子进程被销毁，它生成的变量也会销毁。 ","date":"2022-09-30","objectID":"/linuxBash/:0:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 把命令的输出信息赋值给变量把命令输出的信息赋值给变量有以下方法： 变量名=`命令` 变量名=$(命令) 上述的方式会创建一个子 shell 来运行对应的命令，因此，如果该子 shell 运行的是一个脚本或外部命令，则无法获取变量 ","date":"2022-09-30","objectID":"/linuxBash/:1:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 变量替换表达式 形式 说明 ${var} 变量本身 ${#var} 返回 var 值中元素个数 ${var+str} 如果 var 变量不存在时返回它的值，否则返回 str ${var:+str} 如果 var 变量为空时返回它的值，否则返回 str ${var-str} 如果 var 变量存在时返回它的值，否则返回 str ${var:-str} 如果 var 变量不为空时返回它的值，否则返回 str ${var=str} 如果 var 变量存在时返回它的值，否则把 str 赋值给 var 变量并返回 ${var:=str} 如果 var 变量不为空时返回它的值，否则把 str 赋值给 var 变量并返回 ${var?str} 如果 var 变量存在时返回它的值，否则把 str 输出到标准错误输出 ${var:?str} 如果 var 变量存在或不为空时返回它的值，否则把 str 输出到标准错误输出 ${var:x:y} 从 var 变量下标 x 截取到下标 y，可以是负数(负号前有空格)，表示从结尾倒序截取，注意从结尾计算下标时是从1开始 ${var:x} 从 var 变量下标 x 截取到最后，可以是负数(负号前有空格)，表示从结尾倒序截取，注意从结尾计算下标时是从1开始，${var: -0} 表示整个变量值 ${var::y} 从 var 变量下标 0 截取到下标 y，可以是负数(负号前有空格)，表示从结尾倒序截取，注意从结尾计算下标时是从1开始 ${var#x} 返回变量值，并去掉开头的 x , # 表示从开关去掉字符 ${var%x} 返回变量值，并去掉结尾的 x , % 表示从结尾（从右往左）去掉字符 ${var#?} 返回变量值，并去掉开头第一个字符, 通配符 ? 表示单个字符 ${var#*x} 返回变量值，并去掉从开头到第一个 x , 通配符 * 表示任意字符 ${var#*x?} 返回变量值，并去掉从开头到第一个 x 及其后面的第一个字符 ${var##*x} 返回变量值，并去掉从开头到最后一个 x, ## 表示贪婪模式 ${var##*x?} 返回变量值，并去掉从开头到最后一个 x 及其后面的第一个字符 ${var/x/y} 返回变量值，并把第一个 x 改为 y，可以配合通配符（? 或 *）使用 ${var//x/y} 返回变量值，并把所有 x 改为 y，可以配合通配符（? 或 *）使用 ${var/x/} 返回变量值，并把第一个 x 删除掉，可以配合通配符（? 或 *）使用 ${var} 示例 [root@localhost ~]# var=hello \u0026\u0026 echo ${var} hello ${var-str} 示例 [root@localhost ~]# v1=hello \u0026\u0026 echo ${v1-v2} hello [root@localhost ~]# v1=hello \u0026\u0026 echo ${v2-v1} v1 命令串有以下字符可以把多个命令组合使用： 在多个命令之间使用 | 字符：后面的命令输入是从前面的命令标准输入中获取的，简单说就是把前面的输出交给后面的命令。注意，不是所有命令都支持从标准输出中获取 在多个命令之间使用 \u0026 字符：多个命令并行执行，单个命令执行失败不会影响其他命令（除非有关联） 在多个命令之间使用 ; 字符，前面命令结束之后，无论成功还是失败，都会执行后面命令 在多个命令直接使用 \u0026\u0026 字符，前面命令执行成功后面的命令才会执行 在多个命令直接使用 || 字符，前面命令执行失败后面的命令才会执行 多个命令并行执行示例 # 终端1 [root@centos7 ~]# ping baidu.com \u0026 ping qq.com [1] 1895 PING baidu.com (39.156.69.79) 56(84) bytes of data. PING qq.com (183.3.226.35) 56(84) bytes of data. 64 bytes from 183.3.226.35 (183.3.226.35): icmp_seq=1 ttl=128 time=5.64 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=128 time=42.4 ms ... # 终端2 [root@centos7 ~]# pstree -p systemd(1)─┬─NetworkManager(722)─┬─dhclient(784) │ ├─{NetworkManager}(744) │ └─{NetworkManager}(754) ├─sshd(989)─┬─sshd(1708)───bash(1712)─┬─ping(1895) │ │ └─ping(1896) │ └─sshd(1876)───bash(1880)───pstree(1897) 串行执行多个命令示例 # 终端1 [root@centos7 ~]# ping baidu.com ; ping qq.com PING baidu.com (39.156.69.79) 56(84) bytes of data. 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=128 time=47.8 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=2 ttl=128 time=44.2 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=11 ttl=128 time=43.9 ms ^C ... 64 bytes from 123.151.137.18 (123.151.137.18): icmp_seq=6 ttl=128 time=42.7 ms 64 bytes from 123.151.137.18 (123.151.137.18): icmp_seq=7 ttl=128 time=42.0 ms ^C ... --- qq.com ping statistics --- 7 packets transmitted, 7 received, 0% packet loss, time 6019ms rtt min/avg/max/mdev = 41.955/42.210/42.708/0.228 ms # 终端2 [root@centos7 ~]# pstree -p 989 sshd(989)─┬─sshd(1876)───bash(1880)───pstree(1958) └─sshd(1923)───bash(1927)───ping(1957) 前面命令成功才执行后面命令示例 [root@centos7 ~]# mkkkk \u0026\u0026 echo \"ok\" -bash: mkkkk: command not found 配色","date":"2022-09-30","objectID":"/linuxBash/:2:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 修改字体颜色或背景颜色可以使用非常规字符序列的开始，以\\开关，以m结束，使用多种格式时使用;分隔 编码 效果 \\033[0 重新设置属性到缺省设置 \\033[1 设置粗体 \\033[2 设置一半亮度（模拟彩色显示器的颜色） \\033[4 设置下划线（模拟彩色显示器的颜色） \\033[5 设置闪烁 \\033[7 设置反向图象 \\033[22 设置一般密度 \\033[24 关闭下划线 \\033[25 关闭闪烁 \\033[27 关闭反向图象 \\033[30 设置黑色前景 \\033[31 设置红色前景 \\033[32 设置绿色前景 \\033[33 设置棕色前景 \\033[34 设置蓝色前景 \\033[35 设置紫色前景 \\033[36 设置青色前景 \\033[37 设置白色前景 \\033[38 在缺省的前景颜色上设置下划线 \\033[39 在缺省的前景颜色上关闭下划线 \\033[40 设置黑色背景 \\033[41 设置红色背景 \\033[42 设置绿色背景 \\033[43 设置棕色背景 \\033[44 设置蓝色背景 \\033[45 设置紫色背景 \\033[46 设置青色背景 \\033[47 设置白色背景 \\033[49 设置缺省黑色背景 \\033[2J 清除屏幕 \\033[0q 关闭所有的键盘指示灯 \\033[1q 设置“滚动锁定”指示灯 (Scroll Lock) \\033[2q 设置“数值锁定”指示灯 (Num Lock) \\033[3q 设置“大写锁定”指示灯 (Caps Lock) \\033[15:40H 把关闭移动到第15行，40列 \\007 发蜂鸣生beep ","date":"2022-09-30","objectID":"/linuxBash/:3:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 终端命令行颜色终端配置由 PS1 变量指定 [root@localhost ~]# echo $PS1 [\\u@\\h \\W]\\$ [root@localhost ~]# PS1=\"[\\e[32;1m\\u@\\e[35;1m\\h \\e[31;1m\\W]\\\\$ \" [root@localhost ~]# [root@localhost ~]# ls 这是一些转义字符格式效果： \\d ：代表日期，格式为weekday month date，例如：“Mon Aug 1” \\H ：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \\h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \\t ：显示时间为24小时格式，如：HH：MM：SS \\T ：显示时间为12小时格式 \\A ：显示时间为24小时格式：HH：MM \\u ：当前用户的账号名称 \\v ：BASH的版本信息 \\w ：完整的工作目录名称。家目录会以 ~代替 \\W ：利用basename取得工作目录名称，所以只会列出最后一个目录 \\# ：下达的第几个命令 \\$ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$ \\n ：新建一行 \\e[x;ym ：这就是控制字体和背景颜色的转义字符。其中 x为0~10，表示不同的字体样式（只有在 x 环境下生效），y为字体与背景颜色，如下表。当x为0时，可省略。如 [\\\\e[0;32m等效\\e[;32m 等效\\e[32m 颜色 字符颜色 背景颜色 黑色 30 40 红色 31 41 绿色 32 42 蓝色 34 44 紫色 35 45 白色 37 47 淡红色 33 43 淡蓝色 36 46 shell 脚本书写与规范shell脚本是为了实现某个目的，把一系列命令安装特定方式组织而成的文本，可以理解为一堆 shell 命令+逻辑语言。如果可以，Bash shell 是唯一指定的 shell 解释器。必要时使用 set 设置 shell 选项，使其 bash \u003cshell.sh\u003e 执行脚本时不会出现意外 脚本格式： （可选）第一行指定 shell 解释器。格式 #!/解释器路径1;解释器路径2;... 多个解释器存在时，优先级从左往右 （可选）其余以 # 开头的行或字符都会被当成注释忽略掉 （必须）执行的命令 示例：常见指定 shell 解释器方式 [root@centos7 ~]# cat /mnt/hgfs/note/centos/shell/shell脚本合集/ssc/ssc.sh #!/usr/bin/env bash ... [root@centos7 ~]# head /mnt/hgfs/note/centos/shell/shell脚本合集/vpn_centos.sh #!/bin/bash # [root@centos7 ~]# head /mnt/hgfs/note/centos/shell/shell脚本合集/l2tp.sh #!/usr/bin/env bash PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin 执行一个脚本方式： 增加相应的执行权限，使 ./脚本名称 其能够执行 指定 shell 解释器，如：bash 脚本文件名称 示例：以指定 shell 解释器（bash）执行脚本 [root@centos7 ~]# cat ping.sh ping baidu.com [root@centos7 ~]# [root@centos7 ~]# bash ping.sh PING baidu.com (39.156.69.79) 56(84) bytes of data. 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=1 ttl=128 time=47.1 ms 64 bytes from 39.156.69.79 (39.156.69.79): icmp_seq=2 ttl=128 time=48.9 ms ^C 示例：增加权限执行 [root@centos7 ~]# cat ping.sh #!/bin/bash # ping 百度 ping baidu.com [root@centos7 ~]# chmod +x ping.sh [root@centos7 ~]# ./ping.sh PING baidu.com (220.181.38.148) 56(84) bytes of data. 64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=128 time=43.7 ms 64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=2 ttl=128 time=45.5 ms 64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=3 ttl=128 time=43.3 ms ^C --- baidu.com ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2015ms rtt min/avg/max/mdev = 43.303/44.206/45.572/1.011 ms 规范我个人书写标准，不是必须遵循的规范。目的是使 shell 脚本简洁、易读 ","date":"2022-09-30","objectID":"/linuxBash/:4:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 缩进与文本长度所有缩进为 2 个空格，不使用制表符，如果是已有文件保持之前文件缩进，文本行不能过长，过长的文本和代码应该想办法换行 command1 \\ | command2 \\ | command3 \\ | command4 ","date":"2022-09-30","objectID":"/linuxBash/:5:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 文件名称和路径 脚本文件和库文件以 .sh 结尾 文件名称使用小写，多个单词之间使用 - 连接 尽量使用绝对路径，如果使用相对路径（当前）使用 ./ 开头，增加可读性 ","date":"2022-09-30","objectID":"/linuxBash/:6:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 注释每个文件开头都有以下注释信息： 时间 脚本功能 运行环境 作者及其联系方式 其他必要的声明 任何函数和库文件都必须含有以下注释，使其看注释就能知道怎么使用： 函数或库文件的功能描述 全局变量的修改和说明 使用参数说明 返回值 注释添加标签，给注释分类，这些分类需要在文件头部说明含义： TODO：表示临时功能，等待进一步完善。格式：# TODO(作者及其联系方式)：需要完善的信息 (TODO:序列号) FIXME：表示BUG，不能正常使用，等待修复。格式：# FIXME(作者及联系方式)：需要修复的BUG (HIXME:序列号) DEPRECATED：表示弃用，已经不使用，等待删除。格式：# DEPRECATED(作者以及联系方式)：弃用原因以及替代方案 (DEPRECATED:序列号) 其他自定义类型，也需要在文件开头出注释说明 ","date":"2022-09-30","objectID":"/linuxBash/:7:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 命令命令替换使用 $(command) 而不是 `command`，这样可读性更强 优先选择内建命令 exec 命令： source 命令：当前进程执行，而不是产生子进程执行 {}：当前进程中执行中跨号的命令 ()：子进程中执行大括号的命令 ","date":"2022-09-30","objectID":"/linuxBash/:8:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 条件表达式定义条件表达式以下方式 使用 test 命令 if test 表达式; then 执行操作 fi 使用 [ ... ] 或 `[[ … ]] if [ 表达式 ] ;then 执行操作 fi 注意以下情况： 当 test 命令不带表达式时，条件不成立 当 test 命令表达是为变量，且变量值为空时，条件不成立 所有的表达式[ ... ] 或 [[ … ]] 两边都有空格 [ ... ] 条件表达式不支持正则表达式 高等字符串比较需要使用双中括号[[ ... ]], 优先使用它，能减少错误发生且还支持正则表达式， 使用\u003c或\u003e时需要转义，否则视为重定向（高等表达式除外） 字符使用ASCII排序 普通的运算需要使用中括号[ ] 并不是所有的shell 支持高级字符串比较 字符串比较符 -n，-z 如果有变量要加双引号 如果测试字符串，尽量使用引号，而不是过滤字符串 某些命令能正常执行，但退出状态码不为 0 # 脚本 [root@centos7 ~]# cat if-then.sh #!/bin/bash if $(systemctl status firewalld) ; then echo \"命令执行成功\" fi # 命令执行成功，但 if 语句判断失败 [root@centos7 ~]# bash if-then.sh ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1) 判断条件结果有以下几种情况 表达式：表达式成立为真，否则为假 退出状态码：可执行文件退出状态码为 0 表示为真 true：单纯的三个字符，表示条件为成立 false：单词的四个字符，表示条件为不成立 ","date":"2022-09-30","objectID":"/linuxBash/:9:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 整数比较 整数比较符 描述 示例 -eq 等于 [ 1 -eq 1 ] 表达式成立 -gt 大于 [ 2 -gt 1 ] 表达式成立 -lt 小于 [ 2 -lt 1 ] 表达式不成立 -ne 不等于 [ 1 -ne 1 ] 表达式不成立 -ge 大于或等于 [ 2 -ge 1 ] 表达式成立 -le 小于或等于 [ 2 -le 1 ] 表达式成不成立 ","date":"2022-09-30","objectID":"/linuxBash/:9:1","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 字符串比较 比较符 描述 示例 = 等于 [ \"a\" = \"a\" ] 表达式成立 \u003e 大于 [ \"a\" \u003e \"c\" ] 表达式成立 \u003c 小于 [ \"a\" \u003e \"c\" ] 表达式不成立 \u003e= 大于或等于 [ \"a\" \u003e= \"c\" ] 表达式成立 \u003c= 小于或等于 [ \"a\" \u003e= \"c\" ] 表达式不成立 -n 长度不为0 [ -n \"s\" ] 表达式成立 -z 长度为0 [ -z \"a\" ] 表达式不成立 == 等于 [ \"a\" == \"a\" ] 表达式成立 != 不等于 [ \"s\" != \"d\" ] 表达式成立 =! 右边的扩展正则表达式包含左边的字符串 \"shell\" =~ [a-z]+ 表示成立 str 存在为真 [ dtr \"sdf\" ] 表达式成立 =~ 补充：判断右边的模式是否为左边字符串的子字符串，而不是判断右边的模式是否完全等于左边的字符串，且右边的扩展正则表达式不能被引号包围，否则当成字符串处理，不解析表达式 ","date":"2022-09-30","objectID":"/linuxBash/:9:2","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 文件测试符 测试符 描述 -e 文件或目录存在，表达式成立 -f 文件存在，表达式成立 -d 目录存在，表达式成立 -r 有读权限，表达式成立 -w 有写权限，表达式成立 -x 有执行权限，表达式成立 -s 文件存在且不为空，表达式成立 -O 文件存在且属主为当前用户，表达式成立 -G 文件存在且属主有当前用户，表达式成立 -nt 左边文件比右边文件新（创建日期），表达式成立 -ot 左边文件比右边文件旧（创建日期），表达式成立 ","date":"2022-09-30","objectID":"/linuxBash/:9:3","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 逻辑判断符 判断符 描述 \u0026\u0026 逻辑和，两边条件都成立，则表达式成立 ` ","date":"2022-09-30","objectID":"/linuxBash/:9:4","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 布尔运算符 布尔运算符 描述 ! 非关系，如果表达式成立，则返回 false （表示表达式不成立） -a 和关系，所有表达式成立，整个表达式才算成立 -o 或关系，其中一个表达式成立，整个表达式都成立 ","date":"2022-09-30","objectID":"/linuxBash/:9:5","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 逻辑语句; do , ; then 应该和 if/for/while 放在同一行。 else 应该单独一行，结束语句应该单独一行并且跟开始语句垂直对齐 ","date":"2022-09-30","objectID":"/linuxBash/:10:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" if 语句 # 如果条件判断成立，则执行相应的操作（可以有多个），如果条件不成立，则忽略相应操作 if 条件判断; then 执行操作 fi # if 条件判断 ; then 条件成立执行的相应操作 else 条件失败执行的相应操作 fi # 如果某个条件成立，则执行相应的操作，之后的操作不会再去判断 if 条件判断 ;then 执行操作1 elif 条件判断2 ;then 执行操作2 ... elif 条件判断 n ;then 执行操作 n fi # then可以换行，但then 前面的 ; 要去掉 if 条件判断1 then 执行操作1 elif 条件判断2 then 执行操作2 ... elif 条件判断 n then 执行操作 n else 所有条件都失败执行的操作 fi for dir in ${dirs_to_cleanup}; do if [[ -d \"${dir}/${ORACLE_SID}\" ]]; then log_date \"Cleaning up old files in ${dir}/${ORACLE_SID}\" rm \"${dir}/${ORACLE_SID}/\"* if [[ \"$?\" -ne 0 ]]; then error_message fi else mkdir -p \"${dir}/${ORACLE_SID}\" if [[ \"$?\" -ne 0 ]]; then error_message fi fi done ","date":"2022-09-30","objectID":"/linuxBash/:10:1","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" for 语句for 语句可以创建一个遍历一系列值的循环。每次迭代选区其中一个值来执行已经定义好的一组命令。格式如下 for 变量 in 变量取值列表; do 执行操作 done 第一次迭代使用列表中的第一值，第二次迭代使用第二次值，以此类推直到遍历所有的值，变量值会保持最后一次遍历的值 变量取值列表： 取值列表的值用IFS定义的变量值为分隔符 取值列表的值包含其他的值需要转义或双引号引用 变量取值列表的值可以是一个变量列表、变量数组、命令的执行输出 IFS（内部字段分隔符）默认情况下会把以下字符当成分隔符： 空格 制表符 换行符 IFS 可以添加变量 $IFS 指定分隔符，如下示例： IFS_1=$IFS # 先保留到 IFS_1 ，以便后续恢复到默认值使用 # 只有换行符才被认为是分隔符 IFS=$'\\n' ","date":"2022-09-30","objectID":"/linuxBash/:10:2","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" C 语言风格的 for 语句 示例 for (( i=1; i \u003c= 10; i++ )) do echo \"The next number is $i\" done 上述示例中，i++ 表示每次 +1，i 起始值为 1，每次遍历 i 都会 +1，直到 i 小于等于 10 才停止 示例 for (( a=1, b=10; a \u003c= 10; a++, b-- )) do echo \"$a - $b\" done 上述示例中，每次遍历 a+1，b-1 。直到 a = 10 才停止遍历 ","date":"2022-09-30","objectID":"/linuxBash/:10:3","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" while 语句while 语句当条件成立时，循环执行某些操作，直到条件不成立为止。条件不会自动改变，因此需要在 while 执行操作中要改变判断条件，否则会无限循环 语法格式： while :; do 执行操作（必须包含改变终结循环的条件） done 示例：语法2 [root@localhost ~]# cat while.sh #!/bin/bash while :; do echo read -p \"Please input username: \" USER [ -n \"$USER\" ] \u0026\u0026 break done 由于循环命令是在一个子shell中运行的，在while循环中被修改的变量是不能传递给父shell，且管道导向 while 循环中的隐式子shell使得追踪bug变得很困难。因此，不要使用管道符传递给while 语句或者使用 for 语句替代或使用以下方式 while read count filename; do total+=\"${count}\" last_file=\"${filename}\" done \u003c \u003c(your_command | uniq -c) 当然，不需要传递复杂的结果给父shell时可以使用while循环时可以使用管道符传递给 while 语句 cat /proc/mounts | while read src dest type opts rest; do if [[ ${type} == \"nfs\" ]]; then echo \"NFS ${dest} maps to ${src}\" fi done ","date":"2022-09-30","objectID":"/linuxBash/:10:4","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" until 语句until 语句与while相反，它是当条件不成立时，会循环执行相关操作，直到条件成立。判断条件也不会自动更新，需要在循环语句中更改判断条件，格式如下 util 判断条件 ; do 执行操作（必须包含改变条件判断的语句） done ","date":"2022-09-30","objectID":"/linuxBash/:10:5","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" case 语句case 是一种简洁的条件判断语句：更据变量取值，执行相应的代码块，如果都没有匹配的条件，则执行 * 号的代码块（可选）。语句格式如下： 使用 2 个空格缩进可选项 在同一行可选项的模式右圆括号之后和结束符 ;; 之前各需要一个空格 长可选项或者多命令可选项应该被拆分成多行，模式、操作和结束符 ;; 在不同的行 case \"${expression}\" in a) variable=\"...\" some_command \"${variable}\" \"${other_expr}\" ;; absolute) actions=\"relative\" another_command \"${actions}\" \"${other_expr}\" ;; *) error \"Unexpected expression '${expression}'\" ;; esac ## 简短格式 while getopts 'abf:v' flag; do case \"${flag}\" in a) aflag='true' ;; b) bflag='true' ;; f) files=\"${OPTARG}\" ;; v) verbose='true' ;; *) error \"Unexpected option ${flag}\" ;; esac done 示例 # 脚本内容 [root@localhost ~]# cat ssh.sh #!/binn/bash echo \"sshd服务选项：15:重启、16:启动、17:停止、18:状态\" read -p \"请输入选项：\" option case $option in 15) systemctl restart sshd ;; 16) ystemctl start sshd ;; 17) systemctl stop sshd ;; 18) systemctl status sshd ;; *) echo \"请输入正确的选项\" ;; esac # 执行脚本 [root@localhost ~]# bash ssh.sh sshd服务选项：15:重启、16:启动、17:停止、18:状态 请输入选项：19 请输入正确的选项 [root@localhost ~]# bash ssh.sh sshd服务选项：15:重启、16:启动、17:停止、18:状态 请输入选项：18 ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2020-06-06 07:13:21 CST; 1 day 23h ago Docs: man:sshd(8) man:sshd_config(5) ","date":"2022-09-30","objectID":"/linuxBash/:10:6","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 循环语句控制以下命令可以直接终止循环语句: break：终止循环。以下是示例 # 脚本 for (( a = 1; a \u003c 4; a++ )) do echo \"Outer loop: $a\" for (( b = 1; b \u003c 100; b++ )) do if [ $b -eq 5 ] # b = 5 时，终止当前 for 循环 then break fi echo \" Inner loop: $b\" done done # 执行效果 [root@centos7 shell]# bash break.sh Outer loop: 1 Inner loop: 1 Inner loop: 2 Inner loop: 3 Inner loop: 4 Outer loop: 2 Inner loop: 1 Inner loop: 2 Inner loop: 3 Inner loop: 4 Outer loop: 3 Inner loop: 1 Inner loop: 2 Inner loop: 3 Inner loop: 4 continue：跳出循环（忽略本次循环 [root@centos7 shell]# bash -v continue.sh #!/bin/bash for (( var1 = 1; var1 \u003c 15; var1++ )) do if [ $var1 -gt 5 ] \u0026\u0026 [ $var1 -lt 10 ] then continue # var = 5时忽略下面代码，直接执行下次循环 fi echo \"Iteration number: $var1\" done Iteration number: 1 Iteration number: 2 Iteration number: 3 Iteration number: 4 Iteration number: 5 Iteration number: 10 Iteration number: 11 Iteration number: 12 Iteration number: 13 Iteration number: 14 ","date":"2022-09-30","objectID":"/linuxBash/:10:7","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 脚本参数与选项","date":"2022-09-30","objectID":"/linuxBash/:11:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 位置参数位置参数表示脚本后面的字符串，这些位置参数以空格作为分隔符分别保存在 ${n} 中，n 必须是正整数或为 0。如果 n 小于 10 则可以不用 {} ： $0 表示脚本名称，如果带有路径，则显示路径+脚本名称 $1 表示脚本之后第 1 个字符串 $2 表示脚本之后第 2 个字符串 … $9 表示脚本之后第 9 个字符串 ${10} 表示脚本之后第 10 个字符串 … 示例 # 脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash echo $0--${1}+$2+$3+$4+$5+$6+$7+$8+${9}+${10} # 执行带路径的脚本 [root@centos7 shell]# bash ~/shell/test.sh q w e r t y u i o p /root/shell/test.sh--q+w+e+r+t+y+u+i+o+p # 执行不带路径的脚本 [root@centos7 shell]# bash test.sh q w e r t y u i o p test.sh--q+w+e+r+t+y+u+i+o+p ","date":"2022-09-30","objectID":"/linuxBash/:11:1","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 脚本参数数量脚本参数数量保存在 $# 中，${!#} 表示最后一个位置参数 # 脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash echo \"脚本参数总共有 $# 个，最后一个参数是 ${!#}\" # 执行脚本 [root@centos7 shell]# bash test.sh s f l 脚本参数总共有 3 个，最后一个参数是 l ","date":"2022-09-30","objectID":"/linuxBash/:11:2","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 抓取所有脚本参数$* 会把脚本参数当成一个整体，$@ 会把所有所有脚本参数保存起，单个处理 示例 [root@centos7 shell]# cat test.sh #!/bin/bash echo count=1 for param in \"$*\" do echo \"\\$* Parameter #$count = $param\" count=$[ $count + 1 ] done echo count=1 for param in \"$@\" do echo \"\\$@ Parameter #$count = $param\" count=$[ $count + 1 ] done ","date":"2022-09-30","objectID":"/linuxBash/:11:3","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 脚本参数偏移位shift n 命令可以将每个脚本参数向左移动指定 n 个（缺省为1）位置。如 $3 向左偏移 1 位为 $2 ，$1 再向左偏移则会被删除，无法恢复 # 脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash echo count=1 while [ -n \"$1\" ] do echo \"Parameter #$count = $1\" count=$[ $count + 1 ] shift done # 执行脚本 [root@centos7 shell]# bash test.sh 30 20 10 9 Parameter #1 = 30 Parameter #2 = 20 Parameter #3 = 10 Parameter #4 = 9 ","date":"2022-09-30","objectID":"/linuxBash/:11:4","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 查找选项如果是处理单个脚本参数或对脚本参数执行顺序无要求的情况，可以使用以下方式 # 脚本内容 [root@centos7 shell]# cat option.sh #!/bin/bash while [ -n \"$1\" ] do case \"$1\" in -a) echo \"执行操作a\" ;; --list) shift case \"$1\" in all) echo \"执行操作 list all\" ;; user) echo \"执行操作 list user\" ;; *) echo \"请出入正确的参数\" esac ;; *) echo \"输出帮助信息\" break ;; esac shift done # 执行效果 [root@centos7 shell]# bash option.sh --list all -a --list -p 执行操作 list all 执行操作a 请出入正确的 --list 参数 ","date":"2022-09-30","objectID":"/linuxBash/:11:5","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 处理合并的选选项getopt 命令行自动解析脚本选项和参数，该命令会把空格作为分隔符，且处理带空格或引号的参数值有点麻烦 [root@centos7 shell]# getopt ab:cd: -a -b test -cd test2 test3 -a -b test -c -d test2 -- test3 上述示例中: ab:cd ：表示可用选项有 -a, -b, -c, -d；冒号表示之前的选项有参数（-b test） ；不带 - 开头的字符串视为参数，如果出现 - 之后的字母不是 a,b,c,d 之一，则报错 在脚本中使用 getopt 命令需要把输出传递给 set -- ， 示例 #脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash set -- $(getopt -q ab:cd \"$@\") echo while [ -n \"$1\" ] do case \"$1\" in -a) echo \"Found the -a option\" ;; -b) param=\"$2\" echo \"Found the -b option, with parameter value $param\" shift ;; -c) echo \"Found the -c option\" ;; --) shift break ;; *) echo \"$1 is not an option\";; esac shift done count=1 for param in \"$@\" do echo \"Parameter #$count: $param\" count=$[ $count + 1 ] done # 执行效果 [root@centos7 shell]# bash test.sh -a -b test1 -cd test2 test3 test4 Found the -a option Found the -b option, with parameter value 'test1' Found the -c option -d is not an option Parameter #1: 'test2' Parameter #2: 'test3' Parameter #3: 'test4' getopts 命令能够和已有的 shell 参数变量配合使用，每次调用时，只处理命令行上检测的第一个参数，处理完所有参数之后，会返回一个大于 0 的退出状态码 getopts 命令格式：getopts 有效选项 选项变量 示例： [root@centos7 shell]# cat test.sh #!/bin/bash while getopts :ab:c opt do case \"$opt\" in a) echo \"Found the -a option\" ;; b) echo \"Found the -b option, with value $OPTARG\";; c) echo \"Found the -c option\" ;; *) echo \"Unknown option: $opt\";; esac done # 执行效果 [root@centos7 shell]# ./test.sh -acb test1 Found the -a option Found the -c option Found the -b option, with value test1 上述示例中 opt 变量值为每次迭代的选项，OPTARG 变量值为对应的选项 示例： # 脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash while getopts :ab:cd opt do case \"$opt\" in a) echo \"Found the -a option\" ;; b) echo \"Found the -b option, with value $OPTARG\" ;; c) echo \"Found the -c option\" ;; d) echo \"Found the -d option\" ;; *) echo \"Unknown option: $opt\" ;; esac done shift $[ $OPTIND - 1 ] echo count=1 for param in \"$@\" do echo \"Parameter $count: $param\" count=$[ $count + 1 ] done # 执行效果 [root@centos7 shell]# ./test.sh -a -b test1 -d test2 test3 test4 Found the -a option Found the -b option, with value test1 Found the -d option Parameter 1: test2 Parameter 2: test3 Parameter 3: test4 上述示例中，while 语句只处理了 getopts 命令分解的选项和参数，没处理的选项和参数由 for 语句处理 ","date":"2022-09-30","objectID":"/linuxBash/:11:6","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 标准化选项命令选项没有标准化，以下是 Linux 命令中部分选项常见的含义，通常见到选项都大概知道是什么意思 常见选项 描述 -a 显示所有对象 -c 生成一个计数 -d 指定一个目录 -e 扩展一个对象 -f 指定读入数据的文件 -h 显示帮助信息 -i 忽略文本大小写 -l 产生输出的长格式版本 -n 批处理 -o 重定向输出 -q 静默模式 -r 递归目录 -s 静默模式 -v 详细输出 -x 排出某个对象 -y 自动确认 ","date":"2022-09-30","objectID":"/linuxBash/:11:7","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 函数函数是一个脚本代码块，可以在脚本中引用该函数的代码块，可以有效避免定义重复的代码块，bash shell 会将函数当成小型脚本，因此，可以把函数当成脚本对待；函数也可以向脚本那样在命令行中创建使用或写入 bashrc文件 函数名使用 function 字母开头，尽量使用单词（前面的关键字 function 可选的，但可以增加识别度） 使用 :: 区分 package 函数定义在常用变量和环境变量声明下面，函数之间不能使用可执行代码 ## Single function FunctionFunc() { ... } ## Part of a package FunctionPackage::my_func() { ... } bash shell 中有以下方式创建函数，函数名称在脚本中，必须是唯一的 # 第一种 function 函数名称 { 执行操作 } # 第二种 函数名称 (){ 执行操作 } ","date":"2022-09-30","objectID":"/linuxBash/:12:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 引用函数函数定义之后，直接使用函数名称就能引用函数代码块，函数定义必须在调用函数之前，每次调用函数 shell 脚本都会产生一个新的子进程运行函数 示例 function func1 { echo \"This is an example of a function\" } count=1 while [ $count -le 5 ] do func1 count=$[ $count + 1 ] done echo \"This is the end of the loop\" func1 echo \"Now this is the end of the script\" 函数的执行输出可以赋值给变量 function dbl { read -p \"Enter a value: \" value echo $[ $value * 2 ] } result=$(dbl) echo \"The new value is $result\" ","date":"2022-09-30","objectID":"/linuxBash/:12:1","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 函数的退出状态码函数执行完之后，会返回一个退出状态码。默认情况下，函数退出状态码是函数最后一条命令的退出状态码 func1() { echo \"trying to display a non-existent file\" ls -l badfile } echo \"testing the function: \" func1 echo \"The exit status is: $?\" bash shell 中，return 命令可以指定函数的退出状态码 function dbl { read -p \"Enter a value: \" value echo \"doubling the value\" return $[ $value * 2 ] } dbl echo \"The new value is $?\" ","date":"2022-09-30","objectID":"/linuxBash/:12:2","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 函数中的变量函数可以使用标准的参数环境变量: 调用函数时可以指定位置参数（$1 $2 之类的） 函数中可以使用脚本中定义的变量 函数中修改或定义的变量对整个脚本都是有效的，可以使用 local 变量名=变量值 的方式定义变量，使该变量只在函数内生效 ","date":"2022-09-30","objectID":"/linuxBash/:12:3","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 函数中的数组将数组变量当成单个参数传递给函数时，函数只会读取数组中第一个值。只有把数组的值分解为单个值，然后将这些值作为函数参数使用，在函数内部可以把所有的参数值重新合成一个新的变量。反之，如果要从函数向脚本传递数组也是在函数内部分解，再到脚本组合 示例：脚本向函数传递数组 function addarray { local sum=0 local newarray newarray=($(echo \"$@\")) for value in ${newarray[*]} do sum=$[ $sum + $value ] done echo $sum } myarray=(1 2 3 4 5) echo \"The original array is: ${myarray[*]}\" arg1=$(echo ${myarray[*]}) result=$(addarray $arg1) echo \"The result is $result\" 示例：函数向脚本传递数组 function arraydblr { local origarray local newarray local elements local i origarray=($(echo \"$@\")) newarray=($(echo \"$@\")) elements=$[ $# - 1 ] for (( i = 0; i \u003c= $elements; i++ )) { newarray[$i]=$[ ${origarray[$i]} * 2 ] } echo ${newarray[*]} } myarray=(1 2 3 4 5) echo \"The original array is: ${myarray[*]}\" arg1=$(echo ${myarray[*]}) result=($(arraydblr $arg1)) echo \"The new array is: ${result[*]}\" ","date":"2022-09-30","objectID":"/linuxBash/:12:4","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 函数递归函数局部变量的特性之一的自成体系，除了从脚本命令行处获取变量，自成体系的函数不需要使用任何外部资源。因此，函数可以递归使用，也就是函数可以调用其他函数，也可以调用自己 通常递归函数都有一个最终可以迭代的基准值，许多高级算法用递归对复杂的方程进行逐级规约，指定基准值定义的级别 示例：x=x(x-1)! 方程 function factorial { if [ $1 -eq 1 ] then echo 1 else local temp=$[ $1 - 1 ] local result='factorial $temp' echo $[ $result * $1 ] fi } ","date":"2022-09-30","objectID":"/linuxBash/:12:5","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 函数库函数库文件包含很多函数，其他脚本可以引用函数库文件，不需要重复定义函数 定义函数库文件很简单，只需要将函数写入一个文本文档中，在脚本中引用函数库文件时当成可执行文件使用（注意上下文，文件权限等等） 示例 # 函数库文件 [root@centos7 shell]# cat function.txt function addem { echo $[ $1 + $2 ] } function multem { echo $[ $1 * $2 ] } function divem { if [ $2 -ne 0 ] then echo $[ $1 / $2 ] else echo -1 fi } # 脚本 [root@centos7 shell]# cat test.sh . /root/shell/function.txt # 点(source命令的别名) 和库文件之间是有空格的 # 以下 3 个命令等效上述命令 # . ./function.txt # source /root/shell/function.txt # source ./function.txt result=$(addem 10 15) echo \"The result is $result\" ","date":"2022-09-30","objectID":"/linuxBash/:12:6","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" GUN shtool 函数库GNU shtool是将小型但非常稳定且可移植的shell脚本编译为单个shell工具的工具。多年来，各种成分已成功用于各种免费软件项目中。编译后的shtool程序旨在在其他免费软件包的源代码树中使用。在那里，它可以完成与构建和安装此软件包有关的各种（通常是非便携式的）任务。 下载安装包 [root@centos7 pag]# tar -zxf /mnt/hgfs/note/other/shtool-2.0.8.tar.gz -C ./ [root@centos7 pag]# cd shtool-2.0.8 安装 [root@centos7 shtool-2.0.8]# ./configure \u0026\u0026 make \u0026\u0026 make install Configuring GNU shtool (Portable Shell Tool), version 2.0.8 (18-Jul-2008) Copyright (c) 1994-2008 Ralf S. Engelschall \u003crse@engelschall.com\u003e checking whether make sets $(MAKE)... yes checking for perl interpreter... /usr/bin/perl ... 查看帮助信息 [root@centos7 ~]# shtool --help This is GNU shtool, version 2.0.8 (18-Jul-2008) Copyright (c) 1994-2008 Ralf S. Engelschall \u003crse@engelschall.com\u003e Report bugs to \u003cbug-shtool@gnu.org\u003e Usage: shtool [\u003coptions\u003e] [\u003ccmd-name\u003e [\u003ccmd-options\u003e] [\u003ccmd-args\u003e]] Available global \u003coptions\u003e: -v, --version display shtool version information -h, --help display shtool usage help page (this one) -d, --debug display shell trace information -r, --recreate recreate this shtool script via shtoolize ... ","date":"2022-09-30","objectID":"/linuxBash/:12:7","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 退出状态码shell 中每个命令都使用退出状态码告知 shell 运行完毕。退出状态码为 0 到 255 的整数值，命令执行结束之后，退出状态码会保存在 $? 这个变量中。退出状态码是没有标准化的，也就是说没有统一的标准，因此在 exit 命令中随意指定，但通常状态码 0 表示成功，非 0 表示失败。当 exit N 指定退出状态码(N)大于 255 时，退出状态码=N/256的余数，如 25500/256=99······156，退出态码为 156 示例： [root@centos7 ~]# cat exit.sh #!/bin/bash var1=10 var2=30 var3=$[$var1 + $var2] exit $var3 [root@centos7 ~]# bash exit.sh [root@centos7 ~]# [root@centos7 ~]# echo $? 40 ","date":"2022-09-30","objectID":"/linuxBash/:13:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 重定向与文件描述符Linux 系统将每个对象当成文件处理，包括输入和输出。linux 用文件描述符来标识文件对象。以下文件描述符和输入输出相关 文件描述符 缩写 描述 0 STDIN 标准输入（可以理解为键盘） 1 STDOUT 标准输出（可以理解为屏幕） 2 STDERR 标准错误输出 (可以理解为错误信息输出到屏幕） lsof -p $$ 命令可以查看当前进程打开的文件描述符 [root@centos7 shell]# lsof -p $$ COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME ... bash 1734 root 0u CHR 136,0 0t0 3 /dev/pts/0 bash 1734 root 1u CHR 136,0 0t0 3 /dev/pts/0 bash 1734 root 2u CHR 136,0 0t0 3 /dev/pts/0 bash 1734 root 255u CHR 136,0 0t0 3 /dev/pts/0 上述示例中，u 表示文件描述符，其中 255 是重定向时保存的副本 重新向或追加可以替换原来的标准输入或标准输出，重定向或追加之前标准输出的文件描述符可以省略，全部重定向或追加可以使用 \u0026 替代 示例：重定向正确输出到文件 [root@centos7 ~]# ls \u003efile # 或以下命令 [root@centos7 ~]# ls 1\u003efile # 查看输出的内容 [root@centos7 ~]# cat file anaconda-ks.cfg file pag shell 示例：重定向正确输出到文件，错误信息会继续输出到屏幕 [root@centos7 ~]# systemctl status firewa sshd \u003efile Unit firewa.service could not be found. [root@centos7 ~]# [root@centos7 ~]# cat file ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) 示例：重定向错误输出到文件 [root@centos7 ~]# cat filea 2\u003efile [root@centos7 ~]# cat file cat: filea: No such file or directory 示例：重定向错误输出到文件，正确信息会继续输出到屏幕 [root@centos7 ~]# systemctl status firewa sshd 2\u003efile ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) Active: active (running) since Tue 2020-06-09 08:53:57 CST; 22min ago ... [root@centos7 ~]# cat file Unit firewa.service could not be found. 示例：所有输出信息都重定向到文件 [root@centos7 ~]# systemctl status firewa sshd \u0026\u003efile # 等效上面的命令，2\u003e\u00261 表示错误的信息重定向到标准输出 “1”。1 的信息也重定向到 文件 [root@centos7 ~]# systemctl status firewa sshd \u003efile 2\u003e\u00261 # 等效上面的命令 [root@centos7 ~]# systemctl status firewa sshd 2\u003efile \u003e\u00262 ","date":"2022-09-30","objectID":"/linuxBash/:14:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" cat 和 EOF以相同字符开头和结尾（结尾可以使用 \u003cCtrl+d\u003e ）。通常是 EOF 可以自定义。通常和 cat 命令使用 示例：从标准输入追加到 cat 命令再重定向到 file [root@centos7 ~]# cat \u003e file \u003c\u003cEOF # 等效上面的命令 [root@centos7 ~]# cat \u003c\u003cEOF\u003efile \u003e fds \u003e fds \u003e EOF [root@centos7 ~]# cat file fds fds 向文件重定向内容（会覆盖之前的内容） # 文件内容 [root@localhost ~]# ls a.out a.out # 内容重定向到文件 # [root@localhost ~]# cat \u003c\u003c EOF \u003ea.out #等效下述命令 [root@localhost ~]# cat \u003ea.out \u003c\u003c EOF \u003e 1-abc \u003e 2-abc \u003e EOF # 文件内容 [root@localhost ~]# cat a.out 1-abc 2-abc 向文件追加内容 # 文件内容 [root@localhost ~]# cat a.out 1-abc 2-abc # 内容追加到文件 # [root@localhost ~]# cat \u003e\u003e a.out \u003c\u003c EOF #等效下述命令 [root@localhost ~]# cat \u003c\u003c EOF \u003e\u003ea.out \u003e 3-abc \u003e 4-abc \u003e EOF # 文件内容 [root@localhost ~]# cat a.out 1-abc 2-abc 3-abc 4-abc ","date":"2022-09-30","objectID":"/linuxBash/:14:1","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 脚本中的重定向在 shell 脚本中，除了上述的标准使用，还可以在语法格式（如：if语句 for 语句等）、函数等重定向输出或输入 示例：while 语句中使用重定向 # 脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash count=1 cat /var/log/maillog | while read line do echo \"Line $count: $line\" count=$[ $count + 1] done \u003efile echo \"Finished processing the file\" # 执行效果 [root@centos7 shell]# ./test.sh Finished processing the file # 重定向文件的内容 [root@centos7 shell]# cat file Line 1: Jun 7 21:37:05 centos7 postfix/postfix-script[1275]: starting the Postfix mail system Line 2: Jun 7 21:37:05 centos7 postfix/master[1277]: daemon started -- version 2.10.1, configuration /etc/postfix Line 3: Jun 8 08:51:17 centos7 postfix/postfix-script[1282]: starting the Postfix mail system Line 4: Jun 8 08:51:17 centos7 postfix/master[1284]: daemon started -- version 2.10.1, configuration /etc/postfix Line 5: Jun 9 04:34:32 centos7 postfix/postfix-script[1194]: starting the Postfix mail system Line 6: Jun 9 04:34:32 centos7 postfix/master[1196]: daemon started -- version 2.10.1, configuration /etc/postfix Line 7: Jun 9 08:54:00 centos7 postfix/postfix-script[1282]: starting the Postfix mail system Line 8: Jun 9 08:54:00 centos7 postfix/master[1287]: daemon started -- version 2.10.1, configuration /etc/postfix 示例：脚本从文件中读取内容输入 [root@centos7 shell]# cat test.sh #!/bin/bash exec 0\u003c /var/log/maillog count=1 while read line do echo \"Line $count: $line\" count=$[ $count + 1] done echo \"Finished processing the file\" [root@centos7 shell]# ./test.sh Line 1: Jun 7 21:37:05 centos7 postfix/postfix-script[1275]: starting the Postfix mail system Line 2: Jun 7 21:37:05 centos7 postfix/master[1277]: daemon started -- version 2.10.1, configuration /etc/postfix Line 3: Jun 8 08:51:17 centos7 postfix/postfix-script[1282]: starting the Postfix mail system Line 4: Jun 8 08:51:17 centos7 postfix/master[1284]: daemon started -- version 2.10.1, configuration /etc/postfix Line 5: Jun 9 04:34:32 centos7 postfix/postfix-script[1194]: starting the Postfix mail system Line 6: Jun 9 04:34:32 centos7 postfix/master[1196]: daemon started -- version 2.10.1, configuration /etc/postfix Line 7: Jun 9 08:54:00 centos7 postfix/postfix-script[1282]: starting the Postfix mail system Line 8: Jun 9 08:54:00 centos7 postfix/master[1287]: daemon started -- version 2.10.1, configuration /etc/postfix 脚本输出到文件，不输出到屏幕（标准输出和错误输出） alog.txt exec 1\u003e alog.txt # 相同文件 exec 2\u003e\u00261 # 错误输出到另一个文件 exec 2\u003e blog.txt 脚本输出到文件，也输出到屏幕（标准输出和错误输出） exec 1\u003e \u003e(tee alog.txt) # 错误输出到相同文件 exec 2\u003e\u00261 # 错误输出到另一个文件 exec 2\u003e \u003e(tee blog.txt \u003e\u00262) 脚本输出到文件，正确输出到屏幕（标准出和错误输出都保存到文件） exec 1\u003e \u003e(tee alog.txt) # 错误输出到相同文件 exec 2\u003e \u003e(tee alog.txt \u003e /dev/null) # 错误输出到另一个文件 exec 2\u003eblog.txt 脚本输出到文件，错误输出到屏幕（标准输出和错误输出都保存到文件），不能打乱顺序 exec 3\u003e\u00261 exec 1\u003e \u003e(tee alog.txt \u003e /dev/null) exec 2\u003e \u003e(tee alog.txt \u003e\u00263) # 或者使用以下方式 exec 1\u003ealog.txt exec 2\u003e \u003e(tee alog.txt \u003e\u00262) ","date":"2022-09-30","objectID":"/linuxBash/:14:2","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 自定义文件描述符每个进程可以打开 9 个文件描述符，其中 0-2 已经被 bash shell 保留了，剩下的 3-8 可以使用 exec 命令分配 示例 [root@centos7 shell]# cat test.sh #!/bin/bash exec 0\u003c /var/log/maillog exec 3\u003e file count=1 while read line do echo \"Line $count: $line\" count=$[ $count + 1] done \u003e\u00263 echo \"Finished processing the file\" 示例：重定向文件描述符 exec 3\u003e\u00261 exec 1\u003etest14out echo \"This should store in the output file\" echo \"along with this line.\" exec 1\u003e\u00263 echo \"Now things should be back to normal\" 示例：创建输入文件描述符 exec 6\u003c\u00260 exec 0\u003c testfile count=1 while read line do echo \"Line #$count: $line\" count=$[ $count + 1 ] done exec 0\u003c\u00266 read -p \"Are you done now? \" answer case $answer in Y|y) echo \"Goodbye\";; N|n) echo \"Sorry, this is the end.\";; esac 示例：创建读写文件描述符 exec 3\u003c\u003e testfile read line \u003c\u00263 echo \"Read: $line\" echo \"This is a test line\" \u003e\u00263 ","date":"2022-09-30","objectID":"/linuxBash/:14:3","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 关闭自定义文件描述符一旦关闭了文件描述符，就不能在脚本中向它写入任何数据，否则shell会生成错误消息。此外。如果随后在脚本中打开了同一个输出文件，shell会用一个新文件来替换已有文件。因此输出数据就会覆盖已有文件 示例 exec 3\u003e test17file echo \"This is a test line of data\" \u003e\u00263 exec 3\u003e\u0026- cat test17file exec 3\u003e test17file echo \"This'll be bad\" \u003e\u00263 交互式脚本","date":"2022-09-30","objectID":"/linuxBash/:14:4","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" read 命令read 命令能从键盘或文件中接收输入，并将接收到输入保存在变量中，可以指定多个变量。如果没有指定变量，则保存在环境变量 REPLY 中 常见选项 -p 指定提示符 -t 指定超时时间（秒），在这时间之后还没接收到数据就退出并返回一个非 0 的状态码 -n 指定数据长度，当达到指定字符串长度时，自动提交数据，不用等待用户输入 \u003cEnter\u003e 键 -s 隐藏用户的输入，用户输入的数据不会在屏幕中显示 示例 # 脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash echo -n \"Enter your name: \" read name echo \"Hello $name, welcome to my program. \" # 执行效果 [root@centos7 shell]# ./test.sh Enter your name: user01 # 会等待用户输入 Hello user01, welcome to my program. 上述示例中，echo -n 取消了换行，等待用户输入之后（回车），把输入的内容赋值到变量中，该脚本还可以使用以下方式： # 脚本内容 [root@centos7 shell]# cat test.sh #!/bin/bash read -p \"Enter your name: \" name echo \"Hello $name, welcome to my program. \" ","date":"2022-09-30","objectID":"/linuxBash/:15:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" select 语句在select执行时，会根据list数组给出选择菜单，用户选择后的结果保存在$var变量中，然后执行statements语句。执行完成后，再次给出菜单，等待用户选择。如果用户想跳出选择循环，需要在循环体中根据条件增加break语句 示例 #!/bin/bash fruits=( \"apple\" \"pear\" \"orange\" \"watermelon\" ) echo \"Please guess which fruit I like :\" select var in ${fruits[@]} do if [ $var = \"apple\" ]; then echo \"Congratulations, you are my good firend!\" break else echo \"Try again!\" fi done 重定向错误信息将所有的错误信息都应该被导向STDERR，这样实际问题中分离出正常状态变得更容易 err() { echo \"[$(date +'%Y-%m-%dT%H:%M:%S%z')]: $@\" \u003e\u00262 } if ! do_something; then err \"Unable to do_something\" exit 1 fi 分离输出信息把不同的输出信息重定向到不同的文件标示符 示例：指定错误信息 if [ \"${!var:-}\" ] \u0026\u0026 [ \"${!fileVar:-}\" ]; then echo \u003e\u00262 \"error: both $var and $fileVar are set (but are exclusive)\" exit 1 fi 判断用户身份判断用户身份是否为超级管理员 [ $(id -u) != \"0\" ] \u0026\u0026 { echo -e \"\\033[31m错误：当前用不是管理员用户\\033[0m\" ; exit 1; } # 或 if [ $(id -u) != \"0\" ]; then echo \"错误：当前用不是超级管理员，必须要 root 用户才能执行此脚本\" exit 1 fi 提示错误过程 示例 if [ \"$(ls -A)\" ]; then echo \"WARNING: $PWD is not empty - press Ctrl+C now if this is an error!\" \u003e\u00262 (set -x; ls -A; sleep 10) \u003e\u00262 fi 使用 expr 命令处理字符串","date":"2022-09-30","objectID":"/linuxBash/:16:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 得到字符串长度直接使用 expr 命令 [root@localhost ~]# expr length \"this is a test\" 14 [root@localhost ~]# expr \"sfdsafsd\" : \".*\" 8 此外可以使用变量替换表达式：$echo ${#variable} zhyfly: ~$ x=\"this is a test\" zhyfly: ~$ echo ${#x} 14 ","date":"2022-09-30","objectID":"/linuxBash/:17:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 查找字符串子串位置格式：expr index \"$variable\" \"substring\" [root@localhost ~]# expr index \"this is a test\" \"h\" 2 [root@localhost ~]# expr index \"this is a test\" \"t\" 1 ","date":"2022-09-30","objectID":"/linuxBash/:18:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 获取字符串子串格式：expr substr \"$variable\" startposition length [root@localhost ~]# expr substr \"variable\" 2 3 ari [root@localhost ~]# expr substr \"variable\" 1 4 vari 此外可以使用变量替换表达式：echo ${variable:position:length} zhyfly: ~$ x=\"this is a test\" zhyfly: ~$ echo ${x:1:5} his i ","date":"2022-09-30","objectID":"/linuxBash/:19:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["linux"],"content":" 获取字符串子串长度格式：expr match \"string\" \"regex\" 如果有匹配则反回其长度，否则返回 0。非从字符串头部开始匹配也是反回 0 [root@localhost ~]# expr match \"abcabab\" \"ac\" 0 [root@localhost ~]# expr match \"abcabcab\" \"a.*b\" 8 [root@localhost ~]# expr match \"abcabcab\" \"b.*b\" 0 ","date":"2022-09-30","objectID":"/linuxBash/:20:0","tags":["shell"],"title":"bash shell脚本","uri":"/linuxBash/"},{"categories":["k8s"],"content":" 运行环境： k8s:1.14 Rocky Linux: 8.6 内容来自以下文档： k8s 官方文档: API 概述 k8s 官方文档: 使用 Kubernetes API 访问集群 k8s 官方文档: Kubernetes API 概念 k8s 官方文档: API 访问控制 k8s 官方文档: 访问集群 A_Zeee: 调用k8s API API 概念k8s API 是通过 HTTP 协议提供基于资源(RESTful) 的编程接口，可以通过 HTTP 请示方法（POST、PUT、PATCH、DELETE、GET）检索、创建、更新和删除主要资源。 k8s 通过使用常见的资源术语来描述 API 概念： 资源类型（Resource Type）：是 URL 中使用的名称，如 pod、services 等 类别（Kind）：是所有资源类型都有一个具体的表示 集合（Collection）：是资源实例的列表 资源（Resource）或对象（Object）：资源类型的单个实例 子资源（sub-resources）：某些资源类型包含一个或多个资源，些资源表示为资源下的 URI 路径 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:0:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" API 版本API 有以下版本 Alpha: 版本名称包含 alpha（例如：v1alpha1）: 软件可能会有 BUG。某些特性可能默认禁用。 对某个特性的支持可能会随时被删除 可能在以后的软件版本中以不兼容的方式更改 由于缺陷风险增加和缺乏长期支持，建议该软件仅用于短期测试集群。 Beta： 版本名称包含 beta（例如：v2beta3） 软件被很好的测试过。启用某个特性被认为是安全的。 特性默认开启。 尽管一些特性会发生细节上的变化，但它们将会被长期支持。 该版本的软件不建议生产使用。 后续发布版本可能会有不兼容的变动。 后续版本发生不兼容的方式改变时，将提供迁移说明。 Stable: 版本名称如 vX，其中 X 为整数。后续很多版本的发布软件中。 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:1:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" API 组API 组 能够简化对 k8s API 的扩展。 API 组信息出现在 REST 路径中，也出现在序列化对象的 apiVersion 字段中。 可以通过在 API 服务器上设置 --runtime-config 参数来启用或禁用（需要重新 api 服务）。格式为 \u003ckey\u003e[=true | false ]，当缺省值时默认为 true ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:2:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" API 持久化k8s 通过 API 资源来将序列化的状态写到 etcd 中存储 资源 URI资源 URI 地址有以下路径： /apis/GROUP/VERSION/RESOURCETYPE: 返回指定集群资源类型的资源的集合 GET /apis/GROUP/VERSION/RESOURCETYPE/NAME: 返回指定集群资源类型下名称为 NAME 的资源 GET /apis/GROUP/VERSION/RESOURCETYPE: 返回所有名称空间中指定资源类型的全部实例的集合 GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE: 返回名称空间（NAMESPACE）内给定资源类型的全部实例的集合 GET /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE/NAME: 反回名称空间（NAMESPACE）中给定资源类型的名称为 NAME 的实例 API 服务访问控制访问 k8s API 服务有以下方式： REST API：通过 http 直接访问API服务或使用 kubectl proxy 命令代理 api 服务（也是 HTTP 方式） kubeconfig 文件：应用程序通过 kubeconfig 文件定位和验证 API 服务器。如 kubectl 访问 API 大致分为以下步骤： 身份认证 鉴权: 检查是否有操作权限 准入控制 审计 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:3:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 用户认证k8s 中只有服务账号并不包含用来代表普通用户账号的对象，因此普通用户的信息无法通过 API 调用添加到集群中： 服务账号是 k8s API 所管理的用户。它们被绑定到特定的名字空间， 或者由 API 服务器自动创建，或者通过 API 调用创建。服务账号与一组以 Secret 保存的凭据相关，这些凭据会被挂载到 Pod 中，从而允许集群内的进程访问 Kubernetes API 普通用户账号： 普通用户的信息无法通过 API 调用添加到集群中。但能够提供由集群的证书机构签名的合法证书的用户是通过身份认证的用户。 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:4:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 服务账户k8s 区分用户账号和服务账号的概念，主要基于以下原因： 用户账号是针对操作人员，服务账户是针对 pod 中的进程 用户账户是集群域全局的，服务账户是名称空间域的 用户账户通常涉及到复杂的业务流程。服务账号创建有意做得更轻量，允许集群用户为了具体的任务创建服务账号以遵从权限最小化原则 对操作人员和服务账号审计所考虑的因素可能不同 服务账号通常用于 pod 内进程与 k8s API 服务连接时的身份验证。 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:5:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 身份认证策略k8s 可能启用一个或多个身份认证模块时，API 服务器并不保证身份认证模块的运行顺序。当有一个成功地对请求完成身份认证的模块会直接做出评估决定。 对于所有通过身份认证的用户，system:authenticated 组都会被添加到其组列表中。 k8s 身份认证插件使用客户准备端证书（X509）、令牌（Bearer Token）、认证代理（Proxy） 来认证 API 请求的身份。HTTP 请求发给 API 服务器时，插件会将以下属性关联到请求本身。这些属性对于身份认证系统而言都是不透明的， 只有被鉴权组件解释过之后才有意义： 用户名：用来辩识最终用户的字符串。常见的值可以是 kube-admin 或 jane@example.com。 用户 ID：用来辩识最终用户的字符串，旨在比用户名有更好的一致性和唯一性。 用户组：取值为一组字符串，其中各个字符串用来标明用户是某个命名的用户逻辑集合的成员。 常见的值可能是 system:masters 或者 devops-team 等。 附加字段：一组额外的键-值映射，键是字符串，值是一组字符串； 用来保存一些鉴权组件可能觉得有用的额外信息。 对于其它身份认证协议都可以通过使用一个身份认证代理或身份认证 Webhoook 来实现。 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:6:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" HTTP x509 客户证书认证API 服务使用 --client-ca-file=SOMEFILE 指定 CA 证书，如果提供了客户端证书并且证书被验证通过，则 subject 中的公共名称（Common Name） 就被作为请求的用户名。从 k8s \u003e= 1.4 开始，客户端证书还可以通过证书的 organization 字段标明用户的组成员信息。 查看 k8s api 服务是否启用客户端证书认证 [root@node1 ~]# kubectl -n kube-system get pod kube-apiserver-node1.localdomain -o yaml | grep '\\--client-ca-file' - --client-ca-file=/etc/kubernetes/pki/ca.crt 创建客户端请求证书 [root@node1 ~]# cd /etc/kubernetes/pki [root@node1 pki]# [root@node1 pki]# ll ca.crt -rw-r--r--. 1 root root 1070 Sep 11 03:03 ca.crt # 生成秘钥，给客户端使用 [root@node1 pki]# openssl genrsa -out user.key 2048 Generating RSA private key, 2048 bit long modulus (2 primes) ....................+++++ ..............+++++ e is 65537 (0x010001) # 生成请求证书（SCR） # 从 k8s 1.4 开始证书中 organization 字段可以指定多个用户组（如：\"/CN=jbeda/O=app1/O=app2\"） # 下面命令表示 ，user01 用户，且该用户属于 users 组 [root@node1 pki]# openssl req -new -key user.key -out user01.scr -subj \"/CN=user01/O=users\" 使用 api 服务的 CA 证书为客户端请求证书签名 # 有效期为 1200 天 [root@node1 pki]# openssl x509 -req -in user01.scr -CA ca.crt -CAkey ca.key -CAcreateserial -out user01.crt -days 1200 Signature ok subject=CN = user01, O = users Getting CA Private Key [root@node1 pki]# ls user* user01.crt user01.scr user.key 使用 REST API 方式访问（还没富裕权限，因此没有实质意义） [root@node1 pki]# curl -sk --cert user01.crt --key user.key https://192.168.6.11:6443/api/| jq { \"kind\": \"APIVersions\", \"versions\": [ \"v1\" ], \"serverAddressByClientCIDRs\": [ { \"clientCIDR\": \"0.0.0.0/0\", \"serverAddress\": \"192.168.6.11:6443\" } ] } ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:6:1","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 使用启动引导令牌认证启动引导令牌是一种简单的持有者令牌（Bearer Token），这种令牌是在新建集群 或者在现有集群中添加新节点时使用的。 启动引导令牌被定义成一个特定类型的 Secret（bootstrap.kubernetes.io/token）， 并存在于 kube-system 名字空间中。 这些 Secret 会被 API 服务器上的启动引导认证组件（Bootstrap Authenticator）读取。 控制器管理器中的控制器 TokenCleaner 能够删除过期的令牌。 这些令牌也被用来在节点发现的过程中会使用的一个特殊的 ConfigMap 对象。 BootstrapSigner 控制器也会使用这一 ConfigMap。 动引导令牌必须符合正则表达式 [a-z0-9]{6}\\.[a-z0-9]{16}。令牌的第一部分是（Token ID），它是一种公开信息，用于引用令牌并确保不会泄露认证所使用的秘密信息。 第二部分是令牌秘密（Token Secret），它应该被共享给受信的第三方。 在 api 服务使用 --enable-bootstrap-token-auth 选项启动引导令牌认证组件 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:6:2","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 匿名请求启用匿名请求支持之后，如果请求没有被被已配置的其他身份认证方法拒绝且没有提供有效的身份标识，则被视作匿名请求。如在一个配置了令牌身份认证且启用了匿名访问的服务器上，如果请求提供了非法的持有者令牌， 则会返回 401 Unauthorized 错误。如果请求没有提供持有者令牌，则被视为匿名请求。 在 k8s 1.5x 版本中，匿名访问默认情况下是被禁用的，可以通过为 API 服务器设定 --anonymous-auth=true 启用。在 k8s 1.6 之后版本中，如果所使用的鉴权模式不是 AlwaysAllow，则匿名访问默认是被启用的。 从 k8s 1.6 版本开始，ABAC 或 RBAC 鉴权模块要求对 system:anonymous 用户或者 system:unauthenticated 用户组执行显式的权限判定，用户 * 或用户组 * 赋予访问权限的策略规则都不再包含匿名用户。 如果要禁用匿名的未经过身份验证的用户访问，请在 API 服务器配置中中添加 --anonymous-auth=false 的配置选项。 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:6:3","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 鉴权概述k8s 使用 api 服务器对 api 请求根据所有策略评估所有请求属性来决定允许或拒绝请求。 默认是拒绝，只有明确允许的操作才会执行。 依赖于特定对象种类的特定字段的访问控制和策略由准入控制器处理 k8s 仅审查以下 API 属性： 用户： 身份验证期间提供的 user 字符串 组：经过身份验证的用户所属的组名列表 API: 请求是否针对 API 资源。 请求路径：各种非资源端点的路径 请求动词：HTTP 请求动词对应的请求动词： POST: create GET, HEAD: get(针对单个资源)、list（针对集合） PUT: update PATCH: patch DELETE: delete(针对单个资源)、deletecollection(针对集合) 资源：正在访问的资源的 ID 或名称（仅限资源请求）， 对于使用 get、update、patch 和 delete 动词的资源请求，必须提供名称 名称空间：正在访问的对象的名称空间（仅适用于名字空间资源请求）。 API 组：正在访问的 API 组 （仅限资源请求）。空字符串表示核心 API 组。 有以下鉴权插件： node: 一个专用鉴权模式，根据调度到 kubelet 上运行的 Pod 为 kubelet 授予权限。 ABAC: 基于属性的访问控制（ABAC）定义了一种访问控制范型，通过使用将属性组合在一起的策略， 将访问权限授予用户。策略可以使用任何类型的属性（用户属性、资源属性、对象，环境属性等） RBAC: 基于角色的访问控制（RBAC） 是一种基于企业内个人用户的角色来管理对计算机或网络资源的访问的方法。 在此上下文中，权限是单个用户执行特定任务的能力， 例如查看、创建或修改文件。 Webhook: 它是一个 HTTP 回调：发生某些事情时调用的 HTTP POST； 通过 HTTP POST 进行简单的事件通知。 实现 WebHook 的 Web 应用程序会在发生某些事情时将消息发布到 URL。 查看启用的鉴权插件，靠前的模块具有更高的优先级来允许或拒绝请求： [root@node1 ~]# kubectl get pod kube-apiserver-node1.localdomain -n kube-system -o=jsonpath='{$.spec.containers[0].command}' | jq | grep \"authorization-mode\" \"--authorization-mode=Node,RBAC\", kubectl auth can-i 命令使用 SelfSubjectAccessReview API 来确定当前用户是否可以执行给定操作 # 检查名字空间 dev 里的 dev-sa 服务账户是否可以列举名字空间 target 里的 Pod [root@node1 ~]# kubectl auth can-i list pods --namespace target --as system:serviceaccount:dev:dev-sa no # 检查当前用户可以在 dev 名称空间是否允许创建 `deployments` [root@node1 ~]# kubectl auth can-i create deployments --namespace dev yes 也可以通过创建普通的 k8s 资源来查询这些 API，其中返回对象的响应 status 字段是查询的结果。 [root@node1 ~]# kubectl create -f - -o yaml \u003c\u003c EOF \u003e apiVersion: authorization.k8s.io/v1 \u003e kind: SelfSubjectAccessReview \u003e spec: \u003e resourceAttributes: \u003e group: apps \u003e name: deployments \u003e verb: create \u003e namespace: dev \u003e EOF apiVersion: authorization.k8s.io/v1 kind: SelfSubjectAccessReview metadata: creationTimestamp: null spec: resourceAttributes: group: apps name: deployments namespace: dev verb: create status: allowed: true ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:7:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" RBAC 鉴权基于角色（Role）的访问控制（RBAC）是一种基于组织中用户的角色来调节控制对计算机或网络资源的访问的方法。RBAC 鉴权机制使用 rbac.authorization.k8s.io API 组来驱动鉴权决定， 允许你通过 Kubernetes API 动态配置策略。 在 kube-apiserver --authorization-mode 选项包含 RBAC 参数时表示启用了 RBAC 鉴权 [root@node1 ~]# kubectl get pod kube-apiserver-node1.localdomain -n kube-system -o=jsonpath='{$.spec.containers[0].command}' | jq | grep \"authorization-mode\" \"--authorization-mode=Node,RBAC\", RBAC API 声明了以下 k8s 对象： 权限定义对象，一组相关权限规则。权限是纯粹累加的，不存在拒绝某种操作的规则。 Role: 某个名称空间内权限 ClusterRole: 定义集群级别区域权限 角色绑定对象： RoleBinding: 将 Role 定义的权限赋予一个或者一组用户 ClusterRoleBinding: 将 ClusterRole 定义的权限赋予一个或者一组用户 它们的生效范围： RoleBinding 绑定 Role：在固定名称空间生效。且 RoleBinding 和 Role 必须在同一名称空间 RoleBinding 绑定 ClusterRole：在 RoleBingding 定义的名称空间生效 ClusterRoleBinding 绑定 ClusterRole：在整个集群生效 Role 与 ClusterRoleRBAC 的 Role 或 ClusterRole 中包含一组代表相关权限的规则。 这些权限是纯粹累加的。不存在拒绝某操作的规则。Role 总是用来在某个名字空间内设置访问权限，创建 Role 时必须指定该 Role 所属的名字空间。ClusterRole 则是一个集群作用域的资源。 role 示例 --- apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: note name: user-role rules: - apiGroups: [\"v1\"] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] --- ClusterRole 示例 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: user-cluster-role rules: - apiGroups: [\"v1\"] resources: [\"nodes\"] verbs: [\"get\", \"watch\", \"list\"] 聚合的 ClusterRole可以把若干个 ClusterRole 聚合起来，形成一个复合的 ClusterRole。作为集群控制面的一部分，控制器会监视带有 aggregationRule 的 ClusterRole 对象集合。 aggregationRule 为控制器定义一个标签选择算符供后者匹配应该组合到当前 ClusterRole 的 roles 字段中的 ClusterRole 对象 下面是一个聚合 ClusterRole 的示例： apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: monitoring aggregationRule: # 聚合标签 clusterRoleSelectors: - matchLabels: rbac.example.com/aggregate-to-monitoring: \"true\" rules: [] # 控制面自动填充这里的规则 再创建一个带有 rbac.example.com/aggregate-to-monitoring: true 标签的 ClusterRole 新的规则也会被添加到名为 monitoring 的 ClusterRole 中 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: monitoring-endpoints labels: rbac.example.com/aggregate-to-monitoring: \"true\" # 当你创建 \"monitoring-endpoints\" ClusterRole 时， # 下面的规则会被添加到 \"monitoring\" ClusterRole 中 rules: - apiGroups: [\"\"] resources: [\"services\", \"endpoints\", \"pods\"] verbs: [\"get\", \"list\", \"watch\"] RoleBinding 和 ClusterRoleBindingRoleBinding 与 ClusterRoleBinding 都是用于把权限与某个或某些用户、用户组、服务账号关联，这些主体名称没有过多限制。以下前缀是 k8s 系统保留的： system: system:serviceaccount:: 是用于服务账户用户名的前缀 system:serviceaccounts:: 是用于服务账户组名的前缀 RoleBinding 示例 apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: user-role-binding namespace: note subjects: - kind: User name: user roleRef: kind: Role name: user-role apiGroup: rbac.authorization.k8s.io 默认的 Roles 和 RoleBindingsAPI 服务会创建一组默认的 ClusterRole 与 ClusterRoleBinding 对象，它们都带有 kubernetes.io/bootstrapping=rbac-defaults 。其中有很多用 system: 作为前缀来标识对应资源是直接由集群控制面管理的。因此修改这些资源时要小心，可能导致集群无法正常运作。 每次启动时 API 服务器都会为默认的 ClusterRole 添加缺少的权限，并为默认的 ClusterRoleBindin 添加缺少的主体。这种机制称为自动协商，它有助于保证角色和角色绑定在新的发行版本中有权限或主体变更时仍然保持最新。如果想禁用则把它们的注解 rbac.authorization.kubernetes.io/autoupdate 由 true 改为 false。注意，缺少默认权限和角色绑定主体可能会导致集群无法正常工作。如果启用了 RBAC 鉴权，则该机制是默认启用的 无论是经过身份验证的还是未经过身份验证的用户， 默认的角色绑定都授权他们读取被认为是可安全地公开访问的 API (由名为 system:discovery 的ClusterRole 资源定义) RBAC 会发现以下ClusterRole并通过自动协商机制修复 默认的 ClusterRole 默认绑定的主体 说明 system:basic-user system:authenticated 组 允许用户以只读的方式去访问他们自己的基本信息。在 k8s 1.14 版本之前是 system:unauthenticated 组的一员 system:discovery system:authenticated 组 允许以只读方式访问 API 发现端点，这些端点用来发现和协商 API 级别。在 k8s 1.14 版本之前是 system:unauthenticated 组的一员 system:public-info-viewer system:authenticated 组 system:unauthenticated 组 允许对集群的非敏感信息进行只读访问，在 k8s 1.14 版本中引入 以下 ClusterRole 是面向用户的，允许管理员使用 ClusterRole 聚合标签来添加用于定制资源的规则。 默认的 ClusterRole 默认关联的主体 说明 cluster-admin system:masters 组 允许超级用户在平台上的任何资源上执行所有操作。在 RoleBinding 资源中关联时，可以授权控制角色绑定所在名字空间中的所有资源，包括名字空间本身。 admin 无 允许管理员访问权限，旨在使用 RoleBinding 在名字空间内执行授权。可授予对名字空间中的大多数资源的读/写权限， 包括创建角色和角色绑定的能力。 此角色不允许对资源配额或者名字空间本身进行写操作。不允许对 k8s 1.22 以上版本的 Endpoints 资源进行写操作 edit 无 允许对名字空间的大多数对象进行读/写操作。此角色不允许查看或者修改角色或者角色绑定。 不过可以访问 Secret，以名字空间中任何 ServiceAccount 的身","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:7:1","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" node 鉴权节点鉴权是一种特殊用途的鉴权模式，专门对 kubelet 发出的 API 请求进行授权。允许 kubelet 执行 API 操作。 读取： services、endpoints、nodes、pods 以及绑定到 kubelet 节点的 Pod 相关资源（Secret、ConfigMap、PersistentVolumeClaim 和持久卷） 写入：事件、pod 及其状态（启用 NodeRestriction 准入插件以限制 kubelet 只能修改绑定到自身的 Pod）、节点及其状态（启用 NodeRestriction 准入插件以限制 kubelet 只能修改自己的节点） 对于基于 TLS 的启动引导过程时使用的 certificationsigningrequests API 的读/写权限 为委派的身份验证/鉴权检查创建 TokenReview 和 SubjectAccessReview 的能力 在以后的版本中节点鉴权器可能会添加或删除权限，以确保 kubelet 具有正确操作所需的最小权限集。为了获得节点鉴权器的授权，kubelet 必须使用一个凭证以表示它在 system:nodes 组中，用户名为 system:node:\u003cnodeName\u003e。上述的组名和用户名格式要与 kubelet TLS 启动引导 过程中为每个 kubelet 创建的标识相匹配。 节点名称必须与 kubelet 注册时使用的节点名称一致。获取节点名称优先级从上往下： 使用 kubelet --cloud-provider 选项时具体的主机名可能由云提供商确定 使用 kubelet --hostname-override 选项指定的值 使用 hostname 命令提供的值 在 kube-apiserver --authorization-mode 选项包含 Node 参数时表示启用了 Node 鉴权。想限制 kubelet 可写入的 API 对象需要使用 kube-apiserver --enable-admission-plugins 选项启用 NodeRestriction 准入管制器插件 Node 鉴权只授权于 system:nodes 组的主体，如果 kubelet 具有 system:nodes 组的凭证，但无法给出关联的节点标识（system:node:... 格式的用户名），也不会被 Node 鉴权模式授权。 版本变动使用 RBAC 时，将继续创建 system:node 集群角色，以便与将其他用户或组绑定到该角色的部署方法兼容。 在 k8s 1.6 版本中，使用 RBAC 鉴权时，名为 system:nodes 的 ClusterRole 资源会自动关联到 system:node 组 在 k8s 1.7 版本中，不再推荐将 system:nodes 组自动绑定到 system:node 角色，因为节点鉴权器通过对 Secret 和 ConfigMap 访问的额外限制完成了相同的任务。 如果同时启用了 Node 和 RBAC 鉴权模。如果同时启用了 RBAC 与 Node 鉴权，则不会自动绑定 在 k8s 1.8 版本中，绑定将根本不会被创建 从 k8s 1.7 版本之前升级的使用 RBAC 群将继续按原样运行，因为 system:nodes 组绑定已经存在。如果集群管理员希望开始使用 Node 鉴权器和 NodeRestriction 准入插件来限制节点对 API 的访问。可以通过以下操作完成： 启用 Node 鉴权与 NodeRestriction 准入控制器插件 确保所有 kubelet 的凭据符合组/用户名要求 审核 API 服务器日志以确保 Node 鉴权器不会拒绝来自 kubelet 的请求（日志中没有持续的 NODE DENY 消息） 删除 system:node 集群角色绑定 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:7:2","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 准入控制器准入控制器是一段代码，它会在请求通过认证和授权之后、对象被持久化之前拦截到达 API 服务器的请求。可以执行验证和变更操作。它只限制创建、删除、修改对象或连接到代理的请求，不限制读取对象的请求。 准入控制过程分为以下两个阶段，某些控制器既是变更准入控制器又是验证准入控制器。如果两个阶段之一的任何一个控制器拒绝了某请求，则整个请求将立即被拒绝，并向最终用户返回错误。 运行变更准入控制器 运行验证准入控制器 准入控制器有很多，它们都编译进 kube-apiserver 可执行文件，并且只能由集群管理员配置。 启用准入控制器：kube-apiserver --enable-admission-plugins=NamespaceLifecycle,LimitRanger ... 关闭准入控制器：kube-apiserver --disable-admission-plugins=PodNodeSelector,AlwaysDeny ... 查看已启用的准入控制器：kube-apiserver -h | grep enable-admission-plugins ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:8:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" NodeRestriction该准入控制器限制某个 kubelet 可以修改的 Node 与 Pod 资源对象，它通过限制 system:nodes 组（成员名格式为 system:node:\u003cnodeName\u003e ）的权限实现的。但无法更新或删除 Node 对象的污点。 该插件对 kubelet 做了以下限制： 允许 kubelet 添加、修改、删除以下标签 kubernetes.io/hostname kubernetes.io/arch kubernetes.io/os beta.kubernetes.io/instance-type node.kubernetes.io/instance-type failure-domain.beta.kubernetes.io/region （已弃用） failure-domain.beta.kubernetes.io/zone （已弃用） topology.kubernetes.io/region topology.kubernetes.io/zone kubelet.kubernetes.io/ 为前缀的标签 node.kubernetes.io/ 为前缀的标签 禁止 kubelet 添加、修改、删除以下标签 node-restriction.kubernetes.io/ 为前缀的标签（这类前缀的标签时保留给管理员的，用以为 Node 对象设置标签以隔离工作负载） kubernetes.io 为前缀的标签（除非明确允许） k8s.io 为前缀的标签（除非明确允许） kubelet API 访问控制可以通过 kubelet 的监听端口访问 kubelet API，这些 API 可以访问敏感度不同的数据， 并允许你在节点上和容器内以不同级别的权限执行操作。 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:8:1","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" kubelet API 身份认证kubelet API 有以下身份认证方式： 匿名请求：没有明确说明身份的用户赋予 system:anonymous 用户名和 system:unauthenticated 组。 x509 客户端证书认证 token 认证 ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:9:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 匿名请求使用 kubelet ----anonymous-auth=true 或在配置文件中使用启用 [root@k8s01 ~]# cat /var/lib/kubelet/config.yaml apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: true ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:9:1","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" x509 认证kube-apiserver 使用 x509 认证 kubelt API 需要做以下操作（默认是使用的） kubelet 指定一个 CA 证书，用于验证客户端证书 # 可以使用 kubelet --client-ca-file 选项指定 [root@k8s01 ~]# cat /var/lib/kubelet/config.yaml apiVersion: kubelet.config.k8s.io/v1beta1 authentication: x509: clientCAFile: /etc/kubernetes/pki/ca.crt kube-apiserver 使用 --kubelet-client-certificate 指定客户端证书，使用 --kubelet-client-key 指定秘钥 [root@k8s01 ~]# kubectl get pod kube-apiserver-k8s01.localdomain -n kube-system -o=jsonpath='{$.spec.containers[0].command}' | jq ... \"--kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt\", \"--kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key\", ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:9:2","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" token kube-apiserver 服务中启用了 authentication.k8s.io API 组 [root@node1 ~]# kubectl api-versions | grep \"authentication.k8s.io\" authentication.k8s.io/v1 kubelet 启用 TokenReview API 进行身份认证 # 可以使用 --authentication-token-webhook 选项指定 [root@k8s01 ~]# cat /var/lib/kubelet/config.yaml apiVersion: kubelet.config.k8s.io/v1beta1 authentication: webhook: cacheTTL: 2m0s enabled: true ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:9:3","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" 鉴权kubelet 鉴权模式由 --authorization-mode 选项指定，有以下值： AlwaysAllow: 允许所有请求（缺省时默认值） Webhook: 通过 SubjectAccessReview API 组委派给 kube-apiserver 进行鉴权。在此模式下确保传递给 API 服务器的由 --kubelet-client-certificate 和 --kubelet-client-key 标志标识的用户具有以下属性的鉴权： verb=*, resource=nodes, subresource=proxy verb=*, resource=nodes, subresource=stats verb=*, resource=nodes, subresource=log verb=*, resource=nodes, subresource=spec verb=*, resource=nodes, subresource=metrics kubelet 使用与 apiserver 相同的请求属性对请求进行鉴权 HTTP 动词 请求动词 POST create GET, HEAD get PUT update PATCH patch DELETE delete api url 中地址为 kubelet 监听的 ip:port，名称空间、API 组、node都是空的。如：https://localhost:10250/metrics Kubelet API 资源/子资源 /stats/* nodes/stats /metrics/* nodes/metrics /logs/* nodes/log /spec/* nodes/spec 其它所有 nodes/proxy API查看已启用的 API [root@node1 ~]# kubectl api-resources ... ","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:10:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["k8s"],"content":" SubjectAccessReview","date":"2022-09-11","objectID":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:11:0","tags":["k8s API"],"title":"k8s API 概述及访问控制","uri":"/k8sAPI%E6%A6%82%E8%BF%B0%E5%8F%8A%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： jq手册 查看帮助 [root@localhost ~]# man jq | cat ... # 格式 SYNOPSIS jq [options...] filter [files...] # 选项 INVOKING JQ --version # 查看版本并退出 --seq --stream Parse the input in streaming fashion, outputing arrays of path and leaf values (scalars and empty arrays or empty objects). For example, \"a\" becomes [[],\"a\"], and [[],\"a\",[\"b\"]] becomes [[0],[]], [[1],\"a\"], and [[1,0],\"b\"]. This is useful for processing very large inputs. Use this in conjunction with filtering and the reduce and foreach syntax to reduce large inputs incrementally. --slurp/-s Instead of running the filter for each JSON object in the input, read the entire input stream into a large array and run the filter just once. --raw-input/-R Don´t parse the input as JSON. Instead, each line of text is passed to the filter as a string. If combined with --slurp, then the entire input is passed to the filter as a single long string. --null-input/-n Don´t read any input at all! Instead, the filter is run once using null as the input. This is useful when using jq as a simple calculator or to construct JSON data from scratch. --compact-output / -c By default, jq pretty-prints JSON output. Using this option will result in more compact output by instead putting each JSON object on a single line. --tab Use a tab for each indentation level instead of two spaces. --indent n Use the given number of spaces (no more than 8) for indentation. --color-output / -C or --monochrome-output / -M # 启用或禁用配色，配色方案由JQ_COLORS 环境变量提供，默认为 \"JQ_COLORS=1;30:0;37:0;37:0;37:0;32:1;37:1;37\" # https://jqlang.github.io/jq/manual/#Colors --ascii-output / -a jq usually outputs non-ASCII Unicode codepoints as UTF-8, even if the input specified them as escape sequences (like \"\\u03bc\"). Using this option, you can force jq to produce pure ASCII output with every non-ASCII character replaced with the equivalent escape sequence. --unbuffered Flush the output after each JSON object is printed (useful if you´re piping a slow data source into jq and piping jq´s output elsewhere). --sort-keys / -S Output the fields of each object with the keys in sorted order. --raw-output / -r With this option, if the filter´s result is a string then it will be written directly to standard output rather than being formatted as a JSON string with quotes. This can be useful for making jq filters talk to non-JSON-based systems. --join-output / -j Like -r but jq won´t print a newline after each output. -f filename / --from-file filename Read filter from the file rather than from a command line, like awk´s -f option. You can also use ´#´ to make comments. -Ldirectory / -L directory Prepend directory to the search list for modules. If this option is used then no builtin search list is used. See the section on modules below. -e / --exit-status Sets the exit status of jq to 0 if the last output values was neither false nor null, 1 if the last output value was either false or null, or 4 if no valid result was ever produced. Normally jq exits with 2 if there was any usage problem or system error, 3 if there was a jq program compile error, or 0 if the jq program ran. Another way to set the exit status is with the halt_error builtin function. --arg name value This option passes a value to the jq program as a predefined variable. If you run jq with --arg foo bar, then $foo is available in the program and has the value \"bar\". Note that value will be treated as a string, so --arg foo 123 will bind $foo to \"123\". Named arguments are also available to the jq program as $ARGS.named. --argjson name JSON-text This option passes a JSON-encoded value to the jq program as a predefined variable. If you run jq with --argjson foo 123, then $foo is available in the program and has the value 123. --slurpfile variable-name filename This option reads all the JSON texts in the named file and binds an array of the parsed JSON values to the given global variable. If you run jq with --argfile foo bar, then $foo is available in the program and has an","date":"2022-09-03","objectID":"/CMDjq/:0:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 格式化 josn. 字符表示层级，当只有一个 . 字符时表示所有文本。由于 jq 会高亮输出，单独使用通常是高亮语法或判断格式错误 # 单独的 . 字符可以省略。如 cat j.json | jq 等效以下命令 [root@localhost ~]# cat j.json | jq . [ { \"Id\": \"a595d20441b6dce94e7181d49c41acbc1478a203c9bd502a4a17a2bac222a1ff\", \"Created\": \"2023-04-02T13:00:15.761827266Z\", \"Path\": \"/entrypoint.sh\", ... ","date":"2022-09-03","objectID":"/CMDjq/:1:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 特殊字符如果含有特殊字符，则需要使用双引号 [root@node01 ~]# kubectl -n kube-system get Deployments calico-kube-controllers -o json | jq '.metadata.annotations' { \"deployment.kubernetes.io/revision\": \"1\", \"kubectl.kubernetes.io/last-applied-configuration\": \"{\\\"apiVersion... [root@node01 ~]# kubectl -n kube-system get Deployments calico-kube-controllers -o json | jq '.metadata.annotations.\"kubectl.kubernetes.io/last-applied-configuration\"' \"{\\\"apiVersion\\\":\\\"apps/v1\\\",... ","date":"2022-09-03","objectID":"/CMDjq/:2:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 对象标识符可以通字段名获取想要的值 [root@localhost ~]# cat j.json | jq .[].NetworkSettings.Networks.note.IPAMConfig { \"IPv4Address\": \"172.11.1.11\" } { \"IPv4Address\": \"172.11.1.12\" } [root@localhost ~]# [root@localhost ~]# cat j.json | jq .[].NetworkSettings.Networks.note.IPAMConfig.IPv4Address \"172.11.1.11\" \"172.11.1.12\" ","date":"2022-09-03","objectID":"/CMDjq/:3:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 索引当索引值为整数时，.[\u003cinteger\u003e]可以索引数组或对象的值。索引从零开始，因此.[2]返回第三个元素。允许使用负索引，-1 表示最后一个元素，-2 表示倒数第二个元素，依此类推。当缺少数组索引时表示所有数组。当引用数组或对像多个值时，可以使用,分隔 [root@localhost ~]# cat j.json | jq .[].NetworkSettings.SandboxID \"0c69562161027072efe0125290962ee0d4f89ba80c5cdf20501b9cfe4ad26765\" \"a95152e99bc185f1c6c045dd83cadadd3cccef0f6f80ea4d58ad983499da2d08\" [root@localhost ~]# [root@localhost ~]# cat j.json | jq .[0].NetworkSettings.SandboxID \"0c69562161027072efe0125290962ee0d4f89ba80c5cdf20501b9cfe4ad26765\" [root@localhost ~]# [root@localhost ~]# cat j.json | jq .[1].NetworkSettings.SandboxID \"a95152e99bc185f1c6c045dd83cadadd3cccef0f6f80ea4d58ad983499da2d08\" [root@localhost ~]# [root@localhost ~]# cat j.json | jq .[0,1].NetworkSettings.SandboxID \"0c69562161027072efe0125290962ee0d4f89ba80c5cdf20501b9cfe4ad26765\" \"a95152e99bc185f1c6c045dd83cadadd3cccef0f6f80ea4d58ad983499da2d08\" ","date":"2022-09-03","objectID":"/CMDjq/:4:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 忽略错误引用不存在格式时会报错，使用?会忽略报错 [root@localhost ~]# cat j.json | jq .[1].NetworkSettings.Networks.note[0] jq: error (at \u003cstdin\u003e:499): Cannot index object with number [root@localhost ~]# [root@localhost ~]# echo $? 5 ","date":"2022-09-03","objectID":"/CMDjq/:5:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 切片可以对数组或字符串进行切片操作 [root@localhost ~]# cat j.json | jq .[1].Id \"26cfd596e0fd1b3677d49a887559193db23680f0458e9cca5f8527fb6caf9b04\" [root@localhost ~]# [root@localhost ~]# cat j.json | jq .[1].Id[0:7] \"26cfd59\" ","date":"2022-09-03","objectID":"/CMDjq/:6:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 多个过滤器有多个条件时使用,分隔过滤条件，相同输出会分别被多组过滤条件接收。根据条件从左到右输出结果 [root@localhost ~]# cat j.json | jq .[].Id \"a595d20441b6dce94e7181d49c41acbc1478a203c9bd502a4a17a2bac222a1ff\" \"26cfd596e0fd1b3677d49a887559193db23680f0458e9cca5f8527fb6caf9b04\" [root@localhost ~]# [root@localhost ~]# cat j.json | jq .[1].Id[0:7],.[0].Id[0:7] \"26cfd59\" \"a595d20\" ","date":"2022-09-03","objectID":"/CMDjq/:7:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 过滤器组合| 与 linux 的管道符作用相同，把前面的输入结题再进行过虑 [root@localhost ~]# cat j.json | jq .[1].Mounts [ { \"Type\": \"bind\", \"Source\": \"/data/ArtalkData/mysqlDocker/data\", \"Destination\": \"/var/lib/mysql\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" }, { \"Type\": \"bind\", \"Source\": \"/data/ArtalkData/mysqlDocker/log\", \"Destination\": \"/var/log/mysql\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" }, { \"Type\": \"bind\", \"Source\": \"/data/ArtalkData/mysqlDocker/mysqld\", \"Destination\": \"/var/run/mysqld\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" }, { \"Type\": \"bind\", \"Source\": \"/etc/localtime\", \"Destination\": \"/etc/localtime\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" }, { \"Type\": \"bind\", \"Source\": \"/data/ArtalkData/mysqlDocker/conf\", \"Destination\": \"/etc/mysql\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" } ] [root@localhost ~]# [root@localhost ~]# cat j.json | jq \".[1].Mounts[] | .Source\" \"/data/ArtalkData/mysqlDocker/data\" \"/data/ArtalkData/mysqlDocker/log\" \"/data/ArtalkData/mysqlDocker/mysqld\" \"/etc/localtime\" \"/data/ArtalkData/mysqlDocker/conf\" [root@localhost ~]# [root@localhost ~]# cat j.json | jq .[1].Mounts[].Source \"/data/ArtalkData/mysqlDocker/data\" \"/data/ArtalkData/mysqlDocker/log\" \"/data/ArtalkData/mysqlDocker/mysqld\" \"/etc/localtime\" \"/data/ArtalkData/mysqlDocker/conf\" ","date":"2022-09-03","objectID":"/CMDjq/:8:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 递归所有值.. 会遍历所有键的值 [root@localhost ~]# cat j.json | jq '..' | head -n 7 [ { \"Id\": \"a595d20441b6dce94e7181d49c41acbc1478a203c9bd502a4a17a2bac222a1ff\", \"Created\": \"2023-04-02T13:00:15.761827266Z\", \"Path\": \"/entrypoint.sh\", \"Args\": [ \"server\", [root@localhost ~]# [root@localhost ~]# cat j.json | jq '.. | .IPAMConfig?' null null ... null { \"IPv4Address\": \"172.11.1.11\" } null ... { \"IPv4Address\": \"172.11.1.12\" } null null null ","date":"2022-09-03","objectID":"/CMDjq/:9:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 数学运算可以做数学运算 [root@localhost ~]# cat j.json | jq .[1].NetworkSettings.Networks.note.IPPrefixLen 24 [root@localhost ~]# [root@localhost ~]# cat j.json | jq \".[1].NetworkSettings.Networks.note.IPPrefixLen + 3\" 27 [root@localhost ~]# [root@localhost ~]# cat j.json | jq \".[1].NetworkSettings.Networks.note.IPPrefixLen + 3 | . * 2\" 54 [root@localhost ~]# [root@localhost ~]# cat j.json | jq \"(.[1].NetworkSettings.Networks.note.IPPrefixLen + 3) * 2\" 54 构建对象[...]用于构建新的json数组，即引用字段的值 [root@localhost ~]# cat j.json | jq .[].NetworkSettings.Networks.note.IPAMConfig { \"IPv4Address\": \"172.11.1.11\" } { \"IPv4Address\": \"172.11.1.12\" } [root@localhost ~]# [root@localhost ~]# cat j.json | jq [.[].NetworkSettings.Networks.note.IPAMConfig] [ { \"IPv4Address\": \"172.11.1.11\" }, { \"IPv4Address\": \"172.11.1.12\" } ] [root@localhost ~]# [root@localhost ~]# cat j.json | jq [.[].NetworkSettings.Networks.note.IPAMConfig.IPv4Address] [ \"172.11.1.11\", \"172.11.1.12\" ] {...} 用于构建新的json对象 [root@localhost ~]# echo '{\"user\":\"stedolan\",\"titles\":[\"JQ Primer\", \"More JQ\"]}' | jq { \"user\": \"stedolan\", \"titles\": [ \"JQ Primer\", \"More JQ\" ] } [root@localhost ~]# [root@localhost ~]# echo '{\"user\":\"stedolan\",\"titles\":[\"JQ Primer\", \"More JQ\"]}' | jq '{user, title: .titles[]}' { \"user\": \"stedolan\", \"title\": \"JQ Primer\" } { \"user\": \"stedolan\", \"title\": \"More JQ\" } [root@localhost ~]# [root@localhost ~]# cat j.json | jq '.[0].NetworkSettings.Networks.note' { \"IPAMConfig\": { \"IPv4Address\": \"172.11.1.11\" }, \"Links\": null, \"Aliases\": [ \"a595d20441b6\" ], \"NetworkID\": \"758186f2828160d7c48e9f9a3fc0db8dd2c4d79b66b40d878aaeef9f8b697d4f\", \"EndpointID\": \"8d06c4bec0113740a8875d49db0333ad16032b764487939cd1872cf78b391471\", \"Gateway\": \"172.11.1.1\", \"IPAddress\": \"172.11.1.11\", \"IPPrefixLen\": 24, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:0b:01:0b\", \"DriverOpts\": null } [root@localhost ~]# [root@localhost ~]# cat j.json | jq '.[0].NetworkSettings.Networks.note | {Aliases,IPAMConfig}' { \"Aliases\": [ \"a595d20441b6\" ], \"IPAMConfig\": { \"IPv4Address\": \"172.11.1.11\" } } 在键周围加上括号意味着它将被评估为一个表达式，作为键的变量引用使用变量的值作为键。如果没有值，则变量的名称成为键，其值成为值。即键的值作为新的键，可以引用其它键的值做为值。 [root@localhost ~]# echo '{\"user\":\"stedolan\",\"titles\":[\"JQ Primer\", \"More JQ\"]}' | jq '{(.user): .titles}' { \"stedolan\": [ \"JQ Primer\", \"More JQ\" ] } [root@localhost ~]# aws cloudformation list-stacks --profile \"xiaosi\" --region \"ap-southeast-1\" | jq { \"StackSummaries\": [ { \"StackId\": \"arn:...\", \"StackName\": \"eksctl-attractive-painting-1686793950-cluster\", \"TemplateDescription\": \"EKS c...\", \"CreationTime\": \"...\", \"DeletionTime\": \"...\", \"StackStatus\": \"DELETE_COMPLETE\", \"DriftInformation\": { \"StackDriftStatus\": \"NOT_CHECKED\" } }, .... } [root@localhost ~]# aws cloudformation list-stacks --profile \"xiaosi\" --region \"ap-southeast-1\" | jq \".StackSummaries[] | {StackName,StackStatus}\" { \"StackName\": \"eksctl-attractive-painting-1686793950-cluster\", \"StackStatus\": \"DELETE_COMPLETE\" } { \"StackName\": \"eksctl-eks03-nodegroup-ng-785ac8ef\", \"StackStatus\": \"CREATE_COMPLETE\" } [root@localhost ~]# aws cloudformation list-stacks --profile \"xiaosi\" --region \"ap-southeast-1\" | jq \"[.StackSummaries[] | {StackName,StackStatus}]\" [ { \"StackName\": \"eksctl-attractive-painting-1686793950-cluster\", \"StackStatus\": \"DELETE_COMPLETE\" }, { \"StackName\": \"eksctl-eks03-nodegroup-ng-785ac8ef\", \"StackStatus\": \"CREATE_COMPLETE\" }, ... } 下面示例中，只获取指定字段，并对值进行重构成列表，其中添加status 字段，它的值是引用指定字段值 [root@localhost ~]# cat instances.json | jq { \"instances\": [ { \"name\": \"Debian-10\", ..... \"publicIpAddress\": \"18.15.5.17\", \"state\": { \"code\": 16, \"name\": \"running\" }, .... }, .... ] } [root@localhost ~]# jq '[.instances[] | {name, publicIpAddress,status: .state.name}]' instances.json [ { \"name\": \"Debian-10\", \"publicIpAddress\": \"18.15.5.17\", \"status\": \"running\" }, ... ] 内置运算符某些 jq 运算符会根据其参数类型做不同的事情。但 jq 从不进行隐式类型转换 ","date":"2022-09-03","objectID":"/CMDjq/:10:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 添加运算符+采用两个过滤器，将它们都应用于同一输入，结果取决于所涉及的类型： 数字：正常算术相加 对象：合并成一个数组，如果两个对象都包含同一个键的值，则右边对象的值 数组：合并成一个更大的数组 字符串：合并成一个更大的字符串 [root@localhost ~]# echo '{\"a\": [1,2], \"b\": [3,4]}' | jq '.a + .b' [ 1, 2, 3, 4 ] [root@localhost ~]# [root@localhost ~]# echo '[{\"a\": 1},{\"b\": 2}]' | jq ' .[0] + .[1]' { \"a\": 1, \"b\": 2 } ","date":"2022-09-03","objectID":"/CMDjq/:11:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 删减运算符-采用两个过滤器，将它们都应用于同一输入，结果取决于所涉及的类型： 数字：正常算术相减 数组：从第一个数组中减去第二个数据的值 [root@localhost ~]# echo '[\"xml\", \"yaml\", \"json\"]' | jq '. - [\"xml\", \"yaml\"]' [ \"json\" ] ","date":"2022-09-03","objectID":"/CMDjq/:12:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 乘法、除法、求余 函数","date":"2022-09-03","objectID":"/CMDjq/:13:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 获取长度内置函数length 可以获取各种不同类型值的长度： 字符串：长度是它包含的 Unicode 代码点的数量（如果是纯 ASCII，则与 JSON 编码的字节长度相同）。 数字的长度是它的绝对值。 数组的长度是元素的数量。 对象的长度是键值对的数量。 null 的长度为零。 在布尔值上使用长度是错误的。 [root@localhost ~]# echo '[[1,2], \"string\", {\"a\":2}, null, -5]' | jq '.[] | length' 2 6 1 0 5 ","date":"2022-09-03","objectID":"/CMDjq/:14:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 获取 UTF-8 编码字符串的字节数","date":"2022-09-03","objectID":"/CMDjq/:15:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 获取 keykey_unsorted 内置函数按顺便返回key；key 相似，但会把 key 按字母排序。如果是列表，则它们返回其下标 [root@localhost ~]# echo '[21,33,44]' | jq 'keys_unsorted' [ 0, 1, 2 ] [root@localhost ~]# echo '[21,33,44]' | jq 'keys' [ 0, 1, 2 ] [root@localhost ~]# echo '{\"abc\": 1, \"abcd\": 2, \"Foo\": 3}' | jq 'keys' [ \"Foo\", \"abc\", \"abcd\" ] [root@localhost ~]# echo '{\"abc\": 1, \"abcd\": 2, \"Foo\": 3}' | jq 'keys_unsorted' [ \"abc\", \"abcd\", \"Foo\" ] ","date":"2022-09-03","objectID":"/CMDjq/:16:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 判断是否存在某个keyhas函数能判断对象是否包含某个key，如果包含则返回true；否则返回 false [root@localhost ~]# echo '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}' | jq 'has(\"age\")' true ","date":"2022-09-03","objectID":"/CMDjq/:17:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 判断是数组指定的下标是否存在has 函数能判断数组下标值是否存在 [root@localhost ~]# echo '[21,33,44]' | jq 'has(2)' true [root@localhost ~]# echo '[21,33,44]' | jq 'has(3)' false [root@localhost ~]# echo '[21,33,44]' | jq 'has(0)' true ","date":"2022-09-03","objectID":"/CMDjq/:18:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 对所有key的值或数组进行操作map 与 map_values 都可以对值或数组进行统一操作。对与数组它们的反回结果没有区别，都是返回一个处理后的数组。如果是对象，map 返回的是数组，map_values 返回的是对象 [root@localhost ~]# echo '[1, 2, 3, 4, 5]' | jq 'map(. + 1)' [ 2, 3, 4, 5, 6 ] [root@localhost ~]# echo '[1, 2, 3, 4, 5]' | jq 'map_values(. + 1)' [ 2, 3, 4, 5, 6 ] [root@localhost ~]# echo '{\"a\": 1, \"b\": 2, \"c\": 3}' | jq 'map_values(.+1)' { \"a\": 2, \"b\": 3, \"c\": 4 } [root@localhost ~]# echo '{\"a\": 1, \"b\": 2, \"c\": 3}' | jq 'map(.+1)' [ 2, 3, 4 ] ","date":"2022-09-03","objectID":"/CMDjq/:19:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["linux"],"content":" 根据表达式选择对象或数组select(boolean_expression) 函数表示如果对象或数组满足某个表达式，则输出所在对象或数组 # 输出 id 为 second 所在对象 [root@localhost ~]# echo '[{\"id\": \"first\", \"val\": 1}, {\"id\": \"second\", \"val\": 2}]' | jq '.[] | select(.id == \"second\")' { \"id\": \"second\", \"val\": 2 } 输出数组中大于2的值。下面示例中，map函数将对每个值都判断是否大于2，如果大于2则产生输出被map构建成新的数组 [root@localhost ~]# echo '[1,5,3,0,7]' | jq 'map(select(. \u003e= 2))' [ 5, 3, 7 ] ","date":"2022-09-03","objectID":"/CMDjq/:20:0","tags":["命令","jq","linux","windows"],"title":"jq - 命令行 josn 数据处理工具","uri":"/CMDjq/"},{"categories":["k8s"],"content":" pod抢占其它pod时有多个节点的pod可以被抢占，用什么方式决定抢占哪个节点 pod触发抢占后目标节点上有多个pod可以被抢占，用什么方式决定抢占哪个或哪些pod pod抢占多个pod时，用什么方式决定被抢占pod的驱逐顺序 pod抢占多个pod过程中发起抢占的pod已经被调度，那被抢占的pod可能有这些情况：已经被驱逐、正在被终止、即将被驱逐。k8s是如何处理这些pod 怎么查看准入控制器执行顺序","date":"2022-09-03","objectID":"/k8sFAQ/:0:0","tags":["k8s","FAQ k8s"],"title":"k8s问答","uri":"/k8sFAQ/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux: 8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s官方文档: 名字空间 k8s官方文档: Namespace k8s官方文档: 管理内存、CPU 和 API 资源 名称空间在 k8s 中，名称空间（NameSpace）是将同一集群中资源划分为相互隔离的机制。在同一名称空间中同类资源名称要具有唯一性。并非所有资源对象都在名称空间中，比如名称空间自身。 # 位于名字空间中的资源，被名称空间隔离 [root@k8s01 ~]# kubectl api-resources --namespaced=true NAME SHORTNAMES APIVERSION NAMESPACED KIND bindings v1 true Binding configmaps cm v1 true ConfigMap ... # 不在名字空间中的资源，无法使用名称空间隔离 [root@k8s01 ~]# kubectl api-resources --namespaced=false NAME SHORTNAMES APIVERSION NAMESPACED KIND componentstatuses cs v1 false ComponentStatus namespaces ns v1 false Namespace nodes no v1 false Node persistentvolumes pv v1 false PersistentVolume 查看名称空间信息可以使用以下方式查看现用名称空间 [root@k8s01 ~]# kubectl get namespace NAME STATUS AGE calico-system Active 40d default Active 40d ingress-nginx Active 3d3h kube-node-lease Active 40d kube-public Active 40d kube-system Active 40d note Active 4d2h tigera-operator Active 40d k8s 会创建四个初始名称空间： default: 默认使用的名字空间，可以使用 kubectl config set-context --current --namespace 命令修改 kube-system: k8s 系统创建对象所使用的名字空间 kube-public: 这个名字空间是自动创建的，所有用户（包括未经过身份验证的用户）都可以读取它。 kube-node-lease: 此名字空间用于与各个节点相关对象 查看名称空间信息 [root@k8s01 ~]# kubectl get namespace kube-system -o yaml apiVersion: v1 kind: Namespace metadata: creationTimestamp: \"2022-07-24T10:23:09Z\" labels: kubernetes.io/metadata.name: kube-system name: kube-system resourceVersion: \"4\" uid: f3535844-ad3a-475e-89f2-6b9ddcde2edf spec: finalizers: - kubernetes status: phase: Active namespace.status.phase 字段描述了其生命周期，有以下值： Active: 名称空间可用 Terminating: 名字空间正在被删除（名称空间内对象还没正常删除），且不能被用于新对象。 创建名称空间可以使用 kubectl create namespace 命令或 yaml 文件创建名称空间。名称空间的名称必须是一个合法的 DNS 标签。当名称前缀为 kube- 时被理解为 k8s 集群使用 下面是创建名称空间示例 apiVersion: v1 kind: Namespace metadata: name: note 删除名称空间使用 kubectl delete namespaces 命令可以删除名称空间，删除操作是异步的，会先删除名称空间内资源，在这期间它处于 Terminating 状态 # 终端 1 [root@k8s01 ~]# kubectl delete namespace note namespace \"note\" deleted # 终端 2 [root@k8s01 ~]# kubectl get ns note NAME STATUS AGE note Terminating 4d3h 设置名称空间默认计算机资源限制","date":"2022-09-02","objectID":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/:0:0","tags":["k8s","名称空间"],"title":"k8s中的名称空间","uri":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/"},{"categories":["k8s"],"content":" 配置容器默认内存与cpu资源配额下面清单文件中声明 note 名称空间中容器默认的内存与 cpu 请求和默认的内存限制 apiVersion: v1 kind: LimitRange metadata: name: note-limit-range namespace: note spec: limits: - default: memory: 512Mi # 默认内存限制 cpu: 1 defaultRequest: memory: 256Mi # 默认内存请求 cpu: 0.5 type: Container # 适用限制对象 当 pod 内容器没有指定内存请求与限制时，使用上述清单文件中的值 当 pod 内容器没有指定内存请求值时，容器的内存请求等于它指定的内存限制值。即上述清单文件中默认请求值无效 当 pod 内容器没有指定内存限制值时，使用上述默认内存限制值 cpu 与上述可理 ","date":"2022-09-02","objectID":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/:1:0","tags":["k8s","名称空间"],"title":"k8s中的名称空间","uri":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/"},{"categories":["k8s"],"content":" 配置容器默认内存与cpu限制下面清单文件中声明 note 名称空间中容器内存使用限制。当容器请求内存超过 1G 或低于 500M 时会报错。cpu 同理。 apiVersion: v1 kind: LimitRange metadata: name: note-min-max-demo-lr namespace: note spec: limits: - max: memory: 1Gi cpu: \"800m\" min: memory: 500Mi cpu: \"200m\" type: Container 限制名称空间中pod数量下面清单文件限制 note 名称空间中最多创建 12 个 pod apiVersion: v1 kind: ResourceQuota metadata: name: pod-demo namespace: note spec: hard: pods: \"12\" API 操作","date":"2022-09-02","objectID":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/:2:0","tags":["k8s","名称空间"],"title":"k8s中的名称空间","uri":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/"},{"categories":["k8s"],"content":" 查看现有名称空间GET /api/v1/namespaces 有以下响应状态码： 200 401: 无权限 [root@k8s01 ~]# curl -sX GET 127.0.0.1:8001/api/v1/namespaces | jq '.items[]|.metadata.name' \"calico-system\" \"default\" \"ingress-nginx\" \"kube-node-lease\" \"kube-public\" \"kube-system\" \"note\" \"tigera-operator\" ","date":"2022-09-02","objectID":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/:3:0","tags":["k8s","名称空间"],"title":"k8s中的名称空间","uri":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/"},{"categories":["k8s"],"content":" 查看指定名称空间信息GET /api/v1/namespaces/{name} 有以下状态码： 200 401: 无权限 [root@k8s01 ~]# curl -sX GET 127.0.0.1:8001/api/v1/namespaces/note { \"kind\": \"Namespace\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"note\", \"uid\": \"df94086b-17ea-4c3a-b252-d7a8f791a939\", ","date":"2022-09-02","objectID":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/:4:0","tags":["k8s","名称空间"],"title":"k8s中的名称空间","uri":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/"},{"categories":["k8s"],"content":" 创建名称空间 PS 2023/06/18 22:41:05 \u003e curl.exe -s -w \"\\n响应状态码：%{http_code}\" ` \u003e\u003e --cert .\\localK8s\\xiaosi.crt --key .\\localK8s\\xiaosi.key --cacert .\\localK8s\\ca.crt ` \u003e\u003e -H \"Content-Type: application/yaml\" ` \u003e\u003e --data-binary \"@xiaosiNamespace.yaml\" ` \u003e\u003e -X POST https://192.168.232.100:6443/api/v1/namespaces { \"kind\": \"Namespace\", \"apiVersion\": \"v1\", \"metadata\": { ... } 响应状态码：201 ","date":"2022-09-02","objectID":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/:5:0","tags":["k8s","名称空间"],"title":"k8s中的名称空间","uri":"/k8s%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s官方文档: Ingress k8s官方文档: NGINX Ingress Controller istio官方文档: Kubernetes Ingress ingress 及其控制器ingress 是集群外部访问 k8s 集群中服务进行管理的 API 对象，该对象只是定义规则把流量导向 server 对象，具体由 ingress controller 实现 NGINX Ingress Controller [root@k8s01 ~]# kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.0/deploy/static/provider/baremetal/deploy.yaml namespace/ingress-nginx created serviceaccount/ingress-nginx created serviceaccount/ingress-nginx-admission created role.rbac.authorization.k8s.io/ingress-nginx created role.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrole.rbac.authorization.k8s.io/ingress-nginx created clusterrole.rbac.authorization.k8s.io/ingress-nginx-admission created rolebinding.rbac.authorization.k8s.io/ingress-nginx created rolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx created clusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission created configmap/ingress-nginx-controller created service/ingress-nginx-controller created service/ingress-nginx-controller-admission created deployment.apps/ingress-nginx-controller created job.batch/ingress-nginx-admission-create created job.batch/ingress-nginx-admission-patch created ingressclass.networking.k8s.io/nginx created validatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission created ","date":"2022-08-30","objectID":"/ingress/:0:0","tags":["k8s","ingress","ingress 控制器"],"title":"ingress 与 ingress 控制器","uri":"/ingress/"},{"categories":["golang"],"content":" 运行环境： go: 1.15 内容来自以下文档： Go语言圣经-函数 go语言基础之函数有多个返回值 Nick Coghlan: Go 系列教程 —— 12. 可变参数函数【fengchunsgit 译】 Nick Coghlan: Go 系列教程 —— 6. 函数【Junedayday 译】 函数函数可以把多个语句序列打包为一个单元，然后可以从程序中其它地方多次调用。函数的机制可以让我们将一个大的工作分解为小的任务，这样的小任务可以让不同程序员在不同时间、不同地方独立完成。函数声明包括函数名、形式参数列表、返回值列表（可省略）以及函数体。语法如下： func name(parameter-list) (result-list) { body } 形式参数列表（parameter-list）描述了函数参数以及参数类型，这些参数作为局部变量由参数调用者提供。返回值描述了函数返回值的比那里名以及类型，如果函数返回一个无名变量或没有返回值，则返回值部分括号可以省略不写；如果函数声明没有写返回值列表(result-list 部分)，那边函数不会返回任何值；函数返回的每个值（如果有）是一个局部变量，并更据其类型初始化 // calculateBill 函数名 // 第一个函数参数 price 是 int 类型的，第二个函数参数 no 是 int 类型 // 相同类型的参数可以写为一组如下面参数等效 price no int // calculateBill 行最后一个 int 为返回值类型 func calculateBill(price int, no int) int { // return 把值返回给函数调用者，即 fmt.Println return price * no } func main() { // Total price is 6 fmt.Println(\"Total price is\", calculateBill(2, 3)) // 打印到控制台上 } func first(x int, _ int) int {return x } func main() { fmt.Printf(\"%T\\n\", first) } 函数的类型被称为函数的标识符。如果两个函数形式参数列表和返回值列表中的变量类型一一对应，那么这两个函数被认为有相同的类型或标识符。形参和返回值的变量名不影响函数标识符，也不影响它们是否可以以省略参数类型的形式表示。每一次函数调用都必须按照声明顺序为所有参数提供实参（参数值）。在函数调用时，Go语言没有默认参数值，也没有任何方法可以通过参数名指定形参,因此形参和返回值的变量名对于函数调用者而言没有意义。 在函数体中，函数的形参作为局部变量，被初始化为调用者提供的值。函数的形参和有名返回值作为函数最外层的局部变量，被存储在相同的词法块中。实参通过值的方式传递，因此函数的形参是实参的拷贝。对形参进行修改不会影响实参。但是，如果实参包括引用类型，如指针，slice(切片)、map、function、channel等类型，实参可能会由于函数的间接引用被修改 可变参数参数数量可变的函数称为可变参数函数。在声明可变参数函数时，需要在参数列表的最后一个参数类型之前加上省略符号(...)，这表示该函数会接收任意数量的该类型参数。只有函数的最后一个参数才允许是可变的。如 append 函数 elems 为可变函数，它不能与 slice 参数交换位置 func append(slice []Type, elems ...Type) []Type 示例 // vals 被当成[]int类型的切片处理 func sum(vals ...int) int { total := 0 // fmt.Println(sum(1, 2, 3, 4)) // val = [1, 2, 3, 4] for _, val := range vals { // 等效 total = total + val // fmt.Println(sum(1, 2, 3, 4))： // 第一次：0 = 0 + 1 得 1 // 第二次：1 = 1 + 2 得 3 // 第三次：3 = 3 + 3 得 6 // 第四次：6 = 6 + 4 得 10 total += val } // 返回变量 total return total } func main() { // 输出： 0 fmt.Println(sum()) // 输出： 3 fmt.Println(sum(3)) // 输出： 10 fmt.Println(sum(1, 2, 3, 4)) } 在上面的代码中，调用者隐式的创建一个数组，并将原始参数复制到数组中，再把数组的一个切片作为参数传给被调用函数。如果原始参数已经是切片类型，我们该如何传递给sum？只需在最后一个参数后加上省略符 values := []int{1, 2, 3, 4} fmt.Println(sum(values...)) 由于切片后加上 ... 后缀是将切片直接传入函数，因此函数修改切片值时会影响原值（切片是引用类型），除非在修改前进行了扩容 func change(s ...string) { s[0] = \"Go\" } func main() { welcome := []string{\"hello\", \"world\"} change(welcome...) // Go world fmt.Println(welcome) } 虽然在可变参数函数内部，...int型参数的行为是当成切片处理，但实际上，可变参数函数和以切片作为参数的函数是不同的 func f(...int) {} func g([]int) {} func main() { fmt.Printf(\"%T\\n\", f) // \"func(...int)\" fmt.Printf(\"%T\\n\", g) // \"func([]int)\" } 多返回值在Go中，一个函数可以返回多个值。许多标准库中的函数有两个返回值，一个是期望返回值，一个是函数错误返回值。可以在返回值列表中依次指定返回列表值的类型(不指定返回值变量)。返回值以及接收返回值的变量，它们的数量，数据类型，接收变量必须一一对应，多余的返回值可以使用空标识符(_)接收 //go推荐用法 // 依次指定返回值的三个数据类型，不能缺少 func myfunc01() (int, string, float64) { // 依次指定返回值，，不能缺少 return 1, \"str\", 3.3 } func main() { // 依次指定接收返回值的变量，不能有缺少 // _ 该下划线表示空标识符，会忽略变量 a, b, _ := myfunc01() // 输出：1 str fmt.Println( a, b) } 还可以在返回值列表指定返回值的变量以及数据类型。返回值会更据返回值列表中变量排序，不需要一一对应；接收函数返回值变量必须和函数返回值列表一一对应；多余的返回值可以使用空标识符(_)接收 //go官方推荐写法 // a, b int 等效 a int, b int // 值分别是：222 111 str func myfunc02() (a, b int, c string) { b, a, c = 111, 222, \"str\" // 没有指定返回值按函数指定的返回列表返回 即 a b c 变量 return } func main() { //函数调用 a, _, z := myfunc02() // 输出：222 str fmt.Println( a, z) } 函数值（头等函数）在Go中，函数被看作第一类值（first-class values）: 函数像其他值一样，拥有类型，可以被赋值给其他变量，传递函数，函数返回。对函数值的调用类似函数调用，如下示例 func square(n int) int { return n * n } func negative(n int) int { return -n } func product(m, n int) int { return m * n } func main() { f := square // 输出： 9 fmt.Println(f(3)) f = negative // 输出： -3 fmt.Println(f(3)) // cannot use product (type func(int, int) int) // as type func(int) int in assignment f = product } 函数类型的零值是nil。调用值为nil的函数值会引起panic错误：函数值可以与nil比较，但函数值之间是不可比较，也不能用函数值作为map的key。 func main() { var f func(int) int if f != nil { f(3) } } 函数递归函数递归就是函数本身间接或直接调用自己。Go语言使用可变栈，栈的大小按需增加(初始时很小)。这使得我们使用递归时不必考虑溢出和安全问题 func fibonacci(n int) int { // n 小于 2 时 直接反回 int 类型的值 // 该条件是必须的，否则会无限循环 // n = 0 -\u003e 0 // n = 1 -\u003e 1 if n \u003c 2 { return n } // n = 2 , fibonacci(2-2) + fibonacci(2-1) //","date":"2022-08-26","objectID":"/go-function/:0:0","tags":["golang"],"title":"go 函数","uri":"/go-function/"},{"categories":["golang"],"content":" 错误处理策略当一次函数调用返回错误时，调用者应该选择合适的方式处理错误。根据情况的不同，有很多处理方式 非Go实现的函数如果函数声明中没有函数体，则表示该函数并非Go语言实现，如下： package math // 由汇编语言实现的函数 func Sin(x float64) float 匿名函数匿名函数即没有名称的函数，声明方式与普通函数类似，区别在于func关键字后没有函数名。函数值字面量是一种表达式，它的值被称为匿名函数。允许在使用函数时再定义函数，通过这种方式定义的函数可以访问完整的词法环境，因此，在函数中定义的内部函数可以引用该函数的变量。 语法如下： func(参数列表) 返回值列表 { 函数体... }(传递参数) func main() { // x, y 是传递给函数的参数列表 func(x,y int){ // 5 fmt.Println(x + y) }(2,3)// x=2,y=3 } 如上面示例，匿名函数是一次性的，可以保存在变量中，重复使用 func main() { // x, y 是传递给函数的参数列表 f1 := func(x,y int)int{ return x+y } // 得到匿名函数 f1 内存地址 fmt.Println(f1) // 输出 6 fmt.Println(f1(2,4)) } 无参数的匿名函数传递参数的跨号不能省略 func main() { func() { // 19 fmt.Println(9 + 10) }() } 函数闭包在支持函数是一等公民的语言中，一个函数的返回值是另一个函数，被返回的函数可以访问父函数内的变量，当这个被返回的函数在外部执行时，就产生了闭包。闭包函数有以下关键信息： 函数是一等公民：支持头等函数（First Class Function）的编程语言，可以把函数赋值给变量，也可以把函数作为其它函数的参数或者返回值。Go 语言支持头等函数的机制。 闭包所处环境，可以引用环境里的值 当一个匿名函数所访问的变量定义在函数体的外部时，就称这样的匿名函数为闭包。 func main() { a := 5 func() { // 匿名函数在访问了变量 a ,而 a 存在于函数体的外部。因此这个匿名函数就是闭包。 fmt.Println(\"a =\", a) }() } 每一个闭包都会绑定一个它自己的外围变量（Surrounding Variable）。 func main() { t := \"Hello\" c1 := func(b string) string { // t 变量是外部变量且当前函数是匿名的，称为闭包函数 // 修改 t 变量时会改变外部变量 t 的值 t = t + \" \" + b return t } // Hello a fmt.Println(c1(\"a\")) // Hello a b fmt.Println(c1(\"b\")) } 闭包函数为函数返回值时会保留状态，示例1 func appendStr() func(string) string { t := \"Hello\" // t 分别绑定了 a 变量与 b 变量的值 c := func(b string) string { t = t + \" \" + b return t } return c } func main() { // 变量 a 和 b 都是闭包，它们绑定了各自的 t 值 a := appendStr() b := appendStr() // Hello World // 首先用参数 World 调用了 a。现在 a 中 t 值变为了 Hello World。 fmt.Println(a(\"World\")) // Hello Everyone // 用参数 Everyone 调用了 b。由于 b 绑定了自己的变量 t，因此 b 中的 t 还是等于初始值 Hello fmt.Println(b(\"Everyone\")) // Hello World Gopher fmt.Println(a(\"Gopher\")) // Hello Everyone ! fmt.Println(b(\"!\")) } 示例2，变量f隐式的保存了x变量的值 // 函数名 squares() // 返回值 func() int func squares() func() int { var x int // 返回一个匿名函数 return func() int { x++ return x * x } } func main() { f := squares() fmt.Println(f()) // \"1\" fmt.Println(f()) // \"4\" fmt.Println(f()) // \"9\" fmt.Println(f()) // \"16\" } func main() { done := make(chan bool) values := []string{\"a\", \"b\", \"c\"} for _, v := range values { go func() { fmt.Println(v) done \u003c- true }() } // wait for all goroutines to complete before exiting for _ = range values { \u003c-done } } 自定义函数类型 // 创建了一个新的函数类型 add，它接收两个整数型参数，并返回一个整数型值。 type add func(a int, b int) int func main() { // 定义变量 a 为 add 类型并向赋值了一个符合 add 类型签名的函数 var a add = func(c int, d int) int { return a + b } // 掉用 a 变量，函数运行后返回值赋值给 s 变量 s := a(5, 6) // Sum 11 fmt.Println(\"Sum\", s) } 高阶函数满足下列条件之一的函数称为高阶函数（Hiher-order Function）： 接收一个或多个函数作为参数 返回值是一个函数 函数作为参数示例 // sipmle 函数把匿名函数作，该匿名函数把2个int类型值为参数，int 类型做为返回值，并赋值给 a 变量 // sipmle 函数没有返回值 func simple(a func(aa, bb int) int) { fmt.Println(a(60, 7)) } func main() { f := func(a, b int) int { return a + b } // 67 simple(f) } 函数中返回函数示例 // simple 函数没有参数，它的返回值是一个匿名函数，该函数接收2个 int 类型值，返回一个 int 类型值 func simple() func(c, d int) int { // return 返回 simple 定义的返回类型，即 func(c, d int) int 函数类型 // 60 与 7 传入函数 return func(a, b int) int { // 返回值为 67 return a + b } } func main() { fmt.Println(simple()(60, 7)) } defer 语名延迟调用函数含有 defer 语句的函数，会在该函数将要返回之前，调用另一个函数。 func increaseA() int { var i int defer func() { i++ }() // 此时已经绑定到返回值 // 函数结束时调用匿名函数修改 i 的值不影响输出 return i } func increaseB() (r int) { defer func() { r++ }() // 返回 r 变量, // r int 会把 r 初始化为 0 // 函数结束时调用匿名函数修改 r 的值为 1 return r } func main() { // 0 fmt.Println(increaseA()) // 1 fmt.Println(increaseB()) } ","date":"2022-08-26","objectID":"/go-function/:1:0","tags":["golang"],"title":"go 函数","uri":"/go-function/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： [程磊: 深入理解Linux进程调度][深入理解Linux进程调度] 进程调度策略与优先级转换 chrt 命令 # 修改调度策略: chrt [options] \u003cpriority\u003e \u003ccommand\u003e [\u003carg\u003e...] chrt [options] --pid \u003cpriority\u003e \u003cpid\u003e # 查看进程调度策略 chrt [options] -p \u003cpid\u003e # 可设置的进程调度策略(priority) -b, --batch # SCHED_BATCH -d, --deadline # SCHED_DEADLINE -f, --fifo # SCHED_FIFO -i, --idle # SCHED_IDLE -o, --other # SCHED_OTHER -r, --rr # SCHED_RR (缺省时默认值) # 调度选项(arg) -R, --reset-on-fork # set SCHED_RESET_ON_FORK for FIFO or RR -T, --sched-runtime \u003cns\u003e # runtime parameter for DEADLINE -P, --sched-period \u003cns\u003e # period parameter for DEADLINE -D, --sched-deadline \u003cns\u003e # deadline parameter for DEADLINE # chrt 命令选项 -h, --help # 查看帮助 -a, --all-tasks # 对进程内所有线程操作 -m, --max # 查看调度策略可选的优先级 -p, --pid # 指定进程 PID ","date":"2022-08-26","objectID":"/chrt%E5%91%BD%E4%BB%A4/:0:0","tags":["linux","命令","chrt 命令"],"title":"linux 中的 chrt 命令","uri":"/chrt%E5%91%BD%E4%BB%A4/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： Linux就该这么学: 几种删除Linux目录的方法 使用 rmdir 命令实现rmdir 命令很简单，判断目录是是否有内容，无内容则删除，只能递归空目录 # -p 选项只能递归空目录 [root@localhost ~]# rmdir -p /usr/local/nginx/note/ # 要借助通配符才能实现递归删除空目录 [root@localhost ~]# rmdir -p /usr/local/nginx/note/*/*/*/*/* 使用 find 命令实现 # -type 指定为目录类型 # -empty 只对空目录进行限制 # -delete 执行删除操作，包括子目录在内的所有空目录 [root@localhost ~]# find /usr/local/nginx/note/ -type d -empty -delete ","date":"2022-08-23","objectID":"/rmdir%E5%91%BD%E4%BB%A4/:0:0","tags":["linux","命令","rmdir 命令"],"title":"linux 中删除空目录","uri":"/rmdir%E5%91%BD%E4%BB%A4/"},{"categories":["容器"],"content":" 运行环境： docker: 20.10.17 centos: 7.9.2009 内容来自以下文档： dys: 如何清理 Docker 占用的磁盘空间 docker 使用磁盘情况 [root@localhost ~]# docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 2 1 489.7MB 444MB (90%) Containers 1 1 0B 0B Local Volumes 8 0 615.3MB 615.3MB (100%) Build Cache 0 0 0B 0B TYPE 列展示 docker 使用磁盘空间的类型 Images: 镜像占用的空间 Containers: 运行的容器占用空间，表示每个容器的读写层空间。 Local Volumes: 容器挂载本地数据卷空间。 Build Cache: 镜像构建过程中产生的缓存空间 RECLAIMABLE 表示可回收空间 SIZE: 占用空间总大小 可以使用以下命令一键清理 docker system prune ","date":"2022-08-22","objectID":"/docker/:0:0","tags":["docker"],"title":"docker 的使用","uri":"/docker/"},{"categories":["容器"],"content":" 镜像占用的空间除了下载的镜像以外，还包含以下镜像： 子镜像：被其他镜像引用的中间镜像，不能被删除。 悬挂状态的镜像：不会再被使用的镜像，可以被删除。 使用以下命令查看悬挂状态的镜像： [root@localhost ~]# docker image ls -f dangling=true REPOSITORY TAG IMAGE ID CREATED SIZE 可以使用以下命令清理悬挂状态的镜像 docker image prune # 或 docker image rm $(docker image ls -f dangling=true -q) 想要删除空闲的镜像使用以下命令： # 正在被容器使用的镜像是不能被删除 [root@localhost ~]# docker image rm $(docker image ls -q) Untagged: mysql:latest Untagged: mysql@sha256:152cf187a3efc56afb0b3877b4d21e231d1d6eb828ca9221056590b0ac834c75 Deleted: sha256:33037edcac9b155a185e9555a5da711d754c88cb244e3d13e214db029c3b28ed Deleted: sha256:e07ca19696a3b8bebc2402178e99e2868cb06660659d41c70ebac75fef2765f5 Deleted: sha256:f1dd3e055468ab94e23ee30737526f70fd427a8d06e5c66b28bc853601a847e8 Deleted: sha256:7ded1235e2ffabbcc6e9ec5a7d0294ed5355c802257474753d5323a77eb1986b Deleted: sha256:c78e2197d9a3032659622c07f6dbf7ec74f5c3a1f40fc866518b13a96c36ff21 Deleted: sha256:7218564d8eb6218c8e2d4c42959856d15745d321eec986a308383c7402a0bb3c Deleted: sha256:a6509f1471522b5033d28622c0e48942b16eb685a156b1771d984a7041969a7a Deleted: sha256:ce92b5bb86bd1d23ba0db641ea1a4009a76c59b6f1fb69e917c904407fda060c Deleted: sha256:5b4e33f9109ff778969630f905ff31336c187cace319b73a3f1106bce02dcad9 Deleted: sha256:ef40bcf2fa76e9055e74eba2580488b98e17d795c96b96670f56b238b685a14d Deleted: sha256:c294df63d04d9c99ad34fd2279f9c2b021486088d33f4d5de335c6712657bec9 Deleted: sha256:c6c89a36c214d7ecf7a684bf0fc21692dd60e9f204f48545bcb4085185166031 Error response from daemon: conflict: unable to delete 76fd3504ef5e (cannot be forced) - image is being used by running container 5f586f25f13f ","date":"2022-08-22","objectID":"/docker/:1:0","tags":["docker"],"title":"docker 的使用","uri":"/docker/"},{"categories":["容器"],"content":" 容器占用的空间每次创建一个容器时，都会有一些文件和目录被创建： /var/lib/docker/containers/ID: 如果容器使用了默认的日志模式，他的所有日志都会以 JSON 形式保存到此目录下 /var/lib/docker/overlay2: 目录下含有容器的读写层，如果容器使用自己的文件系统保存了数据，那么就会写到此目录下 可以使用以下命令删除 [root@localhost ~]# docker container prune WARNING! This will remove all stopped containers. Are you sure you want to continue? [y/N] y Total reclaimed space: 0B ","date":"2022-08-22","objectID":"/docker/:2:0","tags":["docker"],"title":"docker 的使用","uri":"/docker/"},{"categories":["容器"],"content":" 数据卷占用的空间容器挂载的数据卷不会随着容器删除而删除，有些镜像制作时有意自动挂载卷来避免容器被销毁时导致的数据丢失。 使用以下命令删除容器自动挂载的数据卷，注意，三思尔后行 docker volume rm $(docker volume ls -q) # 或 [root@localhost ~]# docker volume prune WARNING! This will remove all local volumes not used by at least one container. Are you sure you want to continue? [y/N] y Deleted Volumes: 017f2200bd10ca8b385ef396009e9fbf1d93fc34e8d7e0420940ea1ab9081613 51ef34108bbe565434899193da82d4a8800de78aba43f9cc5ceb7358be23854e 948475daf66f1768afbaa595c636bfcf809dc60c24ca39b81591b0416f4e5308 ArtalkData b04ca26c6af33b934a3921dc193a837fe164583306e62698d6f11984e055781b cde0f661aed8553824775f8f6cdfdba3703a63b5e91ca25f9f44802a501df0c3 e7b1b6fbb553da33a465041450a228b06e44818dfc324899fe735cf830b0852d ff971a81cf454aa4ca3a0533f13a9343881e8f080719fdd7e995d6f50f9761ed Total reclaimed space: 615.3MB ","date":"2022-08-22","objectID":"/docker/:3:0","tags":["docker"],"title":"docker 的使用","uri":"/docker/"},{"categories":["容器"],"content":" 构建镜像时残留的数据Docker 18.09 引入了 BuildKit。 目的是提升了构建过程的性能、安全、存储管理等能力。 使用以下命令可以删除构建残留的数据 docker builder prune ","date":"2022-08-22","objectID":"/docker/:4:0","tags":["docker"],"title":"docker 的使用","uri":"/docker/"},{"categories":["个人记事"],"content":"./R-C.jpg 文档 ID每个文档都有自己的 ID, 且具有唯一性。由2个归档位+2个类型位+8个创建日期位+2个文件顺序位组成 文档 id 写在头部注释中 ","date":"2022-08-18","objectID":"/00012022081801/:0:0","tags":["文档系统"],"title":"个人文档系统","uri":"/00012022081801/"},{"categories":["个人记事"],"content":" 归档编号 00: 个人记事本 01: linux 操作系统相关文档 02: vim 相关文档 03: k8s 相关文档 04: 容器相关 ","date":"2022-08-18","objectID":"/00012022081801/:1:0","tags":["文档系统"],"title":"个人文档系统","uri":"/00012022081801/"},{"categories":["个人记事"],"content":" 文档格式编号 00: txt 文档 01: md 文档 02: sh 文档 03: yaml 文档 ","date":"2022-08-18","objectID":"/00012022081801/:2:0","tags":["文档系统"],"title":"个人文档系统","uri":"/00012022081801/"},{"categories":["个人记事"],"content":" 创建日期与顺序位创建日期由年月日组成，顺序位表示相同日期的第几份文档。如：2022010128 表示2022年1月1日创建的第28份文档 ","date":"2022-08-18","objectID":"/00012022081801/:3:0","tags":["文档系统"],"title":"个人文档系统","uri":"/00012022081801/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux: 8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s 官方文档：调度、抢占和驱逐 k8s 官方文档：Kubernetes 调度器 kube-schedulerk8s 调度器是一个控制面进程，负责将 Pods 指派到节点上。 调度器基于约束和可用资源为调度队列中每个 Pod 确定其可合法放置的节点。 调度器之后对所有合法的节点进行排序，将 Pod 绑定到一个合适的节点。 在同一个集群中可以使用多个不同的调度器 [root@k8s01 ~]# kubectl get pod -n kube-system kube-scheduler-k8s01.localdomain -o=jsonpath='{$.spec.containers[0].command}' | jq [ \"kube-scheduler\", \"--authentication-kubeconfig=/etc/kubernetes/scheduler.conf\", \"--authorization-kubeconfig=/etc/kubernetes/scheduler.conf\", \"--bind-address=0.0.0.0\", \"--feature-gates=TTLAfterFinished=true,EphemeralContainers=true\", \"--kubeconfig=/etc/kubernetes/scheduler.conf\", \"--leader-elect=true\" ] 配置与选项","date":"2022-08-14","objectID":"/k8sScheduler/:0:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 指定鉴权 kubeconfig 文件路径kube-scheduler -authentication-kubeconfig 选项指定 kubeconfig 文件，该 kubeconfig 文件具有创建 tokenaccessreviews.authentication.k8s.io 核心服务的权限。如果此选项为空，则则所有令牌请求均被视为匿名请求，并且不会在集群中查找任何客户端 CA 证书 ","date":"2022-08-14","objectID":"/k8sScheduler/:1:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 指定授权 kubeconfig 文件路径kube-scheduler --authorization-kubeconfig 选项指定 kubeconfig 文件，该 kubeconfig 文件具有创建 subjectaccessreviews.authorization.k8s.io 服务权限。 如果此选项为空，则所有未被鉴权机制略过的请求都会被禁止。 ","date":"2022-08-14","objectID":"/k8sScheduler/:2:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 监听地址kube-scheduler --bind-address 选项指定监听 ip 地址 ","date":"2022-08-14","objectID":"/k8sScheduler/:3:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 特性开关kube-scheduler --feature-gates 指定特性开关 ","date":"2022-08-14","objectID":"/k8sScheduler/:4:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 是否启用选举领导者kube-scheduler --leader-elect 选项如果为 true, 则在执行主循环之前，开始领导者选举并选出领导者。 使用多副本来实现高可用性时，可启用此标志。 调度框架调度框架可以为现有的调度器添加了一组新的插件 API，调度框架定义了一些扩展点。调度器插件注册后在一个或多个扩展点处被调用。 这些插件中的一些可以改变调度决策，而另一些仅用于提供信息。 每次调度一个 Pod 的尝试都分为两个阶段： 调度周期：为 Pod 选择一个节点，是串行运行的 绑定周期。将该决策应用于集群，可能是同时运行的 如果确定 Pod 不可调度或者存在内部错误，则可以终止调度周期或绑定周期。 Pod 将返回队列并重试。 一个 Pod 的调度上下文顺序及可扩展插件点，一个插件可以在多个扩展点处注册，以执行更复杂或有状态的任务： 队列排序：这些插件用于对调度队列中的 Pod 进行排序。一次只能启动一个队列插件。 PreFilter: 这些插件用于预处理 Pod 的相关信息，或者检查集群或 Pod 必须满足的某些条件。 如果 PreFilter 插件返回错误，则调度周期将终止 Filter: 这些插件用于过滤出不能运行该 Pod 的节点。对于每个节点， 调度器将按照其配置顺序调用这些过滤插件。如果任何过滤插件将节点标记为不可行， 则不会为该节点调用剩下的过滤插件。节点可以被同时进行评估。 PostFilter: 这些插件在 Filter 阶段后调用，但仅在该 Pod 没有可行的节点时调用。 插件按其配置的顺序调用。如果任何 PostFilter 插件标记节点为 Schedulable， 则其余的插件不会调用。 PreScore: 这些插件用于执行 “前置评分（pre-scoring）” 工作，即生成一个可共享状态供 Score 插件使用。 如果 PreScore 插件返回错误，则调度周期将终止。 Score: 这些插件用于对通过过滤阶段的节点进行排序。调度器将为每个节点调用每个评分插件。 将有一个定义明确的整数范围，代表最小和最大分数。 在标准化评分阶段之后，调度器将根据配置的插件权重 合并所有插件的节点分数。 NormalizeScore: 这些插件用于在调度器计算 Node 排名之前修改分数。 在此扩展点注册的插件被调用时会使用同一插件的 Score 结果。 每个插件在每个调度周期调用一次。如果任何 NormalizeScore 插件返回错误，则调度阶段将终止。 Reserve: Reserve 是一个信息性的扩展点。 管理运行时状态的插件（也成为“有状态插件”）应该使用此扩展点，以便 调度器在节点给指定 Pod 预留了资源时能够通知该插件。 这是在调度器真正将 Pod 绑定到节点之前发生的，并且它存在是为了防止 在调度器等待绑定成功时发生竞争情况。这个是调度周期的最后一步。 一旦 Pod 处于保留状态，它将在绑定周期结束时触发 Unreserve 插件 （失败时）或 PostBind 插件（成功时）。 Permit: Permit 插件在每个 Pod 调度周期的最后调用，用于防止或延迟 Pod 的绑定。 一个允许插件可以做以下三件事之一： 允许：一旦所有 Permit 插件批准 Pod 后，该 Pod 将被发送以进行绑定。 拒绝：如果任何 Permit 插件拒绝 Pod，则该 Pod 将被返回到调度队列。 这将触发Unreserve 插件。 等待：如果一个 Permit 插件返回 “等待” 结果，则 Pod 将保持在一个内部的 “等待中” 的 Pod 列表，同时该 Pod 的绑定周期启动时即直接阻塞直到得到 批准。如果超时发生，等待 变成 拒绝，并且 Pod 将返回调度队列，从而触发 Unreserve 插件。 PreBind: 这些插件用于执行 Pod 绑定前所需的所有工作。这些插件用于执行 Pod 绑定前所需的所有工作。 Bind: Bind 插件用于将 Pod 绑定到节点上。直到所有的 PreBind 插件都完成，Bind 插件才会被调用。 各 Bind 插件按照配置顺序被调用。Bind 插件可以选择是否处理指定的 Pod。 如果某 Bind 插件选择处理某 Pod，剩余的 Bind 插件将被跳过。 PostBind: 这是个信息性的扩展点。 PostBind 插件在 Pod 成功绑定后被调用。这是绑定周期的结尾，可用于清理相关的资源。 Unreserve: 这是个信息性的扩展点。 如果 Pod 被保留，然后在后面的阶段中被拒绝，则 Unreserve 插件将被通知。 Unreserve 插件应该清楚保留 Pod 的相关状态。使用此扩展点的插件通常也使用 Reserve。 kube-scheduler 调度流程kube-scheduler 给一个 pod 做调度选择时包含两个步骤： 过滤：将所有满足 Pod 调度需求的节点选出来。受以下因素影响： 节点名称 节点标签 pod 标签 资源限制 打分：根据当前启用的打分规则，调度器会给每一个可调度节点进行打分。kube-scheduler 会将 Pod 调度到得分最高的节点上。 如果存在多个得分最高的节点，kube-scheduler 会从中随机选取一个。 kube-scheduler 支持以下方式配置调度器的过滤和打分行为： 调度策略：k8s:1.23 \u003e= 不再支持这种调度策略 调度配置文件：可以通过配置文件实现不同调度阶段的插件 调度到指定节点","date":"2022-08-14","objectID":"/k8sScheduler/:5:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 调度到指定某个节点pod.spec.nodeName 字段可以使 pod 调度到指定节点名，它的优先级比标签选择器、节点亲和性高。使用该方式有以下缺点： 指定的节点名不存在的情况下无法调度到其它节点，而且在某些情况下可能会被自动删除。 节点无法满足 pod 请求资源时，pod 会运行失败 下面是示例 [root@k8s01 ~]# kubectl -n note get pod nginx-deployment-6df7db8cbb-g68tm -o=jsonpath='{$.spec.nodeName}{\"\\n\"}' k8s02.localdomain ","date":"2022-08-14","objectID":"/k8sScheduler/:6:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 调度到有指定标签的节点pod.spec.nodeSelector 字段可以使 pod 调度到带有指定标签的节点。下面示例表示该 pod 调度到有 disktype=ssd 标签的节点 apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: disktype: ssd ","date":"2022-08-14","objectID":"/k8sScheduler/:7:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 节点亲和性亲和性和反亲和类似标签选择器，性扩展了你可以定义的约束类型。使用亲和性与反亲和性的一些好处有： 表达能力比 nodeSelector 方式更强 可以设置偏好，调度器在无法找到匹配节点时仍然调度该 Pod 不只依赖节点标签 设置节点亲和性有以下方式： pod.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution: 调度器只有在规则被满足的时候才能执行调度。功能类似 nodeSelector pod.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution: 调度器会尝试寻找满足对应规则的节点。如果找不到匹配的节点，调度器仍然会调度该 Pod 如果同时指定 pod.spec.nodeSelector字段和 pod.spec.affinity.nodeAffinity字段，必须同时满足， pod 才能调度到候选节点上。 如果指定多个 pod.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms 字段，只要满足其一，就可以作为候选节点。 如果在同个 pod.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms 字段中指定多个 matchExpressions 字段，则当所有 matchExpressions 满足时，就可以作为候选节点 下面示例通过以下方式选择节点，优先级从上往下 节点必须含有 topology.kubernetes.io/zone 标签，且值为 antarctica-east1 或 antarctica-west1 优先调度到具有标签值 label-1=key-1 或 label-2=key-2 节点上。weight 表示权重，该值会加到 kube-scheduler 节点打分上，使其更有优势 apiVersion: v1 kind: Pod metadata: name: with-node-affinity spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: topology.kubernetes.io/zone operator: In values: - antarctica-east1 - antarctica-west1 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: label-1 operator: In values: - key-1 - weight: 50 preference: matchExpressions: - key: label-2 operator: In values: - key-2 containers: - name: with-node-affinity image: k8s.gcr.io/pause:2.0 ","date":"2022-08-14","objectID":"/k8sScheduler/:8:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" pod 容忍度在 pod.spec.taints 字段可以设置标签选择器为节点添加污点，当 pod 无法容忍这些污点时（由 pod.spec.tolerations 字段指定，立即生效），根据污点策略调度执行相应的动作。该方式使节点能够排斥一类特定的 Pod。节点污点策略由 node.spec.taints.effect 字段设置，有以下可用值： NoExecute: pod 无法容忍污点时，节点控制器会驱逐这些 pod NoSchedule: pod 无法容忍污点时，调度器不会把新 pod 调度到该节点。已有 pod 继续运行 PreferNoSchedule: pod 无法容忍污点时，调度器尽量不调度到该节点 当有多个容忍度设置或多个污点设置时，要满足所有污点策略 可以使用 kubectl taint nodes 命令为节点添加污点，如下面示例为 k8s02.localdomain 节点添加一个 NoSchedule 类型的污点。亲的不容忍该污点 pod 不会调度到该节点 [root@k8s01 ~]# kubectl taint nodes k8s02.localdomain key1=value1:NoSchedule [root@k8s01 ~]# kubectl get node k8s02.localdomain -o=jsonpath='{@.spec.taints}' | jq [ { \"effect\": \"NoSchedule\", \"key\": \"key1\", \"value\": \"value1\" } ] 下面是 pod 设置容忍度示例，有以下含义： 能容忍含有 example-key 污点键的节点运行 禁止调度到含有键为 key1 的污点节点 如果节点增加了 NoExecute 类型的污点 node.kubernetes.io/unreachable 时，延迟 3600 秒驱逐（tolerationSeconds 字段只有污点策略为 NoExecute 时有效） apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: tolerations: - key: \"example-key\" operator: \"Exists\" - key: \"key1\" operator: \"Equal\" value: \"value1\" effect: \"NoExecute\" - key: \"node.kubernetes.io/unreachable\" operator: \"Exists\" effect: \"NoExecute\" tolerationSeconds: 6000 ... 当某种条件为真时，节点控制器会自动给节点添加污点： node.kubernetes.io/not-ready: 节点未准备好。这相当于节点状况 Ready 为 False node.kubernetes.io/unreachable: 节点控制器访问不到节点. 这相当于节点状况 Ready 为 Unknown node.kubernetes.io/memory-pressure: 节点存在内存压力 node.kubernetes.io/disk-pressure: 节点存在磁盘压力 node.kubernetes.io/pid-pressure: 节点的 PID 压力 node.kubernetes.io/network-unavailable: 节点网络不可用 node.kubernetes.io/unschedulable: 节点不可调度 ","date":"2022-08-14","objectID":"/k8sScheduler/:9:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" pod 之间和亲和性pod 亲和性可以基于已经在节点上运行的 Pod 的标签来过滤掉节点。人性化来说就是 pod 更倾向与哪些 pod 在同个节点上。该方式需要相当的计算量，因此会在大规模集群中显著降低调度速度。 pod.spec.affinity.podAffinity 字段表示 pod 之间亲和性，pod.spec.affinity.podAntiAffinity 字段表示 pod 之间反亲和性，它们都有以下字段： requiredDuringSchedulingIgnoredDuringExecution: pod 亲和 preferredDuringSchedulingIgnoredDuringExecution: pod 反亲和 下面示例表示有以下含义： pod.spec.affinity.podAffinity.requiredDuringSchedulingIgnoredDuringExecution``: 字段表示调度器必须将 pod调度到具有topology.kubernetes.io/zone=V标签的节点上，并且集群中至少有一个位于该可用区的节点上运行着带有security=S1标签的pod` pod.spec.affinity.podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution: 字段表示调度器不能调度到运行带有 security=S2 标签的 pod 且带有topology.kubernetes.io/zone=R 标签的节点上 apiVersion: v1 kind: Pod metadata: name: with-pod-affinity spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: topology.kubernetes.io/zone podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: topology.kubernetes.io/zone containers: - name: with-pod-affinity image: k8s.gcr.io/pause:2.0 topologyKey 字段指定节点标签，出于性能和安全原因有以下限制： pod.spec.affinity.podAffinity 字段中，topologyKey 字段不能为空 requiredDuringSchedulingIgnoredDuringExecution 字段中，准入控制器 LimitPodHardAntiAffinityTopology 要求 topologyKey 只能是 kubernetes.io/hostname 资源开销一个 pod 实际可能占用的资源 = 运行 pod 本身资源 + pod 内容器所需资源总合。目前默认调度不会考虑 pod 本身资源开销，除非启用了 ResourceQuota 对象 pod 本身开销 k8s 目前无法自动识别，要在 pod.spec.overhead 字段中指定。该字段无法直接设置，它会在 RuntimeClass 准入控制器中引用 RuntimeClass.overhead 字段值。因此要先创建 RuntimeClass 资源。 示例 --- apiVersion: node.k8s.io/v1 kind: RuntimeClass metadata: name: kata-fc handler: kata-fc overhead: podFixed: memory: \"120Mi\" cpu: \"250m\" --- apiVersion: v1 kind: Pod metadata: name: test-pod spec: runtimeClassName: kata-fc containers: - name: busybox-ctr image: busybox:1.28 stdin: true tty: true resources: limits: cpu: 500m memory: 100Mi - name: nginx-ctr image: nginx resources: limits: cpu: 1500m memory: 100Mi 拓扑分布该方法是尽量将 pod 副本分散到不同节点上。由 pod.spec.topologySpreadConstraints 字段设置。示例： --- apiVersion: v1 kind: Pod metadata: name: example-pod spec: # 配置一个拓扑分布约束 topologySpreadConstraints: - maxSkew: \u003cinteger\u003e minDomains: \u003cinteger\u003e # 可选；自从 v1.24 开始成为 Alpha topologyKey: \u003cstring\u003e whenUnsatisfiable: \u003cstring\u003e labelSelector: \u003cobject\u003e ### 其他 Pod 字段置于此处 whenUnsatisfiable 字段表示不满足分布条件时处理方式。有以下值： DoNotSchedule: 默认值，告诉调度器不要调度 ScheduleAnyway: 根据如何能将偏差最小化来对节点进行排序调度 topologyKey: 指定节点标签名进行分组，相同的值认为是同组节点 labelSelector: 标签选择器，在分组中根据 pod 标签统计其数量 maxSkew: 描述这些 Pod 可能被均匀分布的程度，值大于 0，受以下影响: 当 whenUnsatisfiable: DoNotSchedule 时，则表示 pod 调度最大允许差值。比如目前有2个分组节点，有4个 pod 需要调度，不同的值有不同差异： maxSkew: 1 时，每个分组分配 2 个 pod(2-2=0 满足条件) maxSkew: 2 时，同分组分配1~3个 pod(3-1=2，2-2=0 才能满足条件) maxSkew: 3 时，同分组分配1~3个 pod maxSkew 值大于4时，可能都调度到同分组 当 whenUnsatisfiable: ScheduleAnyway 时，该调度器会更为偏向能够降低偏差值的分组 minDomains 字段要启动 MinDomainsInPodToplogySpread 特性才能使用 该方式存在以下问题： 当 Pod 被移除时，无法保证差值仍被满足（不会重新调度正在运行的 pod） 具有污点的节点上匹配的 Pod 也会被统计 该调度器不会预先知道集群拥有的所有可用分组和其他拓扑域 下面是多个拓扑分布约束示例 apiVersion: apps/v1 kind: Deployment metadata: ... spec ... replicas: 4 template: metadata: labels: foo: bar spec: topologySpreadConstraints: - maxSkew: 1 topologyKey: zone whenUnsatisfiable: DoNotSchedule labelSelector: matchLabels: foo: bar - maxSkew: 1 topologyKey: node whenUnsatisfiable: DoNotSchedule labelSelector: matchLabels: foo: bar containers: - name: pause image: k8s.gcr.io/pause:3.1 如果节点标签像以下方式定义时，每个节点将分配一个 pod 才满足条件 node1: zone=1,foo=bar,... node2: zone=1,foo=bar,... node3: zone=2,foo=bar,... node4: zone=2,foo=bar,... pod 调度优先级pod 有优先级，优先级高的 pod 不仅可以更快被调度，还可以驱逐优先级低的 pod 使自己可以被调度。 pod 优先级使用 PriorityClass 资源实现，它是一个无命名空间对象，定义了从优先级类名称到优先级整数值的映射。下面是一个示例 --- apiVersion: scheduling.k8s.io/v1 kind: PriorityClass metadata: name: high-priority value: 1000000 globalDefault: false description: \"此优先级类应仅用于 XYZ 服务 Pod。\" globalDefault: 1 preemptionPolicy: Never --- apiVersion: v1 kind: Pod m","date":"2022-08-14","objectID":"/k8sScheduler/:10:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 驱逐信号驱逐信号是特定资源在特定时间点的当前状态。 kubelete 通过将信号与驱逐条件进行比较来做出驱逐决定， 驱逐条件是节点上应该可用资源的最小量。有以下驱逐信号： memory.available: 值为 node.status.capacity.memory - node.stats.memory.workingSet 字段值（问题：后面字段什么意识，从哪里获得）值来自 cgroupfs nodefs.available: 值为 node.stats.fs.available nodefs.inodesFree: 值为 node.stats.fs.inodesFree imagefs.available: 值为 node.stats.runtime.imagefs.available imagefs.inodesFree: 值为 node.stats.runtime.imagefs.inodesFree pid.available: 值为 node.stats.rlimit.maxpid - node.stats.rlimit.curproc ","date":"2022-08-14","objectID":"/k8sScheduler/:11:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 驱逐条件驱逐条件的形式为 [eviction-signal][operator][quantity]，驱逐方式分为软驱逐与硬驱逐 eviction-signal: 表示驱逐信号 operator: 表示关系运算符 quantity: 表示驱逐条件数量 比如 memory.available\u003c 1G 表示可用内存低于 1Gi 时触发驱逐。在某些情况下，节点在软驱逐条件上下振荡，而没有保持定义的宽限期。 这会导致报告的节点条件在 true 和 false 之间不断切换，从而导致错误的驱逐决策。为了防止振荡，可以在 kubelet 配置文件中设置 evictionPressureTransitionPeriod 参数设置驱逐压力状况解除之前的最长等待时间。该参数默认时间为 5m 软驱逐是条件满足时在一定时间内，kubelet 不会驱逐 Pod。必须指定的宽限期，kubelet 会在启动时返回错误。使用以下来配置软驱逐条件： kubelet --eviction-soft: 指定驱逐条件，如果驱逐条件持续时长超过指定的宽限期，可以触发 Pod 驱逐。如 memory.available\u003c1.5Gi kubelet --eviction-soft-grace-period: 指定驱逐宽限时间。如 memory.available=90m kubelet --eviction-max-pod-grace-period: 触发强制驱逐时间 硬驱逐是条件满足时触发强制驱逐，而不会正常终止以回收紧缺的资源。可以使用 kubelet --eviction-hard 指定强制驱逐条件，kubelet 具有以下默认硬驱逐条件： memory.available\u003c100Mi nodefs.available\u003c10% imagefs.available\u003c15% nodefs.inodesFree\u003c5% ","date":"2022-08-14","objectID":"/k8sScheduler/:12:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 检测时间间隔kubelet --node-status-update-frequency 指定更新节点状态时间间隔， ","date":"2022-08-14","objectID":"/k8sScheduler/:13:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 压力驱逐顺序回收节点资源后没有使驱逐信号低于条件， 则使用以下参数来确定 Pod 驱逐顺序： Pod 的资源使用超过其请求，根据它们的优先级以及它们的资源使用级别超过其请求的程度被逐出。 pod 优先级，计算机资源不足时，优先级低的被驱逐。inode 或 PID 不足时，优先级高的被驱逐 Pod 相对于请求的资源使用情况，使用资源高的被驱逐 在某些情况下，驱逐 Pod 只会回收少量的紧俏资源。 这可能导致 kubelet 反复达到配置的驱逐条件并触发多次驱逐。可以使用 kubelet --eviction-minimum-reclaim 选项或 kubelet 配置文件指定最小回收值减少触发频率，下面是配置文件示例 apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration evictionHard: memory.available: \"500Mi\" nodefs.available: \"1Gi\" imagefs.available: \"100Gi\" evictionMinimumReclaim: memory.available: \"0Mi\" nodefs.available: \"500Mi\" imagefs.available: \"2Gi\" 对于所有资源，默认的 --eviction-minimum-reclaim 为 0 API 发起的驱逐API 发起的驱逐是调用 Eviction 对象删除 pod。 ","date":"2022-08-14","objectID":"/k8sScheduler/:14:0","tags":["k8s","命令","kube-scheduler 命令"],"title":"k8s 调度器","uri":"/k8sScheduler/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s 官方文档：kube-proxy kube-proxyk8s 网络代理在每个节点上运行。网络代理反映了每个节点上 k8s API 中定义的服务，并且可以执行简单的 TCP、UDP 和 SCTP 流转发 [root@k8s01 ~]# kubectl get pod -n kube-system -l \"k8s-app=kube-proxy\" NAME READY STATUS RESTARTS AGE kube-proxy-n24f7 1/1 Running 6 (169m ago) 19d kube-proxy-rwvq9 1/1 Running 6 (169m ago) 19d [root@k8s01 ~]# kubectl get pod -n kube-system kube-proxy-rwvq9 -o=jsonpath='{$.spec.containers[0].command}' | jq [ \"/usr/local/bin/kube-proxy\", \"--config=/var/lib/kube-proxy/config.conf\", \"--hostname-override=$(NODE_NAME)\" ] [root@k8s01 ~]# crictl exec -it edc69d0ad9fb1 sh # # cat /var/lib/kube-proxy/config.conf apiVersion: kubeproxy.config.k8s.io/v1alpha1 bindAddress: 0.0.0.0 bindAddressHardFail: false clientConnection: acceptContentTypes: \"\" burst: 0 contentType: \"\" kubeconfig: /var/lib/kube-proxy/kubeconfig.conf qps: 0 clusterCIDR: 100.64.0.0/10 configSyncPeriod: 0s conntrack: maxPerCore: null min: null tcpCloseWaitTimeout: null tcpEstablishedTimeout: null detectLocal: bridgeInterface: \"\" interfaceNamePrefix: \"\" detectLocalMode: \"\" enableProfiling: false healthzBindAddress: \"\" hostnameOverride: \"\" iptables: masqueradeAll: false masqueradeBit: null minSyncPeriod: 0s syncPeriod: 0s ipvs: excludeCIDRs: - 10.103.97.2/32 minSyncPeriod: 0s scheduler: \"\" strictARP: false syncPeriod: 0s tcpFinTimeout: 0s tcpTimeout: 0s udpTimeout: 0s kind: KubeProxyConfiguration metricsBindAddress: 0.0.0.0 mode: ipvs nodePortAddresses: null oomScoreAdj: null portRange: \"\" showHiddenMetricsForVersion: \"\" udpIdleTimeout: 0s winkernel: enableDSR: false forwardHealthCheckVip: false networkName: \"\" rootHnsEndpointName: \"\" sourceVip: \"\" 监听的 IP 地址kube-proxy --bind-address 选项指定代理服务器的 IP 地址。如果配置文件中指定 bindAddress 配置项，则忽略此参数 无法绑定端口是否退出kube-proxy --bind-address-hard-fail 选项值为 true 时，将无法绑定端口的失败操作视为致命错误并退出。 api server 通信的突发数量kube-proxy --kube-api-burst 选项设置与 k8s apiserver 通信的突发数量。配置文件中指定 clientConnection: burst: 0 发送到 apiserver 的请求的内容类型kube-proxy --kube-api-content-type 选项设置发送到 k8s apiserver 的请求的内容类型。配置文件中指定： clientConnection: contentType: \"\" 与 k8s apiserver 交互时使用的 QPSkube-proxy --kube-api-qps 选项设置与 k8s apiserver 交互时使用的 QPS。在配置文件中设置： clientConnection: qps: 0 鉴权信息的 kubeconfig 文件的路径kube-proxy --kubeconfig 选项指定 kubeconfig 文件路径，主控节点位置由 master 标志设置。在配置文件中指定： clientConnection: kubeconfig: /var/lib/kube-proxy/kubeconfig.conf 集群中 Pod 的 CIDR 范围。kube-proxy --cluster-cidr 选项配置集群中 Pod 的 CIDR 范围。配置后，将从该范围之外发送到服务集群 IP 的流量被伪装，从 Pod 发送到外部 LoadBalancer IP 的流量将被重定向到相应的集群 IP。 对于双协议栈集群，接受一个逗号分隔的列表， 每个 IP 协议族（IPv4 和 IPv6）至少包含一个 CIDR。 如果在配置文件指定，则忽略此参数。 apiserver 的配置的刷新频率kube-proxy --config-sync-period 选项设置 apiserver 的配置的刷新频率。必须大于 0。 每个 CPU 核跟踪的最大 NAT 连接数kube-proxy --conntrack-max-per-core 选项指定每个 CPU 核跟踪的最大 NAT 连接数（0 表示保留当前限制并忽略 kube-proxy --conntrack-min 设置）。在配置文件中指定： conntrack: maxPerCore: null 代理模式kube-proxy --proxy-mode 选项指定 kube-proxy 工作模式，有以下值： iptabes: 使用防火墙规则，仅 linux 系统可用 ipvs: 使用 lvs ，仅 linux 系统可用 kernelspace: 仅 linux 系统可用 userspace: 如果在配置文件在指定，则忽略此选项 ","date":"2022-08-13","objectID":"/k8sProxy/:0:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["k8s"],"content":" IPVS 代理白名单 CIDR 列表kube-proxy --ipvs-exclude-cidrs 选项指定 ipvs 代理在清理 IPVS 规则时不会此列表中的地址范围 ","date":"2022-08-13","objectID":"/k8sProxy/:1:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["k8s"],"content":" IPVS 规则刷新时间kube-proxy --ipvs-min-sync-period 选项指定 ipvs 规则可以随着端点和服务的更改而刷新的最小间隔 ","date":"2022-08-13","objectID":"/k8sProxy/:2:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["k8s"],"content":" IPVS 调度算法类型kube-proxy --ipvs-scheduler 选项指定 kube-proxy --proxy-mode ipvs 时 lvs 调度模式 ","date":"2022-08-13","objectID":"/k8sProxy/:3:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["k8s"],"content":" IPVS 是否启用严格的 ARP如果指定 kube-proxy --ipvs-strict-arp 选项或要配置文件中指定 ipvs.strictARP: false 则启用严格的 ARP。（通过 arp_ignore=1 和 arp_announce=2） ","date":"2022-08-13","objectID":"/k8sProxy/:4:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["k8s"],"content":" IPVS TCP 保持连接时间kube-proxy --ipvs-tcp-timeout 选项指定空间 IPVS TCP 连接保持时间，如果值为 0 表示持续连接 ","date":"2022-08-13","objectID":"/k8sProxy/:5:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["k8s"],"content":" IPVS 连接超时时间kube-proxy --ipvs-tcpfin-timeout 选项指 IPVS 模式下收到 FIN 数据包后 TCP 连接超时时间 ","date":"2022-08-13","objectID":"/k8sProxy/:6:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["k8s"],"content":" IPVS UDP 连接超时时间kube-proxy --ipvs-udp-timeout 选项指定 IPVS 模式下 UDP 连接超时时间 ","date":"2022-08-13","objectID":"/k8sProxy/:7:0","tags":["k8s","kube-proxy","命令","kube-proxy 命令"],"title":"k8s 网络代理","uri":"/k8sProxy/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.23.0 内容来自以下文档： Amir Rawdat: 为 NGINX 配置免费的 Let’s Encrypt SSL/TLS 证书 TLS/SSL 证书获取SSL/TLS 证书要从运营商购买，也有免费的，通常有30~90天限制，需要定期更新。这篇文章33种免费获取SSL证书的方式介绍有免费获取方式 ","date":"2022-08-13","objectID":"/nginx-https/:0:0","tags":["Let’s Encrypt","nginx"],"title":"nginx 配置 https","uri":"/nginx-https/"},{"categories":["nginx"],"content":" 使用 certbot 获取 Let’s Encrypt 颁发的证书 安装 Let’s Encrypt 证书申请客户端工具 # 如果有 python3 建议安装 python3-certbot-nginx [root@localhost ~]# yum install -y certbot python-certbot-nginx ... 配置 nginx 绑定域名 [root@localhost ~]# grep 'server_name' /usr/local/nginx/conf/8023.FixIt.nginx.conf server_name note.xiaosi.host; 使用以下命令生成证书。如果 nginx 配置文件为 /etc/nginx/nginx.conf 则可以使用 certbot --nginx -d 选项指定域名，--nginx 选项还可以自动修改 nginx 配置文件绑定证书 # 确保 80 端口没有被占用后运行 [root@localhost ~]# certbot certonly Saving debug log to /var/log/letsencrypt/letsencrypt.log Error while running nginx -c /etc/nginx/nginx.conf -t. nginx: [emerg] open() \"/etc/nginx/nginx.conf\" failed (2: No such file or directory) nginx: configuration file /etc/nginx/nginx.conf test failed How would you like to authenticate with the ACME CA? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1: Nginx Web Server plugin (nginx) [Misconfigured] 2: Spin up a temporary webserver (standalone) 3: Place files in webroot directory (webroot) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Select the appropriate number [1-3] then [enter] (press 'c' to cancel): 2 # 2 Plugins selected: Authenticator standalone, Installer None Starting new HTTPS connection (1): acme-v02.api.letsencrypt.org Please enter in your domain name(s) (comma and/or space separated) (Enter 'c' to cancel): note.xiaosi.host # 申请证书的域名 Requesting a certificate for note.xiaosi.host Performing the following challenges: http-01 challenge for note.xiaosi.host Waiting for verification... Cleaning up challenges IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/note.xiaosi.host/fullchain.pem # 公钥路径 Your key file has been saved at: /etc/letsencrypt/live/note.xiaosi.host/privkey.pem # 密钥路径 Your certificate will expire on 2022-11-11. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run \"certbot renew\" # 更新提示，到期时间为 2022-11-11 - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 定期更新任务，每月一号检查服务器上的证书是否会在未来 30 天内到期，如果是，则更新证书。--quiet 不生成输出信息 [root@localhost ~]# grep 'certbot' /etc/crontab * 0 1 * * root /usr/bin/certbot renew --quiet nginx 配置 ssl 证书 修改 nginx 配置文件 [root@localhost ~]# cat /usr/local/nginx/conf/8023.FixIt.nginx.conf server { server_name note.xiaosi.host; # 443 端口加上 ssl 参数 listen 103.106.246.17:443 ssl; # 域名默认解析到 80 端口 listen 103.106.246.17:80; # 证书公钥路径 ssl_certificate /etc/letsencrypt/live/note.xiaosi.host/fullchain.pem; # 证书私钥路径 ssl_certificate_key /etc/letsencrypt/live/note.xiaosi.host/privkey.pem; # 把 http 协议通过 301 跳转到 https 协议 if ($scheme != \"https\") { return 301 https://$host$request_uri; } ... 防火墙开放 443 端口 [root@localhost ~]# firewall-cmd --add-port=443/tcp success [root@localhost ~]# firewall-cmd --runtime-to-permanent success 在其它机器或使用浏览器测试 [root@k8s01 ~]# curl -I https://note.xiaosi.host/ HTTP/1.1 200 OK Server: nginx/1.23.0 Date: Sat, 13 Aug 2022 03:22:09 GMT Content-Type: text/html Content-Length: 16393 Last-Modified: Fri, 12 Aug 2022 09:01:10 GMT Connection: keep-alive ETag: \"62f616d6-4009\" Accept-Ranges: bytes ","date":"2022-08-13","objectID":"/nginx-https/:1:0","tags":["Let’s Encrypt","nginx"],"title":"nginx 配置 https","uri":"/nginx-https/"},{"categories":["nginx"],"content":" 内容来自以下文档： 无处不在的海贼: 2021年Nginx配置搭建HTTPS正向代理服务的2种方式 nginx正向代理 [root@localhost nginx]# cat conf/client-proxy.conf server { # 配置DNS解析IP地址，比如 Google Public DNS，以及超时时间（5秒） resolver 8.8.8.8; # 必需 resolver_timeout 5s; # 监听端口 listen 8209; access_log /dev/null; error_log /dev/null; location / { # 配置正向代理参数 proxy_pass $scheme://$host$request_uri; # 解决如果URL中带\".\"后Nginx 503错误 proxy_set_header Host $http_host; # 可有可无 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 配置缓存大小 proxy_buffers 256 4k; # 关闭磁盘缓存读写减少I/O proxy_max_temp_file_size 0; # 代理连接超时时间 proxy_connect_timeout 30; # 配置代理服务器HTTP状态缓存时间 proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; } } # export http_proxy=http://192.168.1.9:8209 # exporthttp_proxy = http://username:password@proxy_ip:port/ # exporthttps_proxy = http://username:password@proxy_ip:port/ ","date":"2022-08-13","objectID":"/nginx-forward-proxy/:0:0","tags":["正向代理","nginx"],"title":"nginx正向代理","uri":"/nginx-forward-proxy/"},{"categories":["linux"],"content":" 运行环境： 内容来自以下文档： chenhuan001 centos 常用快捷键快捷键由于使用终端不同有所差异，但常见快捷键如下： 快捷键 作用 Tab 补全(命令、文件名、路径) Ctrl + r 显示:号提示，根据用户输入查找相关历史命令 Ctrl + u 剪切光标之前到行首的字符 Alt + d 剪切从光标位置到当前所处单词的末尾 Ctrl + k 剪切光标之前到行尾的字符 Ctrl + w 剪切从光标位置前到当前所处单词的开头 Ctrl + y 粘贴最后一次被剪切的单词 Ctrl + l 清屏，相当于执行clear命令 Ctrl + c 取消当前行输入的命令 Ctrl + a 光标移动到行首 Ctrl + e 光标移动到行尾 Ctrl + f 光标向前移动一个字符位置 Ctrl + b 光标往回移动一个字符位置 Ctrl + t 交换光标位置前的两个字符 Alt + b 光标往回移动到前一个单词 Alt + F4 关闭当前窗口 Alt + F9 最小化当前窗口 Alt + F10 最大化当前窗口 Alt + Tab 切换窗口 ","date":"0001-01-01","objectID":"/%E7%BB%88%E7%AB%AF%E5%BF%AB%E6%8D%B7%E9%94%AE/:0:0","tags":["终端"],"title":"终端快捷键","uri":"/%E7%BB%88%E7%AB%AF%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"categories":["k8s"],"content":" 运行环境： crictl: 0.1.0 内容来自以下文档： cri-tools cri-toolscri-tools 项目目的是为 kubelet 容器运行时接口 （CRI） 提供一系列调试和验证工具，目前有： crictl: CRI 客户端工具 critest: CRI 验证测试工具 这些工具目前在测试阶段，通过 CRI 接口不需要 k8s 组件就可以调用容器 crictl","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:0:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 安装 从 cri-toos 发布页面下载 或使用以下命令下载 # $VERSION 变量是版本号，如：v1.24.2 # 使用 wget 命令下载 [root@k8s01 ~]# wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz # 使用 curl 命令下载 [root@k8s01 ~]# curl -L https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-${VERSION}-linux-amd64.tar.gz --output crictl-${VERSION}-linux-amd64.tar.gz 解压安装 [root@k8s01 ~]# sudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:1:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 配置文件crictl --config 或 crictl -c 命令指定配置文件，如果缺少该指定默认使用 /etc/crictl.yaml 文件 [root@k8s01 ~]# cat /etc/crictl.yaml ... image-endpoint: unix:///var/run/image-cri-shim.sock runtime-endpoint: unix:///run/containerd/containerd.sock 使用 crictl config 命令可以获取或指定配置项，命令行指定的配置项会覆盖配置文件 [root@k8s01 ~]# crictl config -h USAGE: crictl config [command options] [\u003ccrictl options\u003e] CRICTL OPTIONS: runtime-endpoint: # 指定容器运行工具 unix 地址 # 该工具必须支持 CRI 接口规范 image-endpoint: # 镜像下载工具 unix 地址 timeout: # 连接超时时间，默认值为 2 s debug: # 是否开始调试模式，默认值为 false pull-image-on-create: # 是否在创建请求时启用拉取镜像，默认值为 flase disable-pull-on-run: # 是否在运行请求时禁用拉取镜像，默认值为 flase OPTIONS: --get value # 获取配置项值 --set value # 设置配置项值，多个配置项用逗号分隔 --help, -h # 是否获取帮助信息，默认值为 flase ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:2:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看 crictl 版本 [root@k8s01 ~]# crictl -v crictl version 1.20.0-24-g53ad8bb7 ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:3:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看容器运行时版本 [root@k8s01 ~]# crictl version Version: 0.1.0 RuntimeName: containerd RuntimeVersion: v1.6.2 RuntimeApiVersion: v1alpha2 ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:4:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看窗口运行时信息 [root@localhost ~]# crictl info --help USAGE: crictl info [command options] [arguments...] OPTIONS: --output value, -o value Output format, One of: json|yaml|go-template (default: \"json\") --quiet, -q Do not show verbose information (default: false) --template value The template string is only used when output is go-template; The Template format is golang template ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:5:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 拉取镜像 [root@k8s01 ~]# crictl pull --help USAGE: crictl pull [command options] NAME[:TAG|@DIGEST] OPTIONS: --auth AUTH_STRING # 使用 AUTH_STRING 访问注册表 # AUTH_STRING 是 base64 编码的 'USERNAME[:PASSWORD] --creds USERNAME[:PASSWORD] # 使用 USERNAME[:PASSWORD] 访问注册表 --pod-config pod-config.[json|yaml] # 使用 k8s pod 清单文件中拉取镜像 --help, -h # 是否获取帮助信息，默认值为 flase 拉取 busybox 镜像 $ crictl pull busybox Image is up to date for busybox@sha256:141c253bc4c3fd0a201d32dc1f493bcf3fff003b6df416dea4f41046e0f37d47 ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:6:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看镜像 [root@k8s01 ~]# crictl image --help ... USAGE: crictl images [command options] [REPOSITORY[:TAG]] OPTIONS: --digests # 是否显示摘要，默认值为 false --verbose, -v # 是否显示完整信息同，默认值为 false --no-trunc # 是否显示完整镜像 ID，默认值为 false --quiet, -q # 是否只显示镜像 ID，默认值为 false --output value, -o value # 指定输出格式，有 json、yaml、table (默认值) --help, -h # 是否显示帮助信息，默认值为 false 查看当前以有镜像 [root@k8s01 ~]# crictl image IMAGE TAG IMAGE ID SIZE sealos.hub:5000/calico/cni v3.22.1 2a8ef6985a3e5 80.5MB sealos.hub:5000/calico/node v3.22.1 7a71aca7b60fc 69.6MB sealos.hub:5000/calico/pod2daemon-flexvol v3.22.1 17300d20daf93 8.46MB sealos.hub:5000/coredns/coredns v1.8.6 a4ca41631cc7a 13.6MB sealos.hub:5000/etcd 3.5.3-0 aebe758cef4cd 102MB sealos.hub:5000/kube-apiserver v1.24.3 d521dd763e2e3 33.8MB sealos.hub:5000/kube-controller-manager v1.24.3 586c112956dfc 31MB sealos.hub:5000/kube-proxy v1.24.3 2ae1ba6417cbc 39.5MB sealos.hub:5000/kube-scheduler v1.24.3 3a5aa3a515f5d 15.5MB sealos.hub:5000/pause 3.7 221177c6082a8 311kB ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:7:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 删除镜像 [root@k8s01 ~]# crictl rmi --help USAGE: crictl rmi [command options] IMAGE-ID [IMAGE-ID...] OPTIONS: --all, -a # 是否删除所有镜像，默认值为 false --prune, -q # 是否删除所有未使用中的镜像，默认值为 false --help, -h # 是否显示帮助信息，默认值为 false ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:8:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 创建容器 [root@k8s01 ~]# crictl create USAGE: crictl create [command options] POD container-config.[json|yaml] pod-config.[json|yaml] OPTIONS: --auth AUTH_STRING Use AUTH_STRING for accessing the registry. AUTH_STRING is a base64 encoded 'USERNAME[:PASSWORD]' --cancel-timeout value, -T value Seconds to wait for a container create request to complete before cancelling the request (default: 0s) --creds USERNAME[:PASSWORD] Use USERNAME[:PASSWORD] for accessing the registry --no-pull Do not pull the image on container creation (overrides pull-image-on-create=true in config) (default: false) --with-pull Pull the image on container creation (overrides pull-image-on-create=false in config) (default: false) --help, -h # 是否显示帮助信息，默认值为 false ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:9:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 运行容器 [root@localhost ~]# crictl run --help USAGE: crictl run [command options] container-config.[json|yaml] pod-config.[json|yaml] OPTIONS: --auth AUTH_STRING Use AUTH_STRING for accessing the registry. AUTH_STRING is a base64 encoded 'USERNAME[:PASSWORD]' --creds USERNAME[:PASSWORD] Use USERNAME[:PASSWORD] for accessing the registry --no-pull Do not pull the image (overrides disable-pull-on-run=false in config) (default: false) --runtime value, -r value Runtime handler to use. Available options are defined by the container runtime. --timeout value, -t value Seconds to wait for a container create request before cancelling the request (default: 0s) --with-pull Pull the image (overrides disable-pull-on-run=true in config) (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:10:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看容器列表 [root@k8s01 ~]# crictl ps --help USAGE: crictl ps [command options] [arguments...] OPTIONS: --all, -a Show all containers (default: false) --id value Filter by container id --image value Filter by container image --label value Filter by key=value label --last value, -n value Show last n recently created containers (includes all states). Set 0 for unlimited. (default: 0) --latest, -l Show the most recently created container (includes all states) (default: false) --name value filter by container name regular expression pattern --no-trunc Show output without truncating the ID (default: false) --output value, -o value Output format, One of: json|yaml|table (default: \"table\") --pod value, -p value Filter by pod id --quiet, -q Only display container IDs (default: false) --state value, -s value Filter by container state --verbose, -v Show verbose information for containers (default: false) --help, -h show help (default: false) 查看 k8s 在当前主机创建的容器 [root@k8s01 ~]# crictl ps CONTAINER IMAGE CREATED STATE NAME ATTEMPT POD ID f0071077d6661 7a71aca7b60fc 2 hours ago Running calico-node 6 07cc01d52a1d3 8d1bfd6a12dec a4ca41631cc7a 2 hours ago Running coredns 6 57dc6ca586c04 ab54268c45bab a4ca41631cc7a 2 hours ago Running coredns 6 8aab4331b9d27 edc69d0ad9fb1 2ae1ba6417cbc 2 hours ago Running kube-proxy 6 2679d92850963 4f224bed182a4 3a5aa3a515f5d 2 hours ago Running kube-scheduler 6 7377e5fe8b065 235c157e36ec5 586c112956dfc 2 hours ago Running kube-controller-manager 6 fbdb14c578a32 baa51b7846610 d521dd763e2e3 2 hours ago Running kube-apiserver 6 ffc9cc253166b 2bc96a77a556d aebe758cef4cd 2 hours ago Running etcd 6 b12bcc5e65693 ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:11:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看容器状态 [root@localhost ~]# crictl inspect --help USAGE: crictl inspect [command options] CONTAINER-ID [CONTAINER-ID...] OPTIONS: --output value, -o value # 指定输出格式，有 json、yaml、table (默认值) --quiet, -q # 是否只显示镜像 ID，默认值为 false --template value The template string is only used when output is go-template; The Template format is golang template ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:12:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看容器日志 [root@localhost ~]# crictl logs --help OPTIONS: --follow, -f Follow log output (default: false) --limit-bytes value Maximum bytes of logs to return. Defaults to no limit (default: -1) --previous, -p Print the logs for the previous instance of the container in a pod if it exists (default: false) --since value Show logs since timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes) --tail value Number of lines to show from the end of the logs. Defaults to all (default: -1) --timestamps, -t Show timestamps (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:13:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 停止容器 [root@localhost ~]# crictl stop --help USAGE: crictl stop [command options] CONTAINER-ID [CONTAINER-ID...] OPTIONS: --timeout value, -t value Seconds to wait to kill the container after a graceful stop is requested (default: 0) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:14:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 启动容器 [root@localhost ~]# crictl start --help USAGE: crictl start [command options] CONTAINER-ID [CONTAINER-ID...] ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:15:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 更新容器 [root@localhost ~]# crictl update --help USAGE: crictl update [command options] CONTAINER-ID [CONTAINER-ID...] OPTIONS: --cpu-count value (Windows only) Number of CPUs available to the container (default: 0) --cpu-maximum value (Windows only) Portion of CPU cycles specified as a percentage * 100 (default: 0) --cpu-period value CPU CFS period to be used for hardcapping (in usecs). 0 to use system default (default: 0) --cpu-quota value CPU CFS hardcap limit (in usecs). Allowed cpu time in a given period (default: 0) --cpu-share value CPU shares (relative weight vs. other containers) (default: 0) --cpuset-cpus value CPU(s) to use --cpuset-mems value Memory node(s) to use --memory value Memory limit (in bytes) (default: 0) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:16:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看容器使用资源统计信息 [root@localhost ~]# crictl stats --help USAGE: crictl stats [command options] [ID] OPTIONS: --all, -a Show all containers (default shows just running) (default: false) --id value Filter by container id --label value Filter by key=value label (accepts multiple inputs) --output value, -o value Output format, One of: json|yaml|table --pod value, -p value Filter by pod id --seconds value, -s value Sample duration for CPU usage in seconds (default: 1) --watch, -w Watch pod resources (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:17:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 在正在运行的容器中运行命令 [root@localhost ~]# crictl exec --help USAGE: crictl exec [command options] CONTAINER-ID COMMAND [ARG...] OPTIONS: --interactive, -i Keep STDIN open (default: false) --sync, -s Run the command synchronously (default: false) --timeout value Timeout in seconds (default: 0) --tty, -t Allocate a pseudo-TTY (default: false) 以交互式方式在容器中执行 sh 命令 [root@k8s01 ~]# crictl exec -it edc69d0ad9fb1 sh # # cat /var/lib/kube-proxy/config.conf ... ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:18:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 删除容器 [root@localhost ~]# crictl rm --help USAGE: crictl rm [command options] CONTAINER-ID [CONTAINER-ID...] OPTIONS: --all, -a # 是否删除所有容器，默认值为 false --force, -f Force removal of the container, disregarding if running (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:19:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 创建 pod [root@localhost ~]# crictl runp --help USAGE: crictl runp [command options] pod-config.[json|yaml] OPTIONS: --cancel-timeout value, -T value Seconds to wait for a run pod sandbox request to complete before cancelling the request (default: 0s) --runtime value, -r value Runtime handler to use. Available options are defined by the container runtime. ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:20:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看 pod 列表 [root@localhost ~]# crictl pods --help USAGE: crictl pods [command options] [arguments...] OPTIONS: --id value filter by pod id --label value filter by key=value label (accepts multiple inputs) --last value, -n value Show last n recently created pods. Set 0 for unlimited (default: 0) --latest, -l Show the most recently created pod (default: false) --name value filter by pod name regular expression pattern --namespace value filter by pod namespace regular expression pattern --no-trunc Show output without truncating the ID (default: false) --output value, -o value Output format, One of: json|yaml|table (default: \"table\") --quiet, -q list only pod IDs (default: false) --state value, -s value filter by pod state --verbose, -v show verbose info for pods (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:21:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看 pod 状态 [root@localhost ~]# crictl inspectp --help USAGE: crictl inspectp [command options] POD-ID [POD-ID...] OPTIONS: --output value, -o value Output format, One of: json|yaml|go-template|table --quiet, -q Do not show verbose information (default: false) --template value The template string is only used when output is go-template; The Template format is golang template ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:22:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 查看 pod 资源使用情况统计 [root@localhost ~]# crictl statsp -h USAGE: crictl statsp [command options] [ID] OPTIONS: --id value Filter by pod id --label value Filter by key=value label (accepts multiple inputs) --output value, -o value Output format, One of: json|yaml|table --seconds value, -s value Sample duration for CPU usage in seconds (default: 1) --watch, -w Watch pod resources (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:23:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 从 sandbox 中运行新的容器 [root@localhost ~]# crictl run --help USAGE: crictl run [command options] container-config.[json|yaml] pod-config.[json|yaml] OPTIONS: --auth AUTH_STRING Use AUTH_STRING for accessing the registry. AUTH_STRING is a base64 encoded 'USERNAME[:PASSWORD]' --creds USERNAME[:PASSWORD] Use USERNAME[:PASSWORD] for accessing the registry --no-pull Do not pull the image (overrides disable-pull-on-run=false in config) (default: false) --runtime value, -r value Runtime handler to use. Available options are defined by the container runtime. --timeout value, -t value Seconds to wait for a container create request before cancelling the request (default: 0s) --with-pull Pull the image (overrides disable-pull-on-run=true in config) (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:24:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 将本地端口转发到 Pod [root@localhost ~]# crictl port-forward -h USAGE: crictl port-forward [command options] POD-ID [LOCAL_PORT:]REMOTE_PORT ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:25:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 停止 pod [root@localhost ~]# crictl stopp --help USAGE: crictl stopp [command options] POD-ID [POD-ID...] ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:26:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 删除 pod [root@localhost ~]# crictl rmp --help USAGE: crictl rmp [command options] POD-ID [POD-ID...] OPTIONS: --all, -a Remove all pods (default: false) --force, -f Force removal of the pod sandbox, disregarding if running (default: false) ","date":"2022-08-10","objectID":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/:27:0","tags":["k8s","crictl","critest"],"title":"kubelet CRI 工具","uri":"/kubelet-CRI-%E5%B7%A5%E5%85%B7/"},{"categories":["k8s"],"content":" 运行环境： 内容来自以下文档： github containerd ShadowYD: runC containerd导入本地镜像的一个小坑 介绍containerd 是从 docker 分离出来的。从 k8s:1.24 版本开始删除了 dockershim 直接调用 containerd 作为推荐的容器运行时。日前是 CNCF 项目中一员，已是 graduated （毕业）状态 containerd 被设计成嵌入到 k8s 系统中，而不是由开发人员或最终用户直接使用。是标准的容器运行时，强调简单性、稳健性和可移植性。可以管理完整的容器生命周期、镜像传输和存储、容器执行和监督、低级存储、网络附件等。可以作为系统守护进程使用。 简单说就是只提供容器基础功能，更多功能需要上级管理系统支持或使用插件。只想用容器还是建议使用 docker 等工具 命令使用","date":"2022-08-10","objectID":"/k8sContainerd/:0:0","tags":["containerd","容器"],"title":"k8s 容器运行时之一 containerd","uri":"/k8sContainerd/"},{"categories":["k8s"],"content":" ctr [root@k8s01 ~]# ctr --help NAME: ... # 子命令 plugins, plugin provides information about containerd plugins version # 查看服务端与客户端版本 containers, c, container # 容器相关子命令 delete, del, remove, rm # 删除容器 --keep-snapshot # 不清理容器快照 list, ls # 查看容器列表 --quiet, -q # 只显示 ID label # 为容器设置标签或清除容器标签 content manage content events, event display containerd events images, image, i # 镜像相关子命令 list, ls # 查看镜像 --quiet, -q # 只显示镜像名称与标签 pull # 拉取镜像 leases manage leases namespaces, namespace, ns # 名称空间相关子命令 pprof provide golang pprof outputs for containerd run run a container snapshots, snapshot manage snapshots tasks, t, task manage tasks install install a new package oci OCI tools shim interact with a shim directly help, h # 查看帮助信息 # 通用选项 --debug enable debug output in logs --address value, -a value address for containerd's GRPC server (default: \"/run/containerd/containerd.sock\") [$CONTAINERD_ADDRESS] --timeout value total timeout for ctr commands (default: 0s) --connect-timeout value timeout for connecting to containerd (default: 0s) --namespace value, -n value # 指定名称空间 --help, -h # 查看帮助信息 --version, -v # 查看版本 ","date":"2022-08-10","objectID":"/k8sContainerd/:1:0","tags":["containerd","容器"],"title":"k8s 容器运行时之一 containerd","uri":"/k8sContainerd/"},{"categories":["k8s"],"content":" 示例 删除 k8s.io 名称空间中镜像 [root@node01 ~]# ctr -n k8s.io image rm 'sha256:6f6e73fa8162ba759f669e5a795b699b93fe8e1236cdf530ca12c7505e383eb1' sha256:6f6e73fa8162ba759f669e5a795b699b93fe8e1236cdf530ca12c7505e383eb1 导入镜像 [root@node01 ~]# ctr -n k8s.io image import --digests=true kube-apiserver\\:v1.27.1.tar unpacking import-2023-04-30@sha256:...6a70763b53020c4ac5b9d8a)...done [root@node01 ~]# [root@node01 ~]# ctr -n k8s.io image ls REF TYPE DIGEST SIZE PLATFORMS LABELS import-2023-04-30@sha256:c29eba34ba055f6f41e2... 修改修改镜像 [root@node01 ~]# ctr -n k8s.io image tag import-2023-04-3... registry.k8s.io/kube-apiserver:v1.27.1 registry.k8s.io/kube-apiserver:v1.27.1 [root@node01 ~]# [root@node01 ~]# ctr -n k8s.io image ls -q import-2023-04-30@sha256:c29eba34ba055f6f41e2795a4763884d47afd7dc86a70763b53020c4ac5b9d8a registry.k8s.io/kube-apiserver:v1.27.1 sha256:6f6e73fa8162ba759f669e5a795b699b93fe8e1236cdf530ca12c7505e383eb1 [root@node01 ~]# [root@node01 ~]# crictl image ls IMAGE TAG IMAGE ID SIZE registry.k8s.io/kube-apiserver v1.27.1 6f6e73fa8162b 122MB ","date":"2022-08-10","objectID":"/k8sContainerd/:2:0","tags":["containerd","容器"],"title":"k8s 容器运行时之一 containerd","uri":"/k8sContainerd/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s 官方文档：kube-controller-manager kube-controller-managerkube-controller-manager (k8s 控制器管理工具)是一个守护进程，内嵌随 k8s 一起发布的核心控制回路（在机器人和自动化的应用中，控制回路是一个永不休止的循环，用于调节系统状态），在 k8s 中，每个控制器是一个控制回路，通过 API 服务器监视集群的共享状态， 并尝试进行更改以将当前状态转为期望状态。 目前，k8s 自带的控制器例子包括： 副本控制器：负责在节点出现故障时进行通知和响应 节点控制器：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 命名空间控制器：待补充 端点分片控制器：填充端点分片（EndpointSlice）对象（以提供 Service 和 Pod 之间的链接） 服务账号控制器：为新的命名空间创建默认的服务账号 kube-controller-manager [flags] [root@k8s01 ~]# kubectl get pod kube-controller-manager-k8s01.localdomain -n kube-system -o=jsonpath='{$.spec.containers[0].command}' | jq [ \"kube-controller-manager\", \"--allocate-node-cidrs=true\", \"--authentication-kubeconfig=/etc/kubernetes/controller-manager.conf\", \"--authorization-kubeconfig=/etc/kubernetes/controller-manager.conf\", \"--bind-address=0.0.0.0\", \"--client-ca-file=/etc/kubernetes/pki/ca.crt\", \"--cluster-cidr=100.64.0.0/10\", \"--cluster-name=kubernetes\", \"--cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt\", \"--cluster-signing-key-file=/etc/kubernetes/pki/ca.key\", \"--controllers=*,bootstrapsigner,tokencleaner\", \"--experimental-cluster-signing-duration=876000h\", \"--feature-gates=TTLAfterFinished=true,EphemeralContainers=true\", \"--kubeconfig=/etc/kubernetes/controller-manager.conf\", \"--leader-elect=true\", \"--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt\", \"--root-ca-file=/etc/kubernetes/pki/ca.crt\", \"--service-account-private-key-file=/etc/kubernetes/pki/sa.key\", \"--service-cluster-ip-range=10.96.0.0/22\", \"--use-service-account-credentials=true\" ] 是否允许为 pod 分配地址kube-container-manager --allocate-node-cidrs 选项值为布尔值类型，当为 true 时允许为 pod 分配 IP 地址 身份验证 kubeconfig 文件路径kube-controller-manager --authentication-kubeconfig 选项指定 kubeconfig 文件路径。文件所包含信息具有创建 tokenreviews.authentication.k8s.io 权限。当值为空时，则所有令牌请求都会被认作匿名请求， k8s 也不再在集群中查找客户端的 CA 证书信息。 鉴权验证 kubeconfig 文件路径kube-controller-manager --authorization-kubeconfig 选项指定 kubeconfig 文件路径，文件所包含信息具有创建 subjectaccessreviews.authorization.k8s.io 权限。如果配置为空字符串，未被鉴权模块所忽略的请求都会被禁止 绑定 IP 地址kube-controller-manager --bind-address 选项指定控制器管理工具绑定的 IP 地址 客户端 CA 证书路径kube-controller-manager --client-ca-file 选项指定 CA 证书 pod ip 地址范围kube-controller-manager --cluster-cidr 选项指定集群中 Pod 的 CIDR 范围。要求 --allocate-node-cidrs 标志为 true。 集群实例的前缀kube-controller-manager --cluster-name 选项指定集群实例的前缀。默认值为 kubernetes 集群的 CA 证书kube-controller-manager --cluster-signing-cert-file 选项指定一个包含 PEM 编码格式的 X509 CA 证书的文件名。该证书用来发放集群范围的证书。 如果设置了此标志，则不能指定更具体的 --cluster-signing-* 标志。 集群 CA 证书密钥kube-controller-manager --cluster-signing-key-file 选项指定一个包含 PEM 编码的 RSA 或 ECDSA 私钥的文件名。该私钥用来对集群范围证书签名。 若指定了此选项，则不可再设置 --cluster-signing-* 参数 启用的控制器列表kube-controller-manager --controllers 指定要启用的控制器列表，多个控制器使用逗号分隔。如果值为 * 表示使用默认值（除了 bootstrapsigner 和 tokencleaner 其它都启用了）。控制器名称前面有 - 表示禁用，如 -foo 表示禁用 foo 控制器 --controllers=*,bootstrapsigner,tokencleaner 证书有效期kube-controller-manager --experimental-cluster-signing-duration 选项指定签发的证书有效期。默认值为 8760h0m0s 特性开关kube-controller-manager --feature-gates 选项指定特性开关。 主节点 kubeconfig 文件路径kube-controller-manager --kubeconfig 选项指定一个 kubeconfig 配置文件，该文件中包含主控节点位置以及鉴权凭据信息。 是否启用领导选举kube-controller-manager --leader-elect 选项值是布尔类型，当为 true 时在执行主循环之前，启动领导选举（Leader Election）客户端，并尝试获得领导者身份。 在运行多副本组件时启用此标志有助于提高可用性。 验证客户端请求的 ca 证书路径kube-controller-manager --requestheader-client-ca-file 选项指定根证书包文件名。在 通过 kube-controller-manager --requestheader-username-headers 选项之前要使用这里的证书来检查请求中的客户证书。 警告：一般不要依赖对请求所作的鉴权结果。 服务账号令牌 CA 证书路径kube-controller-manager --root-ca-file 如果此标志非空，则在服务账号的令牌 Secret 中会包含此根证书机构。 所指定标志值必须是一个合法的 PEM 编码的 CA 证书包。 对服务账号令牌签名的私钥路径kube-controller-manager --service-account-private-key-file 包含 PEM 编码的 RSA 或 ECDSA 私钥数据的文件名，这些私钥用来对服务账号令牌签名。 集群 service IP 范围kube-controller-manager --service-cluster-ip-range 指定集群中 Service 对象的 CIDR 范围。要求 kube-controller-manager --allocate-node-cidrs=true 为每个控制器单独使用服务账号凭据kube-controller-manager --use-service-account-credentials 选项值为 true 时，为每个控制器单独使用服务账号凭据。 ","date":"2022-08-07","objectID":"/k8sControllerManager/:0:0","tags":["k8s","k8s controller manager"],"title":"k8s controller manager","uri":"/k8sControllerManager/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s 官方文档：kube-apiserver kube-apiserverkube-apiserver 用于验证并配置 API 对象的数据、提供 HTTP REST 操作、为集群的共享状态提供前端， 所有其他组件都通过该前端进行交互。 现在 kube-apiserver 通常是以静态 pod 方式运行的 [root@k8s01 ~]# kubectl get pod kube-apiserver-k8s01.localdomain -n kube-system NAME READY STATUS RESTARTS AGE kube-apiserver-k8s01.localdomain 1/1 Running 2 (8h ago) 13d [root@k8s01 ~]# kubectl get pod kube-apiserver-k8s01.localdomain -n kube-system -o=jsonpath='{$.spec.containers[0].command}' | jq [ \"kube-apiserver\", \"--advertise-address=192.168.64.111\", \"--allow-privileged=true\", \"--audit-log-format=json\", \"--audit-log-maxage=7\", \"--audit-log-maxbackup=10\", \"--audit-log-maxsize=100\", \"--audit-log-path=/var/log/kubernetes/audit.log\", \"--audit-policy-file=/etc/kubernetes/audit-policy.yml\", \"--authorization-mode=Node,RBAC\", \"--client-ca-file=/etc/kubernetes/pki/ca.crt\", \"--enable-admission-plugins=NodeRestriction\", \"--enable-aggregator-routing=true\", \"--enable-bootstrap-token-auth=true\", \"--etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt\", \"--etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt\", \"--etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key\", \"--etcd-servers=https://192.168.64.111:2379\", \"--feature-gates=TTLAfterFinished=true,EphemeralContainers=true\", \"--kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt\", \"--kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key\", \"--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\", \"--proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt\", \"--proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key\", \"--requestheader-allowed-names=front-proxy-client\", \"--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt\", \"--requestheader-extra-headers-prefix=X-Remote-Extra-\", \"--requestheader-group-headers=X-Remote-Group\", \"--requestheader-username-headers=X-Remote-User\", \"--secure-port=6443\", \"--service-account-issuer=https://kubernetes.default.svc.cluster.local\", \"--service-account-key-file=/etc/kubernetes/pki/sa.pub\", \"--service-account-signing-key-file=/etc/kubernetes/pki/sa.key\", \"--service-cluster-ip-range=10.96.0.0/22\", \"--tls-cert-file=/etc/kubernetes/pki/apiserver.crt\", \"--tls-private-key-file=/etc/kubernetes/pki/apiserver.key\" ] 与 api 服务通信地址kube-apiserver --advertise-address 选项指定与 api 服务通信地址。会向集群所有成员告知。这个地址必须能够被集群中其他成员访问。 如果地址为空，将会使采用 --bind-address 选项，如果它也未指定，则使用主机的默认接口地址 是否允许特权容器kube-apiserver --allow-privileged 选项取值是布尔值类型，如果为 true 则允许特权容器，默认值为 false 审计日志格式kube-apiserver --audit-log-format 指定保存的审计日志格式，有以下取值： legacy: 以一行文本记录一个事件方式保存 json: 以 json 格式记录。默认值 保留审计日志时间kube-apiserver --audit-log-maxage 设置根据文件名中编码的时间戳保留旧审计日志文件的最大天数 保留审计日志个数kube-apiserver --audit-log-maxbackup 指定要保留的旧的审计日志文件个数上限。 将值设置为 0 表示对文件个数没有限制 审计日志最大值kube-apiserver --audit-log-maxsize 指定轮换之前，审计日志文件的最大大小（以兆字节为单位） 审计日志保存路径kube-apiserver --audit-log-path 如果设置该选项，则所有到达 API 服务器的请求都将记录到该文件中。如果值为 - 表示标准输出 审计策略文件路径kube-apiserver --audit-policy-file 定义审计策略配置的文件的路径 鉴权插件的顺序列表kube-apiserver --authorization-mode 定义在安全端口上进行鉴权的插件的顺序列表。这些列表以逗号分隔。有以下值： AlwaysAllow: AlwaysDeny: ABAC: Webhook: RBAC: Node: 客户端 ca 证书路径kube-apiserver --client-ca-file 如果使用该选项，则使用与客户端证书的 CommonName 对应的标识对任何出示由 client-ca 文件中的授权机构之一签名的客户端证书的请求进行身份验证 启用插件kube-apiserver --enable-admission-plugins 选项指定启用非默认启用的插件列表。插件列表以逗号分隔，插件的顺序无关紧要 以下插件默认启用： NamespaceLifecycle: LimitRanger: ServiceAccount: TaintNodesByCondition: PodSecurity: Priority: DefaultTolerationSeconds: DefaultStorageClass: StorageObjectInUseProtection: PersistentVolumeClaimResize: RuntimeClass: CertificateApproval: CertificateSigning: CertificateSubjectRestriction: DefaultIngressClass: MutatingAdmissionWebhook: ValidatingAdmissionWebhook: ResourceQuota: 以下插件需要使用该选项指定启用： AlwaysAdmit: AlwaysDeny: AlwaysPullImages: CertificateApproval: CertificateSigning: CertificateSubjectRestriction: DefaultIngressClass: DefaultStorageClass: DefaultTolerationSeconds: DenyServiceExternalIPs: EventRateLim","date":"2022-08-06","objectID":"/k8sKubeApiServer/:0:0","tags":["k8s","k8s API server"],"title":"k8s API 服务","uri":"/k8sKubeApiServer/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s官方文档：kubelet k8s官方文档：kubelet 配置（v1beta1） kubeletkubelet 在每个节点上都有运行，是执行 API server 传递的操作。它是基于 PodSpec 来工作的，每个 PodSpec 是一个描述 Pod 的 YAML 或 JSON 对象。 kubelet 接受通过各种机制（主要是通过 apiserver）提供的一组 PodSpec，并确保这些 PodSpec 中描述的容器处于运行状态且运行状况良好。 kubelet 不管理不是由 Kubernetes 创建的容器。 除了来自 apiserver 的 PodSpec 之外，还可以通过以下三种方式将容器清单（manifest）提供给 kubelet。 文件：利用命令行参数传递路径。kubelet 周期性地监视此路径下的文件是否有更新。 监视周期默认为 20s，且可通过参数进行配置 HTTP 端点（HTTP endpoint）：利用命令行参数指定 HTTP 端点。 此端点的监视周期默认为 20 秒，也可以使用参数进行配置。 HTTP 服务器（HTTP server）：kubelet 还可以侦听 HTTP 并响应简单的 API （目前没有完整规范）来提交新的清单。 查看 kubelet 运行状态 [root@k8s01 ~]# systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Sat 2022-08-06 13:14:14 CST; 6h ago Docs: http://kubernetes.io/docs/ Process: 1401 ExecStopPost=/usr/bin/kubelet-post-stop.sh (code=exited, status=0/SUCCESS) Process: 1601 ExecStartPre=/usr/bin/kubelet-pre-start.sh (code=exited, status=0/SUCCESS) Main PID: 1625 (kubelet) Tasks: 17 (limit: 23507) Memory: 107.7M CGroup: /system.slice/kubelet.service ... 连接 API server 配置文件kubelet --kubeconfig 选项指定 kubelet 配置文件路径，该配置文件指定连接 API server。如果缺省该选项则启用独立模式。 通常配置文件有以下内容 [root@k8s01 ~]# cat /etc/kubernetes/kubelet.conf apiVersion: v1 clusters: - cluster: certificate-authority-data: LS0tLS... server: https://apiserver.cluster.local:6443 name: kubernetes contexts: - context: cluster: kubernetes user: system:node:k8s01.localdomain name: system:node:k8s01.localdomain@kubernetes current-context: system:node:k8s01.localdomain@kubernetes kind: Config preferences: {} users: - name: system:node:k8s01.localdomain user: client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem client-key: /var/lib/kubelet/pki/kubelet-client-current.pem 配置文件kubelet --config 选项指定加载的初始配置。省略此参数时 kubelet 会使用内置的默认配置值。 命令行参数会覆盖此文件中的配置。 [root@k8s01 ~]# cat /var/lib/kubelet/config.yaml apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false webhook: cacheTTL: 2m0s enabled: true x509: clientCAFile: /etc/kubernetes/pki/ca.crt authorization: mode: Webhook webhook: cacheAuthorizedTTL: 5m0s cacheUnauthorizedTTL: 30s cgroupDriver: systemd cgroupsPerQOS: true clusterDNS: - 10.96.0.10 clusterDomain: cluster.local configMapAndSecretChangeDetectionStrategy: Watch containerLogMaxFiles: 5 containerLogMaxSize: 10Mi contentType: application/vnd.kubernetes.protobuf cpuCFSQuota: true cpuCFSQuotaPeriod: 100ms cpuManagerPolicy: none cpuManagerReconcilePeriod: 10s enableControllerAttachDetach: true enableDebuggingHandlers: true enforceNodeAllocatable: - pods eventBurst: 10 eventRecordQPS: 5 evictionHard: imagefs.available: 15% memory.available: 100Mi nodefs.available: 10% nodefs.inodesFree: 5% evictionPressureTransitionPeriod: 5m0s failSwapOn: true fileCheckFrequency: 20s hairpinMode: promiscuous-bridge healthzBindAddress: 127.0.0.1 healthzPort: 10248 httpCheckFrequency: 20s imageGCHighThresholdPercent: 85 imageGCLowThresholdPercent: 80 imageMinimumGCAge: 2m0s iptablesDropBit: 15 iptablesMasqueradeBit: 14 kind: KubeletConfiguration kubeAPIBurst: 10 kubeAPIQPS: 5 logging: flushFrequency: 0 options: json: infoBufferSize: \"0\" verbosity: 0 makeIPTablesUtilChains: true maxOpenFiles: 1000000 maxPods: 110 memorySwap: {} nodeLeaseDurationSeconds: 40 nodeStatusReportFrequency: 10s nodeStatusUpdateFrequency: 10s oomScoreAdj: -999 podPidsLimit: -1 port: 10250 registryBurst: 10 registryPullQPS: 5 rotateCertificates: true runtimeRequestTimeout: 2m0s serializeImagePulls: true shutdownGracePeriod: 0s shutdownGracePeriodCriticalPods: 0s staticPodPath: /etc/kubernetes/manifests streamingConnectionIdleTimeout: 4h0m0s syncFrequency: 1m0s volumeStatsAggPeriod: 1m0s 选择使用的容器运行时kubelet --container-runtime 指定要要使用的容器运行时，旧版本可以选择值为 docker 或 remote。由于后续版本已弃用 docker , remote 成了唯一值，因此该参数将在 1.27 版本中","date":"2022-08-06","objectID":"/k8sKubelet/:0:0","tags":["k8s","k8s kubelet"],"title":"k8s kubelet","uri":"/k8sKubelet/"},{"categories":["json"],"content":" 运行环境： 内容来自以下文档： JSONPath expressions JsonPath 表达式 JsonPath 说明 $ 根对象 @ 当前对象 · 或 [] 子运算符 .. 递归下降 * 通配符。获取所有对象 [start:end :step] 下标运算符 [,] 并集运算符 () 分组 ?() 过滤分组 range, end 迭代列表 '' 引用解释执行字符串 ","date":"2022-08-06","objectID":"/JsonPath/:0:0","tags":["json","JsonPath 表达式"],"title":"JsonPath","uri":"/JsonPath/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s官方文档：kubectl k8s官方文档：kubectl options k8s官方文档：使用 kubeconfig 文件组织集群访问 k8s官方文档：配置对多集群的访问 k8s官方文档：kubeconfig (v1) 上海_运维_Q先生: K8s kubectl 报错 c-bash: _get_comp_words_by_ref: command not found解决过程 kubectlkubectl 是使用 k8s API 与 k8s 集群控制平面通信的命令行工具。安装方式如下 # 添加 yum 源 cat \u003c\u003cEOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF [root@localhost ~]# yum install -y kubectl --disableexcludes=kubernetes Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile ... 命令行自动补全实现自动补全需先安装 bash-completion 包 [root@k8s01 ~]# yum install -y bash-completion [root@k8s01 ~]# source /usr/share/bash-completion/bash_completion 在当前 bash 中设置自动补全 source \u003c(kubectl completion bash) bash shell 中永久地添加自动补全 echo \"source \u003c(kubectl completion bash)\" \u003e\u003e ~/.bashrc 命令行操作kubeclt使用语法如下： # TYPE: 指定资源类型 # NAME: 指定资源名称 # command: 对指定的资源执行操作 # flags: 可选参数 kubectl [command] [TYPE] [NAME] [flags] # 获取帮助信息 kubectl help 下表列出 kubectl 部分操作： 操作与语法 描述 kubectl annotate ... 添加或更新一个或多个资源的注解 kubectl api-resources [flags] 列出可用的 API 资源 kubectl api-versions [flags] 列出可用的 API 版本 kubectl apply -f FILENAME [flags] 从文件或 stdin 对资源应用配置更改 kubectl attach POD -c CONTAINER [-i] [-t] [flags] 挂接到正在运行的容器，查看输出流或与容器交互 kubectl auth [flags] [options] 检查授权 kubectl certificate SUBCOMMAND [options] 修改证书资源 kubectl cluster-info [flags] 显示有关集群中主服务器和服务的端口信息 kubectl config SUBCOMMAND [flags] 修改 kubeconfig 文件 kubectl cordon NODE [options] 将节点标记为不可调度 kubectl cp \u003cfile-spec-src\u003e \u003cfile-spec-dest\u003e [options] 从容器复制文件、目录或将文件、目录复制到容器 kubectl delete ... 删除资源 kubectl describe ... 显示一个或多个资源的详细状态 kubectl drain NODE [options] 腾空节点以准备维护 kubectl edit ... 使用默认编辑器编辑和更新服务器上一个或多个资源的定义 kubectl explain [--recursive=false] [flags] 获取多种资源的文档 kubectl logs POD [-c CONTAINER] [--follow] [flags] 打印 Pod 中容器的日志 kubectl options 全局命令行选项列表，这些选项适用于所有命令 kubectl proxy ... 运行访问 Kubernetes API 服务器的代理 kubectl top [flags] [options] 显示资源（CPU、内存、存储）的使用情况 kubectl uncordon NODE [options] 将节点标记为可调度 kubectl version [--client] [flags] 显示运行在客户端和服务器上的 Kubernetes 版本 kubectl logs POD [-c CONTAINER] [--follow] [flags] 查看 pod 中容器日志 输出选项","date":"2022-08-06","objectID":"/k8sKubeclt/:0:0","tags":["k8s","kubectl","kubeconfig"],"title":"k8s kubectl","uri":"/k8sKubeclt/"},{"categories":["k8s"],"content":" 格式化输出部分操作（如 get）支持特定格式输出详细信息（通常是 -o, --output=''选项）。通常有以下输出格式： -o custom-columns=\u003cspec\u003e: 使用逗号分隔的自定义列列表打印表 -o custom-columns-file=\u003cfilename\u003e: 使用文件中的自定义列模板打印表 -o json: 以 JSON 格式输出 -o jsonpath=\u003ctemplate\u003e: 输出 jsonpath 表达式定义的字段 -o jsonpath-file=\u003cfilename\u003e: 以文件中的 jsonpath 表达式定义的字段输出 -o name: 仅打印资源名称 -o wide: 以纯文本格式输出 -o yaml: 以 YAML 格式输出 Kubectl 支持使用 JSONPath 表达式来过滤 JSON 对象中的特定字段并格式化输出。 除了原始的 JSONPath 模板语法，以下函数和语法也是有效的: 使用双引号将 JSONPath 表达式内的文本引起来 使用 range，end 运算符来迭代列表。 使用负片索引后退列表。负索引不会“环绕”列表，并且只要 -index + listLength\u003e = 0 就有效 JsonPath 说明 $ 根对象 @ 当前对象 · 或 [] 子运算符 .. 递归下降 * 通配符。获取所有对象 [start:end :step] 下标运算符 [,] 并集运算符 () 分组 ?() 过滤分组 range, end 迭代列表 '' 引用解释执行字符串 示例： kubectl get pods -o json kubectl get pods -o=jsonpath='{@}' kubectl get pods -o=jsonpath='{.items[0]}' kubectl get pods -o=jsonpath='{.items[0].metadata.name}' kubectl get pods -o=jsonpath=\"{.items[*]['metadata.name', 'status.capacity']}\" kubectl get pods -o=jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.status.startTime}{\"\\n\"}{end}' ","date":"2022-08-06","objectID":"/k8sKubeclt/:1:0","tags":["k8s","kubectl","kubeconfig"],"title":"k8s kubectl","uri":"/k8sKubeclt/"},{"categories":["k8s"],"content":" 输出排序部分操作支持 --sort-by 参数指定任何数字或字符串字段（jsonpath 表达式）来对对象进行排序。 查看容器日志语法：kubectl logs [-f] [-p] (POD | TYPE/NAME) [-c CONTAINER] --all-containers=true # 查看 pod 内所有容器日志，默认为 false -c, --container='' # 查看指定容器日志 -l, --selector='' # 通过标签选择器筛选 Pod 调试容器语法：kubectl debug (POD | TYPE[[.VERSION].GROUP]/NAME) [ -- COMMAND [args...] ] -c, --container= # 指定调试容器和名称 --image= # 指定调试容器镜像 -i, --stdin=false # 运行的指定 -t, --tty=false: # 是否分配一个 tty 终端 --target='' # 创建临时容器时指定的进程名称空间 修改 kubeconfig 文件用于配置集群访问的文件称为 kubeconfig 文件，使用 kubeconfig 文件来组织有关集群、用户、命名空间和身份认证机制的信息。kubectl 使用的 kubeconfig 文件路径为 $HOME/.kube/config。可以通过设置 KUBECONFIG 环境变量或 kubectl config --kubeconfig 选项修改 使用 kubeconfig 文件，可以组织集群、用户和命名空间。还可以定义上下文，以便在集群和命名空间之间快速轻松地切换。下面是kubectl 默认使用的 kubeconfig 文件（使用 kubectl config view 命令可以查看kubeconfig内容） apiVersion: v1 # api 版本 kind: Config preferences: {} current-context: kubernetes-admin@kubernetes # 当前使用的上下文 clusters: # 集群列表，必须有 - name: kubernetes # 集群命令，必须有 cluster: certificate-authority-data: DATA+OMITTED # 集群 CA 证书文件的 base64 编码格式，必须有 server: https://apiserver.cluster.local:6443 # k8s 集群地址，必须的 users: # 用户列表，必须有 - name: kubernetes-admin # 命令用户，必须有，注意它不并不是集群中的用户 user: client-certificate-data: REDACTED # 集群签发的客户端证书的 base64 编码格式，必须有 client-key-data: REDACTED # 客户端密钥的 base64 编码格式 contexts: # 命名上下文列表，必须有 - name: kubernetes-admin@kubernetes # 上下文名称，被 kubectl 引用 context: cluster: kubernetes # 使用的集群名称上下文，由前面的 clusters.name 字段定义 user: kubernetes-admin # 使用的用户名上下文，由前面的 users.name 字段定义 查看当前使用的kubeconfig 上下文 [root@node01 ~]# kubectl config current-context kubernetes-admin@kubernetes 永久修改当前使用的kubeconfig 上下文 [root@node01 ~]# kubectl config current-context xiaosi [root@node01 ~]# [root@node01 ~]# kubectl config current-context xiaosi 永久删除指定的 kubeconfig 上下文（不会删除关联的集群与用户信息；也不会修改当前使用的上下文） [root@node01 ~]# kubectl config delete-context kubernetes-admin@kubernetes deleted context kubernetes-admin@kubernetes from /root/.kube/config # 删除当前上下文会有警告提示，但不会阻止 [root@node01 ~]# kubectl config delete-context xiaosi warning: this removed your active context, use \"kubectl config use-context\" to select a different one deleted context xiaosi from /root/.kube/config [root@node01 ~]# kubectl get pod Error in configuration: context was not found for specified context: xiaosi 运行一个 kubernetes API 服务器代理kubectl proxy 以前台方式运行一个在localhost和Kubernetes API服务器之间创建一个代理服务器或应用程序级网关。它还允许通过指定的HTTP路径提供静态内容。所有传入的数据都通过一个端口进入，并转发到远程Kubernetes API服务器端口，除了与静态内容路径匹配的路径。 kubectl proxy [--port=PORT] [--www=static-dir] [--www-prefix=prefix] [--api-prefix=prefix] # 选项 accept-hosts # 指定可访问的主机列表。主机列表以正则表示，以逗号分隔 # 默认值为：^localhost$,^127.0.0.1$,^[::1]$ address # 监听地址 # 默认值为：127.0.0.1 port # 监听端口 # 默认值为：80001 查看 API 资源查看位于名称空间内的资源 [root@node03 ~]# kubectl api-resources --namespaced=true NAME SHORTNAMES APIVERSION NAMESPACED KIND bindings v1 true Binding configmaps cm v1 true ConfigMap 查看全局资源 [root@node03 ~]# kubectl api-resources --namespaced=false NAME SHORTNAMES APIVERSION NAMESPACED KIND componentstatuses cs v1 false ComponentStatus namespaces ns v1 false Namespace 节点污点 PS 2023/06/17 23:12:49 \u003e curl.exe --cert .\\localK8s\\xiaosi.crt --key .\\localK8s\\xiaosi.key --cacert .\\localK8s\\ca.crt -X GET https://192.168.232.100:6443/api/v1/nodes/node04.my.host -s | jq-win64.exe -r '.spec.taints' [ { \"key\": \"node.kubernetes.io/unreachable\", \"effect\": \"NoSchedule\", \"timeAdded\": \"2023-06-15T18:41:26Z\" }, { \"key\": \"node.kubernetes.io/unreachable\", \"effect\": \"NoExecute\", \"timeAdded\": \"2023-06-17T16:43:14Z\" } ] 删除污点 [root@node01 ~]# kubectl taint nodes node04.my.host node.kubernetes.io/unreachable:NoExecute- node/node04.my.host untainted 更新资源字段 kubectl patch (-f FILENAME | TYPE NAME) [-p PATCH|--patch-file FILE] --filename, -f # 指定文件名（URL）更新资源 --patch, -p # 指定 json 格式更新资源 更新 PVC 资源指定的 PV 类 [root@localhost ~]# kubectl -n prometheus patch pvc prometheus-server -p '{\"spec\":{\"storageClassName\": \"ebs\"}}' persistentvolumeclaim/prometheus-server patched 进入 pod 容器 kubectl exec (POD | TYPE/NAME) [-c CONTAINER] [flags] -- COMMAND [args...] --con","date":"2022-08-06","objectID":"/k8sKubeclt/:2:0","tags":["k8s","kubectl","kubeconfig"],"title":"k8s kubectl","uri":"/k8sKubeclt/"},{"categories":["k8s"],"content":" -bash: _get_comp_words_by_ref: command not found使用 \u003cTab\u003e 键补全 kubectl 命令时出错 [root@k8s01 ~]# kubectl -bash: _get_comp_words_by_ref: command not found -bash: _get_comp_words_by_ref: command not found 原因是缺少 bash-completion 包 yum install bash-completion -y source /usr/share/bash-completion/bash_completion ","date":"2022-08-06","objectID":"/k8sKubeclt/:3:0","tags":["k8s","kubectl","kubeconfig"],"title":"k8s kubectl","uri":"/k8sKubeclt/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24.3 Rocky Linux: 8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s 官方文档：服务 k8s 官方文档：service API 服务资源k8s 中的服务是将运行在一组 Pod 上的应用程序公开为网络服务的抽象方法，是提供访问一组 Pod 的策略。它用于解决以下问题： 容器不会使用节点上的特定端口，也不会使用任何特定的 NAT 规则去路由流量到 Pod 上 Pod 是有生命周期的，如果 Pod 被摧毁重新创建之后如何让前端访问 Pod 中应用程序 server也是通过标签选择器来关联 pod 的 这是一个示例： apiVersion: apps/v1 kind: Deployment metadata: name: deployment-nginx-test labels: deployment: nginx annotations: kubernetes.io/change-cause: \"nginx stable\" spec: replicas: 4 selector: matchLabels: nginx: NginxServiceTest strategy: type: RollingUpdate rollingUpdate: maxSurge: 7 maxUnavailable: 3 template: metadata: labels: nginx: NginxServiceTest spec: containers: - name: nginx image: nginx:stable ports: - containerPort: 80 name: http-web-svc --- apiVersion: v1 kind: Service metadata: name: nginx-service spec: selector: nginx: NginxServiceTest ports: - name: name-of-service-port protocol: TCP port: 801 targetPort: http-web-svc 上面示例中： service.spec.selector: 是标签选择器，服务选择算符的控制器不断扫描与其选择算符匹配的 Pod，然后将所有更新到其 Endpoint 中 service.spec.ports.name: 名称。一个 service 可以管理公开多个端口 service.spec.ports.port: 暴露的端口号 service.spec.ports.protocol: 端口使用的协议，值为：TCP (默认值)、UDP、SCTP 之一 service.spec.ports.targetPort: pod 端口号，也可以是端口名 部署后进行访问测试： [root@k8s01 ~]# kubectl get service nginx-service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx-service ClusterIP 10.96.3.72 \u003cnone\u003e 801/TCP 115s [root@k8s01 ~]# curl -I 10.96.3.72:801 HTTP/1.1 200 OK Server: nginx/1.22.0 Date: Wed, 03 Aug 2022 10:40:27 GMT Content-Type: text/html Content-Length: 615 Last-Modified: Mon, 23 May 2022 23:59:19 GMT Connection: keep-alive ETag: \"628c1fd7-267\" Accept-Ranges: bytes Endpoints 对象Endpoints （端点）是实现实际服务 pod IP 的集合，它会收集满足标签的就绪 pod IP 创建 service 时，如果有 .spec.selector 字段，则会自动创建同名的 Endpoint 资源。当 Endpoint 收集的端点个数超过 1000 个时，会为该 Endpoint 添加注解 endpoints.kubernetes.io/over-capacity: truncated ，同时 Endpoints 控制器还会将 Endpoints 对象数量截断到 1000 EndpointSlices特性状态：Kubernetes v1.21 [stable] EndpointSlices 是一种 API 资源，可以为 Endpoints 提供更可扩展的替代方案。 尽管从概念上讲与 Endpoints 非常相似，但 EndpointSlices 允许跨多个资源分布网络端点。 默认情况下，一旦到达 100 个 Endpoint，该 EndpointSlice 将被视为“已满”， 届时将创建其他 EndpointSlices 来存储任何其他 Endpoints。 VIP 与 service在 Kubernetes 集群中，每个 Node 运行一个 kube-proxy 进程。 kube-proxy 负责为 Service 实现了一种 VIP（虚拟 IP）的形式 kube-proxy 工作模式由 kube-proxy --proxy-mode 选项决定，不同工作模式代理实现代理方式不一样，有以下代理模式： userspace iptables IPVS 在这些代理模型中，绑定到服务 IP 的流量： 在客户端不了解 Kubernetes 或服务或 Pod 的任何信息的情况下，将 Port 代理到适当的后端。如果要确保每次都将来自特定客户端的连接传递到同一 Pod， 则可以通过将 service.spec.sessionAffinity 设置为 “ClientIP” （默认值是 “None\"），来基于客户端的 IP 地址选择会话亲和性。 你还可以通过适当设置 service.spec.sessionAffinityConfig.clientIP.timeoutSeconds 来设置最大会话停留时间。（默认值为 10800 秒，即 3 小时，windows 系统不支持为服务设置最大会话停留时间）。 在 userspace 模式中，kube-proxy 会监视 Kubernetes 控制平面对 Service 对象和 Endpoints 对象的添加和移除操作。 对每个 Service，它会在本地 Node 上打开一个端口（随机选择）。 任何连接到“代理端口”的请求，都会被代理到 Service 的后端 Pods 中的某个上面（如 Endpoints 所报告的一样）。 使用哪个后端 Pod，是 kube-proxy 基于 SessionAffinity 来确定的。最后，它配置 iptables 规则，捕获到达该 Service 的 clusterIP（是虚拟 IP） 和 Port 的请求，并重定向到代理端口，代理端口再代理请求到后端Pod。默认情况下，用户空间模式下的 kube-proxy 通过轮转算法选择后端。 在 iptables 代理模式中，kube-proxy 会监视 Kubernetes 控制节点对 Service 对象和 Endpoints 对象的添加和移除。 对每个 Service，它会配置 iptables 规则，从而捕获到达该 Service 的 clusterIP 和端口的请求，进而将请求重定向到 Service 的一组后端中的某个 Pod 上面。 对于每个 Endpoints 对象，它也会配置 iptables 规则，这个规则会选择一个后端组合。默认的策略是，kube-proxy 在 iptables 模式下随机选择一个后端。如果所选的第一个 Pod 没有响应，则连接失败，并不会自动使用其他后端 Pod 重试。因此，使用需要 Pod 就绪探测器验证后端 Pod 可以正常工作，避免将流量通过 kube-proxy 发送到已知已失败的 Pod。 使用 iptables 处理流量具有较低的系统开销，因为流量由 Linux netfilter 处理， 而无需在用户空间和内核空间之间切换。 这种方法也可能更可靠。 IPVS 代理模式中，kube-proxy 监视 Kubernetes 服务和端点，调用 netlink 接口相应地创建 IPVS 规则， 并定期将 IPVS 规则与 Kubernetes 服务和端点同步。该控制循环可确保 IPVS 状态与所需状态匹配。访问服务时，IPVS 将流量定向到后端 Pod 之一。 特性状态： Kubernetes v1.11 [stable] IPVS 代理模式基于类似于 iptables 模式的 netfilter 挂钩函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。 这意味着，与 iptables 模式下的 kube-proxy 相比，IPVS 模式下的 kube-proxy 重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。 与其他代理模式相比，IPVS 模式还支持更高的网络流量吞吐量。 要在 IPVS 模式下运行 kube-proxy，必须在启动 kube-proxy 之前使 IPVS 在节点上可用。当 kube-proxy 以 IPVS 代理模式启动时，它将验证 IPVS 内核模块是否可用。 如果未检测到 IPVS 内核","date":"2022-08-03","objectID":"/Service/:0:0","tags":["k8s","k8s 服务"],"title":"k8s 服务暴露","uri":"/Service/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24.3 Rocky Linux: 8.5 内核: 4.18.0-348.el8.0.2.x86_64 内容来自以下文档： k8s官方文档: Pod Jimmy: Pause 容器 k8s官方文档: 调试 Init 容器 k8s官方文档: 配置 Pod 初始化 k8s官方文档: 配置 Pods 和容器 k8s官方文档: 通过环境变量将 Pod 信息呈现给容器 k8s官方文档: 通过文件将 Pod 信息呈现给容器 k8s官方文档: 为容器和 Pods 分配 CPU 资源 k8s官方文档: 为容器和 Pod 分配内存资源 k8s官方文档: 创建静态Pod podPod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。 它由一个或多个容器组成。这些容器共享存储、网络、以及怎样运行这些容器的声明。 Pod 中的内容总是并置（colocated）的并且一同调度，在共享的上下文中运行。 这些容器相对紧密地耦合在一起。共享上下文包括一组 Linux 名字空间、控制组 （cgroup）和可能一些其他的隔离方面。 创建pod示例 [root@k8s01 ~]# cat simple-pod.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 [root@k8s01 ~]# kubectl apply -f simple-pod.yaml pod/nginx created # 查看现有`pod` [root@k8s01 ~]# kubectl get pods NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 3m37s # 查看`pod`信息 [root@k8s01 ~]# kubectl describe pods nginx | grep ' IP:' IP: 100.120.95.67 # 测试 [root@k8s01 ~]# curl -I 100.120.95.67:80 HTTP/1.1 200 OK Server: nginx/1.14.2 Date: Wed, 27 Jul 2022 11:01:22 GMT Content-Type: text/html Content-Length: 612 Last-Modified: Tue, 04 Dec 2018 14:44:49 GMT Connection: keep-alive ETag: \"5c0692e1-264\" Accept-Ranges: bytes 以yaml格式查看pod信息 [root@k8s01 ~]# kubectl get pods nginx -o yaml apiVersion: v1 kind: Pod metadata: annotations: cni.projectcalico.org/containerID: a756cb1a6d459422635ef839329c17797ea28d9af9432ac31711e47af419ff93 cni.projectcalico.org/podIP: 100.120.95.67/32 cni.projectcalico.org/podIPs: 100.120.95.67/32 kubectl.kubernetes.io/last-applied-configuration: | {\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"annotations\":{},\"name\":\"nginx\",\"namespace\":\"default\"},\"spec\":{\"containers\":[{\"image\":\"nginx:1.14.2\",\"name\":\"nginx\",\"ports\":[{\"containerPort\":80}]}]}} creationTimestamp: \"2022-07-27T10:53:20Z\" name: nginx namespace: default resourceVersion: \"8029\" uid: b1852d0e-d355-47b9-9b6d-7493dfffdf64 spec: containers: - image: nginx:1.14.2 imagePullPolicy: IfNotPresent name: nginx ports: - containerPort: 80 protocol: TCP resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-98t5l readOnly: true dnsPolicy: ClusterFirst enableServiceLinks: true nodeName: k8s02.localdomain preemptionPolicy: PreemptLowerPriority priority: 0 restartPolicy: Always schedulerName: default-scheduler securityContext: {} serviceAccount: default serviceAccountName: default terminationGracePeriodSeconds: 30 tolerations: - effect: NoExecute key: node.kubernetes.io/not-ready operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 volumes: - name: kube-api-access-98t5l projected: defaultMode: 420 sources: - serviceAccountToken: expirationSeconds: 3607 path: token - configMap: items: - key: ca.crt path: ca.crt name: kube-root-ca.crt - downwardAPI: items: - fieldRef: apiVersion: v1 fieldPath: metadata.namespace path: namespace status: conditions: - lastProbeTime: null lastTransitionTime: \"2022-07-27T10:53:20Z\" status: \"True\" type: Initialized - lastProbeTime: null lastTransitionTime: \"2022-07-27T10:53:52Z\" status: \"True\" type: Ready - lastProbeTime: null lastTransitionTime: \"2022-07-27T10:53:52Z\" status: \"True\" type: ContainersReady - lastProbeTime: null lastTransitionTime: \"2022-07-27T10:53:20Z\" status: \"True\" type: PodScheduled containerStatuses: - containerID: containerd://8cf375b23cded851fe3995706b5f0cbd84eebf5b84e9d0183d43ebdf6cc60517 image: docker.io/library/nginx:1.14.2 imageID: docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d lastState: {} name: nginx ready: true restartCount: 0 started: true state: running: startedAt: \"2022-07-27T10:53:51Z\" hostIP: 192.168.64.112 phase: Running podIP: 100.120.95.67 podIPs: - ip: 100.120.95.67 qosClass: BestEffort startTime: \"2022-07-27T10:53:20Z\" pod通常是由控制器管理。很少有像上面那样单独创建。 pod中的容器pod内通常只运行单个容器，也有多个容器组成的实例。每个 Pod 都旨在运行给定应用程序的单个实例","date":"2022-07-27","objectID":"/k8sPod/:0:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 镜像pod.spec.containers.image指定创建容器的镜像名称。镜像名称可以包包含仓库主机名、仓库端口号、镜像标签： 如果不指定仓库主机名则使用docker公共仓库、 如果不指定镜像标签则使用latest标签。镜像标签可以包含这些字符：字母、数字、_、.、- 也可以使用镜像sha(\u003cimage-name\u003e@\u003cdigest\u003e)，如 image@sha256:45b23dee08af5e... 查看pod kube-apiserver-k8s01.localdomain使用的image镜像 [root@k8s01 ~]# kubectl get pod kube-apiserver-k8s01.localdomain -n kube-system -o yaml | grep \"image: \" image: k8s.gcr.io/kube-apiserver:v1.24.3 image: sealos.hub:5000/kube-apiserver:v1.24.3 注意仓库地址，有些地址要写仓库名 [root@k8s01 ~]# kubectl -n note get pod artalk-deployment-7668ccb557-z2rcg -o yaml | grep \"image: \" image: docker.io/mysql:8.0.30 image: docker.io/artalk/artalk-go:2.1.10 pod.spec.containers.imagePullPolicy字段指定镜像取策略： IfNotPresent: 只有当镜像在本地不存在时才会拉取。默认策略 Always: 每当 kubelet 启动一个容器时，kubelet 会查询容器的镜像仓库， 将名称解析为一个镜像摘要（sha256）如果能与本地有镜像且能对应镜像摘要，则使用它。否则 kubelet 就会使用解析后的摘要拉取镜像，并使用该镜像来启动容器。该方法要求能访问镜像仓库 Never: 不拉取镜像，该方式要求本地必须有镜像才会成功启动容器 默认情况下，kubelet 以串行方式拉取镜像。 也就是说，kubelet 一次只向镜像服务发送一个镜像拉取请求。 其他镜像拉取请求必须等待，直到正在处理的那个请求完成。从 kubelet v1.27 开始，可以在 kubelet 配置 中将字段 serializeImagePulls 设置为 false，kubelet 会立即向镜像服务发送镜像拉取请求，多个镜像将同时被拉动。注意此功能要确定运行的容器运行时工具支持；此外kubelet 从不代表一个 Pod 并行地拉取多个镜像，它取决与节点拉取镜像的队列，并不是 pod 中所需的镜像。例如，有一个 Pod，它有一个初始容器和一个应用容器，那么这两个容器的镜像拉取将不会并行。 但是，如果有两个使用不同镜像的 Pod，当启用并行镜像拉取时，kubelet 会代表两个不同的 Pod 并行拉取镜像。 ","date":"2022-07-27","objectID":"/k8sPod/:1:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 容器生命周期回调类似于许多具有生命周期回调组件的编程语言框架，Kubernetes 为容器提供了生命周期回调。 回调使容器能够了解其管理生命周期中的事件，并在执行相应的生命周期回调时运行在处理程序中实现的代码。有两个回调暴露给容器： PostStart 在容器被创建之后立即被执行。 但是，不能保证回调会在容器入口点（ENTRYPOINT）之前执行，即 postStart 处理函数与容器的代码是异步执行的，但 Kubernetes 的容器管理逻辑会一直阻塞等待 postStart 处理函数执行完毕。 只有 postStart 处理函数执行完毕，容器的状态才会变成 RUNNING。 PreStop 在容器因 API 请求或者管理事件（诸如存活态探针、启动探针失败、资源抢占、资源竞争等） 而被终止之前，此回调会被调用。 如果容器已经处于已终止或者已完成状态，则对 preStop 回调的调用将失败。PreStop 回调在执行期间停滞不前，Pod 的阶段会变成 Terminating 并且一直处于该状态。在用来停止容器的 TERM 信号被发出之前，回调必须执行结束。 Pod 的终止宽限周期在 PreStop 回调被执行之前即开始计数， 所以无论回调函数的执行结果如何，容器最终都会在 Pod 的终止宽限期内被终止。 如果PostStart 或 PreStop 回调失败，它会杀死容器。应该使他们的回调处理程序尽可能的轻量级。 但也需要考虑长时间运行的命令也很有用的情况，比如在停止容器之前保存状态。 容器可以通过实现和注册该回调的处理程序来访问该回调。 针对容器，有两种类型的回调处理程序可供实现： exec: 在容器的 cgroups 和名字空间中执行特定的命令（例如 pre-stop.sh）。 命令所消耗的资源计入容器的资源消耗。 HTTP: 对容器上的特定端点执行 HTTP 请求，它是由 kubelet 进程执行 示例 apiVersion: v1 kind: Pod metadata: name: lifecycle-demo spec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: # 容器创建后执行的命令 exec: command: [\"/bin/sh\", \"-c\", \"echo Hello from the postStart handler \u003e /usr/share/message\"] preStop: # 容器终止后执行的命令 exec: command: [\"/bin/sh\",\"-c\",\"nginx -s quit; while killall -0 nginx; do sleep 1; done\"] 回调处理程序的日志不会在 Pod 事件中公开。 如果处理程序由于某种原因失败，它将播放一个事件。 对于 PostStart，这是 FailedPostStartHook 事件，对于 PreStop，这是 FailedPreStopHook 事件。 # PostStart 回调处理程序失败事件 Events: ... Warning FailedPostStartHook 4s (x2 over 5s) kubelet Exec lifecycle hook ([badcommand]) for Container \"lifecycle-demo-container\" in Pod \"lifecycle-demo_default(30229739-9651-4e5a-9a32-a8f1688862db)\" failed - error: command 'badcommand' exited with 126: , message: \"OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: \\\"badcommand\\\": executable file not found in $PATH: unknown\\r\\n\" ... ","date":"2022-07-27","objectID":"/k8sPod/:2:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 容器探针探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 可以执行三种动作： ExecAction（借助容器运行时执行） TCPSocketAction（由 kubelet 直接检测） HTTPGetAction（由 kubelet 直接检测） 容器探针在pod.spec.containers字段下，针对运行中的容器，kubelet 可以选择是否执行以下三种探针类型，以及如何针对探测结果作出反应： livenessProbe(存活态探针): 指示容器是否正在运行。如果存活态探测失败，则 kubelet 会杀死容器， 并且容器将根据其重启策略决定未来。如果容器不提供存活探针， 则默认状态为 Success。 readinessProbe(绪态探针): 指示容器是否准备好为请求提供服务。如果就绪态探测失败， 端点控制器将从与 Pod 匹配的所有服务的端点列表中删除该 Pod 的 IP 地址。 初始延迟之前的就绪态的状态值默认为 Failure。 如果容器不提供就绪态探针，则默认状态为 Success。 startupProbe(启动探针): 指示容器中的应用是否已经启动。如果提供了启动探针，则所有其他探针都会被 禁用，直到此探针成功为止。如果启动探测失败，kubelet 将杀死容器，而容器依其 重启策略进行重启。 如果容器没有提供启动探测，则默认状态为 Success。 使用探针来检查容器有四种不同的方法。 每个探针都必须准确定义为这四种机制中的一种： exec: 在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。 grpc: 使用 gRPC 执行一个远程过程调用。 目标应该实现 gRPC健康检查。 如果响应的状态是 SERVING，则认为诊断成功。 gRPC 探针是一个 alpha 特性，只有在你启用了 GRPCContainerProbe 特性门控时才能使用。 httpGet: 对容器的 IP 地址上指定端口和路径执行 HTTP GET 请求。如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的。 tcpSocket: 对容器的 IP 地址上的指定端口执行 TCP 检查。如果端口打开，则诊断被认为是成功的。 如果远程系统（容器）在打开连接后立即将其关闭，这算作是健康的。 每次探测都将获得以下三种结果之一： Success（成功） Failure（失败） Unknown（未知），诊断失败，因此不会采取任何行动。 ","date":"2022-07-27","objectID":"/k8sPod/:3:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 容器状态Kubernetes 会跟踪 Pod 中每个容器的状态，一旦调度器将 Pod 分派给某个节点，kubelet 就通过 容器运行时 开始为 Pod 创建容器。 容器的状态有三种： Waiting(等待): 处于 Waiting 状态的容器仍在运行它完成启动所需要的操作：例如，从某个容器镜像 仓库拉取容器镜像，或者向容器应用 Secret 数据等等。 当你使用 kubectl 来查询包含 Waiting 状态的容器的 Pod 时，你也会看到一个 Reason 字段，其中给出了容器处于等待状态的原因。 Running(运行中): Running 状态表明容器正在执行状态并且没有问题发生。 如果配置了 postStart 回调，那么该回调已经执行且已完成。 如果你使用 kubectl 来查询包含 Running 状态的容器的 Pod 时，你也会看到 关于容器进入 Running 状态的信息。 Terminated(已终止): 已经开始执行并且或者正常结束或者因为某些原因失败。 如果你使用 kubectl 来查询包含 Terminated 状态的容器的 Pod 时，你会看到 容器进入此状态的原因、退出代码以及容器执行期间的起止时间。如果容器配置了 preStop 回调，则该回调会在容器进入 Terminated 状态之前执行 可以使用以下方式查看容器状态 [root@k8s01 ~]# kubectl describe pod nginx Name: nginx ... Containers: nginx: ... State: Running ... # 或 [root@k8s01 ~]# kubectl get pods nginx -o yaml apiVersion: v1 ... status: ... containerStatuses: ... state: running: ... ","date":"2022-07-27","objectID":"/k8sPod/:4:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 容器的特权模式容器运行时必须支持特权容器的概念才能使用这一配置。 在 Linux 中，Pod 中的任何容器都可以使用容器规约中的 安全性上下文中的 privileged（Linux）参数启用特权模式。 这对于想要使用操作系统管理权能（Capabilities，如操纵网络堆栈和访问设备）的容器很有用。 如果你的集群启用了 WindowsHostProcessContainers 特性，你可以使用 Pod 规约中安全上下文的 windowsOptions.hostProcess 参数来创建 Windows HostProcess Pod。 这些 Pod 中的所有容器都必须以 Windows HostProcess 容器方式运行。 HostProcess Pod 可以直接运行在主机上，它也能像 Linux 特权容器一样，用于执行管理任务。 ","date":"2022-07-27","objectID":"/k8sPod/:5:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 基础容器由于容器原本是被名称空间与 cgroups 隔离的，基础容器是为了打破这个隔离。基础容器为 pod 内其它容器实现以下功能使容器间能够进行数据共享和通信： 在 pod 中担任 Linux 命名空间共享的基础 启用 pid 命名空间，开启 init 进程 目前在 k8s 中使用 pause 容器作为基础容器，它有以下特点： 镜像非常小，只有几百 k 永远处于 Pause (暂停) 状态 ","date":"2022-07-27","objectID":"/k8sPod/:6:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" init 容器init 容器是一种特殊容器，它在应用容器启动之前运行。init 容器可以包括一些应用镜像中不存在的实用工具和安装脚本。每个 pod 内可以有多个 init 容器 init 容器在 pod.spec.initContainers 中定义。除了以下几点，其它与普通容器没有区别： init 容器按顺序启动，每个 init 容器成功退出后才会启动下一个 init 容器。 由于当 pod 重启策略为 Always 时，init 容器启动失败使用 OnFailure 策略.因此 init 容器失败有以下可能性： 当 pod 重启策略为 Never 或 OnFailure时，kubelet 会不断地重启该 init 容器直到该容器成功为止，此外由于垃圾收集机制的原因，Init 容器的完成记录将会丢失。 当 pod 重启策略为 Never 时，k8s 会将整个 Pod 设置为失败状态。 由于 init 容器是在 pod 就绪之前运行完成，因此不支持容器探针 pod 重启，所有 Init 容器必须重新执行。 k8s:1.20 \u003e= 版本时，当 Init 容器的镜像发生改变或者 Init 容器的完成记录因为垃圾收集等原因被丢失时，Pod 不会被重启。 因为 Init 容器可能会被重启、重试或者重新执行，所以 Init 容器的代码应该是幂等的。 特别地，基于 emptyDirs 写文件的代码，应该对输出文件可能已经存在做好准备。 在 Pod 中的每个应用容器和 Init 容器的名称必须唯一； 与任何其它容器共享同一个名称，会在校验时抛出错误。 在所有 ini 容器没成功之前，Pod 将不会变成 Ready 状态。init 容器的端口将不会在 Service 中进行聚集。正在初始化中的 Pod 处于 Pending 状态， 但会将状况 Initializing 设置为 false。 在 Pod 上使用 activeDeadlineSeconds 和在容器上使用 livenessProbe 可以避免 Init 容器一直重复失败。 activeDeadlineSeconds 时间包含了 Init 容器启动的时间。 但建议仅在团队将其应用程序部署为 Job 时才使用 activeDeadlineSeconds， 因为 activeDeadlineSeconds 在 Init 容器结束后仍有效果。 如果你设置了 activeDeadlineSeconds，已经在正常运行的 Pod 会被杀死。 这是一个官方文档的示例，init 容器在 nginx 容器运行之前下载网站文件 apiVersion: v1 kind: Pod metadata: name: init-demo spec: containers: - name: nginx image: nginx ports: - containerPort: 80 volumeMounts: - name: workdir mountPath: /usr/share/nginx/html # 这些容器在 Pod 初始化期间运行 initContainers: - name: install image: busybox:1.28 command: - wget - \"-O\" - \"/work-dir/index.html\" - http://info.cern.ch volumeMounts: - name: workdir mountPath: \"/work-dir\" dnsPolicy: Default volumes: - name: workdir emptyDir: {} 创建 pod [root@k8s01 ~]# kubectl apply -f https://k8s.io/examples/pods/init-containers.yaml pod/init-demo created [root@k8s01 ~]# [root@k8s01 ~]# kubectl get pod init-demo NAME READY STATUS RESTARTS AGE init-demo 0/1 Init:0/1 0 11s [root@k8s01 ~]# [root@k8s01 ~]# kubectl get pod init-demo NAME READY STATUS RESTARTS AGE init-demo 0/1 PodInitializing 0 23s [root@k8s01 ~]# [root@k8s01 ~]# kubectl get pod init-demo NAME READY STATUS RESTARTS AGE init-demo 1/1 Running 0 116s ","date":"2022-07-27","objectID":"/k8sPod/:7:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" init 容器状态以 Init: 开头的 Pod 状态汇总了 Init 容器执行的状态： Init:N/M: pod 中有 M 个 Init 容器，其中 N 个已经运行完成。 Init:Error: Init 容器已执行失败。 Init:CrashLoopBackOf: init 容器执行总是失败 Pending: pod 还没有开始执行 init 容器 PodInitializing: pod 已经完成执行 init 容器 Running: pod 已经完成执行 init 容器 ","date":"2022-07-27","objectID":"/k8sPod/:7:1","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 临时容器特性状态： Kubernetes v1.23 [beta] 临时容器是一种特殊的容器，该容器在现有 Pod 中临时运行，以便完成用户发起的操作，例如故障排查。与其他容器的不同之处在于，它们缺少对资源或执行的保证，并且永远不会自动重启， 因此不适用于构建应用程序。 临时容器使用与常规容器相同的 ContainerSpec 节来描述，但许多字段是不兼容和不允许的。具体查看：临时容器参考文档 当由于容器崩溃或容器镜像不包含调试程序而导致 kubectl exec 无法运行时，临时容器对于排除交互式故障很有用。 与常规容器一样，将临时容器添加到 Pod 后，将不能更改或删除临时容器。但 临时容器是使用 API 中的一种特殊的 ephemeralcontainers 处理器进行创建的， 而不是直接添加到 pod.spec 段，因此无法使用 kubectl edit 来添加一个临时容器。当由于容器崩溃或容器镜像不包含调试工具而导致 kubectl exec 无用时， 临时容器对于交互式故障排查很有用。 使用临时容器时，启用 进程名字空间共享 很有帮助，可以查看其他容器中的进程 添加临时容器是使用 kubectl debug 命令，下面是一个示例 # --image 指定临时容器镜像 # --it 是指定交互式 TTY 终端，会自动挂接到临时容器的控制台 # --target 指定进程名称空间，由于创建 `pod` 时不会共享进程命名空间 # 因此这选项通常是必须的。该选项必须要 容器运行时支持 --target 参数才行 kubectl debug -it ephemeral-demo --image=busybox:1.28 --target=ephemeral-demo 生命周期Pod 遵循一个预定义的生命周期：Pending-\u003eRunning-\u003eSucceeded或Failed或Unknown。这些状态记录在pod.status.phase字段中 Pending(悬决): Pod 已被 Kubernetes 系统接受，但有一个或者多个容器尚未创建亦未运行。此阶段包括等待 Pod 被调度的时间和通过网络下载镜像的时间。 Running(运行中): Pod 已经绑定到了某个节点，Pod 中所有的容器都已被创建。至少有一个容器仍在运行，或者正处于启动或重启状态 Succeeded(成功): Pod 中的所有容器都已成功终止，并且不会再重启。 Failed(失败): Pod 中的所有容器都已终止，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。此外，如果某节点死掉或者与集群中其他节点失联，Kubernetes 会实施一种策略，将失去的节点上运行的所有 Pod 的 phase 设置为 Failed Unknown(未知): 为某些原因无法取得 Pod 的状态。这种情况通常是因为与 Pod 所在主机通信失败。 可以使用以下方式查看pod状态 [root@k8s01 ~]# kubectl describe pod nginx Name: nginx ... Status: Running ... # 或 [root@k8s01 ~]# kubectl get pods nginx -o yaml ... status: ... phase: Running pod重启策略pod.spec.restartPolicy字段定义了pod重启策略，有以下值： Always: 默认值，容器失效时重启 OnFailure: 容器异常退出时重启（退出状态码不为 0 ） Never: 不管容器什么情况，都不重启 Pod 重启策略适用于 Pod 中所有容器，由 Pod 所在节点的 Kubelet 重启容器。重启时间上限为五分钟的指数延迟（10秒，20秒，40秒…）启动，并在成功执行十分钟后重置。通常一个 Pod 绑定到某个节点，将不会调度到其他节点 pod状况pod.status.conditions数组记录了pod状况，有以下字段值： lastProbeTime: 上次探测 Pod 状况时的时间戳 lastTransitionTime: Pod 上次从一种状态转换到另一种状态时的时间戳 status: 表明该状况是否适用，可能的取值有 “True”, “False” 或 “Unknown” type: 状况类型，有以下值： PodScheduled：Pod 是否已经被调度到某节点 ContainersReady：Pod 中所有容器都是否已就绪 Initialized: 所有的 Init 容器是否都已成功完成 Ready: Pod 是否可以为请求提供服务，并且应该被添加到对应服务的负载均衡池中 reason: 表述上次状况变化的原因（驼峰编码） message: 上次状态转换的详细信息（人类可读方式） ","date":"2022-07-27","objectID":"/k8sPod/:8:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" pod就绪态特性状态： Kubernetes v1.14 [stable] 你的应用可以向 PodStatus 中注入额外的反馈或者信号：Pod Readiness（Pod 就绪态）。 要使用这一特性，可以设置 Pod 规约中的 readinessGates 列表，为 kubelet 提供一组额外的状况供其评估 Pod 就绪态时使用。 就绪态门控基于 Pod 的 status.conditions 字段的当前值来做决定。 如果 Kubernetes 无法在 status.conditions 字段中找到某状况，则该状况的 状态值默认为 “False”。 你所添加的 Pod 状况名称必须满足 Kubernetes 标签键名格式。 示例： kind: Pod ... spec: readinessGates: - conditionType: \"www.example.com/feature-1\" status: conditions: - type: Ready # 内置的 Pod 状况 status: \"False\" lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z - type: \"www.example.com/feature-1\" # 额外的 Pod 状况 status: \"False\" lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z containerStatuses: - containerID: docker://abcd... ready: true ... 命令 kubectl patch 不支持修改对象的状态。 如果需要设置 Pod 的 status.conditions，应用或者 Operators 需要使用 PATCH 操作。对于使用定制状况的 Pod 而言，只有当下面的陈述都适用时，该 Pod 才会被评估为就绪： Pod 中所有容器都已就绪； spec.readinessGates 中的所有状况都为 True 值。 当 Pod 的容器都已就绪，但至少一个定制状况没有取值或者取值为 False， kubelet 将 Pod 的状况设置为 ContainersReady pod终止由于 Pod 所代表的是在集群中节点上运行的进程，当不再需要这些进程时允许其体面地 终止是很重要的。一般不应武断地使用 KILL 信号终止它们，导致这些进程没有机会 完成清理操作。 设计的目标是令你能够请求删除进程，并且知道进程何时被终止，同时也能够确保删除 操作终将完成。当你请求删除某个 Pod 时，集群会记录并跟踪 Pod 的体面终止周期， 而不是直接强制地杀死 Pod。在存在强制关闭设施的前提下， kubelet 会尝试体面地终止 Pod。 通常情况下，容器运行时会发送一个 TERM 信号到每个容器中的主进程。 很多容器运行时都能够注意到容器镜像中 STOPSIGNAL 的值，并发送该信号而不是 TERM。 一旦超出了体面终止限期，容器运行时会向所有剩余进程发送 KILL 信号，之后 Pod 就会被从 API 服务器 上移除。如果 kubelet 或者容器运行时的管理服务在等待进程终止期间被重启， 集群会从头开始重试，赋予 Pod 完整的体面终止限期。 体面终止流程： 使用 kubectl 工具手动删除某个特定的 Pod，而该 Pod 的体面终止限期是默认值（30 秒） API 服务器中的 Pod 对象被更新，记录涵盖体面终止限期在内 Pod 的最终死期，超出所计算时间点则认为 Pod 已死（dead）。 如果你使用 kubectl describe 来查验你正在删除的 Pod，该 Pod 会显示为 “Terminating” （正在终止）。 在 Pod 运行所在的节点上：kubelet 一旦看到 Pod 被标记为正在终止（已经设置了体面终止限期），kubelet 即开始本地的 Pod 关闭过程： 如果 Pod 中的容器之一定义了 preStop 回调， kubelet 开始在容器内运行该回调逻辑。如果超出体面终止限期时，preStop 回调逻辑 仍在运行，kubelet 会请求给予该 Pod 的宽限期一次性增加 2 秒钟 如果 preStop 回调所需要的时间长于默认的体面终止限期，你必须修改 terminationGracePeriodSeconds 属性值来使其正常工作 kubelet 接下来触发容器运行时发送 TERM 信号给每个容器中的进程 1。od 中的容器会在不同时刻收到 TERM 信号，接收顺序也是不确定的。 如果关闭的顺序很重要，可以考虑使用 preStop 回调逻辑来协调。 与此同时，kubelet 启动体面关闭逻辑，控制面会将 Pod 从对应的端点列表（以及端点切片列表， 如果启用了的话）中移除，过滤条件是 Pod 被对应的 服务以某 选择算符选定。 ReplicaSets和其他工作负载资源 不再将关闭进程中的 Pod 视为合法的、能够提供服务的副本。关闭动作很慢的 Pod 也无法继续处理请求数据，因为负载均衡器（例如服务代理）已经在终止宽限期开始的时候 将其从端点列表中移除。 超出终止宽限期限时，kubelet 会触发强制关闭过程。容器运行时会向 Pod 中所有容器内 仍在运行的进程发送 SIGKILL 信号。 kubelet 也会清理隐藏的 pause 容器，如果容器运行时使用了这种容器的话 kubelet 触发强制从 API 服务器上删除 Pod 对象的逻辑，并将体面终止限期设置为 0 （这意味着马上删除） API 服务器删除 Pod 的 API 对象，从任何客户端都无法再看到该对象 ","date":"2022-07-27","objectID":"/k8sPod/:9:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 强制终止pod于某些工作负载及其 Pod 而言，强制删除很可能会带来某种破坏。 默认情况下，所有的删除操作都会附有 30 秒钟的宽限期限。kubectl delete -grace-period=\u003cseconds\u003e 选项，允许你重载默认值， 设定自己希望的期限值。 将宽限期限强制设置为 0 且使用--force 参数 意味着立即从 API 服务器删除 Pod。 如果 Pod 仍然运行于某节点上，强制删除操作会触发 kubelet 立即执行清理操作。 执行强制删除操作时，API 服务器不再等待来自 kubelet 的、关于 Pod 已经在原来运行的节点上终止执行的确认消息。 API 服务器直接删除 Pod 对象，这样新的与之同名的 Pod 即可以被创建。 在节点侧，被设置为立即终止的 Pod 仍然会在被强行杀死之前获得一点点的宽限时间。 pod垃圾收集对于已失败的 Pod 而言，对应的 API 对象仍然会保留在集群的 API 服务器上，直到 用户或者控制器进程显式地 将其删除。 控制面组件会在 Pod 个数超出所配置的阈值 （根据 kube-controller-manager 的 terminated-pod-gc-threshold 设置）时 删除已终止的 Pod（阶段值为 Succeeded 或 Failed）。 这一行为会避免随着时间演进不断创建和终止 Pod 而引起的资源泄露问题。 Downward APIDownward API 允许容器在不使用 Kubernetes 客户端或 API 服务器的情况下获得自己或集群的信息。在 Kubernetes 中，有两种方法可以将 Pod 和容器字段暴露给运行中的容器（这两种暴露 Pod 和容器字段的方式统称为 Downward API）： 作为环境变量 作为 downwardAPI 卷中的文件 字段 含义 提供方式 fieldRef.fieldPath: metadata.name pod 名称 环境变量或 downwardAPI 卷 fieldRef.fieldPath: metadata.namespace pod 名称空间 环境变量或 downwardAPI 卷 fieldRef.fieldPath: metadata.uid pod ID 环境变量或 downwardAPI 卷 fieldRef.fieldPath: metadata.annotations['\u003cKEY\u003e'] pod 注解 \u003cKEY\u003e 的值 环境变量或 downwardAPI 卷 fieldRef.fieldPath: metadata.labels['\u003cKEY\u003e'] pod 标签 \u003cKEY\u003e 的值 环境变量或 downwardAPI 卷 fieldRef.fieldPath: spec.serviceAccountName pod 务账号名称 环境变量或 downwardAPI 卷 fieldRef.fieldPath: spec.nodeName pod 所在节点名称 环境变量或 downwardAPI 卷 fieldRef.fieldPath: status.hostIP pod 所在节点主 IP 环境变量或 downwardAPI 卷 fieldRef.fieldPath: status.podIP pod IP 环境变量或 downwardAPI 卷 resourceFieldRef.resource: limits.cpu 容器 cpu 限制值 环境变量或 downwardAPI 卷 resourceFieldRef.resource: limits.memory 容器内存限制值 环境变量或 downwardAPI 卷 resourceFieldRef.resource: requests.cpu 容器 cpu 请示值 环境变量或 downwardAPI 卷 resourceFieldRef.resource: requests.memory 容器内存请示值 环境变量或 downwardAPI 卷 resourceFieldRef.resource: limits.hugepages-* 容器大内存页限制值 环境变量或 downwardAPI 卷 resourceFieldRef.resource: requests.hugepages-* 容器大内存页请求值 环境变量或 downwardAPI 卷 resourceFieldRef.resource: limits.ephemeral-storage 容器临时存储限制值 环境变量或 downwardAPI 卷 resourceFieldRef.resource: requests.ephemeral-storage 容器临时存储请求值 环境变量或 downwardAPI 卷 fieldRef.fieldPath: metadata.labels pod 所有标签，格式为标签键名=\"转义后的标签值\"，每行一个标签 只能用于 downwardAPI 卷 fieldRef.fieldPath: metadata.annotations pod 所有注解，格式为注解键名=\"转义后的注解值\"，每行一个注解 只能用于 downwardAPI 卷 ","date":"2022-07-27","objectID":"/k8sPod/:10:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 通过环境变量将 Pod 信息呈现给容器示例 apiVersion: v1 kind: Pod metadata: name: dapi-envars-fieldref spec: containers: - name: test-container image: k8s.gcr.io/busybox command: [ \"sh\", \"-c\"] args: - while true; do echo -en '\\n'; printenv MY_NODE_NAME MY_POD_NAME MY_POD_NAMESPACE; printenv MY_POD_IP MY_POD_SERVICE_ACCOUNT; printenv MY_CPU_REQUEST MY_CPU_LIMIT; printenv MY_MEM_REQUEST MY_MEM_LIMIT; sleep 10; done; env: - name: MY_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: MY_POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: MY_POD_IP valueFrom: fieldRef: fieldPath: status.podIP - name: MY_POD_SERVICE_ACCOUNT valueFrom: fieldRef: fieldPath: spec.serviceAccountName - name: MY_CPU_REQUEST valueFrom: resourceFieldRef: containerName: test-container resource: requests.cpu - name: MY_CPU_LIMIT valueFrom: resourceFieldRef: containerName: test-container resource: limits.cpu - name: MY_MEM_REQUEST valueFrom: resourceFieldRef: containerName: test-container resource: requests.memory - name: MY_MEM_LIMIT valueFrom: resourceFieldRef: containerName: test-container resource: limits.memory restartPolicy: Never ","date":"2022-07-27","objectID":"/k8sPod/:11:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 通过文件将 Pod 信息呈现给容器示例 apiVersion: v1 kind: Pod metadata: name: kubernetes-downwardapi-volume-example-2 spec: containers: - name: client-container image: k8s.gcr.io/busybox:1.24 command: [\"sh\", \"-c\"] args: - while true; do echo -en '\\n'; if [[ -e /etc/podinfo/cpu_limit ]]; then echo -en '\\n'; cat /etc/podinfo/cpu_limit; fi; if [[ -e /etc/podinfo/cpu_request ]]; then echo -en '\\n'; cat /etc/podinfo/cpu_request; fi; if [[ -e /etc/podinfo/mem_limit ]]; then echo -en '\\n'; cat /etc/podinfo/mem_limit; fi; if [[ -e /etc/podinfo/mem_request ]]; then echo -en '\\n'; cat /etc/podinfo/mem_request; fi; sleep 5; done; resources: requests: memory: \"32Mi\" cpu: \"125m\" limits: memory: \"64Mi\" cpu: \"250m\" volumeMounts: - name: podinfo mountPath: /etc/podinfo volumes: - name: podinfo downwardAPI: items: - path: \"cpu_limit\" resourceFieldRef: containerName: client-container resource: limits.cpu divisor: 1m - path: \"cpu_request\" resourceFieldRef: containerName: client-container resource: requests.cpu divisor: 1m - path: \"mem_limit\" resourceFieldRef: containerName: client-container resource: limits.memory divisor: 1Mi - path: \"mem_request\" resourceFieldRef: containerName: client-container resource: requests.memory divisor: 1Mi 用户名称空间https://kubernetes.io/docs/concepts/workloads/pods/user-namespaces/#set-up-a-node-to-support-user-namespaces pod 与容器资源限制这里资源是指计算机资源，计算资源的数量是可测量的，可以被请求、被分配、被消耗。只能对容器指定请求资源与限制资源，它们的和就是 pod 请求与限制资源，但有 init 容器时，如果某个 init 容器请示与限制的资源与应用容器请求限制的资源总和还大，则使用 init 最大请求限制值 请求值表示 pod 启动时向系统请求分配的资源，限制值表示 pod 最大使用的资源。以下这些字段都是容器的资源请求与限制 spec.containers[].resources.limits.cpu: 容器限制 cpu 值 spec.containers[].resources.limits.memory: 容器请求内存值 spec.containers[].resources.limits.hugepages-\u003csize\u003e: spec.containers[].resources.requests.cpu: 容器限制 cpu 值 spec.containers[].resources.requests.memory: 容器限制内存 spec.containers[].resources.requests.hugepages-\u003csize\u003e: ","date":"2022-07-27","objectID":"/k8sPod/:12:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 限制 CPUk8s 中 cpu 单位只能使用绝对数量，1 表示1个cpu核心，0.5表示使用半个cpu核心。也可以使用 m (豪)单位 示例 apiVersion: v1 kind: Pod metadata: name: cpu-demo-2 namespace: cpu-example spec: containers: - name: cpu-demo-ctr-2 image: vish/stress resources: limits: cpu: \"100\" requests: cpu: \"100\" args: - -cpus - \"2 ","date":"2022-07-27","objectID":"/k8sPod/:13:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 限制内存内存单位是字节，但也可以使用这些单位：E、P、T、G、M、K、Ei、Pi、Ti、Gi、Mi、Ki 示例 apiVersion: v1 kind: Pod metadata: name: memory-demo namespace: mem-example spec: containers: - name: memory-demo-ctr image: polinux/stress resources: requests: memory: \"100Mi\" limits: memory: \"200Mi\" command: [\"stress\"] args: [\"--vm\", \"1\", \"--vm-bytes\", \"150M\", \"--vm-hang\", \"1\"] 静态pod静态 Pod 是在指定节点上由 kubelet 进程直接管理的 Pod。有以下特性： 静态 Pod 永远都会绑定到一个指定节点上的 kubelet kubelet 监视每个静态 Pod ，在崩溃之后重新启动 kubblet 会尝试通过 k8s API 服务为每个静态 Pod 自动创建一个镜像 Pod API 服务虽然能检测到节点上运行的静态 Pod ，但不能控制静态 Pod 静态 Pod 也拥有应用 Pod 字段，但Pod.spec 不能引用其他的 API 对象（例如： ServiceAccount、 ConfigMap、 Secret 等）。 kubelet 使用以下方式管理静态 pod 使用 kubelet --pod-manifest-path 命令指定或者在 kubelet 配置文件中增加 staticPodPath 字段指定一个目录。kubelet 会定期扫描该目录下的清单文件（不能以 . 开头）来创建或删除 Pod 使用 kubelet --manifest-url=\u003cURL\u003e 指定一个定期下载文档地址，该文件会转换为清单文件格式，当清单文件内容发生变化时，更新相应的 Pod [root@node01 ~]# grep manifest /var/lib/kubelet/config.yaml staticPodPath: /etc/kubernetes/manifests [root@node01 ~]# ls /etc/kubernetes/manifests etcd.yaml kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml kube-vip.yaml ","date":"2022-07-27","objectID":"/k8sPod/:14:0","tags":["k8s pod","k8s 容器","k8s 静态 pod"],"title":"k8s pod","uri":"/k8sPod/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内容来自以下文档： k8s官方文档：垃圾收集 垃圾收集垃圾收集是 Kubernetes 用于清理集群资源的各种机制的统称。 垃圾收集允许系统清理如下资源： 失败的 Pod 已完成的 Job 不再存在属主引用的对象 未使用的容器和容器镜像 动态制备的、StorageClass 回收策略为 Delete 的 PV 卷 阻滞或者过期的 CertificateSigningRequest (CSRs) 在以下情形中删除了的节点对象： 当集群使用云控制器管理器运行于云端时； 当集群使用类似于云控制器管理器的插件运行在本地环境中时。 节点租约对象 ","date":"2022-07-24","objectID":"/k8sGarbageCollection/:0:0","tags":["k8s","k8s 垃圾收集"],"title":"k8s 垃圾收集","uri":"/k8sGarbageCollection/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内容来自以下文档： k8s官方文档：控制器 k8s官方文档：Deployment k8s官方文档：StatefulSet k8s官方文档：DaemonSet k8s官方文档：Job k8s官方文档：CronJob 控制器在 Kubernetes 中，控制器通过监控集群 的公共状态，并致力于将当前状态转变为期望的状态 一个控制器至少追踪一种类型的 Kubernetes 资源。这些 对象 有一个代表期望状态的 spec 字段。 该资源的控制器负责确保其当前状态接近期望状态。 控制器可能会自行执行操作；在 Kubernetes 中更常见的是一个控制器会发送信息给 API 服务器 Kubernetes 内置一组控制器，运行在 kube-controller-manager 内。 这些内置的控制器提供了重要的核心功能。 内置控制器通过和集群 API 服务器交互来管理状态。 ReplicationController 控制器ReplicationController 确保在任何时候都有特定数量的 Pod 副本处于运行状态。 换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的。 ReplicaSet 控制器是 ReplicationController 的后继者。二者目的相同且行为类似，只是 ReplicationController 不支持 标签用户指南 中讨论的基于集合的选择算符需求。 因此，相比于 ReplicationController，应优先考虑 ReplicaSet ReplicaSet 控制器ReplicaSet 的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。 因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。 ReplicaSet 确保任何时间都有指定数量的 Pod 副本在运行。 然而，Deployment 是一个更高级的概念，它管理 ReplicaSet，并向 Pod 提供声明式的更新以及许多其他有用的功能。 因此，我们建议使用 Deployment 而不是直接使用 ReplicaSet， 除非你需要自定义更新业务流程或根本不需要更新。 Deployment 控制器一个 Deployment 为 Pod 和 ReplicaSet 提供声明式的更新能力。不要管理 Deployment 所拥有的 ReplicaSet 。 下面是编写 Deployment 的清单文件常见的字段 apiVersion: apps/v1 # API 组，必须字段 kind: Deployment # Deployment 资源类型，必须字段 metadata: # 属性 必须字段 name: nginx-deployment # 名称 必须字段 .spec # 必须字段 replicas: # 副本数量 selector: # 必须字段，选择算符，必须与 .spec.template.metadata.labels 匹配 template: # 必须字段，与 pod 语法相同只是这里它是嵌套的， # 因此不需要 apiVersion 或 kind spec: restartPolicy: Always # 该字段值必须为 Always 下面是一个 Deployment 示例。其中创建了一个 ReplicaSet，负责启动三个 nginx Pods： apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 .metadata.name字段标明Deployment资源名称 .spec.replicas字段标明pod数量 .spec.selector字段标明标签选择器 .spec.template字段标明pod信息 可以使用以下命令创建上述deployment资源 [root@k8s01 ~]# kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml deployment.apps/nginx-deployment created # 查看 deployment 资源 # READY: 就绪个数/期望个数 # UP-TO-DATE: 显示为了达到期望状态已经更新的副本数 # AVAILABLE: 显示应用可供用户使用的副本数 # AGE: 运行时间 [root@k8s01 ~]# kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 3/3 3 3 7s 查看 Deployment 创建的 ReplicaSet 资源 # DESIRED 显示应用的期望副本个数 # CURRENT 显示当前运行状态中的副本个数 # READY 显示应用中有多少副本可以为用户提供服务 # AGE 显示应用已经运行的时间长度 # NAME: Deployment 创建的 ReplicaSet 名称始终被格式化为[Deployment名称]-[随机字符串]。 # 其中的随机字符串是使用 pod-template-hash 作为种子随机生成的 [root@k8s01 ~]# kubectl get ReplicaSet NAME DESIRED CURRENT READY AGE nginx-deployment-6595874d85 3 3 3 3m10s 查看 Deployment 创建的 pod 资源 [root@k8s01 ~]# kubectl get pods -l app=nginx NAME READY STATUS RESTARTS AGE nginx-deployment-6595874d85-ds649 1/1 Running 0 9m38s nginx-deployment-6595874d85-mvwxm 1/1 Running 0 9m38s nginx-deployment-6595874d85-qd4n7 1/1 Running 0 9m38s ","date":"2022-07-24","objectID":"/k8sController/:0:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" 更新与回滚使用yaml文件更新 [root@k8s01 ~]# cat nginx-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 4 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.16.1 ports: - containerPort: 80 [root@k8s01 ~]# kubectl apply -f nginx-deployment.yaml deployment.apps/nginx-deployment configured 临时更新可以使用kubectl set或kubectl edit命令 kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1 kubectl edit deployment/nginx-deployment 查看已更新的deployment [root@k8s01 ~]# kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 4/4 4 4 18m [root@k8s01 ~]# kubectl get pod | grep nginx-deployment nginx-deployment-66b957f9d-7wjk8 1/1 Running 0 24m nginx-deployment-66b957f9d-hlckg 1/1 Running 0 24m nginx-deployment-66b957f9d-p85qh 1/1 Running 0 23m nginx-deployment-66b957f9d-qpcfs 1/1 Running 0 24m 旧的ReplicaSet资源并不会删除，会保留下来，方便后续回滚 [root@k8s01 ~]# kubectl get ReplicaSet | grep nginx-deployment nginx-deployment-57c47d7f59 0 0 0 26m nginx-deployment-6595874d85 0 0 0 41m nginx-deployment-66b957f9d 4 4 4 23m 可以使用kubectl rollout history命令可以查看更新历史 [root@k8s01 ~]# kubectl rollout history deployment/nginx-deployment deployment.apps/nginx-deployment REVISION CHANGE-CAUSE 1 \u003cnone\u003e 2 \u003cnone\u003e 3 \u003cnone\u003e CHANGE-CAUSE 的内容是从.metadata.annotations.kubernetes.io/change-cause 注解字段复制过来的。也可以使用kubectl annotate命令添加 [root@k8s01 ~]# kubectl annotate deployment/nginx-deployment kubernetes.io/change-cause=\"image updated to 1.16.1\" deployment.apps/nginx-deployment annotated [root@k8s01 ~]# kubectl rollout history deployment/nginx-deployment deployment.apps/nginx-deployment REVISION CHANGE-CAUSE 1 \u003cnone\u003e 2 \u003cnone\u003e 3 image updated to 1.16.1 kubectl rollout undo用于回滚到之前的版本 # --to-revision 指定回滚的版本，缺省为上一个版本 [root@k8s01 ~]# kubectl rollout undo deployment/nginx-deployment --to-revision=1 deployment.apps/nginx-deployment rolled back ","date":"2022-07-24","objectID":"/k8sController/:1:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" Deployment 状态Deployment 的生命周期中会有许多状态。上线新的 ReplicaSet 期间可能处于 Progressing（进行中），可能是 Complete（已完成），也可能是 Failed（失败）以至于无法继续进行。 在执行下面的任务期间，Kubernetes 标记 Deployment 为 Progressing（进行中）状态： Deployment 创建新的 ReplicaSet Deployment 正在为其最新的 ReplicaSet 扩容 Deployment 正在为其旧有的 ReplicaSet) 缩容 新的 Pods 已经就绪或者可用（就绪至少持续了 MinReadySeconds 秒）。MinReadySeconds 表示最短就绪时间 处于进行中状态时，Deployment 控制器会向 Deployment 的 .status.conditions 中添加以下字段： type: Progressing status: \"True\" reason: 该字段有这些取值：NewReplicaSetCreated、FoundNewReplicaSet、ReplicaSetUpdated 当 Deployment 具有以下特征时，Kubernetes 将其标记为完成（Complete） 与 Deployment 关联的所有副本都已更新到指定的最新版本，这意味着之前请求的所有更新都已完成。 与 Deployment 关联的所有副本都可用。 未运行 Deployment 的旧副本。 处于已完状态时，Deployment 控制器会向 Deployment 的 .status.conditions 中添加以下字段： type: Progressing status: \"True\" reason: NewReplicaSetAvailable kubectl rollout status 查看deployment状态时，如果是完成状态中，该状态为0 [root@k8s01 ~]# kubectl rollout status deployment/nginx-deployment deployment \"nginx-deployment\" successfully rolled out [root@k8s01 ~]# echo $? 0 造成 Deployment 失败可能有以下原因： 资源配额不足 就绪探测失败 镜像拉取错误 权限不足 限制范围问题 容器内应用程序运行失败 处于失败状态时，Deployment 控制器会向 Deployment 的 .status.conditions 中添加以下字段： Type=Progressing Status=False Reason=ProgressDeadlineExceeded ","date":"2022-07-24","objectID":"/k8sController/:2:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" 标签选择器.spec.selector 是指定本 Deployment 管理的 Pod 标签选择算符的必需字段。该字段必须匹配 .spec.template.metadata.labels ，否则请求会被 API 拒绝。这是因为控制器通过标签管理匹配的 pod 。如果创建的 pod 或其它控制器创建的 pod 的标签与 Deployment 控制器管理的标签匹配，k8s 会认为该 pod 由它管理。当多个控制器的选择算符发生重叠，则控制器之间会因冲突而无法正常工作。 在 apps/v1版本中，.spec.selector 和 .metadata.labels 如果没有设置的话， 不会被默认设置为 .spec.template.metadata.labels，所以需要明确进行设置。 同时在 apps/v1版本中，Deployment 创建后 .spec.selector 是不可变的。 ","date":"2022-07-24","objectID":"/k8sController/:3:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" pod 替换策略.spec.strategy.type 字段指定用于用新 Pod 替换旧 Pod 的策略，有以下值： Recreate: 在创建新 Pod 之前，所有现有的 Pod 会被杀死。 RollingUpdate: 滚动更新，先扩展再缩减的方式，默认值 Recreate 策略会确保为了升级而创建新 Pod 之前其他 Pod 都已终止。 所有旧版本的 Pod 都会立即被终止。控制器等待这些 Pod 被成功移除之后， 才会创建新版本的 Pod。如果你手动删除一个 Pod，其生命周期是由 ReplicaSet 来控制的， 后者会立即创建一个替换 Pod（即使旧的 Pod 仍然处于 Terminating 状态）。 RollingUpdate策略会先缩减再扩容，重复过程直到满足数量。受 .spec.strategy.rollingUpdate.maxUnavailable 和 .spec.strategy.rollingUpdate.maxSurge 字段影响。 .spec.strategy.rollingUpdate.maxSurge：是一个可选字段，用来指定可以创建数量（新旧 pod 总数）。值为大于0的正整数或百分百比（会转换为绝对值）。默认值为 25% .spec.strategy.rollingUpdate.maxUnavailable: 是一个可选字段，用来指定 更新过程中不可用的 Pod 的个数上限。值为大于0的正整数或百分百比（会转换为绝对值）。默认值为 25% ","date":"2022-07-24","objectID":"/k8sController/:4:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" 失败超时时间.spec.progressDeadlineSeconds 是一个可选字段，如果指定，则此字段值需要大于 .spec.minReadySeconds 取值。该字段用于指定系统在报告 Deployment 进展失败 之前等待 Deployment 取得进展的秒数。Deployment 控制器将持续重试 Deployment。 这类报告会在资源状态中体现为： type: Progressing status: False reason: ProgressDeadlineExceeded 将来，一旦实现了自动回滚，Deployment 控制器将在探测到这样的条件时立即回滚 Deployment。 ","date":"2022-07-24","objectID":"/k8sController/:5:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" 最短就绪时间.spec.minReadySeconds 是一个可选字段，用于指定新创建的 Pod 在没有任意容器崩溃情况下的最小就绪时间， 只有超出这个时间 Pod 才被视为可用。默认值为 0（Pod 在准备就绪后立即将被视为可用）。 ","date":"2022-07-24","objectID":"/k8sController/:6:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" 历史版本数量.spec.revisionHistoryLimit 是一个可选字段，用来设定出于会滚目的所要保留的旧 ReplicaSet 数量。 这些旧 ReplicaSet 会消耗 etcd 中的资源，Deployment 的修订历史记录存储在它所控制的 ReplicaSets 中。因此，一旦删除了旧的 ReplicaSet, 或值为0时将失去回滚到 Deployment 的对应修订版本的能力。 默认情况下，系统保留 10 个旧 ReplicaSet StatefulSet 控制器StatefulSet 是用来管理有状态应用的工作负载 API 对象。用来管理某 pod 集合的部署、扩容、缩减，并为这些 pod 提供持久存储和持久标识符： 稳定的、唯一的网络标识符 稳定的、持久的存储 有序的部署与扩容、缩减 StatefulSet 有以下限制： 为了保证数据安全，删除 pod 时不会删除相关存储卷。 需要手动创建无头服务（Headless Services）负责 pod 网络标识 删除一个 StatefulSet 控制器时，不提供任何终止 pod 的保证。可以在删除之前缩容到 0 实现 滚动更新时出现错误可能要人工参与修复（不会回滚） 如果应用程序不需要任何稳定的标识符或有序的部署、删除或扩缩， 则应该使用由一组无状态的副本控制器（如：Deployment）提供的工作负载来部署应用程序 DaemonSet 控制器DaemonSet 确保全部（或者某些）节点上运行一个 Pod 的副本。 当有节点加入集群时， 也会为他们新增一个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。 ","date":"2022-07-24","objectID":"/k8sController/:7:0","tags":["k8s","k8s 控制器"],"title":"k8s控制器","uri":"/k8sController/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内容来自以下文档： 节点与控制面之间的通信 节点到控制面Kubernetes 采用的是中心辐射型（Hub-and-Spoke）API 模式。 所有从节点（或运行于其上的 Pod）发出的 API 调用都终止于 API 服务器。 其它控制面组件都没有被设计为可暴露远程服务。 API 服务器被配置为在一个安全的 HTTPS 端口（通常为 443）上监听远程连接请求， 并启用一种或多种形式的客户端身份认证机制。 一种或多种客户端鉴权机制应该被启用， 特别是在允许使用匿名请求 或服务账户令牌的时候。 应该使用集群的公共根证书开通节点，这样它们就能够基于有效的客户端凭据安全地连接 API 服务器。 一种好的方法是以客户端证书的形式将客户端凭据提供给 kubelet。 想要连接到 API 服务器的 Pod 可以使用服务账号安全地进行连接。 当 Pod 被实例化时，Kubernetes 自动把公共根证书和一个有效的持有者令牌注入到 Pod 里。 kubernetes 服务（位于 default 名字空间中）配置了一个虚拟 IP 地址， 用于（通过 kube-proxy）转发请求到 API 服务器的 HTTPS 末端。 控制面组件也通过安全端口与集群的 API 服务器通信。 这样，从集群节点和节点上运行的 Pod 到控制面的连接的缺省操作模式即是安全的， 能够在不可信的网络或公网上运行。 控制面到节点从控制面（API 服务器）到节点有两种主要的通信路径。 第一种是从 API 服务器到集群中每个节点上运行的 kubelet 进程。 第二种是从 API 服务器通过它的代理功能连接到任何节点、Pod 或者服务。 从 API 服务器到 kubelet 的连接用于： 获取 Pod 日志 挂接（通过 kubectl）到运行中的 Pod 提供 kubelet 的端口转发功能。 这些连接终止于 kubelet 的 HTTPS 末端。 默认情况下，API 服务器不检查 kubelet 的服务证书。这使得此类连接容易受到中间人攻击， 在非受信网络或公开网络上运行也是 不安全的。为了对这个连接进行认证，使用 –kubelet-certificate-authority 标志给 API 服务器提供一个根证书包，用于 kubelet 的服务证书。 如果无法实现这点，又要求避免在非受信网络或公共网络上进行连接，可在 API 服务器和 kubelet 之间使用 SSH 隧道。最后，应该启用 kubelet 用户认证和/或鉴权 来保护 kubelet API 从 API 服务器到节点、Pod 或服务的连接默认为纯 HTTP 方式，因此既没有认证，也没有加密。 这些连接可通过给 API URL 中的节点、Pod 或服务名称添加前缀 https: 来运行在安全的 HTTPS 连接上。 不过这些连接既不会验证 HTTPS 末端提供的证书，也不会提供客户端证书。 因此，虽然连接是加密的，仍无法提供任何完整性保证。 这些连接 目前还不能安全地 在非受信网络或公共网络上运行 ","date":"2022-07-24","objectID":"/k8s%E9%9B%86%E7%BE%A4%E4%B8%8EAPI%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/:0:0","tags":["k8s"],"title":"k8s集群与API服务通信","uri":"/k8s%E9%9B%86%E7%BE%A4%E4%B8%8EAPI%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内容来自以下文档： k8s官方文档：节点 k8s官方文档：node k8s官方文档：lease k8s官方文档：安全地清空一个节点 节点（node）Kubernetes 通过将容器放入在节点（Node）上运行的 Pod 中来执行你的工作负载。 节点可以是一个虚拟机或者物理机器，取决于所在的集群配置。 每个节点包含运行 Pods 所需的服务； 这些节点由 控制平面 负责管理。 节点上的组件包括： kubelet 容器管理工具 kube-proxy 节点管理向 API 服务器添加节点的方式主要有两种： kubeelet向控制平面执行自注册 手动添加 node 对象 手动添加节点 { \"kind\": \"Node\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"10.240.79.157\", \"labels\": { \"name\": \"my-first-k8s-node\" } } } Kubernetes 会在内部创建一个 Node 对象作为节点的表示。Kubernetes 检查 kubelet 向 API 服务器注册节点时使用的 metadata.name 字段是否匹配。 如果节点是健康的（即所有必要的服务都在运行中），则该节点可以用来运行 Pod。 否则，直到该节点变为健康之前，所有的集群活动都会忽略该节点。Kubernetes 会一直保存着非法节点对应的对象，并持续检查该节点是否已经变得健康。 或控制器必须显式地删除该 Node 对象以停止健康检查操作。 ","date":"2022-07-24","objectID":"/k8sNode/:0:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 节点名称唯一性Node 对象的名称必须是合法的 DNS 子域名。节点的名称用来标识 Node 对象，具有唯一性 。 Kubernetes 还假定名字相同的资源是同一个对象。 就 Node 而言，隐式假定使用相同名称的实例会具有相同的状态（例如网络配置、根磁盘内容） 和类似节点标签这类属性。这可能在节点被更改但其名称未变时导致系统状态不一致。 如果某个 Node 需要被替换或者大量变更，需要从 API 服务器移除现有的 Node 对象， 之后再在更新之后重新将其加入。 ","date":"2022-07-24","objectID":"/k8sNode/:1:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 节点自注册当 kubelet 标志 --register-node 为 true（默认）时，它会尝试向 API 服务注册自己。。会使用下列参数启动： --kubeconfig: 用于向 API 服务器执行身份认证所用的凭据的路径 --cloud-provider: 与某云驱动 进行通信以读取与自身相关的元数据的方式 --register-node: 自动向 API 服务注册 --register-with-taints: 使用所给的污点列表 --node-ip: 节点 IP 地址 --node-labels: 在集群中注册节点时要添加的标签 --node-status-update-frequency: 指定 kubelet 向控制面发送状态的频率 启用Node 鉴权模式和 NodeRestriction 准入插件时， 仅授权 kubelet 创建或修改其自己的节点资源。 ","date":"2022-07-24","objectID":"/k8sNode/:2:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 手动节点管理你可以使用 kubectl 来创建和修改 Node 对象。被 DaemonSet 控制器创建的 Pod 能够容忍节点的不可调度属性。 DaemonSet 通常提供节点本地的服务，即使节点上的负载应用已经被腾空， 这些服务也仍需运行在节点之上。 节点状态使用以下方式查看节点信息 kubectl describe node \u003c节点名称\u003e ","date":"2022-07-24","objectID":"/k8sNode/:3:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" Addresses部分 [root@node1 ~]# kubectl describe node node1 ... Addresses: InternalIP: 192.168.64.132 Hostname: node1.localdomain ... Addresses部分取决于你的云服务商或者物理机配置： HostName: 由节点的内核报告。可以通过 kubelet --hostname-override 参数覆盖 InternalIP: 通常是节点的仅可在集群内部路由的 IP 地址 ExternalIP: 通常是节点的可外部路由（从集群外可访问）的 IP 地址 ","date":"2022-07-24","objectID":"/k8sNode/:4:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" conditions部分 [root@node1 ~]# kubectl describe node node1 ... Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- NetworkUnavailable False Sun, 24 Jul 2022 12:28:52 +0800 Sun, 24 Jul 2022 12:28:52 +0800 CalicoIsUp Calico is running on this node MemoryPressure False Sun, 24 Jul 2022 14:50:48 +0800 Sun, 24 Jul 2022 05:28:45 +0800 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Sun, 24 Jul 2022 14:50:48 +0800 Sun, 24 Jul 2022 05:28:45 +0800 KubeletHasNoDiskPressure kubelet has no disk pressure PIDPressure False Sun, 24 Jul 2022 14:50:48 +0800 Sun, 24 Jul 2022 05:28:45 +0800 KubeletHasSufficientPID kubelet has sufficient PID available Ready True Sun, 24 Jul 2022 14:50:48 +0800 Sun, 24 Jul 2022 05:33:03 +0800 KubeletReady kubelet is posting ready status ... conditions字段描述了所有运行节点的状况。状况的示例包括： Ready: 有以下值： True: 节点是健康的并已经准备好接收Pod False: 表示节点不健康而且不能接收Pod Unknown: 超时状态，节点控制器在最近node-monitor-grace-period期间 （默认 40 秒）没有收到节点的消息。 DiskPressure: 磁盘可用量低是否过低 MemoryPressure: 内存内存可用量过低 PIDPressure: 节点上进程是否过多 NetworkUnavailabl: 网络配置是否不正确(True表示不正确) SchedulingDisabled: 不可被调度 ","date":"2022-07-24","objectID":"/k8sNode/:5:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 容量（Capacity）与可分配（Allocatable）部分 [root@node1 ~]# kubectl describe node node1 ... Capacity: cpu: 4 ephemeral-storage: 17394Mi hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 3798864Ki pods: 110 Allocatable: cpu: 4 ephemeral-storage: 16415037823 hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 3696464Ki pods: 110 capacity 块中的字段标示节点拥有的资源总量。 allocatable 块指示节点上可供普通 Pod 消耗的资源量。 ","date":"2022-07-24","objectID":"/k8sNode/:6:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 系统信息 [root@node1 ~]# kubectl describe node node1 ... System Info: Machine ID: 1604675af82446cdad4ea11adbae9b50 System UUID: d5064d56-792f-fe2e-666e-a2d1c4a140a1 Boot ID: 1a0f8bf1-b82c-454d-a804-1eb9b242da34 Kernel Version: 4.18.0-348.el8.0.2.x86_64 OS Image: Rocky Linux 8.5 (Green Obsidian) Operating System: linux Architecture: amd64 Container Runtime Version: containerd://1.6.2 Kubelet Version: v1.24.3 Kube-Proxy Version: v1.24.3 ... Info 指的是节点的一般信息，如内核版本、Kubernetes 版本等 心跳检测Kubernetes 节点发送的心跳帮助你的集群确定每个节点的可用性，并在检测到故障时采取行动。对于节点，有两种形式的心跳: 更新节点的 .status kube-node-lease名称空间中的Lease对象。 使用Lease来表达心跳在大型集群中可以减少这些更新对性能的影响 kubelet 负责创建和更新节点的 .status，以及更新它们对应的 Lease 当节点状态发生变化时，或者在配置的时间间隔内没有更新事件时，kubelet 会更新 .status。 更新的默认间隔为 5 分钟（比节点不可达事件的 40 秒默认超时时间长很多） kubelet 会创建并每 10 秒（默认更新间隔时间）更新 Lease 对象。 Lease 的更新独立于 Node 的 .status 更新而发生。 如果 Lease 的更新操作失败，kubelet 会采用指数回退机制，从 200 毫秒开始重试， 最长重试间隔为 7 秒钟。 节点控制器节点控制器在节点的生命周期中扮演多个角色，管理节点的方方面面。 当节点注册时为它分配一个 CIDR 区段（如果启用了 CIDR 分配） 保持节点控制器内的节点列表与云服务商所提供的可用机器列表同步。 如果在云环境下运行，只要某节点不健康，节点控制器就会询问云服务是否节点的虚拟机仍可用。 如果不可用，节点控制器会将该节点从它的节点列表删除。 监控节点的健康状况。节点控制器负责： 在节点不可达的情况下，在 Node 的 .status 中更新 Ready 状况。 在这种情况下，节点控制器将 NodeReady 状况更新为 Unknown 如果节点仍然无法访问：对于不可达节点上的所有 Pod 触发 API 发起的逐出操作。 默认情况下，节点控制器在将节点标记为 Unknown 后等待 5 分钟提交第一个驱逐请求。 默认情况下，节点控制器每 5 秒检查一次节点状态，可以使用 kube-controller-manager 组件上的 --node-monitor-period 参数来配置周期。 ","date":"2022-07-24","objectID":"/k8sNode/:7:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 逐出速率限制大部分情况下，节点控制器把逐出速率限制在每秒 –node-eviction-rate 个（默认为 0.1）。 这表示它每 10 秒钟内至多从一个节点驱逐 Pod。 当一个可用区域（Availability Zone）中的节点变为不健康时，节点的驱逐行为将发生改变。 节点控制器会同时检查可用区域中不健康（Ready 状况为 Unknown 或 False） 的节点的百分比： 如果不健康节点的比例超过 –unhealthy-zone-threshold （默认为 0.55）， 驱逐速率将会降低。 如果集群较小（意即小于等于 –large-cluster-size-threshold 个节点 - 默认为 50）， 驱逐操作将会停止。 否则驱逐速率将降为每秒 –secondary-node-eviction-rate 个（默认为 0.01）。 在逐个可用区域中实施这些策略的原因是， 当一个可用区域可能从控制面脱离时其它可用区域可能仍然保持连接。 如果你的集群没有跨越云服务商的多个可用区域，那（整个集群）就只有一个可用区域。 跨多个可用区域部署你的节点的一个关键原因是当某个可用区域整体出现故障时， 工作负载可以转移到健康的可用区域。 因此，如果一个可用区域中的所有节点都不健康时，节点控制器会以正常的速率 –node-eviction-rate 进行驱逐操作。 在所有的可用区域都不健康（也即集群中没有健康节点）的极端情况下， 节点控制器将假设控制面与节点间的连接出了某些问题，它将停止所有驱逐动作 （如果故障后部分节点重新连接，节点控制器会从剩下不健康或者不可达节点中驱逐 Pod）。 节点控制器还负责驱逐运行在拥有 NoExecute 污点的节点上的 Pod， 除非这些 Pod 能够容忍此污点。 节点控制器还负责根据节点故障（例如节点不可访问或没有就绪） 为其添加污点。 这意味着调度器不会将 Pod 调度到不健康的节点上。 ","date":"2022-07-24","objectID":"/k8sNode/:8:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 资源容量跟踪Node 对象会跟踪节点上资源的容量（例如可用内存和 CPU 数量）。 通过自注册机制生成的 Node 对象会在注册期间报告自身容量。 如果你手动添加了 Node， 你就需要在添加节点时手动设置节点容量。 Kubernetes 调度器 保证节点上有足够的资源供其上的所有 Pod 使用。 它会检查节点上所有容器的请求的总和不会超过节点的容量。 总的请求包括由 kubelet 启动的所有容器，但不包括由容器运行时直接启动的容器， 也不包括不受 kubelet 控制的其他进程。 优雅关闭节点特性状态： Kubernetes v1.21 [beta] kubelet 会尝试检测节点系统关闭事件并终止在节点上运行的 Pods。 在节点终止期间，kubelet 保证 Pod 遵从常规的 Pod 终止流程。 优雅关闭节点特性依赖于 systemd，因为它要利用 systemd 抑制器锁机制， 在给定的期限内延迟节点关闭。 默认情况下，下面描述的两个配置选项，shutdownGracePeriod 和 shutdownGracePeriodCriticalPods 都是被设置为 0 的，因此不会激活节点体面关闭功能。 要激活此功能特性，这两个 kubelet 配置选项要适当配置，并设置为非零值。 在体面关闭节点过程中，kubelet 分两个阶段来终止 Pod： 终止在节点上运行的常规 Pod。 终止在节点上运行的关键 Pod。 节点体面关闭的特性对应两个 KubeletConfiguration 选项： shutdownGracePeriod：指定节点应延迟关闭的总持续时间。此时间是 Pod 体面终止的时间总和，不区分常规 Pod 还是关键 Pod。 shutdownGracePeriodCriticalPods：在节点关闭期间指定用于终止关键 Pod 的持续时间。该值应小于 shutdownGracePeriod。 例如，如果设置了 shutdownGracePeriod=30s 和 shutdownGracePeriodCriticalPods=10s， 则 kubelet 将延迟 30 秒关闭节点。 在关闭期间，将保留前 20（30 - 10）秒用于体面终止常规 Pod， 而保留最后 10 秒用于终止关键 Pod。 当 Pod 在正常节点关闭期间被驱逐时，它们会被标记为已经失败（Failed）。 运行 kubectl get pods 时，被驱逐的 Pod 的状态显示为 Shutdown。 并且 kubectl describe pod 表示 Pod 因节点关闭而被驱 ","date":"2022-07-24","objectID":"/k8sNode/:9:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" 节点非体面关闭特性状态： Kubernetes v1.24 [alpha] 当 Pod 在正常节点关闭期间被驱逐时，它们会被标记为已经失败（Failed）。 运行 kubectl get pods 时，被驱逐的 Pod 的状态显示为 Shutdown。 并且 kubectl describe pod 表示 Pod 因节点关闭而被驱 当某节点关闭但 kubelet 的节点关闭管理器未检测到这一事件时， 在那个已关闭节点上、属于 StatefulSet 的 Pod 将停滞于终止状态，并且不能移动到新的运行节点上。 这是因为已关闭节点上的 kubelet 已不存在，亦无法删除 Pod， 因此 StatefulSet 无法创建同名的新 Pod。 如果 Pod 使用了卷，则 VolumeAttachments 不会从原来的已关闭节点上删除， 因此这些 Pod 所使用的卷也无法挂接到新的运行节点上。 所以，那些以 StatefulSet 形式运行的应用无法正常工作。 如果原来的已关闭节点被恢复，kubelet 将删除 Pod，新的 Pod 将被在不同的运行节点上创建。 如果原来的已关闭节点没有被恢复，那些在已关闭节点上的 Pod 将永远滞留在终止状态。 为了缓解上述情况，用户可以手动将具有 NoExecute 或 NoSchedule 效果的 node kubernetes.io/out-of-service 污点添加到节点上，标记其无法提供服务。 如果在 kube-controller-manager 上启用了 NodeOutOfServiceVolumeDetach 特性门控， 并且节点被通过污点标记为无法提供服务，如果节点 Pod 上没有设置对应的容忍度， 那么这样的 Pod 将被强制删除，并且该在节点上被终止的 Pod 将立即进行卷分离操作。 这样就允许那些在无法提供服务节点上的 Pod 能在其他节点上快速恢复。 在非体面关闭期间，Pod 分两个阶段终止： 强制删除没有匹配的 out-of-service 容忍度的 Pod。 立即对此类 Pod 执行分离卷操作。 在添加 node.kubernetes.io/out-of-service 污点之前，应该验证节点已经处于关闭或断电状态（而不是在重新启动中）。 将 Pod 移动到新节点后，用户需要手动移除停止服务的污点，并且用户要检查关闭节点是否已恢复，因为该用户是最初添加污点的用户。 交换分区管理特性状态： Kubernetes v1.22 [alpha] 在 Kubernetes 1.22 之前，节点不支持使用交换内存，并且默认情况下， 如果在节点上检测到交换内存配置，kubelet 将无法启动。 在 1.22 以后，可以逐个节点地启用交换内存支持。 要在节点上启用交换内存，必须启用kubelet 的 NodeSwap 特性门控， 同时使用 –fail-swap-on 命令行参数或者将 failSwapOn 配置设置为 false。用户还可以选择配置 memorySwap.swapBehavior 以指定节点使用交换内存的方式。例如: memorySwap: swapBehavior: LimitedSwap 可用的 swapBehavior 的配置选项有： LimitedSwap：Kubernetes 工作负载的交换内存会受限制。 不受 Kubernetes 管理的节点上的工作负载仍然可以交换。 UnlimitedSwap：Kubernetes 工作负载可以使用尽可能多的交换内存请求， 一直到达到系统限制为止。 LimitedSwap 这种设置的行为取决于节点运行的是 v1 还是 v2 的控制组（也就是 cgroups）： cgroupsv1: Kubernetes 工作负载可以使用内存和交换，上限为 Pod 的内存限制值（如果设置了的话）。 cgroupsv2: Kubernetes 工作负载不能使用交换内存。 添加节点","date":"2022-07-24","objectID":"/k8sNode/:10:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":" kubeadm 添加工作节点 主节点创建 token，默认24小时有效 [root@node03 ~]# kubeadm token create --print-join-command kubeadm join 192.168.232.100:6443 --token 5sr666.3e5w3mvhp59rf5sc --discovery-token-ca-cert-hash sha256:0f71490a08826bd7ccc1cb68fce0ff2e3df31eb6fe8787251692cbc849645d12 工作节点（已初始化）执行上面生成的 kubeadm join 命令 [root@node04 ~]# kubeadm join 192.168.232.100:6443 --token 5sr666.3e5w3mvhp59rf5sc --discovery-token-ca-cert-hash sha256:0f71490a08826bd7ccc1cb68fce0ff2e3df31eb6fe8787251692cbc849645d12 [preflight] Running pre-flight checks ... ","date":"2022-07-24","objectID":"/k8sNode/:11:0","tags":["k8s","k8s 节点"],"title":"k8s 节点","uri":"/k8sNode/"},{"categories":["k8s"],"content":"k8sObjects","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内容来自以下文档： k8s官方文档 k8s对象在 k8s 系统中，Kubernetes 对象 是持久化的实体。 k8s 使用这些实体去表示整个集群的状态。 比較特别地是，它们描述了如下信息： 哪些容器化应用正在运行（以及在哪些节点上运行） 可以被应用使用的资源 关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略 Kubernetes 对象是“目标性记录”——一旦创建对象，Kubernetes 系统将不断工作以确保对象存在。 通过创建对象，你就是在告知 k8s 系统，你想要的集群工作负载状态看起来应是什么样子的， 这就是 k8s 集群所谓的 期望状态（Desired State） 操作 k8s 对象 —— 无论是创建、修改，或者删除 —— 需要使用 k8s API。 对象规约（Spec）与状态（Status）几乎每个 k8s 对象包含两个嵌套的对象字段，它们负责管理对象的配置： 对象 spec（规约） 和 对象 status（状态）。 对于具有 spec 的对象，你必须在创建对象时设置其内容，描述你希望对象所具有的特征： 期望状态（Desired State）。 status 描述了对象的当前状态（Current State），它是由 k8s 系统和组件设置并更新的。 在任何时刻，Kubernetes 控制平面 都一直都在积极地管理着对象的实际状态，以使之达成期望状态。 在想要创建的 k8s 对象所对应的 .yaml 文件中，需要配置的字段如下： apiVersion: 创建该对象所使用的 Kubernetes API 的版本 kind: 想要创建的对象的类别 metadata: 帮助唯一性标识对象的一些数据，包括一个 name 字符串、UID 和可选的 namespace spec: 你所期望的该对象的状态 下面示例展示了 Kubernetes Deployment 的必需字段和对象 spec apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # 告知 Deployment 运行 2 个与该模板匹配的 Pod template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 对象名称和 IDs集群中的每一个对象都有一个名称来标识在同类资源中的唯一性。 以下是比较常见的四种资源命名约束： DNS 子域名： 不能超过 253 个字符 只能包含小写字母、数字，以及 - 和 . 必须以字母数字开头 必须以字母数字结尾 RFC 1123 标签名： 不能超过 63 个字符 只能包含小写字母、数字，以及 - 必须以字母数字开头 必须以字母数字结尾 RFC 1035 标签名： 不能超过 63 个字符 只能包含小写字母、数字，以及 - 必须以字母开头 必须以字母数字结尾 某些资源类型可能具有额外的命名约束 每个 k8s 对象也有一个 UID 来标识在整个集群中的唯一性。 它旨在区分类似实体的历史事件 名称空间 查看集群中的名称空间 [root@node1 ~]# kubectl get namespace NAME STATUS AGE calico-system Active 6h56m default Active 7h kube-node-lease Active 7h kube-public Active 7h kube-system Active 7h tigera-operator Active 6h56m 在 k8s 中，“名称空间（Namespace）”提供一种机制，将同一集群中的资源划分 为相互隔离的组。 同一名称空间内的资源名称要唯一。 名称空间作用域仅针对带有名称空间的对象 当你创建一个服务时， k8s 会创建一个相应的 DNS 条目。 该条目的形式是\u003c服务名称\u003e.\u003c名称空间名称\u003e.svc.cluster.local，这意味着如果容器 只使用 \u003c服务名称\u003e，它将被解析到本地名称空间的服务。 因此，所有的名称空间名称都必须是合法的RFC 1123 DNS 标签 通过创建与公共顶级域名 同名的名称空间，这些名称空间中的服务可以拥有与公共 DNS 记录重叠的、较短的 DNS 名称。 所有名称空间中的负载在执行 DNS 查找时，如果查找的名称没有 尾部句点， 就会被重定向到这些服务上，因此呈现出比公共 DNS 更高的优先序。 大多数 kubernetes 资源（例如 Pod、Service、副本控制器等）都位于某些名称空间中。 但是名称空间资源本身并不在名称空间中。而且底层资源，例如 节点和持久化卷不属于任何名称空间。 # 位于名称空间中的资源 [root@node1 ~]# kubectl api-resources --namespaced=true NAME SHORTNAMES APIVERSION NAMESPACED KIND bindings v1 true Binding ... # 不在名称空间中的资源 [root@node1 ~]# kubectl api-resources --namespaced=false NAME SHORTNAMES APIVERSION NAMESPACED KIND componentstatuses cs v1 false ComponentStatus namespaces ns v1 false Namespace ... k8s 1.21 [beta]控制面会为所有名称空间设置一个不可变更的 标签 kubernetes.io/metadata.name，只要 NamespaceDefaultLabelName 这一 特性门控 被启用。标签的值是名称空间的名称。 标签和选择算符标签（Labels）是附加到 k8s 对象（比如 Pods）上的键值对。 标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接对核心系统有语义含义。 标签可以用于组织和选择对象的子集。标签可以在创建时附加到对象，随后可以随时添加和修改。 每个对象都可以定义一组键/值标签。每个键对于给定对象必须是唯一的。 标签使用户能够以松散耦合的方式将他们自己的组织结构映射到系统对象，而无需客户端存储这些映射。 标签是键值对。有效的标签键有两个段：可选的前缀和名称，用斜杠（/）分隔。 名称段是必需的，必须小于等于 63 个字符，以字母数字字符（[a-z0-9A-Z]）开头 和结尾， 带有破折号（-），下划线（_），点（ .）和之间的字母数字。 前缀是可选的。如果指定，前缀必须是 DNS 子域：由点（.）分隔的一系列 DNS 标签，总共不超过 253 个字符， 后跟斜杠（/）；如果省略前缀，则假定标 签键值对用户是私有的。 向最终用户对象添加标签的自动系统组件必须指定前缀。 有效标签值： 必须为 63 个字符或更少（可以为空） 除非标签值为空，必须以字母数字字符（[a-z0-9A-Z]）开头和结尾 包含破折号（-）、下划线（_）、点（.）和字母或数字 带有environment: production 和 app: nginx 标签的 Pod 配置文件” apiVersion: v1 kind: Pod metadata: name: label-demo labels: environment: production app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:0:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 标签选择算符通过标签选择算符，客户端/用户可以识别一组对象。标签选择算符是 k8s 中的核心分组原语。 API 目前支持两种类型的选择算符：基于等值的和基于集合的。 标签选择算符可以由逗号分隔的多个需求组成。 在多个需求的情况下，必须满足所有要求，因此逗号分隔符充当逻辑与（\u0026\u0026）运算符。 空标签选择算符或者未指定的选择算符的语义取决于上下文， 支持使用选择算符的 API 类别应该将算符的合法性和含义用文档记录下来 基于等值或基于不等值的需求允许按标签键和值进行过滤。 匹配对象必须满足所有指定的标签约束，尽管它们也可能具有其他标签： =或==: 表示相等 !=: 表示不相等 基于集合的标签需求允许你通过一组值来过滤键。 支持三种操作符： in、notin 和 exists（只可以用在键标识符上）。例如： # environment 标签值等于 production 或者 qa 的资源 environment in (production, qa) # tier标签值不等于 frontend 或者 backend 的资源，以及没有 tier 键标签的资源 tier notin (frontend, backend) # 所有包含了有 partition 标签的资源；没有校验它的值。 partition # 所有没有 partition 标签的资源；没有校验它的值。 !partition 基于集合的要求可以与基于相等的要求混合使用。例如： partition in (customerA, customerB),environment!=qa ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:1:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" LIST 和 WATCH 过滤LIST 和 WATCH 操作可以使用查询参数指定标签选择算符过滤一组对象。 两种需求都是允许的。（这里显示的是它们出现在 URL 查询字符串中） # 基于等值的需求 ?labelSelector=environment%3Dproduction,tier%3Dfrontend # 基于集合的需求 ?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29 ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:2:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" kubectl命令行使用标签 # 基于等值的标签选择算符 kubectl get pods -l environment=production,tier=frontend # 基于集合 kubectl get pods -l 'environment in (production),tier in (frontend)' # 基于集合实现值的或操作 kubectl get pods -l 'environment in (production, qa)' # 通过exists运算符限制不匹配 kubectl get pods -l 'environment,environment notin (frontend)' ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:3:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 支持基于集合需求的资源 来自 matchLabels 和 matchExpressions 的所有要求都按逻辑与的关系组合到一起 它们必须都满足才能匹配 selector: matchLabels: component: redis matchExpressions: - {key: tier, operator: In, values: [cache]} - {key: environment, operator: NotIn, values: [dev]} matchLabels: 是由 {key,value} 对组成的映射。 映射中的单个{key,value} matchExpressions: key指定键，operator指定运算符，values指定值。 有效的运算符包括 In、NotIn、Exists 和 DoesNotExist, 在 In 和 NotIn 的情况下值必须是非空的 注解你可以使用 Kubernetes 注解为对象附加任意的非标识的元数据。客户端程序（例如工具和库）能够获取这些元数据信息 标签与注解差别：标签只是对管理k8s人员用的；注解是给对象附加的元数据。 客户端程序能够获取注解，无法获取标签 ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:4:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 为对象附加元数据注解（Annotations） 存储的形式是键/值对。 有效的注解键分为两部分： 可选的前缀和名称，以斜杠（/）分隔： 名称段是必需项，并且必须在 63 个字符以内，以字母数字字符（[a-z0-9A-Z]）开头 和结尾， 并允许使用破折号（-），下划线（_），点（.）和字母数字 前缀是可选的。如果指定，前缀必须是 DNS 子域：由点（.）分隔的一系列 DNS 子域：一系列由点（.）分隔的 DNS 标签， 总计不超过 253 个字符， 后跟斜杠（/）。 如果省略前缀，则假定注解键对用户是私有的。 由系统组件添加的注解 必须为终端用户添加注解前缀 metadata.annotations字段添加注解 apiVersion: v1 kind: Pod metadata: name: annotations-demo annotations: imageregistry: \"https://hub.docker.com/\" spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 FinalizersFinalizer 是带有命名空间的键，告诉 Kubernetes 等到特定的条件被满足后， 再完全删除被标记为删除的资源。 Finalizer 提醒控制器清理被删除的对象拥有的资源。 当你告诉 Kubernetes 删除一个指定了 Finalizer 的对象时， Kubernetes API 通过填充 .metadata.deletionTimestamp 来标记要删除的对象， 并返回202状态码 (HTTP “已接受”) 使其进入只读状态。 此时控制平面或其他组件会采取 Finalizer 所定义的行动， 而目标对象仍然处于终止中（Terminating）的状态。 这些行动完成后，控制器会删除目标对象相关的 Finalizer。 当 metadata.finalizers 字段为空时，Kubernetes 认为删除已完成。 你可以使用 Finalizer 控制资源的垃圾收集。 例如，你可以定义一个 Finalizer，在删除目标资源前清理相关资源或基础设施。 你可以通过使用 Finalizers 提醒控制器 在删除目标资源前执行特定的清理任务， 来控制资源的垃圾收集。 Finalizers 通常不指定要执行的代码。 相反，它们通常是特定资源上的键的列表，类似于注解。 Kubernetes 自动指定了一些 Finalizers，但你也可以指定你自己的。 ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:5:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" Finalizers 工作流程在 metadata.finalizers 字段指定 Finalizers。 当你试图删除该资源时，处理删除请求的 API 服务器会注意到 finalizers 字段中的值， 并进行以下操作： 修改对象，将你开始执行删除的时间添加到 metadata.deletionTimestamp 字段 禁止对象被删除，直到其 metadata.finalizers 字段为空 返回 202 状态码（HTTP “Accepted”）。 管理 finalizer 的控制器注意到对象上发生的更新操作，对象的 metadata.deletionTimestamp 被设置，意味着已经请求删除该对象。然后，控制器会试图满足资源的 Finalizers 的条件。 每当一个 Finalizer 的条件被满足时，控制器就会从资源的 finalizers 字段中删除该键。 当 finalizers 字段为空时，deletionTimestamp 字段被设置的对象会被自动删除。 你也可以使用 Finalizers 来阻止删除未被管理的资源。 一个常见的 Finalizer 的例子是 kubernetes.io/pv-protection， 它用来防止意外删除 PersistentVolume 对象。 当一个 PersistentVolume 对象被 Pod 使用时， Kubernetes 会添加 pv-protection Finalizer。 如果你试图删除 PersistentVolume，它将进入 Terminating 状态， 但是控制器因为该 Finalizer 存在而无法删除该资源。 当 Pod 停止使用 PersistentVolume 时， Kubernetes 清除 pv-protection Finalizer，控制器就会删除该卷。 属主与附属在 Kubernetes 中，一些对象是其他对象的“属主（Owner）”。 例如，ReplicaSet 是一组 Pod 的属主。 具有属主的对象是属主的“附属（Dependent）”。 属主关系不同于一些资源使用的标签和选择算符机制。 例如，有一个创建 EndpointSlice 对象的 Service， 该 Service 使用标签来让控制平面确定，哪些 EndpointSlice 对象属于该 Service。 除开标签，每个代表 Service 所管理的 EndpointSlice 都有一个属主引用。 属主引用避免 Kubernetes 的不同部分干扰到不受它们控制的对象。 ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:6:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 对象规约中的属主引用附属对象有一个 metadata.ownerReferences 字段，用于引用其属主对象。 一个有效的属主引用，包含与附属对象同在一个命名空间下的对象名称和一个 UID。 Kubernetes 自动为一些对象的附属资源设置属主引用的值， 这些对象包含 ReplicaSet、DaemonSet、Deployment、Job、CronJob、ReplicationController 等。 你也可以通过改变这个字段的值，来手动配置这些关系。 然而，通常不需要这么做，你可以让 Kubernetes 自动管理附属关系。 附属对象还有一个 ownerReferences.blockOwnerDeletion 字段，该字段使用布尔值， 用于控制特定的附属对象是否可以阻止垃圾收集删除其属主对象。 如果控制器（例如 Deployment 控制器） 设置了 metadata.ownerReferences 字段的值，Kubernetes 会自动设置 blockOwnerDeletion 的值为 true。 你也可以手动设置 blockOwnerDeletion 字段的值，以控制哪些附属对象会阻止垃圾收集。 根据设计，kubernetes 不允许跨名字空间指定属主。 名字空间范围的附属可以指定集群范围的或者名字空间范围的属主。 名字空间范围的属主必须和该附属处于相同的名字空间。 如果名字空间范围的属主和附属不在相同的名字空间，那么该属主引用就会被认为是缺失的， 并且当附属的所有属主引用都被确认不再存在之后，该附属就会被删除。 集群范围的附属只能指定集群范围的属主。 在 v1.20+ 版本，如果一个集群范围的附属指定了一个名字空间范围类型的属主， 那么该附属就会被认为是拥有一个不可解析的属主引用，并且它不能够被垃圾回收。 在 v1.20+ 版本，如果垃圾收集器检测到无效的跨名字空间的属主引用， 或者一个集群范围的附属指定了一个名字空间范围类型的属主， 那么它就会报告一个警告事件。该事件的原因是 OwnerRefInvalidNamespace， involvedObject 属性中包含无效的附属。 你可以运行 kubectl get events -A –field-selector=reason=OwnerRefInvalidNamespace 来获取该类型的事件。 ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:7:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 属主关系与 Finalizer当你告诉 Kubernetes 删除一个资源，API 服务器允许管理控制器处理该资源的任何 Finalizer 规则。 Finalizer 防止意外删除你的集群所依赖的、用于正常运作的资源。 例如，如果你试图删除一个仍被 Pod 使用的 PersistentVolume，该资源不会被立即删除， 因为 PersistentVolume 有 kubernetes.io/pv-protection Finalizer。 相反，它将进入 Terminating 状态，直到 Kubernetes 清除这个 Finalizer， 而这种情况只会发生在 PersistentVolume 不再被挂载到 Pod 上时。 当你使用前台或孤立级联删除时， Kubernetes 也会向属主资源添加 Finalizer。 在前台删除中，会添加 foreground Finalizer，这样控制器必须在删除了拥有 ownerReferences.blockOwnerDeletion=true 的附属资源后，才能删除属主对象。 如果你指定了孤立删除策略，Kubernetes 会添加 orphan Finalizer， 这样控制器在删除属主对象后，会忽略附属资源。 ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:8:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 属主引用、标签和 Finalizers与标签类似， 属主引用 描述了 Kubernetes 中对象之间的关系，但它们作用不同。 当一个控制器 管理类似于 Pod 的对象时，它使用标签来跟踪相关对象组的变化。 例如，当 Job 创建一个或多个 Pod 时， Job 控制器会给这些 Pod 应用上标签，并跟踪集群中的具有相同标签的 Pod 的变化。 Job 控制器还为这些 Pod 添加了“属主引用”，指向创建 Pod 的 Job。 如果你在这些 Pod 运行的时候删除了 Job， Kubernetes 会使用属主引用（而不是标签）来确定集群中哪些 Pod 需要清理。 当 Kubernetes 识别到要删除的资源上的属主引用时，它也会处理 Finalizers。 在某些情况下，Finalizers 会阻止依赖对象的删除， 这可能导致目标属主对象被保留的时间比预期的长，而没有被完全删除。 在这些情况下，你应该检查目标属主和附属对象上的 Finalizers 和属主引用，来排查原因。 字段选择器“字段选择器（Field selectors）”允许你根据一个或多个资源字段的值 筛选 Kubernetes 资源。 kubectl 命令将筛选出 status.phase 字段值为 Running 的所有 Pod： kubectl get pods --field-selector status.phase=Running 字段选择器本质上是资源“过滤器（Filters）”。默认情况下，字段选择器/过滤器是未被应用的， 这意味着指定类型的所有资源都会被筛选出来。 这使得以下的两个 kubectl 查询是等价的： kubectl get pods kubectl get pods --field-selector \"\" ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:9:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 支持的字段不同的 Kubernetes 资源类型支持不同的字段选择器。 所有资源类型都支持 metadata.name 和 metadata.namespace 字段。 使用不被支持的字段选择器会产生错误。 $ kubectl get ingress --field-selector foo.bar=baz Error from server (BadRequest): Unable to find \"ingresses\" that match label selector \"\", ... ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:10:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 支持的操作符字段选择器中使用: = 或 ==表示等于 !=: 表示不等于 kubectl 命令将筛选所有不属于 default 命名空间的 Kubernetes 服务 kubectl get services --all-namespaces --field-selector metadata.namespace!=default ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:11:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 链式选择器同标签和其他选择器一样， 字段选择器可以通过使用逗号分隔的列表组成一个选择链。 kubectl 命令将筛选 status.phase 字段不等于 Running 同时 spec.restartPolicy 字段等于 Always 的所有 Pod kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:12:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 多种资源类型你能够跨多种资源类型来使用字段选择器。 kubectl 命令将筛选出所有不在 default 命名空间中的 StatefulSet 和 Service： kubectl get statefulsets,services --all-namespaces --field-selector metadata.namespace!=default 清单文件中描述对象kubectl api-resources命令可以查看已启用的对象，kubectl explain [选项] 资源对象 可以查看该如何在清单文件(yaml)中描述或解读对象信息。通常资源有以下描述字段： apiVersion: k8s API版本 KIND: 资源对象名称 metadata: 对象元数据 spec: 期望对象的状态 status: 资源当前状态信息，由k8s生成 如查看pod资源 [root@k8s01 ~]# kubectl explain pod KIND: Pod VERSION: v1 DESCRIPTION: Pod is a collection of containers that can run on a host. This resource is created by clients and scheduled onto hosts. ... 字段之间用点表示层级，在帮助信息中，字段后面都用字段取值类型注释信息在 \u003c\u003e 内，可能有以下值： required: 表示必选字段 [ ]: 表示列表 Object: 表示有子对象字段 string: 表示字符串 integer: 表示整数 boolean: 表示布尔值 如下面命令查看pod的spec字段中containers该如何描述。其中args字段取值为字符串列表 [root@k8s01 ~]# kubectl explain pod.spec.containers KIND: Pod VERSION: v1 ... FIELDS: args \u003c[]string\u003e Arguments to the entrypoint. The container image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell ... ","date":"2022-07-24","objectID":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/:13:0","tags":["k8s","k8s 对象","k8s UID","k8s 名称空间","k8s 标签","k8s 标签运算符","k8s 注解","k8s finalizers","k8s 属主","k8s 字段选择器"],"title":"k8s中的对象","uri":"/k8s%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.24 Rocky Linux:8.5 内容来自以下文档： k8s官方文档 k8sKubernetes简称为k8s(k 和 s 之间有八个字符)是一个可移植、可扩展的开源平台 ，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 k8s可以做： 服务发现和负载均衡：k8s 可以使用 DNS 名称或自己的 IP 地址来曝露容器。 如果进入容器的流量很大， K8s 可以负载均衡并分配网络流量，从而使部署稳定 存储编排：k8s允许自动挂载你选择的存储系统，例如本地存储、公共云提供商等 自动部署和回滚：可以使用 K8s 描述已部署容器的所需状态， 它可以以受控的速率将实际状态更改为期望状态 自动完成装箱计算：可以指定每个容器所需的 CPU 和内存，当容器指定了资源请求时 可以做出更好的决策来为容器分配资源 自我修复：将重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的 容器， 并且在准备好服务之前不将其通告给客户端 密钥与配置管理：允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置 中暴露密钥 k8s： 不限制支持的应用程序类型 不部署源代码 不提供应用程序级别的服务作为内置服务 不是日志记录、监视或警报的解决方案 不提供也不要求配置用的语言、系统 不提供也不采用任何全面的机器配置、维护、管理或自我修复系统 k8s组件服务运行在容器中，pod封装了1个或多个容器。k8s管理这些pod ","date":"2022-07-24","objectID":"/k8s%E6%A6%82%E8%BF%B0/:0:0","tags":["k8s","k8s概述","k8s组件","k8s API"],"title":"k8s概述","uri":"/k8s%E6%A6%82%E8%BF%B0/"},{"categories":["k8s"],"content":" 控制平面组件（Control Plane Components）控制平面组件会为集群做出全局决策，比如资源的调度。 以及检测和响应集群事件， 可以在集群中的任何节点上运行。 然而，为了简单起见，通常只在master节点运行 控制平面组件包含以下组件： kube-apiserver: 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。由kube-apiserver实现 etcd: 是兼顾一致性与高可用性的键值数据库，可以作为保存 k8s 所有集群 数据的后台数据库。 kube-scheduler: 负责pod调度 kube-controller-manager: 负责运行控制器进程，从逻辑上讲， 每个控制器都是一个 单独的进程。 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在同一个 进程中运行。这些控制器包括： 节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应 任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 端点控制器（Endpoints Controller）：填充端点（Endpoints）对象（即加入 Service 与 Pod） 服务帐户和令牌控制器（Service Account \u0026 Token Controllers）：为新的命名空间创建默认帐户和 API 访问令牌 cloud-controller-manager: 仅运行特定于云平台的控制器。与 kube-controller-manager 类似 ","date":"2022-07-24","objectID":"/k8s%E6%A6%82%E8%BF%B0/:1:0","tags":["k8s","k8s概述","k8s组件","k8s API"],"title":"k8s概述","uri":"/k8s%E6%A6%82%E8%BF%B0/"},{"categories":["k8s"],"content":" Node 组件节点组件会在每个节点上运行，负责维护运行的 Pod 并提供 k8s 运行环境 ","date":"2022-07-24","objectID":"/k8s%E6%A6%82%E8%BF%B0/:2:0","tags":["k8s","k8s概述","k8s组件","k8s API"],"title":"k8s概述","uri":"/k8s%E6%A6%82%E8%BF%B0/"},{"categories":["k8s"],"content":" kubeletkubelet 会在集群中每个节点（node）上运行。 它保证容器都运行在Pod中。 kubelet 不会管理不是由 k8s 创建的容器。 kubelet 接收一组通过各类机制提供给它的 PodSpecs， 确保这些 PodSpecs 中描述的容器处于运行状态且健康 ","date":"2022-07-24","objectID":"/k8s%E6%A6%82%E8%BF%B0/:3:0","tags":["k8s","k8s概述","k8s组件","k8s API"],"title":"k8s概述","uri":"/k8s%E6%A6%82%E8%BF%B0/"},{"categories":["k8s"],"content":" kube-proxykube-proxy 是集群中每个节点（node）所上运行的网络代理， 实现 k8s 服务（Service） 概念的一部分。 kube-proxy 维护节点上的一些网络规则， 这些网络规则会允许从集群内部或外部的网络会话与 Pod 进行网络通信。 如果操作系统提供了可用的数据包过滤层，则 kube-proxy 会通过它来实现网络规则。 否则，kube-proxy 仅做流量转发 ","date":"2022-07-24","objectID":"/k8s%E6%A6%82%E8%BF%B0/:4:0","tags":["k8s","k8s概述","k8s组件","k8s API"],"title":"k8s概述","uri":"/k8s%E6%A6%82%E8%BF%B0/"},{"categories":["k8s"],"content":" 容器运行时（Container Runtime）容器运行环境是负责运行容器的软件。Kubernetes 支持许多容器运行环境，例如 Docker、 containerd、 CRI-O 以及 k8s CRI (容器运行环境接口) 的其他任何实现 ","date":"2022-07-24","objectID":"/k8s%E6%A6%82%E8%BF%B0/:5:0","tags":["k8s","k8s概述","k8s组件","k8s API"],"title":"k8s概述","uri":"/k8s%E6%A6%82%E8%BF%B0/"},{"categories":["k8s"],"content":" 插件（Addons）插件使用 k8s 资源（DaemonSet、 Deployment 等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 kube-system 命名空间 k8s APIKubernetes 控制面 的核心是 API 服务器。 API 服务器负责提供 HTTP API，以供用户、集群中的不同部分和集群外部组件相互通信。 大部分操作都可以通过 kubectl 命令行接口或 类似 kubeadm 这类命令行工具来执行， 这些工具在背后也是调用 API。不过，你也可以使用 REST 调用来访问这些 API。 ","date":"2022-07-24","objectID":"/k8s%E6%A6%82%E8%BF%B0/:6:0","tags":["k8s","k8s概述","k8s组件","k8s API"],"title":"k8s概述","uri":"/k8s%E6%A6%82%E8%BF%B0/"},{"categories":["k8s"],"content":" 运行环境： rockylinux: 8.6 kernel: 4.18 sealos: 4.0.0 内容来自以下文档： sealos 基本要求 系统：Debian 或 Red Hat 发行版 配置：至少2GB内存，至少 2核心 数量：node节点至少1台，主节点1台。 如果是高可用则至少需要3台主节点且主节点数量为奇数 准备工作 每个节点IP地址唯一性 每个节点网卡MAC地址唯一性 每个节点主机名具有唯一性 能解析主机名 能连接网络 快速开始 安装一个高可用的 k8s 集群，并用 calico 作为网络插件 # 可以从 https://github.com/labring/sealos/releases 下载 $ wget -c https://sealyun-home.oss-cn-beijing.aliyuncs.com/sealos-4.0/latest/sealos-amd64 -O sealos $ chmod +x sealos $ mv sealos /usr/bin # 镜像地址在 https://hub.docker.com/u/labring # 可以修改版本 # 已使用 container 作为容器运行时 $ sealos run labring/kubernetes:v1.24.0 labring/calico:v3.22.1 \\ --masters 192.168.64.2,192.168.64.22,192.168.64.20 \\ --nodes 192.168.64.21,192.168.64.19 -p [your-ssh-passwd] 单主集群 配置静态ip，所有机器都配置，不能冲突 [root@node1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens160 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=ens160 DEVICE=ens160 ONBOOT=yes IPADDR=192.168.64.112 PREFIX=24 GATEWAY=192.168.64.2 [root@node1 ~]# nmcli c reload ens160 [root@node1 ~]# nmcli c up ens160 修改主机名，所有机器都配置不能冲突 [root@node1 ~]# hostnamectl set-hostname k8s01.localdomain [root@node1 ~]# bash [root@k8s01 ~]# 密码统一 使用 sealos 搭建 k8s 集群 [root@k8s01 ~]# ll sealos_4.0.0_linux_amd64.tar.gz -rw-r--r--. 1 root root 23578164 Jul 24 18:02 sealos_4.0.0_linux_amd64.tar.gz [root@k8s01 ~]# [root@k8s01 ~]# tar -zxf sealos_4.0.0_linux_amd64.tar.gz [root@k8s01 ~]# ll se* -rwxr-xr-x. 1 root root 9068984 Jun 30 22:27 sealctl -rwxr-xr-x. 1 root root 15679688 Jun 30 22:27 sealos -rw-r--r--. 1 root root 23578164 Jul 24 18:02 sealos_4.0.0_linux_amd64.tar.gz [root@k8s01 ~]# mv sealos /usr/bin/ [root@k8s01 ~]# mv sealctl /usr/bin/ [root@k8s01 ~]# sealos run labring/kubernetes:v1.24.3 labring/calico:v3.22.1 --masters 192.168.64.111 --nodes 192.168.64.112 -p \" \" 2022-07-24 18:17:31 [INFO] Start to create a new cluster: master [192.168.64.111], worker [192.168.64.112] 2022-07-24 18:17:31 [INFO] Executing pipeline Check in CreateProcessor. 2022-07-24 18:17:31 [INFO] checker:hostname [192.168.64.111:22 192.168.64.112:22] 2022-07-24 18:17:32 [INFO] checker:timeSync [192.168.64.111:22 192.168.64.112:22] 2022-07-24 18:17:32 [INFO] Executing pipeline PreProcess in CreateProcessor. ... 2022-07-24 18:23:44 [INFO] guest cmd is kubectl apply -f manifests/calico.yaml installation.operator.tigera.io/default created 2022-07-24 18:23:46 [INFO] succeeded in creating a new cluster, enjoy it! 2022-07-24 18:23:46 [INFO] ___ ___ ___ ___ ___ ___ /\\ \\ /\\ \\ /\\ \\ /\\__\\ /\\ \\ /\\ \\ /::\\ \\ /::\\ \\ /::\\ \\ /:/ / /::\\ \\ /::\\ \\ /:/\\ \\ \\ /:/\\:\\ \\ /:/\\:\\ \\ /:/ / /:/\\:\\ \\ /:/\\ \\ \\ _\\:\\~\\ \\ \\ /::\\~\\:\\ \\ /::\\~\\:\\ \\ /:/ / /:/ \\:\\ \\ _\\:\\~\\ \\ \\ /\\ \\:\\ \\ \\__\\ /:/\\:\\ \\:\\__\\ /:/\\:\\ \\:\\__\\ /:/__/ /:/__/ \\:\\__\\ /\\ \\:\\ \\ \\__\\ \\:\\ \\:\\ \\/__/ \\:\\~\\:\\ \\/__/ \\/__\\:\\/:/ / \\:\\ \\ \\:\\ \\ /:/ / \\:\\ \\:\\ \\/__/ \\:\\ \\:\\__\\ \\:\\ \\:\\__\\ \\::/ / \\:\\ \\ \\:\\ /:/ / \\:\\ \\:\\__\\ \\:\\/:/ / \\:\\ \\/__/ /:/ / \\:\\ \\ \\:\\/:/ / \\:\\/:/ / \\::/ / \\:\\__\\ /:/ / \\:\\__\\ \\::/ / \\::/ / \\/__/ \\/__/ \\/__/ \\/__/ \\/__/ \\/__/ Website :https://www.sealos.io/ Address :github.com/labring/sealos [root@k8s01 ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s01.localdomain Ready control-plane 2m42s v1.24.3 k8s02.localdomain Ready \u003cnone\u003e 2m9s v1.24.3 error","date":"2022-07-24","objectID":"/%E4%BD%BF%E7%94%A8sealos%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4/:0:0","tags":["k8s","搭建k8s集群"],"title":"使用sealos搭建k8s集群","uri":"/%E4%BD%BF%E7%94%A8sealos%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4/"},{"categories":["k8s"],"content":" succeeded install app in this cluster: no change apps首次安装失败后无法安装 [root@k8s01 ~]# sealos run labring/kubernetes:v1.24.3 labring/calico:v3.22.1 \\ \u003e --masters 192.168.64.111 --nodes 192.168.64.112 -p ' ' 2022-07-24 18:05:09 [INFO] Start to create a new cluster: master [192.168.64.111], worker [192.168.64.112] 2022-07-24 18:05:10 [INFO] Executing pipeline Check in CreateProcessor. 2022-07-24 18:05:10 [INFO] checker:hostname [192.168.64.111:22 192.168.64.112:22] 2022-07-24 18:05:10 [INFO] checker:timeSync [192.168.64.111:22 192.168.64.112:22] 2022-07-24 18:05:10 [INFO] Executing pipeline PreProcess in CreateProcessor. Resolving \"labring/kubernetes\" using unqualified-search registries (/etc/containers/registries.conf) Trying to pull docker.io/labring/kubernetes:v1.24.3... 2022-07-24 18:05:10 [EROR] Applied to cluster error: initializing source docker://labring/kubernetes:v1.24.3: (Mirrors also failed: [registry.cn-qingdao.aliyuncs.com/labring/kubernetes:v1.24.3: pinging container registry registry.cn-qingdao.aliyuncs.com: Get \"http://registry.cn-qingdao.aliyuncs.com/v2/\": dial tcp: lookup registry.cn-qingdao.aliyuncs.com on [::1]:53: read udp [::1]:59599-\u003e[::1]:53: read: connection refused]): docker.io/labring/kubernetes:v1.24.3: pinging container registry registry-1.docker.io: Get \"http://registry-1.docker.io/v2/\": dial tcp: lookup registry-1.docker.io on [::1]:53: read udp [::1]:35966-\u003e[::1]:53: read: connection refused [root@k8s01 ~]# sealos run labring/kubernetes:v1.24.3 labring/calico:v3.22.1 --masters 192.168.64.111 --nodes 192.168.64.112 -p \" \" 2022-07-24 18:11:17 [INFO] start to install app in this cluster 2022-07-24 18:11:17 [INFO] succeeded install app in this cluster: no change apps 2022-07-24 18:11:17 [INFO] start to scale this cluster 2022-07-24 18:11:17 [INFO] succeeded in scaling this cluster: no change nodes 2022-07-24 18:11:17 [INFO] 解决方法 [root@k8s01 ~]# rm -fr .sealos ","date":"2022-07-24","objectID":"/%E4%BD%BF%E7%94%A8sealos%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4/:1:0","tags":["k8s","搭建k8s集群"],"title":"使用sealos搭建k8s集群","uri":"/%E4%BD%BF%E7%94%A8sealos%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4/"},{"categories":["k8s"],"content":" ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 运行环境： rockylinux: 8.6 kernel: 4.18 k8s: 1.27.1 内容来自以下文档： 丛宇鸿: Kubeadm搭建高可用(k8s)Kubernetes v1.23.5集群 使用 kubeadm 引导集群 容器运行时 k8s 组件使用的端口和协议 高可用性注意事项 网络插件 基本要求创建k8s集群满足以下要求： 系统：Debian 或 Red Hat 发行版 内存：至少2GB内存 CPU：至少 2 核心 节点数量：工作节点至少1台，控制节点1台（如果是高可用则至少需要3台控制节点且数量为奇数） 节点之间能通过低延迟的网络连接 能够获取安装包 准备工作开始创建k8s集群时必要的设置： 节点之间能通过网络连接： 控制节点放行的端口：6443/tcp、2379-2380/tcp、10250/tcp、10259/tcp、10257/tcp 工作节点放行的端口：10250/tcp、30000-32767/tcp 节点网络具有唯一性（IP、MAC、product_uuid、主机名） 禁止用交换分区 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:0:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 确保每个节点product_uuid唯一性 查看product_uuid, 这个通常不会重复 [root@node01 ~]# cat /sys/class/dmi/id/product_uuid d5064d56-792f-fe2e-666e-a2d1c4a140a1 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:1:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 确保每个节点IP唯一性 使用静态IP [root@node01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens160 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=no IPV6_DEFROUTE=no IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=no NAME=ens160 DEVICE=ens160 ONBOOT=yes BOOTPROTO=none IPADDR=192.168.232.101 PREFIX=24 GATEWAY=192.168.232.2 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:2:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 确保每个节点网卡MAC地址唯一性 查看网卡MAC地址，这具通常不会重复 [root@node01 ~]# ip link | egrep 'ether [0-9a-fA-F]{2}(:[0-9a-fA-F]{2}){5}' -o ether 00:0c:29:a1:40:a1 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:3:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 确保每个节点主机名唯一性与绑定解析 查看主机名 [root@node01 ~]# hostnamectl Static hostname: node01.my.host ... 如果主机名重复，修改主机名方法 # 临时有效 [root@node01 ~]# hostnamectl set-hostname name # 开机生效 [root@node01 ~]# echo 'name' \u003e /etc/hostname 解析主机名（所有节点） [root@node01 ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 [root@node01 ~]# [root@node01 ~]# echo \u003e\u003e /etc/hosts [root@node01 ~]# [root@node01 ~]# vi /etc/hosts ... [root@node01 ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.232.101 node01.my.host 192.168.232.102 node02.my.host 192.168.232.103 node03.my.host 192.168.232.104 node04.my.host 192.168.232.105 node05.my.host ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:4:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 放行所需的端口如果不确定会使用到哪些端口，则可以临时关闭防火墙 控制节点 [root@node01 ~]# firewall-cmd --zone=public --add-port=6443/tcp --add-port=2379-2380/tcp --add-port=10250/tcp --add-port=10259/tcp --add-port=10257/tcp \u0026\u0026 firewall-cmd --runtime-to-permanent 工作节点 firewall-cmd --zone=public --add-port=10250/tcp --add-port=30000-32767/tcp \u0026\u0026 firewall-cmd --runtime-to-permanent ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:5:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 所有节点关闭selinux # 临时关闭并禁止开机启动 [root@node01 ~]# setenforce 0 ; sed -i '/^SELINUX=/ s/.*/SELINUX=permissive/g' /etc/selinux/config ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:6:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 所有节点关闭交换分区 # 临时关闭 并禁止开机挂载 swap 分区 [root@node01 ~]# swapoff -a \u0026\u0026 sed '/swap/ s/^/#/' /etc/fstab -i ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:7:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 所有节点开启内核 ipv4 转发 查看是否加载 br_netfilter 模块 # br_netfilter 模块：用于将桥接流量转发至 iptables 链，NAT转发要依赖该模块 # ip_conntrack 模块：记录 iptables 网络包的状态，并把每条记录保存到 table 里 # 这个 table 在内存里，可以通过/proc/net/ip_conntrack 查看 # 当前已经记录的总数 # 查看是否加载 br_netfilter 模块 [root@node01 ~]# lsmod | grep br_netfilter # 临时加载 ip_conntrack、br_netfilter 模块 [root@node02 ~]# modprobe br_netfilter \u0026\u0026 modprobe ip_conntrack \u0026\u0026 lsmod | grep br_netfilter br_netfilter 24576 0 bridge 290816 1 br_netfilter # 开机自动加载脚本 [root@node01 ~]# cat /etc/rc.sysinit #!/bin/bash for file in /etc/sysconfig/modules/*.modules ; do [ -x $file ] \u0026\u0026 $file done # 创建加载模快文件 [root@node01 ~]# echo \"modprobe br_netfilter\" \u003e /etc/sysconfig/modules/br_netfilter.modules [root@node01 ~]# echo \"modprobe ip_conntrack\" \u003e/etc/sysconfig/modules/ip_conntrack.modules # 增加执行权限 [root@node01 ~]# chmod 755 /etc/sysconfig/modules/*.modules 允许ipv4 nat转发与过虑桥接流量 # 查看是否允许 ipv4 nat转发，0表示关闭 [root@node01 ~]# sysctl -a | grep 'net.ipv4.ip_forward ' net.ipv4.ip_forward = 0 # 临时允许ipv4 nat转发 [root@node01 ~]# echo '1' \u003e /proc/sys/net/ipv4/ip_forward # 开机允许ipv4 nat转发 [root@node01 ~]# echo \"net.ipv4.ip_forward = 1\" \u003e\u003e /etc/sysctl.conf # 查看是否允许过虑 ipv4 桥接流量 [root@node01 ~]# sysctl -a | grep 'bridge.bridge-nf-call-iptables ' net.bridge.bridge-nf-call-iptables = 1 # 临时允许过虑ipv4桥接流量： # echo '1' \u003e /proc/sys/net/bridge/bridge-nf-call-iptables # 开机允许过虑ipv4桥接流量： # echo 'net.bridge.bridge-nf-call-iptables = 1' \u003e\u003e /etc/sysctl.conf ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:8:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 所有节点时间同步 # 设置时区 [root@node01 ~]# timedatectl set-timezone Asia/Shanghai # 启动时间同步服务 [root@node01 ~]# systemctl start chronyd # 设置开机启动 [root@node01 ~]# systemctl enable chronyd # 启用时间同步 [root@node01 ~]# timedatectl set-ntp yes # 将当前的 UTC 时间写入硬件时钟 [root@node01 ~]# timedatectl set-local-rtc 0 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:9:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 所有节点配置yum源 配置 kubeadm、kubeclt、kubelet 所需的yum源(阿里) cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF setenforce 0 yum install -y kubelet kubeadm kubectl systemctl enable kubelet \u0026\u0026 systemctl start kubelet 官方yum源 cat \u003c\u003cEOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:10:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 所有节点安装依赖包 iptables是Linux服务器上进行网络隔离的核心技术，内核在处理网络请求时会对iptables中的策略进行逐条解析，因此当策略较多时效率较低；而是用IPSet技术可以将策略中的五元组(协议，源地址，源端口,目的地址，目的端口)合并到有限的集合中，可以大大减少iptables策略条目从而提高效率。 从k8s:1.8版本开始，kube-proxy引入了IPVS模式，IPVS模式与iptables同样基于Netfilter，但是采用的hash表，因此当service数量达到一定规模时，hash查表的速度优势就会显现出来，从而提高service的服务性能。 [root@node01 ~]# yum install -y ipset ipvsadm conntrack libseccomp iproute-tc ipvs依赖nf_conntrack_ipv4 # ipvs依赖于nf_conntrack_ipv4内核模块,4.19包括之后内核里改名为nf_conntrack # 其它在部分 3.10 版本中也增加了 nf_conntrack [root@node01 ~]# cat /etc/sysconfig/modules/ipvs.modules modprobe -- ip_vs modprobe -- ip_vs_rr modprobe -- ip_vs_wrr modprobe -- ip_vs_sh modprobe -- nf_conntrack [root@node01 ~]# bash /etc/sysconfig/modules/ipvs.modules [root@node01 ~]# chmod 755 /etc/sysconfig/modules/ipvs.modules 所有节点安装容器运行时容器运行时是指满足k8s CRI接口的运行容器工具，常见有以下： containerd: containerd从Docker中拆分出来，支持大部分平台 CRI-O: 在RedHat相关系统轻量级的容器运行管理工具，其它平台不一定支持 Docker Engine: 从1.20版本开始已经被移除了，需要使用 cri-dockerd 适配器来将 Docker Engine 与 Kubernetes 集成。 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:11:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 使用containerd作为容器运行时若CNI插件尚未升级且/或CNI配置文件中未声明CNI配置版本时，则 containerd v1.6.0-v1.6.3版本将导致Pod CNI网络setup及tear down发生问题。 containerd团队报告称，这些问题已经在containerd v1.6.4中得到解决。 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:12:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 安装 libseccomplibseccomp版本要\u003e2.4 [root@node01 ~]# rpm -qa | grep libseccomp libseccomp-2.5.2-1.el8.x86_64 升级方法 #下载高于2.4以上的包 [i4t@web01 ~]# wget http://rpmfind.net/linux/centos/8-stream/BaseOS/x86_64/os/Packages/libseccomp-2.5.1-1.el8.x86_64.rpm #安装 [i4t@web01 ~]# rpm -ivh libseccomp-2.5.1-1.el8.x86_64.rpm #下载高于2.4以上的包 [i4t@web01 ~]# wget http://rpmfind.net/linux/centos/8-stream/BaseOS/x86_64/os/Packages/libseccomp-2.5.1-1.el8.x86_64.rpm #安装 [i4t@web01 ~]# rpm -ivh libseccomp-2.5.1-1.el8.x86_64.rpm ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:12:1","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 安装containerd 从containerd/releases # 命名规则：\u003ccontainer\u003e-\u003cVERSION\u003e-\u003cOS\u003e-\u003cARCH\u003e.tar.gz # container有以下值： # containerd: 容器管理工具 # cri-containerd: 支持作为容器运行时接口CRI # cri-containerd-cni: 支持k8s CRI CNI 接口 解压使用 # 查看内容 [root@node01 ~]# tar -ztvf cri-containerd-cni-1.6.20-linux-amd64.tar.gz drwxr-xr-x root/root 0 2023-03-31 04:54 etc/ drwxr-xr-x root/root 0 2023-03-31 04:51 etc/systemd/ drwxr-xr-x root/root 0 2023-03-31 04:51 etc/systemd/system/ -rw-r--r-- root/root 1270 2023-03-31 04:51 etc/systemd/system/containerd.service drwxr-xr-x root/root 0 2023-03-31 04:52 etc/cni/ ... # 解压 [root@node01 ~]# tar -zxf cri-containerd-cni-1.6.20-linux-amd64.tar.gz -C / [root@node01 ~]# containerd --version containerd github.com/containerd/containerd v1.6.20 2806fc1057397dbaeefbea0e4e17bddfbd388f38 配置systemctl服务 [root@node01 ~]# cp /etc/systemd/system/containerd.service /usr/lib/systemd/system/ 配置containerd # 创建配置目录 [root@node01 ~]# mkdir /etc/containerd -p # 生成默认配置文件 [root@node01 ~]# containerd config default \u003e /etc/containerd/config.toml # 配置 systemd cgroup 驱动程序 [root@node01 ~]# sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:12:2","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 检查是否能获取镜像 检测是否能获沙箱镜像 [root@node05 ~]# grep 'sandbox_image' /etc/containerd/config.toml sandbox_image = \"registry.k8s.io/pause:3.6\" [root@node05 ~]# # 检测失败 [root@node01 ~]# ctr -n k8s.io image pull registry.k8s.io/pause:3.6 registry.k8s.io/pause:3.6: resolving |--------------------------------------| elapsed: 21.0s total: 0.0 B (0.0 B/s) INFO[0021] trying next host error=\"failed to do request: Head \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/pause/manifests/3.6\\\": dial tcp 64.233.187.82:443: connect: connection refused\" host=registry.k8s.io ctr: failed to resolve reference \"registry.k8s.io/pause:3.6\": failed to do request: Head \"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/pause/manifests/3.6\": dial tcp 64.233.187.82:443: connect: connection refused # 更换沙箱地址解决 [root@node01 ~]# [root@node01 ~]# sed '/sandbox_image/ s/r.*6/docker.io\\/yuhais\\/pause:3.9/' /etc/containerd/config.toml -i [root@node01 ~]# [root@node01 ~]# ctr -n k8s.io image pull docker.io/yuhais/pause:3.9 docker.io/yuhais/pause:3.9: resolved |++++++++++++++++++++++++++++++++++++++| manifest-sha256:0fc1f3b764be56f7c881a69cbd553ae25a2b5523c6901fbacb8270307c29d0c4: done |++++++++++++++++++++++++++++++++++++++| config-sha256:e6f1816883972d4be47bd48879a08919b96afcd344132622e4d444987919323c: done |++++++++++++++++++++++++++++++++++++++| layer-sha256:61fec91190a0bab34406027bbec43d562218df6e80d22d4735029756f23c7007: done |++++++++++++++++++++++++++++++++++++++| elapsed: 2.5 s total: 0.0 B (0.0 B/s) unpacking linux/amd64 sha256:0fc1f3b764be56f7c881a69cbd553ae25a2b5523c6901fbacb8270307c29d0c4... done: 14.70142ms ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:12:3","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 开机启动 systemctl start containerd \u0026\u0026 systemctl enable --now containerd 在所有节点安装 kubelet kubeadm kubectl yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes 开机启动kubelet systemctl enable --now kubelet 控制面高可用要实现k8s集群高可用，必须实现控制面与etcd的高可用。根据etcd运行的位置分为以下情况： 堆叠etcd：控制平面与etcd运行在同一个节点上。架构如下 外部etcd： etcd 分布式数据存储集群在独立于控制平面节点的其他节点上运行。架构如下 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:12:4","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" apiserver高可以方案选择高可用方案有很多，如keepalived和haproxy的组合、kube-vip 等等 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:13:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 以静态 pod 方式运行 kube-vip准备pod相关文档，在初始化集群时使用(在所有控制节点) # 指定 VIP 地址 [root@node01 ~]# export VIP=192.168.232.100 [root@node01 ~]# # 指定网卡接口 [root@node01 ~]# export INTERFACE=ens160 [root@node01 ~]# # 获取 kube-vip 镜像（官方地址为：ghcr.io） # 版本号可通过获取：curl -sL https://api.github.com/repos/kube-vip/kube-vip/releases | jq -r \".[0].name\" [root@node01 ~]# ctr image pull docker.io/plndr/kube-vip:v0.5.12 ... unpacking linux/amd64 sha256:58d31ffc3b6bd0d6bcc091dbed7d9e52135bbd44f9fe861e97f80f2bf0a3d78c... [root@node01 ~]# # 生成 yaml 文件，采用的 arp 模式 [root@node01 ~]# ctr run --rm --net-host docker.io/plndr/kube-vip:v0.5.12 \\ vip /kube-vip manifest pod \\ --interface $INTERFACE \\ --vip $VIP \\ --controlplane \\ --services \\ --arp \\ --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml # 修改镜像地址（官方地址无法连接的情况） [root@node01 ~]# sed '/image:/ s/ghcr.io\\/kube-vip/docker.io\\/plndr/' /etc/kubernetes/manifests/kube-vip.yaml | grep docker image: docker.io/plndr/kube-vip:v0.5.12 [root@node01 ~]# [root@node01 ~]# sed '/image:/ s/ghcr.io\\/kube-vip/docker.io\\/plndr/' /etc/kubernetes/manifests/kube-vip.yaml -i 搭建高可用集群可以生成配置文件，修改文件后引用。或使用命令行 # 更详细的配置: # kubeadm config print init-defaults --component-configs KubeProxyConfiguration,KubeletConfiguration \u003e kubeadm-init.yaml 使用命令行搭建： [root@node01 ~]# [root@node01 ~]# kubeadm init --control-plane-endpoint \"192.168.232.100:6443\" \\ --image-repository \"docker.io/yuhais\" \\ --pod-network-cidr \"172.16.0.0/12\" \\ --upload-certs [init] Using Kubernetes version: v1.27.1 [preflight] Running pre-flight checks ... # 有以下信息说明初始化成功 Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of the control-plane node running the following command on each as root: kubeadm join 192.168.232.100:6443 --token uspj6f.wi36dnkhvondpqrf \\ --discovery-token-ca-cert-hash sha256:d32886aa7f295949837f178474e85a536357d548aebcd194d683f1be35f6e760 \\ --control-plane --certificate-key 04d400da9be71f5677f6ff8b7e01300c9072eaafc5dbef56a503dffc88e3cb0e Please note that the certificate-key gives access to cluster sensitive data, keep it secret! As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use \"kubeadm init phase upload-certs --upload-certs\" to reload certs afterward. Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.232.100:6443 --token uspj6f.wi36dnkhvondpqrf \\ --discovery-token-ca-cert-hash sha256:d32886aa7f295949837f178474e85a536357d548aebcd194d683f1be35f6e760 添加 kubelctl 配置文件，用于连接集群apiserver [root@node01 ~]# mkdir -p $HOME/.kube [root@node01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@node01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:14:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 添加主节点在另外2台控制节点服务器上使用以下命令 [root@node02 ~]# kubeadm join 192.168.232.100:6443 --token uspj6f.wi36dnkhvondpqrf \\ \u003e --discovery-token-ca-cert-hash sha256:d32886aa7f295949837f178474e85a536357d548aebcd194d683f1be35f6e760 \\ \u003e --control-plane --certificate-key 04d400da9be71f5677f6ff8b7e01300c9072eaafc5dbef56a503dffc88e3cb0e [preflight] Running pre-flight checks [WARNING FileExisting-tc]: tc not found in system path ... # 有以下信息表示成功 This node has joined the cluster and a new control plane instance was created: * Certificate signing request was sent to apiserver and approval was received. * The Kubelet was informed of the new secure connection details. * Control plane label and taint were applied to the new node. * The Kubernetes control plane instances scaled up. * A new etcd member was added to the local/stacked etcd cluster. To start administering your cluster from this node, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Run 'kubectl get nodes' to see this node join the cluster. 添加 kubelctl 配置文件，用于连接集群apiserver [root@node01 ~]# mkdir -p $HOME/.kube [root@node01 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [root@node01 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config 如果没有上面这些操作则会出现以下问题 [root@node03 ~]# kubectl get nodes E0430 21:30:03.825921 8777 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused E0430 21:30:03.826608 8777 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused E0430 21:30:03.829282 8777 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused E0430 21:30:03.830864 8777 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused E0430 21:30:03.832930 8777 memcache.go:265] couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp [::1]:8080: connect: connection refused The connection to the server localhost:8080 was refused - did you specify the right host or port? ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:15:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 添加工作节点在工作节点中使用以下命令 [root@node04 ~]# kubeadm join 192.168.232.100:6443 --token uspj6f.wi36dnkhvondpqrf \\ \u003e --discovery-token-ca-cert-hash sha256:d32886aa7f295949837f178474e85a536357d548aebcd194d683f1be35f6e760 [preflight] Running pre-flight checks ... # 有以下信息表示成功 This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 网络插件k8s不管理网络管理，它提供了一个CNI接口，使用网络插件实现k8s网络模型与pod网络管理 使用 calico 作为网络插件 error","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:16:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 解决无法从 registry.k8s.io 拉取镜像问题大致有以下几种方式 使用其它的镜像仓库 导入镜像文件 使用代理 ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:17:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" 使用其它镜像创库查看初始化安装时需要哪些镜像 [root@node01 ~]# kubeadm config images list W0430 02:07:43.920523 23995 images.go:80] could not find officially supported version of etcd for Kubernetes v1.27.1, falling back to the nearest etcd version (3.5.7-0) registry.k8s.io/kube-apiserver:v1.27.1 registry.k8s.io/kube-controller-manager:v1.27.1 registry.k8s.io/kube-scheduler:v1.27.1 registry.k8s.io/kube-proxy:v1.27.1 registry.k8s.io/pause:3.9 registry.k8s.io/etcd:3.5.7-0 registry.k8s.io/coredns/coredns:v1.10.1 通过修改镜像源获取 [root@node01 ~]# kubeadm config images pull --image-repository \"docker.io/yuhais/\" imageRepository: Invalid value: \"docker.io/yuhais/\": invalid image repository format To see the stack trace of this error execute with --v=5 or higher [root@node01 ~]# kubeadm config images pull --image-repository \"docker.io/yuhais\" W0430 04:30:40.951932 32015 images.go:80] could not find officially supported version of etcd for Kubernetes v1.27.1, falling back to the nearest etcd version (3.5.7-0) [config/images] Pulled docker.io/yuhais/kube-apiserver:v1.27.1 [config/images] Pulled docker.io/yuhais/kube-controller-manager:v1.27.1 [config/images] Pulled docker.io/yuhais/kube-scheduler:v1.27.1 [config/images] Pulled docker.io/yuhais/kube-proxy:v1.27.1 [config/images] Pulled docker.io/yuhais/pause:3.9 [config/images] Pulled docker.io/yuhais/etcd:3.5.7-0 [config/images] Pulled docker.io/yuhais/coredns:v1.10.1 containerd也要修改 [root@node01 ~]# sed '/sandbox_image/ s/r.*6/docker.io\\/yuhais\\/pause:3.9/' /etc/containerd/config.toml -i [root@node01 ~]# [root@node01 ~]# systemctl restart containerd ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:17:1","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["k8s"],"content":" err=“rpc error: code = Unknown desc = failed to get sandbox image …”kubeadm ini 初始化集群时kubelet 报错，无法获取 registry.k8s.io/pause:3.6 Apr 30 04:54:15 node01.my.host kubelet[32808]: E0430 04:54:15.763905 32808 kuberuntime_manager.go:1122] \"CreatePodSandbox for pod failed\" err=\"rpc error: code = Unknown desc = failed to get sandbox image \\\"registry.k8s.io/pause:3.6\\\": failed to pull image \\\"registry.k8s.io/pause:3.6\\\": failed to pull and unpack image \\\"registry.k8s.io/pause:3.6\\\": failed to resolve reference \\\"registry.k8s.io/pause:3.6\\\": failed to do request: Head \\\"https://asia-east1-docker.pkg.dev/v2/k8s-artifacts-prod/images/pause/manifests/3.6\\\": dial tcp 142.251.170.82:443: connect: connection refused\" pod=\"kube-system/etcd-node01.my.host\" 本地无法从 registry.k8s.io 中获取镜像，重新指定sandbox image地址 [root@node01 ~]# sed '/sandbox_image/ s/r.*6/docker.io\\/yuhais\\/pause:3.9/' /etc/containerd/config.toml -i [root@node01 ~]# [root@node01 ~]# systemctl restart containerd ","date":"2022-07-23","objectID":"/kubeadmCreateK8sCluster/:18:0","tags":["k8s","搭建k8s集群"],"title":"使用kubeadm搭建k8s集群","uri":"/kubeadmCreateK8sCluster/"},{"categories":["nginx"],"content":" ","date":"2022-07-22","objectID":"/nginx%E6%90%AD%E5%BB%BA%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1/","tags":["nginx","文件下载服务"],"title":"nginx搭建文件下载服务","uri":"/nginx%E6%90%AD%E5%BB%BA%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1/"},{"categories":["nginx"],"content":" 运行环境： centos:7 nginx:1.23.0 nginx搭建文件下载服务 # 提供下载的文件在/data/download/ 目录下 # 日志记录格式 log_format download '$remote_addr:$remote_port \u003e $uri ' \"$status $connection $request_time\" \"s \" \"$time_iso8601 $request_completion\"; server { listen 8024; #防止乱码，需要加上编码 charset utf-8; # 指定日志记录位置 error_log logs/8024.download.nginx.error.log; access_log logs/8024.download.nginx.access.log download; root /data/; location /download { autoindex on; # 启用文件以目录列表方式输出 autoindex_exact_size off; # 只显示大概大小（单位kb、mb、gb） autoindex_localtime on; # 显示 UTC 时间 } } 日志记录效果 [root@localhost nginx]# tail -n 1 logs/8024.download.nginx.access.log 119.123.151.155:14847 \u003e /download/index.heml 200 223 0.000s 2022-07-26T04:00:10+08:00 OK ","date":"2022-07-22","objectID":"/nginx%E6%90%AD%E5%BB%BA%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1/:0:0","tags":["nginx","文件下载服务"],"title":"nginx搭建文件下载服务","uri":"/nginx%E6%90%AD%E5%BB%BA%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1/"},{"categories":["vim"],"content":" 运行环境： vim:8 neovim:0.7.2 内容来自以下文档： vim官方文档英文版 vim官方文档其它语言版本 Willis翻译的中文文档 vim 与 neovimVim是一个功能强大的文本编辑器，已有20多年历史， Vim 已经积累了大约 30 万行可怕的 C89 代码。 导致程序的维护、Bug 的 修复、以及新特性的添加都变得越来越困难。 巴西程序员 Thiago de Arruda Padilha（aka tarruda）向 Vim开源编辑器项目递交了两大补丁，对Vim的架构进行了大幅调整，结果遭到了Vim作者Bram Moolenaar的拒绝，因为对于Vim这样一个成熟的项目进行如此大的改变风险太高。于是tarruda发起了Vim fork项目Neovim 简单说，neovim是vim重构版本，两者目前活跃的人也很多 安装vim9 [root@localhost vim]# git clone https://github.com/vim/vim.git Cloning into 'vim'... remote: Enumerating objects: 153669, done. remote: Counting objects: 100% (41/41), done. remote: Compressing objects: 100% (30/30), done. remote: Total 153669 (delta 18), reused 22 (delta 11), pack-reused 153628 Receiving objects: 100% (153669/153669), 175.81 MiB | 3.09 MiB/s, done. Resolving deltas: 100% (130555/130555), done. [root@localhost vim]# cd vim/src/ [root@localhost src]# make [root@localhost src]# make install [root@localhost src]# vim --version VIM - Vi IMproved 9.0 (2022 Jun 28, compiled Jul 18 2022 18:32:55) error: NOT FOUND! 在安装vim9过程中make操作报错 [root@localhost src]# make Makefile:298: auto/config.mk: No such file or directory ... no terminal library found checking for tgetent()... configure: error: NOT FOUND! You need to install a terminal library; for example ncurses. On Linux that would be the libncurses-dev package. Or specify the name of the library with --with-tlib. make: *** [auto/config.mk] Error 1 提示缺少libncurses-dev库 yum install ncurses ncurses-devel -y 安装neovim二进制包可以在neovim-releases下载 vim 与 neo vim 配置差异","date":"2022-07-18","objectID":"/%E5%AE%89%E8%A3%85-vim/:0:0","tags":["vim","vim 安装","neovim 安装","error: NOT FOUND!"],"title":"安装 vim","uri":"/%E5%AE%89%E8%A3%85-vim/"},{"categories":["vim"],"content":" 配置文件差异 # vim 的个人配置文件 ~/.vimrc # neovim 的个人配置文件 ~/.config/nvim/init.vim # vim 会话文件 home/.viminfo # neovim 会话文件 ~/.config/nvim/shada/main.shada ","date":"2022-07-18","objectID":"/%E5%AE%89%E8%A3%85-vim/:1:0","tags":["vim","vim 安装","neovim 安装","error: NOT FOUND!"],"title":"安装 vim","uri":"/%E5%AE%89%E8%A3%85-vim/"},{"categories":["vim"],"content":" 运行环境： vim:8 gvim:8 内容来自以下文档： name 使用方式把vimrc.vim替换vimrc；vimrc/放在~/vimrc windows 使用 # D盘源文件，C盘硬链接 [C:\\~]$ mklink /H/J/D C:\\Users\\Administrator\\vimrc D:\\xiaosi\\posts\\vim\\vimrc 为 C:\\Users\\Administrator\\vimrc \u003c\u003c===\u003e\u003e D:\\xiaosi\\posts\\vim\\vimrc 创建的联接 待办清单 日志","date":"2022-07-18","objectID":"/%E6%88%91%E7%9A%84-vimrc/:0:0","tags":["vim","vim 配置","vimrc"],"title":"我的 vimrc","uri":"/%E6%88%91%E7%9A%84-vimrc/"},{"categories":["vim"],"content":" v8运行逻辑： vim根据是否为GUI版本加载配置文件 vim读取文件到缓冲区 调整或定义文件类型（如果有相关设置） 否是为编辑新文件： 编辑新文件：加载CreateFile.vim -\u003e 根据文档类型调用相关配置文件 （如果有相关设置） 编辑现有文件：根据文档类型调用相关配置文件（如果有相关设置） 2022-07月总计更新： 增加配置文件: YamlFileConfig.vim: yaml文件类型配置文件 NginxFileConfig.vim: nginx文件类型配置文件 VimFileConfig.vim: vim文件类型配置文件 修改vimrc.vim文件： 明确指定后缀结尾的文件才能触发BufNewFile事件 FileConfig函数增加vim文件类型 扩展vim文件类型定义 定义nginx文件类型 修改CreateFile.vim: 修改md文件类型插入的内容来满足hugo-FixIt使用 执行逻辑：插入内容-\u003e调用配置文件 改为：调用配置文件 -\u003e 插入内容 移除了python文件类型的插入 修改MarkdownFileConfig.vim： 增加BufWritePre事件，保存md文件时修改文件内容 增加通用配置文件： Gvim.vim: GUI版本通用配置文件 Terminal.vim: 终端通用配置文件 ","date":"2022-07-18","objectID":"/%E6%88%91%E7%9A%84-vimrc/:1:0","tags":["vim","vim 配置","vimrc"],"title":"我的 vimrc","uri":"/%E6%88%91%E7%9A%84-vimrc/"},{"categories":["linux"],"content":" 运行环境： centos:7 squid:3.5 内核:3.10.0-1160.66.1.el7.x86_64 内容来自以下文档： squid官方: 下载 squid官方: 指令说明 Squid极简搭建HTTP/HTTPS代理服务器 squidSquid是一个高性能的代理缓存服务器，Squid用一个单独的、非模块化的、I/O驱动的进程来处理所有的客户端请求。 Squid 提供了丰富的访问控制、授权和日志记录环境来开发 Web 代理和内容服务应用程序。Squid 提供了一组丰富的流量优化选项，其中大部分默认启用，以实现更简单的安装和高性能 安装大部分系统自带有squid安装包 # 查找 squid 相关软件包 [root@localhost ~]# yum serche squid ... squid.x86_64 : The Squid proxy caching server squid-migration-script.x86_64 : Migration script for squid caching proxy squid-sysvinit.x86_64 : SysV initscript for squid caching proxy squidGuard.x86_64 : Filter, redirector and access controller plugin for squid calamaris.noarch : Analyzer and report generator for web proxy servers like Squid libecap.i686 : Squid interface for embedded adaptation modules libecap.x86_64 : Squid interface for embedded adaptation modules ufdbGuard.x86_64 : A URL filter for squid ... # 查看软件包信息 [root@localhost ~]# yum info squid Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.ustc.edu.cn * epel: mirror2.totbb.net * extras: mirrors.tuna.tsinghua.edu.cn * updates: mirrors.ustc.edu.cn Available Packages Name : squid Arch : x86_64 Epoch : 7 Version : 3.5.20 Release : 17.el7_9.6 Size : 3.1 M Repo : updates/7/x86_64 Summary : The Squid proxy caching server URL : http://www.squid-cache.org License : GPLv2+ and (LGPLv2+ and MIT and BSD and Public Domain) Description : Squid is a high-performance proxy caching server for Web clients, : supporting FTP, gopher, and HTTP data objects. Unlike traditional : caching software, Squid handles all requests in a single, : non-blocking, I/O-driven process. Squid keeps meta data and especially : hot objects cached in RAM, caches DNS lookups, supports non-blocking : DNS lookups, and implements negative caching of failed requests. : : Squid consists of a main server program squid, a Domain Name System : lookup program (dnsserver), a program for retrieving FTP data : (ftpget), and some management and client tools. # 安装 [root@localhost ~]# yum install -y squid .... https://www.jianshu.com/p/64a6bcf5f590 配置配置文件默认在/etc/squid/squid.conf [root@localhost ~]# systemctl status squid ● squid.service - Squid caching proxy Loaded: loaded (/usr/lib/systemd/system/squid.service; disabled; vendor preset: disabled) Active: inactive (dead) [root@localhost ~]# [root@localhost ~]# cat /usr/lib/systemd/system/squid.service [Unit] Description=Squid caching proxy After=syslog.target network.target nss-lookup.target [Service] Type=forking LimitNOFILE=16384 EnvironmentFile=/etc/sysconfig/squid ExecStartPre=/usr/libexec/squid/cache_swap.sh ExecStart=/usr/sbin/squid $SQUID_OPTS -f $SQUID_CONF ExecReload=/usr/sbin/squid $SQUID_OPTS -k reconfigure -f $SQUID_CONF ExecStop=/usr/sbin/squid -k shutdown -f $SQUID_CONF TimeoutSec=0 [Install] WantedBy=multi-user.target [root@localhost ~]# [root@localhost ~]# cat /etc/sysconfig/squid # default squid options SQUID_OPTS=\"\" # Time to wait for Squid to shut down when asked. Should not be necessary # most of the time. SQUID_SHUTDOWN_TIMEOUT=100 # default squid conf file SQUID_CONF=\"/etc/squid/squid.conf\" [root@localhost ~]# [root@localhost ~]# grep -v -e '^#' -e '^$' /etc/squid/squid.conf acl localnet src 10.0.0.0/8 # RFC1918 possible internal network acl localnet src 172.16.0.0/12 # RFC1918 possible internal network acl localnet src 192.168.0.0/16 # RFC1918 possible internal network acl localnet src fc00::/7 # RFC 4193 local private network range acl localnet src fe80::/10 # RFC 4291 link-local (directly plugged) machines acl SSL_ports port 443 acl Safe_ports port 80 # http acl Safe_ports port 21 # ftp acl Safe_ports port 443 # https acl Safe_ports port 70 # gopher acl Safe_ports port 210 # wais acl Safe_ports port 1025-65535 # unregistered ports acl Safe_ports port 280 # http-mgmt acl Safe_ports port 488 # gss-http acl Safe_ports port 591 # filemaker acl Safe_ports port 777 # multiling http acl CONNECT method CONNECT http_access deny !Safe_ports http_access deny CONNECT !SSL_por","date":"2022-07-02","objectID":"/squid/:0:0","tags":["squid"],"title":"squid","uri":"/squid/"},{"categories":["linux"],"content":" acl访问控制由访问列表+ACL元素组合形成的。当加载配置文件时，squid 将所有acl行 （指令）作为测试处理到内存中，这些测试可以针对任何请求事务执行。 acl指令指定受控制的地址集合，格式如下： # aclname: acl命令的名称，是唯一的，长度为31字符，只能修改源码实现 # acltype: acl命令元素类型 # argument: 参数，可以有多个 # filename: 从文件中加载参数，文件中的参数以换行符分隔 acl aclname acltype [option] { argument ... | \"filename\" ... } acltype 有以下可用类型 - random # 概率匹配，有以下方式 # - N:M：M个匹配中命中N个，已就是说命中N个之后要等M个后才命中 # - N/M：M分之N概率命中 # - 0.N[NNN]：如 0.1234 表示 12.34% 概率命中 - src # 源地址gIP - dst # 目标地址IP - arp # mac地址 - srcdomain # 源地址g域名 - dstdomain # 目标地址域名 - srcdom_regex # 正则表达式表示的源地址g地址 - dstdom_regex # 正则表达式表示的目标地址地址 - src_as # 系统给源地址标记的编号 - dst_as # 系统给目标地址标记的编号 - peername # 分配给期望发送请求的 cache_peer 标签名 - time # 一天中的时间和星期几 - url_regex # 正则表达式表示的URL - urlpath_regex # 正则表达式表示的URL路径，省略协议和主机名 - port # 目标地址端口 - myip # 监听端口的IP - myport # 监听端口号 - myportname # 监听端口名称 - proto # 协议 - method # http协议请求方法 - http_status # http协议状响应态码 - browser # 正则表达式表示的用户代理标识 - referer_regex # 正则表达式表示的请求 http-referer 标识 - ident # 用户名 - ident_regex # 正则表达式表示的用户名 - proxy_auth # 通过外部进程进行用户身份验证 - proxy_auth_regex # 通过外部进程进行用户身份验证的正则表达式模式匹配 - snmp_community # SNMP 字符串匹配 - maxconn # 单个客户端IP地址最大连接数限制 - max_user_ip # 单个用户可以登录的 IP 地址的最大数量限制 - req_mime_type # 请求内容类型标头上的正则表达式模式匹配 - req_header # 对请求标头内容进行正则表达式模式匹配 - rep_mime_type # 正则表达式模式匹配回复（下载的内容）内容类型标头。这只能在 http_reply_access 指令中使用，而不是 http_access。 - rep_header # 正则表达式模式匹配回复标头内容。这只能在 http_reply_access 指令中使用，而不是 http_access。 - external # 通过 external_acl_type 定义的外部 acl 助手查找 - user_cert # 匹配用户 SSL 证书中的属性 - ca_cert # 与颁发 CA SSL 证书的用户的属性匹配 - ext_user # 匹配由 external_acl_type 定义的外部 acl 帮助程序返回的 user= 字段 - ext_user_regex # 由 external_acl_type 定义的外部 acl 帮助器返回的 user= 字段上的正则表达式模式匹配 option 选项可以修改acl默认行为 -i,+i # 是否区分正则表达式大小写，默认为`+1`表示区分 -n # 域名说地址是否要转换，-n 表示禁用 -m[=delimiters] # 执行列表成员资格测试，多个值使用,分隔 -- # 用于停止处理所有选项 ","date":"2022-07-02","objectID":"/squid/:1:0","tags":["squid"],"title":"squid","uri":"/squid/"},{"categories":["linux"],"content":" 访问日志 # \u003e= 2.6版本 access_log /path/to/finame logformat ","date":"2022-07-02","objectID":"/squid/:2:0","tags":["squid"],"title":"squid","uri":"/squid/"},{"categories":["linux"],"content":" http 相关http_port指定http协议监听的端口 # \u003e=2.6 http_port [ip:|hstname:|ip:]port [mode] [options] http_ports [ip:|hstname:|ip:]port [mode] tls-cert=certificate.pem [options] http_access 根据定义的访问列表允许或拒绝访问，默认为拒绝 http_reply_access 指定请求出口IP tcp_outgoing_address: 指定请求出口的IP，优先级从上往下 tcp_outgoing_tos: 指定请求的TOS tcp_outgoing_mark: 可以根据防火墙标记指定出口IP tls_outgoing_options： TLS相关 udp_outgoing_address UDP相关 tcp_outgoing_address示例： 该方式只适本地连接，如果使用客户端能需要用cache_peer重写地址 acl my src 119.123.150.24 http_access allow my acl output2 random 0.5 # 有50%概率使用16 ip作为出口 tcp_outgoing_address 103.106.246.16 output2 acl output1 myport 831 # 使用连接 831 端口时使用17 IP做为出口 tcp_outgoing_address 103.106.246.17 output1 # 关闭持久连接 server_persistent_connections off forwarded_for delete via off http_access deny all 正向代理 http_access allow all https_port 222 \\ cert=/etc/letsencrypt/live/pro/fullchain.pem \\ key=/etc/letsencrypt/live/prox/privkey.pem # 清除请求中的代理头信息 request_header_access Via deny all request_header_access X-Forwarded-For deny all request_header_access Proxy-Authorization deny all request_header_access Cache-Control deny all # 清除响应中的代理头信息 reply_header_access Via deny all reply_header_access X-Forwarded-For deny all reply_header_access Proxy-Authenticate deny all reply_header_access WWW-Authenticate deny all forwarded_for off ","date":"2022-07-02","objectID":"/squid/:3:0","tags":["squid"],"title":"squid","uri":"/squid/"},{"categories":["linux"],"content":" http [root@localhost squid]# cat squid.conf #http_access allow all http_port 3121 auth_param basic program /usr/lib64/squid/basic_ncsa_auth /etc/squid/userpasswd auth_param basic realm proxy auth_param basic children 10 auth_param basic realm CoolTube Proxy Serve #auth_param basic credentialsttl 24 hours acl authenticated proxy_auth REQUIRED http_access allow authenticated http_access deny all #visible_hostname squid.CoolTube forwarded_for off request_header_access Allow allow all request_header_access Authorization allow all request_header_access WWW-Authenticate allow all request_header_access Proxy-Authorization allow all request_header_access Proxy-Authenticate allow all request_header_access Cache-Control allow all request_header_access Content-Encoding allow all request_header_access Content-Length allow all request_header_access Content-Type allow all request_header_access Date allow all request_header_access Expires allow all request_header_access Host allow all request_header_access If-Modified-Since allow all request_header_access Last-Modified allow all request_header_access Location allow all request_header_access Pragma allow all request_header_access Accept allow all request_header_access Accept-Charset allow all request_header_access Accept-Encoding allow all request_header_access Accept-Language allow all request_header_access Content-Language allow all request_header_access Mime-Version allow all request_header_access Retry-After allow all request_header_access Title allow all request_header_access Connection allow all request_header_access Proxy-Connection allow all request_header_access User-Agent allow all request_header_access Cookie allow all request_header_access All deny all request_header_access Via deny all request_header_access Forwarded-For deny all request_header_access X-Forwarded-For deny all cache deny all ","date":"2022-07-02","objectID":"/squid/:4:0","tags":["squid"],"title":"squid","uri":"/squid/"},{"categories":["linux"],"content":" 内容来自以下文档： 官方文档 开源访谈录：章文嵩：开源为我打开一扇窗 Linux Virtual ServerLVS项目是由章文嵩在1998年成立的，中国国内最早出现的自由软件项目之一。 目前最近有关作者信息： 2009年9月，36岁的章文嵩加入淘宝，任资深技术总监。 2016年5月，章文嵩出任滴滴出行高级副总裁 2021年4月，加入高瓴集团 Linux Virtual Server 简称LVS。项目的基本目标是构建高性能、高可用的服务器， 提供良好的可扩展性、可靠性和可服务性。LVS 集群系统也称为负载均衡服务器集群。 目前，LVS项目已提供了一个实现可伸缩网络服务的Linux Virtual Server框架： 三种IP负载均衡技术的IP虚拟服务器软件IPVS 基于内容请求分发的内核Layer-7交 换机KTCPVS和集群管理软件 可以利用LVS框架实现高可伸缩的、高可用的Web、Cache、Mail和Media等网络服务； 在此基础上，可以开 发支持庞大用户数的、高可伸缩的、高可用的电子商务应用。 LVS集群采用三层结构，主要组成部分为： 负载调度器（load balancer），它是整个集群对外面的前端机，负责将客户的请求发送到一组服务器上执行，而客户认为服务是来自一个IP地址（我们可称之为虚拟IP地址）上的。 服务器池（server pool），是一组真正执行客户请求的服务器，执行的服务有WEB、MAIL、FTP和DNS等。 共享存储（shared storage），它为服务器池提供一个共享的存储区，这样很容易使得服务器池拥有相同的内容，提供相同的服务。 IP虚拟服务器软件IPVS在调度器的实现技术中，IP负载均衡技术是效率最高的。IPVS软件实现了三种IP负载均衡技术，它们的大致原理如下： Virtual Server via Network Address Translation（VS/NAT）： 通过网络地址转换，调度器重写请求报文的目标地址，根据预设的调度算法，将请求 分派给后端的真实服务器；真实服务器的响应报文通过调度器时，报文的源地址被重写， 再返回给客户，完成整个负载调度过程。 Virtual Server via IP Tunneling（VS/TUN）： 采用NAT技术时，由于请求和响应报文都必须经过调度器地址重写，当客户请求 越来越多时，调度器的处理能力将成为瓶颈。为了解决这个问题，调度器把请求报文 通过IP隧道转发至真实服务器，而真实服务器将响应直接返回给客户，所以调度器只 处理请求报文。由于一般网络服务应答比请求报文大许多，采用 VS/TUN技术后，集群 系统的最大吞吐量可以提高10倍。 Virtual Server via Direct Routing（VS/DR）： VS/DR通过改写请求报文的MAC地址，将请求发送到真实服务器，而真实服务器将响应 直接返回给客户。VS/DR技术可极大地 提高集群系统的伸缩性。这种方法没有IP隧道的 开销，对集群中的真实服务器也没有必须支持IP隧道协议的要求，但是要求调度器与 真实服务器都有一块网卡连在同一物理网段上。 针对不同的网络服务需求和服务器配置，IPVS调度器实现了如下八种负载调度算法： 轮巡（Round Robin）： 调度器通过\"轮叫\"调度算法将外部请求按顺序轮流分配到集群中的真实服务器上， 它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。 加权轮叫（Weighted Round Robin） 调度器通过\"加权轮叫\"调度算法根据真实服务器的不同处理能力来调度访问请求。这样 可以保证处理能力强的服务器处理更多的访问流量。调度器可以自动问询真实服务器的 负载情况，并动态地调整其权值。 最少链接（Least Connections）： 调度器通过\"最少连接\"调度算法动态地将网络请求调度到已建立的链接数最少的服务器上 。如果集群系统的真实服务器具有相近的系统性能，采用\"最小连接\"调度算法可以较好 地均衡负载。 加权最少链接（Weighted Least Connections）： 在集群系统中的服务器性能差异较大的情况下，调度器采用\"加权最少链接\"调度算法优化 负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动 问询真实服务器的负载情况，并动态地调整其权值。 基于局部性的最少链接（Locality-Based Least Connections）： “基于局部性的最少链接” 调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器 是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用\"最少链接\"的原则选出一个可用的服务 器，将请求发送到该服务器。 带复制的基于局部性最少链接（Locality-Based Least Connections with Replication）： “带复制的基于局部性最少链接\"调度算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。它与LBLC算法的不同之处是它要维护从一个 目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。该算法根据请求的目标IP地址找出该目标IP地址对应的服务 器组，按\"最小连接\"原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器，若服务器超载；则按\"最小连接\"原则从这个集群中选出一 台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的 程度。 目标地址散列（Destination Hashing）： “目标地址散列\"调度算法根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 源地址散列（Source Hashing）： “源地址散列\"调度算法根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。 ipvsadmLVS在已经加入到内核中，高与2.6.10版本中直接安装管理工具ipvsadm [root@localhost ~]# uname -r 3.10.0-1160.66.1.el7.x86_64 [root@localhost ~]# yum install -y ipvsadm 查看生成的文件 [root@localhost ~]# rpm -ql ipvsadm # 配置文件 /etc/sysconfig/ipvsadm-config # systemctl 服务配置文件 /usr/lib/systemd/system/ipvsadm.service # 配置规则命令 /usr/sbin/ipvsadm # 规则保存命令 /usr/sbin/ipvsadm-restore # 重载配置文件命令 /usr/sbin/ipvsadm-save /usr/share/doc/ipvsadm-1.27 /usr/share/doc/ipvsadm-1.27/README /usr/share/man/man8/ipvsadm-restore.8.gz /usr/share/man/man8/ipvsadm-save.8.gz /usr/share/man/man8/ipvsadm.8.gz ","date":"2022-06-28","objectID":"/lvs/:0:0","tags":["lvs","linux"],"title":"lvs","uri":"/lvs/"},{"categories":["游戏"],"content":" 内容来自以下文档： 卡普空官方: 街霸5角色数据 暧昧の丁酱: 格斗游戏术语详解之 —-街霸5基本系统篇 暧昧の丁酱: 格斗游戏术语详解之 —-格斗游戏通用术语篇 emojixd: emoji图标 街霸 街霸5 按键说明以下说明文档角色位置默认在左边。除非有有特殊说明。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:0:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 按键修改街霸5默认是手柄操作，初次进入游戏时会提示修改一次， 键盘玩家不要被图标上的字母误导。进入游戏后在选项-\u003e其它设置-\u003e键位设置中修改 图标 键盘默认键 对战场 菜单表 A G 轻脚 确定 B N 中脚 返回 X G 轻拳 Y H 中拳 RB J 重拳 LB K 同时按3种拳 RT M 重脚 LT , 同时按3种脚 RS LS ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:1:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 玩家通用在玩家交流中，用小键盘上的数字表示方向，用英文首字母表示基本拳脚 7(左上) 8(上) 9(右上) 4(左) 5 6(右) 1(左下) 2(下) 3(右下) 基本拳脚 拳(Punch) 脚(Kick) 跳(Jump) 轻(Light) LP LK 中(Medium) MP MK 重(Heavy) HP HK ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:2:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 文档中的按键表示 特殊字符 含义 ⇖ 左上 ⇑ 上 ⇗ 右上 ⇐ 左 ⇒ 右 ⇙ 左下 ⇓ 下 ⇘ 右下 👊🏻 轻拳 👊🏽 中拳 👊🏿 重拳 👊 拳，表示轻/中/重拳之一 🦶🏻 轻脚 🦶🏽 中脚 🦶🏿 重脚 🦶 脚,表示轻/中/重脚之一 格斗游戏常见术语","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:3:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 帧数帧（frame），即游戏中的最短的时间单位，对于现在的大部分格斗游戏而言， 1秒=60帧。同时这个单位也是游戏处理输入指令的最小时间单位，一般缩写为f, 人类的极限反应时间一般为12帧。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:4:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 发生帧/Startup/前摇攻击实际生效之前的准备动作，在此期间不会打出伤害 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:5:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 持续帧/Active攻击以经开始，在这期间命令对方才可能打出伤害， 发生帧最后一帧和持续帧第一帧是重叠的。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:6:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 后摇/收招帧/Recovery招式释放后返回初始状态的收招动作 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:7:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 立回/Footsies/走位一个较为模糊的概念。格斗游戏中，指双方均未占得优势时采取的各种行为，包括移动、跳跃、试探性攻击等。立回的意义是为了能让自己长期处于一个有利的状态，从而能够成功施展连段或对对手产生压制。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:8:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 确认/Confirm广义指任何确认敌我状态的行为。狭义指击中确认（Hit-Confirm），即击中对手时反应过来确定对手被打从而追加之后的打击。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:9:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 有利帧/不利帧/+X帧/-X帧常用于讨论出招被防御、出招击中、起身等多种情况，用来描述敌我可先动作的时间，如果自己可以比对手先进行下一个动作则称为有利（帧数表体现为+X帧），如果对手可以比自己先进行下一个动作则称为不利（帧数表体现为-X帧）。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:10:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 派生技能部分特定招式使用之后可以后续接的必杀技为派生技。派生只能在其基本招式使用后放出， 不可单独使用。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:11:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 凹预判对方动并针对它发动的意想不到的攻击。 一旦没有击中对方会产生极大的不利，通常会导致严重的后果 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:12:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 目押/Link利用击中的有利帧数，使进攻方的普通技（或必杀技）之间产生衔接，形成连段，使被攻击方产生连续的受创状态。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:13:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 确反使用被防不利帧数较多的招式被防之后，会产生较长时间的硬直， 对方利用这段硬直时间进行的攻击行为称作确反 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:14:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 差合打中对方使用招式时延伸出来的拳脚 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:15:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 波/Fireball最早用于称呼格斗游戏中的波动拳，后逐渐演变为格斗游戏中对飞行道具的统称。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:16:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 升龙/SRK/Dragon Punch最早用于称呼街霸中的升龙拳，后逐渐演变为格斗游戏中对具有对空性能招式的统称， 通常动作与升龙拳类似，并会于出招时离开地面。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:17:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 民工连非贬义，一般指起手要求较低、难度相对较低、伤害较为可观的连段 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:18:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 装逼连一般指观赏性较高，但伤害性价比较低的连段 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:19:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 择/Mixup压制对手时让对手猜测你不同进攻方式的局面。 如果进攻方同时拥有两种甚至多种可选择的进攻行为， 且被攻击的一方不能同时防御这两个选项，只能猜测其中一种进行防御时， 则称进攻方对防守方的二择 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:20:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 对空/Anti Air通常指各种应对对方跳入攻击的手段、招式 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:21:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 相杀指双方的攻击同时命中对方，一般情况下双方都会受到伤害 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:22:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 嘲讽/Taunt/Tea Bag 通过输入特定指令来完成游戏中已经预设的嘲讽动作 Teabag，也可以简称为T-bag：是一个梗，将睾丸拖到性伴侣额头上/口腔里的行为， 就像在吊茶包。赢了之后面对地上躺着对手，不断地下蹲鬼畜来隐喻这个梗 街霸5对战系统与玩家通用语在游戏中主页面 -\u003e 挑战模式 -\u003e 演示 -\u003e VOL1 中也有系统介绍 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:23:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 移动控制游戏只有2个维度，控制角色移动有以下方式 向前移动：⇒ 向后移动：⇐ 前冲/dash/66：快速连续按2次⇒⇒可以使角色快速向前一段距离，俗称66。 后冲/back/44：快速连续按2次⇐⇐可以使角色快速后冲，俗称44。 所有角色在后冲的前2帧（1/30秒）免疫投技，从第3帧开始处于空中状态有被康判断 向上跳：⇑ 向前跳：⇗ 向后跳：⇖ 街霸5中角色永远会自动面向对方，因此，涉及有方向键的操作时， 左边角色与右边角色方向建成镜像。比如： 前冲 角色在左边时：⇒⇒ 角色在右边时：⇐⇐ 波动拳指令： 角色在左边时为：⇓⇘⇒+👊（从下逆时针90度） 角色在右边时为：⇓⇙⇐+👊（从下顺时针90度） 升龙拳指令： 角色在左边时为：⇒⇓⇘+👊（从右顺时针90度再逆时针45度） 角色在右边时为：⇐⇓⇙+👊（从左逆时针90度再顺时针45度） ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:24:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 普通攻击普通攻击有三种力度： 轻：造成伤害少，攻击后摇小 中：造成伤害一般，攻击后摇中等 重：造成伤害大，攻击后摇大 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:25:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 特殊技/Unique Attack单一方向+特定拳脚所释放的招式。 每个角色都有自己的特殊技，具体参考角色的出招表 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:26:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 必杀技/Special Move较为华丽的必杀往往就代表着更为复杂的招式， 在一定时间内输入方向键组合后再按1个特定建。 街霸2时代开始人们把必杀技主要分为指令型，蓄力型，360型，连打型： 指令型必杀技：是按特定顺序摇方向+拳脚按键释放 蓄力型必杀技：是按住一个方向一定时间，然后拨向另一个方向同时按下拳脚按键释放 360型必杀技：需要短时间内按出（与顺序无关）上下左右四个方向之后， 按下拳脚按键释放 连打型必杀技：连打型需要短时间内迅速按下数次同类型（即拳或脚）按键释放 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:27:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" Grtitcal Gauge/EX能量槽Ex能量槽处于最下方： 使用EX必杀技消耗一格 使用超级必杀技消耗三格 攻击、防御可以增加EX能量槽 EX能量槽可以保留到下一场 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:28:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" EX必杀/EX Special在一定时间内输入方向键组合后再2个特定键， 同时消耗一格EX蓝色能量槽从而获得的增强型必杀技， 伤害、判定、属性都可能会有所变化。身体会发出黄色的闪光。 此外，EX必杀技只有一种力度。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:29:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 超必杀技/CA/Critical Art消耗三格EX蓝色能量槽释放的伤害极高的技能。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:30:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" V系统的VS、VT、VR屏幕下方红色的计量槽称为V系统(V-System)可以通过被打、成功使用VS、 打对手C康等方式积累，各个角色V计量槽长度不完全相同： vs/v-skill：按👊🏽+🦶🏽（部分角色会在这个基础上有其他输入）释放的技能。 成功产生效果之后可以增加V系统计量槽。 VT(V-Trigger)：V系统计量槽完全充满之后可以按👊🏿+🦶🏿释放的技能 VR(V-Reversal)：在防御对手攻击的动画时间期间按下⇒+👊/🦶(因角色而异）， 消耗一格V系统计量槽，使自己脱离不利环境的技能。VR都具有对打击和飞行道具无敌， 但不能脱离投技 V能量槽无法保留到下一场 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:31:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 判定范围与防御对方攻击时，如果你在命中判定范围内且处于站立或蹲下姿态时， 按⇐键可以进入防御状态。防御是免受除投技技能以外其它攻击伤害方式一种 按攻击命中的判断高度可简单分为： 上段攻击：可以被站防，蹲防的招式 中段攻击：只能被站防的招式 下段攻击：只能被蹲防的招式 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:32:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 逆向/Cross-up使对手必须要拉当前面对的方向（而不是拉后）才能防御的攻击。 一般是跳跃攻击或者是“闪现”到身后的攻击。 己方版边会出现橙色“Cross-up”字样。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:33:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 投技投技分为普通投技与指令投： 普通投技/Throw与拆投/Tech Throw：按下👊🏻+🦶🏻所释放的技能， 只有接近对方才能命中，该技能不能被普通防御，只能被拆投或免疫投技令其失效。 拆投是指对方普通投生效之前使用投技可以让对手的投技失效。 可以配合方向建决定角色投掷方向(⇒/⇐+👊🏻+🦶🏻)缺省方向键时默认 向前投掷 指令投/Command Throw: 必杀技的一种，不可防御，也不能拆投。伤害通常很可观 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:34:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 打康/Counter在对方整套技能动作完成之前打命中对方，俗称打康。 打出普通Counter可以延长对手的受创硬直2帧。 成功时己方版边会出现黄色“Counter”字样，且会增加V系统能量槽与EX能量槽。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:35:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" C康/Crush Counter在对方整套技能动作完成之前使用特定的招式击倒对方， 对手会产生一个相当长时间的硬直或者直接倒地。 成功时己方版边出现橙色“Crush Counter”字样且会增加较多的V系统能量槽与EX能量槽。 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:36:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 击晕/Stun血量槽下方的一条短槽。受到伤害时会积累眩晕槽，一旦眩晕槽充满立即进入眩晕状态， 角色会立刻倒地，起身之后保持眩晕状态一段时间。 眩晕状态头上出现星星或骷髅且无法动作 将对手击晕后，在对方醒来之前继续连段会保持连击数 在一段时间内未被对方触碰或命中可以减少自己的眩晕槽 使用VR技能可以减少自己的眩晕槽 已被击晕的玩家通过快速输入大量指令俗称搓摇杆）来减少自己眩晕状态持续时间 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:37:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 可恢复血量/白血防御中攻击或重攻击、霸体时收到伤害、被对手的VR等击中都会使生命槽部分血量变为白色 ，如果一段时间内没有被攻击摸到就会缓慢恢复， 如果被对手击中就会直接从绿色部分连同白血一起扣掉。 些外如是存在白血时则只能被超必杀技能被击败 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:38:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 磨血/Chip Damage防御必杀技或超必杀技时会扣除一小部分的血量。但只有超必杀技可以将人磨血致死。 磨血死亡的情况下获胜亮灯那里会显示为“C” ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:39:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 胜利条件双方血条中间有个计时器，如果在这时间内打掉对方血条能获胜。如果当计时器为0时， 双方血条长的一方获胜，否则平局 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:40:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 无敌状态/Invicibility无敌可以无法被某些攻击类型命中 飞行道具无敌：无法被飞行道具命中 投技无敌：无法被投技命中 完全无敌：无法被所有技能命中 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:41:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 霸体/Armor部分招式具有收到攻击时不会产生受创硬直、不会打断当前动作的特性称为霸体： 霸体状态时受到的伤害会完全转化为可恢复血量（即白血） 霸体状态无法阻挡投技以及超必杀技 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:42:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 起身方式倒地后使用一定方式可以减少自然起身时间： 快速起身/Quick Rise：在角色被击倒即将落地时按⇓或两个以上👊 可以较快的从地面原地起身 向后起身/Back Rise：在角色被击倒即将落地时按⇐或两个以下🦶 可以较快的从地面向后弹跳起身。相比向后起身比快速起身时间多5帧 有些情况无法快速起身： 被投技投掷后无法向后快速起身 被蹲下🦶🏿后无法快速起身（成为不可快速起身性质） 部分超必杀技可以让对方无法快速起身 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:43:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 反击在起身或防御过程中输入指令，一但可以行动便立即发动技能 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:44:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 取消/Cancel与僵直在使用一个招式命令对方后，在特殊时间段输入下一个招式。如果下一个招式成立， 则跳过当前招式后摇直接打出下一个招式 使用特定招式后进入僵直状态一段时间，在该状态下无法操作角色。攻击越强， 僵直时间越长： 完全僵直：无法防御、无法接收指令、无法移动 可防御僵直：无法接收指令、无法移动，可防御 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:45:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 修正/Proration为了防止连招伤害过高，在连段中每个后续的招式会递减伤害和眩晕值（不会低到0）。 连击数每+1，则伤害逐步-10% 血量较低时所受的伤害也会降低。 超必杀至少会造成基础伤害的50% 在VT技能持续其间，无视修正且连击数越多伤害反而越高 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:46:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 攻击优先级双方攻击同时生效时： 较重的攻击会对较轻的攻击产生打康效果 必杀技不具有优先级，可以和任何拳脚相杀 投技优先级比打击高 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:47:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 补正/reset部分特殊打击会使对方向后空翻后进入站立状态称为空中受身， 在其期间对方处于无敌状态 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:48:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" TC/Target Combo多个普通拳脚或特殊技之间可以取消的连段称作TC， 它是特殊技的一种，因此不同角色均有自己的TC技 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:49:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 松键输入/Negative Edge按住拳脚按键一段时间，松开按键时才会释放的技能。 在松开按键时判定必杀技是否成立。 例如⇓🦶🏽⇓⇙⇐🦶🏽可以简化为：⇓(长按🦶🏽)⇙⇐(松开🦶🏽) 角色数据角色技能在游戏中主页面 -\u003e 挑战模式 -\u003e 演示 -\u003e VOL2至vol7 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:50:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 春丽数值： 来自卡普空官网：CHUN-LI 本文档更新时间：2022-06-26 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:51:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 技能 技能类型 技能名称 指令 特殊技 Senenshu ⇘+🦶🏽 特殊技 Tsuitotsuken ⇐/⇒+👊🏽 特殊技 Hakkei ⇐+👊🏿 特殊技 Kakurakukyaku ⇘+👊🏽 特殊技 Tenkukyaku ⇐+🦶🏽 特殊技 Yokusenkyaku ⇒+🦶🏽 特殊技 Yosokyaku (⇓+🦶🏿)x3 特殊技 Wall Jump 在板边浮空时+⇗ 投技 Koshuto [⇒]+👊🏻+🦶🏻 投技 Tenshin Shushu ⇐+👊🏻+🦶🏻 投技 Ryuseiraku 近身时+👊🏻+🦶🏻 VS1技1 Rankyaku 🦶🏽+🦶🏽 VS1技1+1 Souseikyaku 🦶🏽+🦶🏽-\u003e🦶🏽+🦶🏽 VS1技2 Hazansyu 👊🏽+🦶🏽 VT技 Renkiko 👊🏿+🦶🏿 VR技 Sohakkei 防御时+⇒+👊 VR技 V-Shift 👊🏿+🦶🏽 VR技 Ensenbu 👊🏿+🦶🏽成功躲避后\u003e👊🏿+🦶🏽 必杀技 Kikoken ⇐蓄力\u003e⇒+👊 EX必杀技 EX Kikoken ⇐蓄力\u003e⇒+👊+👊 必杀技 Hyakuretsukyaku (可在空中)⇓⇘⇒+🦶 或 🦶x7 EX 必杀技 EX Hyakuretsukyaku (可在空中)⇓⇘⇒+🦶+🦶 或 (🦶+🦶)x7 必杀技 Spinning Bird Kick ⇓蓄力\u003e⇑+🦶 EX 必杀技 EX Spinning Bird Kick ⇓蓄力\u003e⇑+🦶+🦶 CA 技 Hoyokusen (⇓⇘⇒)x2+🦶 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:51:1","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 隆/RYU数值： 来自卡普空官网：RYN 本文档更新时间：2022-06-26 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:52:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 技能表 技能类型 技能名称 指令 说明 特殊技 Collarbone Breaker ⇒👊🏽 特殊技 Solar Plexus Strike ⇒👊🏿 特殊技 Axe Kick ⇐🦶🏿 特殊技 Jodan Nirengeki 👊🏿命中时\u003e🦶🏿 特殊技 Jodan Sanrengeki 站立时👊🏽\u003e👊🏿 特殊技 Jodan Sanrengeki(1) 👊🏽命中时\u003e⇓+👊🏿 投技 Shoulder Throw [⇒]+👊🏻+🦶🏻 近身时命中 投技 Somersault Throw ⇐+👊🏻+🦶🏻 近身时命中 VS1技 Mind’s Eye 👊🏽+🦶🏽 招架 VS2技 Thust Strike 👊🏽+🦶🏽 VT 技 Denjin Renki 👊🏿+🦶🏿 VR 技 DURING GUARD (防御时)⇒+👊 VR 技 V-Shift 👊🏿+🦶🏽 VR 技 V-Shift 👊🏿+🦶🏽成功躲避后\u003e👊🏿+🦶🏽 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:52:1","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 纳什/nash数值: 来自卡普空官网：NASH 文档更新时间：2022-06-30 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:53:0","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["游戏"],"content":" 技能表 技能类型 技能名称 指令 说明 特殊技 Chopping Assault ⇒+👊🏽 特殊技 Spinning Back Knuckle ⇒+👊🏿 特殊技 Knee Bazooka ⇒+🦶🏻 特殊技 Jumping Sobat ⇒+🦶🏽 特殊技 Side Knee Attack ⇐+🦶🏽 特殊技 Step Kick ⇒+🦶🏿 特殊技 Rainfall (直跳在空中时)⇑+🦶🏿 特殊技 Rapid Punch 👊🏻\u003e👊🏽 特殊技 Rapid Kick 👊🏻\u003e🦶🏽 特殊技 Wind Shear 👊🏽\u003e🦶🏻\u003e[👊🏿] 特殊技 Down Burst ⇓+👊🏽\u003e⇒+👊🏽 特殊技 Combination 🦶🏽\u003e🦶🏿 特殊技 Raptor Combination 🦶🏽\u003e🦶🏿\u003e🦶🏽 特殊技 Bullet Combination 🦶🏽\u003e🦶🏿\u003e👊🏽+🦶🏽 VS-1 特殊技 Gust Front ⇒+🦶🏻\u003e👊🏿 投技 Dragon Suplex [⇒+]👊🏻+🦶🏻 近身时命中 投技 Target Down ⇐+👊🏻+🦶🏻 近身时命中 投技 Air Jack (空中)👊🏻+🦶🏻 VS技 Bullet Clear 👊🏽+🦶🏽 VS-1 VT技 Sonic Move - Hide [⇓+]👊🏿+🦶🏿 VS-1 VT技 Sonic Move - Blitz Air ⇐+👊🏿+🦶🏿 VS-1 VT技 Sonic Move - Steel Air ⇒+👊🏿+🦶🏿 VS-1 VS技 Silent Sharpness 👊🏽+🦶🏽 VS-2 VT技 Stealth Dash 👊🏿+🦶🏿 VS-2 VT技 Stealth Dash Stop 👊🏿+🦶🏿-\u003e⇐ VS-2 VT技 Justice Corridor 👊🏿+🦶🏿-\u003e👊 VS-2 VT技 Justice Shell 👊🏿+🦶🏿-\u003e🦶 VS-2 VR技 Sonic Move - Avoid (防御时)⇒+🦶🏻+🦶🏽+🦶🏿 V闪技 V-Shift/V闪 👊🏿+🦶🏽 V闪技 Vengeful Bullet 👊🏿+🦶🏽(成功躲避后)\u003e👊🏿+🦶🏽 必杀技 Sonic Boom ⇓⇘⇒+👊🏻/👊🏽/👊🏿 EX 必杀技 EX Sonic Boom ⇓⇘⇒+👊+👊\u003e[👊] 必杀技 Moonsault Slash ⇓⇘⇒+🦶🏻/🦶🏽/🦶🏿 EX 必杀技 Moonsault Slash ⇓⇘⇒+🦶+🦶 必杀技 Tragedy Assault ⇒⇓⇘+👊🏻/👊🏽/👊🏿 EX 必杀技 EX Tragedy Assault ⇒⇓⇘+👊+👊 必杀技 Sonic Scythe ⇓⇙⇐+🦶🏻/🦶🏽/🦶🏿 EX 必杀技 EX Sonic Scythe ⇓⇙⇐+🦶+🦶 CA 技 Judgement Saber (⇓⇙⇐)x2+👊 ","date":"2022-06-24","objectID":"/%E8%A1%97%E9%9C%B85/:53:1","tags":["街霸5"],"title":"街霸 5","uri":"/%E8%A1%97%E9%9C%B85/"},{"categories":["hugo"],"content":"测试hugo","date":"2022-06-04","objectID":"/hugo/","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 运行环境： hugo: 0.102.0、0.111.3 centos:7 docker:20 内容来自以下文档： hugo官方文档 凡梦星尘: hugo-theme-next 大妞: inux inotify 研究7 微力同步用户使用手册 Artalk官方文档 hugoHugo是一个用Go编写的快速而现代的静态网站生成器 安装有以下几种安装方式： 从hugo-Releases下载二进制包直接运行。 但二进制包生产的编译环境高于当前使用环境时，无法运行。 如v0.101.0无法在centos7运行 源码编译，推荐方式 docker镜像，没必要且使用场景少 ","date":"2022-06-04","objectID":"/hugo/:0:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 源码编译 mkdir $HOME/src cd $HOME/src git clone https://github.com/gohugoio/hugo.git cd hugo go install --tags extended # 编译完成后hugo在$GOPATH变量值目录中 # 如果该变量值为空则在$HOME/go/bin下 [root@localhost ~]# /root/go/bin/hugo version hugo v0.102.0-DEV-223bf2800488ad5d38854bbb595d789bc35ebe32+extended linux/amd64 BuildDate=2022-07-09T14:03:11Z # [root@localhost ~]# mv /root/go/bin/hugo /usr/local/bin/ [root@localhost ~]# hugo version hugo v0.102.0-DEV-223bf2800488ad5d38854bbb595d789bc35ebe32+extended linux/amd64 BuildDate=2022-07-09T14:03:11Z ","date":"2022-06-04","objectID":"/hugo/:1:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 直接安装（不修改源码）v0.111.3+extended安装前提 安装 git 安装 go 1.18+ 安装目录由 GOPATH 和 GOBIN 环境变量控制。如果设置了 GOBIN，则会将二进制文件安装到该目录。如果设置了 GOPATH，则二进制文件将安装到 GOPATH 列表中第一个目录的 bin 子目录中。否则，二进制文件将安装到默认 GOPATH 的 bin 子目录（$HOME/go 或 %USERPROFILE%\\go） [root@localhost ~]# go install -tags extended github.com/gohugoio/hugo@latest [root@localhost ~]# [root@localhost ~]# /root/go/bin/hugo version hugo v0.111.3+extended linux/amd64 BuildDate=unknown [root@localhost ~]# mv /root/go/bin/hugo /usr/local/bin/ ","date":"2022-06-04","objectID":"/hugo/:2:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" docker 运行 hugo官方没有制作 docker 镜像，但推荐使用 klakegg/hugo。 该镜像有几个标签： latest：基础版，是基于 busybox ext：扩展版，有基于 alpine debian 等系统 初始化目录： [root@c8 hugo]# docker container run --rm -it -v $(pwd):/src klakegg/hugo:ext-alpine new site book Congratulations! Your new Hugo site is created in /src/book. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new \u003cSECTIONNAME\u003e/\u003cFILENAME\u003e.\u003cFORMAT\u003e\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. [root@c8 hugo]# ls book 运行服务： [root@c8 book]# docker container run -d --name book -it -v $(pwd):/src -p 1313:1313 klakegg/hugo:ext-alpine server -t book 362614c608e99215961fee9c1fe3d8473944b3a47d28893c5a6a2f6e3cfceefb ","date":"2022-06-04","objectID":"/hugo/:3:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 注意事项配置文件中的bashURL不会覆盖默认值，可以通过-b或--baseURL覆盖 [root@localhost next]# grep \"baseURL\" config.yaml baseURL: a.b.c [root@localhost next]# docker container run --rm -it -v $(pwd):/src klakegg/hugo:ext-alpine server Start building sites … ... Web Server is available at //localhost:1313/ (bind address 0.0.0.0) Press Ctrl+C to stop [root@localhost next]# docker container run --rm -it -v $(pwd):/src klakegg/hugo:ext-alpine server -b a.b.c Start building sites … ... Web Server is available at //a.b.c:1313/ (bind address 0.0.0.0) Press Ctrl+C to stop 目录结构 [root@localhost hugo]# ls next/ | sed 's/ /\\n/' # hugo new 命令创建的文档存放位置 archetypes # 配置文件，也可以是config目录 config.toml # 原使网站内容，即md文档之类的 content # 生成网站时可使用的配置文件或数据模板目录 data # 以文件的形式存储模板，指定如何将内容视图呈现到静态网站中。 # 模板包括列表页 、主页、 分类模板、 部分、 单页模板等。.html layouts # hugo生成的所有静态内容，即网站主页 # 从 Hugo 0.31 开始，您可以拥有多个静态目录。 public # 静态内容 static # 主题文件 themes 命令","date":"2022-06-04","objectID":"/hugo/:3:1","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" hugohugo命令用来快速生成静态页面 # hugo [flags] -b, --baseURL string # 修改访问网站的URL地址 -D, --buildDrafts # 生成静态页面时包含 draft 标记的文档 -E, --buildExpired # 生成静态页面时包含 expired 标记的文档 -F, --buildFuture # 生成静态页面时包含 Future 标记的文档 -d, --destination string # 静态页面位置 -e, --environment string # 包含环境变量 -t, --theme strings # 指定主题 配置文件配置文件有yaml,json,toml三种格式， 默认配置文件为config.toml，在主目录下。 可以使用hugo --config选项指定1个或多个配置文件 hugo --config debugconfig.toml # 多个配置文件使用逗号分隔 hugo --config a.toml,b.toml,c.toml 还可以在主目录下使用配置目录config，可以把配置项目分为多个文件，方便维护 ├── config │ ├── _default # 默认配置文件 │ │ ├── config.toml # 配置文件 │ │ ├── languages.toml # languages对象配置文件 │ │ ├── menus.en.toml │ │ ├── menus.zh.toml │ │ └── params.toml # params对象配置文件 │ ├── production │ │ ├── config.toml │ │ └── params.toml │ └── staging │ ├── config.toml │ └── params.toml # 每个文件表示一个配置根对象，在对象配置文件中，内容必须是顶级的 以下是一些配置说明，更多配置查看官方文件 # 内容模板目录位置 # 所需版本：Hugo 0.56 archetypeDir: \"archetypes\" # 资源文件的目录 # 所需版本：Hugo 0.56 assetDir: “assets” # hostname，为/时表示本地 baseURL: \"\" # 启用 balckFriday(Markdown 渲染引擎，已被Goldmark取代) blackfriday # 构建静态文件时的选项 # https://next--gohugoio.netlify.app/documentation/getting-started/configuration/#configure-build # New in v0.66.0 build: # 是否将 jsconfig.json 写入 /assets 目录， # 该文件旨在帮助在 VS Code 等代码编辑器中进行智能感知/导航 # New in v0.78.0 noJSConfigInAssets: false # 何时将 /resources/_gen 中的缓存资源用于 PostCSS 和 ToCSS。有以下值： # - never: 禁止 # - always: 总是 # - fallback: 如果 PostCSS/扩展版本不可用，将尝试缓存 # New in v0.78.0 useResourceCacheWhen: fallback # 生成 hugo_stats.json 文件，其中包含一些关于构建的聚合数据 # New in v0.69.0 writeStats: false # 生成静态文件时是否包含带有 draft: true 标识的文档 # 该标识表示文档为：草稿 buildDrafts: false # 生成静态文件时是否包含带有 expirydate: date 标识的文档 # 该标识表示文档为：设置过期时间，如果过期，则不生成静态文件 buildExpired: false # 生成静态文件时是否包含带有 publishdate: date 标识的文档 # 该标识表示文档为：设置发布时间，如果时间来到，则不生成静态文件 buildFuture: false # 缓存配置:https://next--gohugoio.netlify.app/documentation/getting-started/configuration/#configure-file-caches # 0.52 caches: assets: dir: :resourceDir/_gen maxAge: -1 getcsv: dir: :cacheDir/:project maxAge: -1 getjson: dir: :cacheDir/:project maxAge: -1 images: dir: :resourceDir/_gen maxAge: -1 modules: dir: :cacheDir/modules maxAge: -1 # 是否将相对 URL 转换为绝对 URL canonifyURLs: false # 原文件内容目录，如md文档目录 # Hugo 0.56 contentDir: \"conftent\" # 数据目录 # Hugo 0.56 dataDir: \"data\" # 默认语言 defaultContentLanguage: \"en\" # 是否在 subdir 中渲染默认的内容语言 defaultContentLanguageInSubdir: false # 是否启用别名重定向，请注意，即使设置了，别名本身也会保留在页面上 disableAliases: false # 是否禁止hugo在主页注入元数据(可以在主页源代码中看到hugo，提升人气) disableHugoGeneratorInject: false # 禁用指定的页面类型 disableKinds: [] # 是否浏览器窗口的自动实时重新加载 disableLiveReload: false # 是否把网址路径转换为小写 disablePathToLower: false # 是否启用emoji表情支持 enableEmoji: false # 是否自动检测内容中的中文/日文/韩文语言 hasCJKLanguage: false # 图片处理 # https://next--gohugoio.netlify.app/documentation/content-management/image-processing/ imaging: # 锚点 anchor: Smart # 支持透明度的格式 bgColor: '#ffffff' # 此选项适用于 WebP 图像： # - drawing # - icon # - photo # - picture # - text hint: photo # 该值适用于 JPEG 和 WebP 图像 # 值为1-100，值越高，生成的图像质量越好 quality: 75 # 重采样过滤器 resampleFilter: Box # 语言选项 languages: ar: languagedirection: rtl title: مدونتي weight: 2 en: params: linkedin: https://linkedin.com/whoever title: My blog weight: 1 fr: params: linkedin: https://linkedin.com/fr/whoever navigation: help: Aide title: Mon blogue weight: 2 pt-pt: title: O meu blog weight: 3 # Markdown 渲染 # New in v0.60.0 # https://next--gohugoio.netlify.app/documentation/getting-started/configuration-markup/ markup: # 设置默认渲染引擎 defaultMarkdownHandler: goldmark # asciidocExt: attributes: {} backend: html5 extensions: [] failureLevel: fatal noHeaderOrFooter: true preserveTOC: false safeMode: unsafe sectionNumbers: false trace: false verbose: false workingFolderCurrent: false # blackFriday 渲染引擎 blackFriday: angledQuotes: false extensions: null extensionsMask: null footnoteAnchorPrefix: \"\" footnoteReturnLinkContents: \"\" fractions: true hrefTargetBlank: false latexDashes: true nofollowLinks: false noreferrerLinks: false plainIDAnchors: true skipHTML: false smartDashes: true smartypants: true smartypan","date":"2022-06-04","objectID":"/hugo/:4:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 资源分组资源分组有以下方式： 以_index.md做为索引页面 以index.md做为索引页面 示例： content/ ├── posts │ ├── my-post │ │ ├── content1.md │ │ ├── content2.md │ │ ├── image1.jpg │ │ ├── image2.png │ │ └── index.md │ └── my-other-post ├── branch-bundle-1 │ ├── branch-content1.md │ ├── branch-content2.md │ ├── image1.jpg │ ├── image2.png │ └── _index.md └── branch-bundle-2 ├── _index.md └── a-leaf-bundle └── index.md ","date":"2022-06-04","objectID":"/hugo/:5:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 内容格式html文档与markdown文档都是默认支持的， 扩展格式文档参考内容格式 ","date":"2022-06-04","objectID":"/hugo/:6:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 前置变量前置变量是将元数据附加到内容类型的实例（即嵌入在内容文件中）进行保留， 并且是赋予Hugo其优势的众多功能之一 这些变量定义在文档开头，它会覆盖默认值 \u003c!-- toml格式--\u003e +++ .... +++ \u003c!-- yaml格式 --\u003e --- ... --- \u003c!-- json格式 --\u003e { ... } 这些变量是给hugo模板调用的，不会被转换为html内容。yaml格式示例 categories: - Development - VIM date: \"2012-04-06\" description: spf13-vim is a cross platform distribution of vim plugins and resources for Vim. slug: spf13-vim-3-0-release-and-new-website tags: - .vimrc - plugins - spf13-vim - vim title: spf13-vim 3.0 release and new website 有以下变量： aliases: 别名 audio: 音频文件的路径数组 cascade: 映射，其值将向下传递 date: 创建日期，可以由hugo自动生成 description: 内容描述 summary: 内容摘要 draft: true: 表示为草稿，默认不生成html文件 expiryDate: 到期日期，过期时不会生成html文件 headless: true: 表示不使用索引文件inde.md images: 图片路径 isCJKLanguage: true: 是否含有CJK语言 keywords: 关键字 publishDate: 发布(生效)日期，时间不到则不生成html文件 title: 标题 type: 内容归类类型 url: url地址，通常由hugo生成 weight: 排序权重，值越小则优先级越高，0表示不设置 _bulid: 构建静态文件时的选项，使用与配置文件config.yaml中的build相同 更多变量：front-matter 自定义变量：自定义变量会在.Params中引用 ","date":"2022-06-04","objectID":"/hugo/:7:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 内容类型hugo是围绕内容类型构建的，不同类型可以使用不同的模板创建html文件。 内容类型由type变量指定，如果没有指定，则默认为主目录下的第1个目录， 如content/blog/my-first-event.md，它的内容类型为blog ","date":"2022-06-04","objectID":"/hugo/:8:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 内容模板hugo new创建文件时使用的模板， https://next--gohugoio.netlify.app/documentation/content-management/archetypes/ ","date":"2022-06-04","objectID":"/hugo/:9:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 内容分组文档划分为不同的组，不同的组可以添加预定的内容。分组之间存在逻辑关联关系。 划分由taxonomies指定，hugo默认配置如下 taxonomies: category: categories tag: tags 这样在前置变量中使用tags打标签或categories进行归类。 想要修改默认值只要在配置文件中taxonomies值，想要禁止使用某些分组时， 可以使用disableKinds字段，如： disableKinds: - taxonomy - term 在New in v0.73.0中，为了减少混乱，hugo对以下组进行约定: home: 表示首页 page: 表示文件 section: 表示某个目录 taxonomy: 表示分组 term: 登录页 ","date":"2022-06-04","objectID":"/hugo/:10:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 短代码md文档格式简单，但功能也简单，更多功能通常插入html标签实现。 hugo提供一种支持自定义的模块语法，称为短代码(类似函数、模板)。 可以调用这短代码，实现重复的功能。 ","date":"2022-06-04","objectID":"/hugo/:11:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" hugo与markdown资源引用差异hugo中图片必须是页面资源或全局资源才行进行访问： 页面资源大概意思是一个文档应该为它创建一个目录(称为页包)， 以a.md文档为例，那该创建一个a目录，该目录里面有_index.md或index.md才是文档内容，还有与之相关的静态资源，如图片，这种情况可以使用相对路径与绝对路径引用。 全局资源在assets或static 目录下，图片在该目录下，只能使用绝对路径引用 当从其它环境转到hugo环境中时，如下： a.md中使用![](./t.png \"t2\")时是无法加载的 [root@localhost FixIt]# ll content/posts/test/ total 360 -rw-r--r--. 1 root root 202 Jul 17 16:43 a.md -rw-r--r--. 1 root root 364231 Jul 17 12:54 t.png 这是因为在hugo中当前路径指的是文章的slug路径。没有页包的情况下， 生成的静态网页会默认创建与文件同名无后缀的目录做为页包目录。 虽然生成的静态文件无法正确的引用，但也还是会把图片复制对应的目录中。 即hugo会解析为/public/posts/test/a/t.png。 因此可以使用../t.png引用. 这种方式把md文档放在其它环境时不兼容。有以下解决方法： 方法1：资源使用绝对路径，这种方式优缺点： 缺点：上层及其以上的目录发生变化时也无法正确引用 缺点：要修改现有文档中的图片引用 优点：能兼容其它环境 优点：能使用永久链接 方法2：资源使用相对路径，这种方式优缺点： 缺点：需要从 web 改写 url 地址 优点：不用修改现有文档 方法2在没有使用永久链接时nginx改写url地址只去除图片路径的上层目录即可 [root@localhost nginx]# cat conf/FixIt.nginx.conf ... location / { # 默认需要修改 rewrite (.*\\/)(.*\\/)(.*\\.png$) $1$3 break; index index.html index.xml; } # 不需要修改，绝对路径或使用页包 location ~ /hugo/hugotheme-.*/ { index index.html index.xml; } } } 方法2使用永久链接时需要把资源移到统一的路径，这样才方便写 url 规则 # /usr/local/nginx/note/ 是网站目录 # /usr/local/nginx/note/download 是资源统一目录 [root@localhost hugo]# cd /data/hugo/ \u0026\u0026 \\ rm -rf /usr/local/nginx/note/* \u0026\u0026 \\ hugo --config Hugo.theme.next.yaml -d /usr/local/nginx/note/ \u0026\u0026 \\ mkdir /usr/local/nginx/note/download \u0026\u0026 \\ mv $(find /usr/local/nginx/note/archives/ -type f -a ! -name \"*.xml\" -a ! -name \"*.html\") /usr/local/nginx/note/download/ \u0026\u0026 \\ echo 'ok' Start building sites … hugo v0.102.0-DEV-223bf2800488ad5d38854bbb595d789bc35ebe32+extended linux/amd64 BuildDate=2022-07-09T14:03:11Z WARNING: calling IsSet with unsupported type \"invalid\" (\u003cnil\u003e) will always return false. | ZH-CN -------------------+-------- Pages | 454 Paginator pages | 31 Non-page files | 108 Static files | 46 Processed images | 0 Aliases | 171 Sitemaps | 1 Cleaned | 0 Total in 4900 ms ok # nginx 规则 # 除 imgs/ （主题图片）以外的都要重写 server { rewrite ([^imgs]\\/)(.*\\.(gif|jpg|jpeg|png|bmp|swf|webp|sh|vim)$) /download/$2 ; } 主题","date":"2022-06-04","objectID":"/hugo/:12:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" next主题 下载 # 获取主题 [root@localhost next]# git submodule add https://github.com/hugo-next/hugo-theme-next.git themes/hugo-theme-next Cloning into 'themes/hugo-theme-next'... remote: Enumerating objects: 1997, done. remote: Counting objects: 100% (791/791), done. remote: Compressing objects: 100% (487/487), done. remote: Total 1997 (delta 422), reused 604 (delta 283), pack-reused 1206 Receiving objects: 100% (1997/1997), 691.50 KiB | 0 bytes/s, done. Resolving deltas: 100% (976/976), done. [root@localhost next]# # 把示例目录内容复制到网站家目录 [root@localhost next]# cp -r themes/hugo-theme-next/exampleSite/* . [root@localhost next]# [root@localhost next]# ls archetypes config.toml config.yaml content data layouts public start.sh static themes [root@localhost next]# # 删除hugo默认配置文件 [root@localhost next]# rm -rf config.toml ","date":"2022-06-04","objectID":"/hugo/:13:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" FixIt来自：https://fixit.lruihao.cn/zh-cn/theme-documentation-basics/ # 创建hugo环境 [root@localhost nginx]# hugo new site FixIt Congratulations! Your new Hugo site is created in /root/nginx/FixIt. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new \u003cSECTIONNAME\u003e/\u003cFILENAME\u003e.\u003cFORMAT\u003e\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. # 安装主题 [root@localhost nginx]# cd FixIt/ [root@localhost FixIt]# git clone https://github.com/Lruihao/FixIt.git themes/FixIt Cloning into 'themes/FixIt'... remote: Enumerating objects: 16856, done. remote: Counting objects: 100% (1537/1537), done. remote: Compressing objects: 100% (615/615), done. remote: Total 16856 (delta 967), reused 1423 (delta 891), pack-reused 15319 Receiving objects: 100% (16856/16856), 47.48 MiB | 3.51 MiB/s, done. Resolving deltas: 100% (9045/9045), done. ","date":"2022-06-04","objectID":"/hugo/:14:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 修改字体默认字体大写i与小写L辨识度不高。在 assets/css/_custom.scss 或 FixIt/assets/css/_custom.scss 中设置，覆盖主题默认设置 [root@localhost FixIt]# cat assets/css/_custom.scss html { font-family: \"JetBrains Mono\",'system-ui, -apple-system'; } error","date":"2022-06-04","objectID":"/hugo/:15:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" hugo: /lib64/libstdc++.so.6 下载二进制文件后无法直接运行 [root@localhost hugo]# hugo version hugo: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by hugo) hugo: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by hugo) hugo: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by hugo) 该问题没有得到解决，从其它地方下载库文件(如klakegg/hugo镜像中 )虽然可以正常 运行，但有其它报错，放弃继续使用该库文件。改用了源码编译方式 使用incron实现hugo自动发布我的场景：在windows上修改或增加文件后， verysync软件自动同步到linux服务器上。 当Inotify监控到文件发生变化时重新生成静态文件 ","date":"2022-06-04","objectID":"/hugo/:16:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" verysync是一款简单易用的多平台文件同步软件链接：微力同步用户使用手册 ","date":"2022-06-04","objectID":"/hugo/:17:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" incron配置文件监控incron是inotify的cron系统，包含一个后台守护进程(incrond)和一个事件编辑器 (incrontab)。由系统事件触发的机制，对于应用系统来说，几乎可以做到实时性。 安装icron [root@localhost ~]# yum install incron -y Loaded plugins: fastestmirror 编辑事件触发任务 # 查看支持的事件。监控对象为文件或目录 [root@localhost ~]# incrontab -t | sed 's/,/\\n/g' IN_ACCESS # 监控对象被读取 IN_MODIFY # 监控对象被写入 IN_ATTRIB # 监控对象属性被修改，如 chmod、chown、touch 等 IN_CLOSE_WRITE IN_CLOSE_NOWRITE IN_OPEN IN_MOVED_FROM # 监控对象被移走，如mv IN_MOVED_TO # 监控对象被移来，如cp、mv IN_CREATE # 监控对象增加，如创建新文件 IN_DELETE # 监控对象被删除，如rm IN_DELETE_SELF # 监控对象自删除，即一个可执行文件在执行时删除自己 IN_CLOSE IN_MOVE # 监控对象被移动，等同于(IN_MOVED_FROM | IN_MOVED_TO) IN_ONESHOT IN_ALL_EVENTS # 所有事件 IN_DONT_FOLLOW IN_ONLYDIR IN_MOVE_SELF # 监控对象自移动，即一个可执行文件在执行时移动自己 # 编辑配置文件，会默认保存在/var/spool/incron/ 目录下 [root@localhost ~]# incrontab -e [root@localhost ~]# cat /var/spool/incron/root /data/posts/ IN_MODIFY,IN_CREATE,IN_DELETE,IN_MOVE cd /usr/local/nginx/FixIt/ \u0026\u0026 rm -rf public \u0026\u0026 hugo 启动incron并设置为开机启动 [root@localhost ~]# systemctl enable --now incrond Created symlink from /etc/systemd/system/multi-user.target.wants/incrond.service to /usr/lib/systemd/system/incrond.service. [root@localhost ~]# systemctl status incrond ● incrond.service - Inotify System Scheduler Loaded: loaded (/usr/lib/systemd/system/incrond.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2022-07-19 22:34:49 CST; 1min 14s ago Process: 5916 ExecStart=/usr/sbin/incrond (code=exited, status=0/SUCCESS) Main PID: 5917 (incrond) CGroup: /system.slice/incrond.service └─5917 /usr/sbin/incrond 测试：修改、删除、添加监控对象，观察日志 [root@localhost ~]# tail /var/log/cron Jul 19 22:01:01 localhost run-parts(/etc/cron.hourly)[2596]: finished 0anacron Jul 19 22:34:49 localhost incrond[5916]: starting service (version 0.5.12, built on Mar 18 2019 17:56:43) Jul 19 22:34:49 localhost incrond[5917]: loading system tables Jul 19 22:34:49 localhost incrond[5917]: loading user tables Jul 19 22:34:49 localhost incrond[5917]: loading table for user root Jul 19 22:34:49 localhost incrond[5917]: ready to process filesystem events Jul 19 22:38:10 localhost incrond[5917]: PATH (/data/posts/hugo) FILE (hugo.md) EVENT (IN_DELETE) Jul 19 22:38:10 localhost incrond[5917]: (root) CMD (cd /usr/local/nginx/FixIt/ \u0026\u0026 rm -rf public \u0026\u0026 hugo) Jul 19 22:38:10 localhost incrond[5917]: PATH (/data/posts/hugo) FILE (hugo.md) EVENT (IN_MOVED_TO) Jul 19 22:38:10 localhost incrond[5917]: (root) CMD (cd /usr/local/nginx/FixIt/ \u0026\u0026 rm -rf public \u0026\u0026 hugo) 配置 Artalk 评论","date":"2022-06-04","objectID":"/hugo/:18:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 使用docker容器创建artalk 生成配置文件 # 当前目录 [root@localhost ArtalkData]# pwd /data/ArtalkData # 生成配置文件 [root@localhost ArtalkData]# docker run -it -v /data/ArtalkData:/data --rm artalk/artalk-go gen config data/artalk-go.yml INFO[0000] 创建文件: /data/artalk-go.yml [root@localhost ArtalkData]# ls artalk-go.yml 生成密码，artalk配置文件能用上 # bcrypt 加密方式 [root@localhost ~]# yum install -y htpasswd [root@localhost ~]# htpasswd -bnBC 10 \"\" \"密码\" | tr -d ':' $2y$10$ZSJcesGd7PeNBHy05rnZ8uFIXQDmgkODX.KcBgkDWuYv/7mfxWe9a # md5 加密方式，要后面的空格与- [root@localhost ~]# echo -n \"密码\" | md5sum a8105204604a0b11e916f3879aae3b0b - 修改配置文件 [root@localhost ArtalkData]# cat artalk-go.yml ... # 加密密钥，随意修改 app_key: \"OlCEAagaGMBDghhR\" ... db: type: \"sqlite\" # 支持 sqlite, mysql, pgsql, mssql file: \"./data/artalk-go.db\" # sqlite 数据库文件 # 使用SQLite, 注释多余的字段： # name: \"artalk\" # 数据库名 # host: \"localhost\" # 地址 # port: \"3306\" # 端口 # user: \"root\" # 账号 # password: \"\" # 密码 # charset: \"utf8mb4\" # 编码格式 # table_prefix: \"\" # 表前缀 (例如：\"atk_\") ... # 可信域名，网页绑定的主机名或IP地址 trusted_domains: - http://12.12.246.17:8023 ... # 默认站点名，artalk使用单站点时使用该配置 site_default: \"测试artalk\" ... # 管理员账户 admin_users: - name: \"admin\" email: \"admin@example.com\" # password: \"\" # 密码支持 bcrypt 或 md5 加密，例如填写：\"(md5)50c2... password: \"(bcrypt)$2y$10$oEw8wmUv... badge_name: \"管理员\" badge_color: \"#FF6C00\" # 评论审核 moderator: ... keywords: enabled: true pending: true # 匹配成功设为待审状态 files: # 支持多个词库文件 - \"./data/黑名单词库1.txt\" file_sep: \"\\n\" # 词库文件内容分割符 replac_to: \"x\" # 替换字符 ... # 验证码 captcha: enabled: true # 总开关 always: true # 总是需要验证码 ... 生成评论审核过滤词库 [root@localhost ArtalkData]# echo '妈' \u003e黑名单词库1.txt 运行 docker 容器 [root@localhost ~]# docker run -it -v /data/ArtalkData:/data -p 12.12.246.17:23366:23366 -d --name artalk-go-SQLite artalk/artalk-go ab6004885c9ba988b48498ad332529a6fd164c727da313c885f1d6a3ab328c69 [root@localhost ~]# docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ab6004885c9b artalk/artalk-go \"/entrypoint.sh serv…\" About a minute ago Up About a minute 12.12.246.17:23366-\u003e23366/tcp artalk-go-SQLite # 检测 [root@localhost ~]# nc -zw 5 12.12.246.17 23366 \u0026\u0026 echo $? 0 防火墙放行端口 [root@localhost ~]# firewall-cmd --add-rich-rule='rule family=\"ipv4\" destination address=\"12.12.246.17\" port port=\"23366\" protocol=\"tcp\" accept' success # 写入防火墙配置文件 [root@localhost ~]# firewall-cmd --runtime-to-permanent success ","date":"2022-06-04","objectID":"/hugo/:19:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["hugo"],"content":" 修改hugo配置文件 # artalk 相关部分 comment: # FixIt 更改 | 0.2.15 评论系统设置, # enable: false enable: true artalk: # FixIt 新增 | 0.2.13 Artalk 评论系统设置 (https://artalk.js.org/) # artalk前端配置：https://artalk.js.org/guide/frontend/config.html#前端配置 # enable: false enable: true server: \"http://12.12.246.17:23366\" # artalk 地址 site: \"测试artalk\" # 与 artalk 配置站点名相同 editorTravel: true flatMode: auto maxNesting: 30 # 评论「层级嵌套」模式的最大嵌套层数 lightgallery: false noComment: \" \" # 评论为空时显示字符 vote: true # 启用评论投票功能 (赞同 / 反对) uaBadge: true # 显示用户的 UserAgent 信息徽标(浏览器与系统标识) listSort: true # 鼠标移到评论列表左上角「n 条评论」的位置，显示悬浮下拉层， # 可以指定评论排序方式 placeholder: \"在这里输入内容\" # 评论框占位字符 locale: \"zh-CN\" # artalk 显示默认语言 sendBtn: \"发送评论\" # 发送按钮文字 pagination: # 评论分页 readMore: true # 加载更多模式: true(加载更多) or false(分页条) autoLoad: true # “加载更多”模式下滚动到底部自动加载 pageSize: 20 # 每次请求获取数量 heightLimit: # 超过设定高度的内容将被隐藏，并显示“阅读更多”按钮 content: 300 # 评论内容限高。当值为 0 时，关闭限高 children: 400 # 子评论区域限高 我的网站配置nginx 配置 log_format note escape=json '{ ' '\"responseTime\": \"$time_iso8601\",' '\"requestIP\": \"$remote_addr\",' '\"requestPort\": \"$remote_port\",' '\"requestScheme\": \"$scheme\",' '\"requestProtocol\": \"$server_protocol\",' '\"requestMethod\": \"$request_method\",' '\"requestDomainName\": \"$host\",' '\"requestUri\": \"$request_uri\",' '\"responseUrl\": \"$uri\",' '\"responseIP\": \"$server_addr\",' '\"responseport\": \"$server_port\",' '\"responseStatus\": \"$status\",' \"\\\"responseSize\\\": \" \"\\\"$bytes_sent\" 'B\\\",' \"\\\"responseBodySize\\\": \" \"\\\"$body_bytes_sent\" \"B\\\",\" \"\\\"processingConsumeTime\\\": \" \"\\\"$request_time\" \"s\\\",\" '\"processingStatus\": \"$request_completion\",' '}'; server { server_name note.xiaosi.host; # 443 端口加上 ssl 参数 listen 103.106.246.17:443 ssl; listen 103.106.246.17:80 ; # 证书公钥路径 ssl_certificate /etc/letsencrypt/live/note.xiaosi.host/fullchain.pem; # 证书私钥路径 ssl_certificate_key /etc/letsencrypt/live/note.xiaosi.host/privkey.pem; # 把 http 协议通过 301 跳转到 https 协议 if ($scheme != \"https\") { return 301 https://$host$request_uri; } # 指定日志记录位置 error_log logs/note.xiaosi.host.nginx.error.log; access_log logs/note.xiaosi.host.nginx.access.log note; # 重写资源路径 rewrite ([^imgs]\\/)(.*\\.(gif|jpg|jpeg|png|bmp|swf|webp|sh|vim)$) /download/$2 ; # 设置浏览器缓存时间 expires 1d; location / { root note; index index.html index.xml; } } 允许 URL 使用大写字母 disablePathToLower: true # URL禁止转换为小写 通过定时任务发布 创建脚本，以获得最新的文档 [root@localhost ~]# cat /data/hugo/noteUpdate.sh #!/bin/bash # hugoConfig=/data/hugo/hugoThemeFixItv0.3.1.config.yaml webDir=/usr/local/nginx/note/ hugoDir=/data/hugo/ noteDir=/data/hugo/content/posts/ noteFiles=/data/hugo/content/posts/ cd ${noteDir} git pull origin cd ${hugoDir} rm -rf ${webDir} hugo --config ${hugoConfig} -d ${webDir} # 删除多余文件 find ${webDir}posts/ \\ -mindepth 1 -maxdepth 1 \\ -type d -a -not -name 'page' \\ -exec rm -rf {} \\; # 由于我的文档结构没有按hugo官方要求 # 要手动复制文件到资源目标地址，避免出现 404 fileList=$(find ${noteFiles} -name \"*.md\" -and -type f ) for fileName in ${fileList}; do fileSlug=$(sed -n '2,/---/ {/slug/ {s/.*\"\\(.*\\)\"/\\1/; p; } }' ${fileName}) if [[ -z ${fileSlug} ]];then echo \"该文件没有slug前缀：${fileName}\" continue fi attachmentList=$(sed -n '/\u003c!--start of attachment line--\u003e/,/\u003c!--End of attachment line--\u003e/{ /\\]:/ {s/.*://; p;} }' ${fileName}) if [[ -z ${attachmentList} ]]; then continue fi for cpFile in ${attachmentList}; do dir=\"$(dirname ${fileName})/${cpFile}\" cp ${dir} ${webDir}${fileSlug} done done 创建 service 单元执行脚本 [root@localhost system]# cat /usr/lib/systemd/system/noteUpdate.service [Unit] Description=更新 note After=network.target [Service] Type=simple ExecStart=/bin/bash /data/hugo/noteUpdate.sh RestartSec=10 Restart=on-failure [Install] WantedBy=multi-user.target 创建定时单元 [root@localhost system]# cat noteUpdate.timer [Unit] Description=每30小时更新note [Timer] OnBootSec=10min OnUnitActiveSec=30h Unit=noteUpdate.service [Install] WantedBy=default.target 加载systemd 配置并启动 [root@localhost system]# systemctl daemon-reload [root@localhost system]# systemctl start noteUpdate.timer [root@localhost system]# [root@localhost system]# systemctl status noteUpdate.timer ● noteUpdate.timer","date":"2022-06-04","objectID":"/hugo/:20:0","tags":["hugo"],"title":"hugo的使用","uri":"/hugo/"},{"categories":["golang"],"content":" ","date":"2022-02-16","objectID":"/goQuestion/","tags":["Go每日一题","golang"],"title":"Go每日一题","uri":"/goQuestion/"},{"categories":["golang"],"content":" 来自以下内容： Go每日一题 Golang修养之路 Go语言爱好者周刊 2022-02-16 执行下面的代码会发生什么 package main import ( \"fmt\" \"time\" ) func main() { ch := make(chan int, 1000) go func() { for i := 0; i \u003c 10; i++ { ch \u003c- i } }() go func() { for { a, ok := \u003c-ch if !ok { fmt.Println(\"close\") return } fmt.Println(\"a: \", a) } }() close(ch) fmt.Println(\"ok\") time.Sleep(time.Second * 100) } 点击查看答案 记住 channel 的一些关键特性： 给一个 nil channel 发送数据，造成永远阻塞 从一个 nil channel 接收数据，造成永远阻塞 给一个已经关闭的 channel 发送数据，引起 panic 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 无缓冲的channel是同步的，而有缓冲的channel是非同步的 15字口诀：“空读写阻塞，写关闭异常，读关闭空零”，往已经关闭的 channel 写入数据会 panic。 本题中，因为 main 在开辟完两个 goroutine 之后，立刻关闭了 ch， 结果就是 panic： panic: send on closed channel 2022-02-17 以下代码有什么问题？ package main import ( \"sync\" ) const N = 10 var wg = \u0026sync.WaitGroup{} func main() { for i := 0; i \u003c N; i++ { go func(i int) { wg.Add(1) println(i) defer wg.Done() }(i) } wg.Wait() } 点击查看答案 输出结果不唯一，代码存在风险, 所有 go 语句未必都能执行到。 这是使用 WaitGroup 经常犯下的错误！多次运行就会发现输出都会不同甚至又出现报错的问题。 这是因为 go 执行太快了，导致 wg.Add(1) 还没有执行 main 函数就执行完毕了。wg.Add的位置放错了。 package main import ( \"sync\" ) const N = 10 var wg = \u0026sync.WaitGroup{} func main() { for i:= 0; i\u003c N; i++ { wg.Add(1) go func(i int) { println(i) defer wg.Done() }(i) } wg.Wait() } 关于 channel，下面语法正确的是？ A. var ch chan int B. ch := make(chan int) C. \u003c- ch D. ch \u003c- A B C D 点击查看答案 正确：A,B,C。传入信道必须有值 下面这段代码输出什么？20220220 func main() { a := 5 b := 8.1 fmt.Println(a + b) } A.13.1 B.13 C.compilation error 点击查看答案 C, 类型不同不能直接计算 下面这段代码输出什么？20220221 package main import ( \"encoding/json\" \"fmt\" ) type AutoGenerated struct { Age int `json:\"age\"` Name string `json:\"name\"` Child []int `json:\"child\"` } func main() { jsonStr1 := `{\"age\": 14,\"name\": \"potter\", \"child\":[1,2,3]}` a := AutoGenerated{} json.Unmarshal([]byte(jsonStr1), \u0026a) aa := a.Child fmt.Println(aa) jsonStr2 := `{\"age\": 12,\"name\": \"potter\", \"child\":[3,4,5,7,8,9]}` json.Unmarshal([]byte(jsonStr2), \u0026a) fmt.Println(aa) A：[1 2 3] [1 2 3] B：[1 2 3] [3 4 5] C：[1 2 3] [3 4 5 6 7 8 9] D：[1 2 3] [3 4 5 0 0 0] 点击查看答案 选B：[1 2 3] [3 4 5] 答案解析链接：https://polarisxu.studygolang.com/posts/go/action/interview-slice-json/ json部分解析： 要将一个 JSON 数组解码到切片（slice）中，Unmarshal 将切片长度重置为零， 然后将每个元素 append 到切片中。特殊情况，如果将一个空的 JSON 数组解码 到一个切片中，Unmarshal 会用一个新的空切片替换该切片。因此第一次解析时， a.Child 是 [1 2 3]，aa 自然也是 [1 2 3]。第二次解析时，a.Child 的 长度会被重置为 0，也就说里面的值会被重置（比如 a.Child = a.Child[:0]） ，然后将 3,4,5,7,8,9 一个个 append 到 a.Child 中。 而 append 操作可能会涉及到底层数组的扩容：当原来的容量不足时，会进行扩容。 扩容规则依赖具体实现，不同版本可能不一样。目前的版本（Go1.15.x）按照如下规则扩容： 初始容量最小为 4； 之后按照容量的一半扩容，所以容量是 4、6、9、13、19… 代码 // Get element of array, growing if necessary. if v.Kind() == reflect.Slice { // Grow slice if necessary if i \u003e= v.Cap() { newcap := v.Cap() + v.Cap()/2 if newcap \u003c 4 { newcap = 4 } newv := reflect.MakeSlice(v.Type(), v.Len(), newcap) reflect.Copy(newv, v) v.Set(newv) } if i \u003e= v.Len() { v.SetLen(i + 1) } } 因此，第一次解析，aa.Child 是：[1 2 3]，cap = 4。第二次解析， aa.Child 先被重置，之后将 3,4,5,7,8,9 一个个 append， 最后 aa.Child 是：[3 4 5 6 7 8 9], cap = 6 slice解析 a.Child 的内部结构如下： ———————————————————————————— # a.Child | pointer | len=3 | cap=4 | ———————————————————————————— | V —————————————————— # 底层array | 1 | 2 | 3 | 0 | —————————————————— 当赋值给 aa 后呢， aa 和 a.Child 共用底层数组。内部结构如下： ———————————————————————————— # a.Child | pointer | len=3 | cap=4 | ———————————————————————————— | V ——————————————————— # 底层array | 1 | 2 | 3 | 0 | ——————————————————— ^ | ———————————————————————————— # aa | pointer | len=3 | cap=4 | ———————————————————————————— 执行第二次 json 解析后，底层数组从索引 0 位置开始依次被 3、4、5、7 填充。 因为 aa 的 len 是 3，所以即使底层数组变成了 3、4、5、7。当再继续解析时， 底层数组容量不够，因此进行扩容，cap 变成 6，将原底层数组的元素拷贝一份到新的数组中。 所以最后 a.Child 的底层数组是这个新的底层数组：[3 4 5 7 8 9]， cap = 6。而 aa 的底层数组还是原来的。最后的内部表示如下： ———————————————————————————— # a.Child | pointer | len=3 | cap=4 | ———————————————————————————— | V ———————————————————————————— # 复制的底层array | 3 | 4 | 5 | 6 | 7 | 8 | 9 | ———————————————————————————— -------------------------------------------------- —————————————————— # 底层array | 3 | 4 | 5 | 7 | —————————————————— ^ | ———————————————————————————— #","date":"2022-02-16","objectID":"/goQuestion/:0:0","tags":["Go每日一题","golang"],"title":"Go每日一题","uri":"/goQuestion/"},{"categories":["linux"],"content":" 运行环境： 内容来自以下文档： 使用 SELinux SELinux项目页面 selinuxSecurity Enhanced Linux(SELinux)实施强制访问控制(MAC)。每个进程和系统资源 都有一个特殊的安全性标签,称为SELinux 上下文（context），有时被称为SELinux 标签，它是一个提取系统级别细节并专注于实体的安全属性的标识符。SELinux策略在 一系列规则中使用这些上下文，它们定义进程如何相互交互以及与各种系统资源进行交互。 默认情况下,策略不允许任何交互,除非规则明确授予了相应的权限 简单说selinux提供了一个额外的系统安全层，selinux策略定义了“主体”是否可以对“对象”进行”操作“。对SELinux策略规则的检查是在DAC (由用户、组、其它成员组成的标准访问策略)规则后进行的。如果DAC规则已拒绝了访问 ，则不会使用SELinux策略规则。 SELinux 旨在增强现有的安全解决方案，不是其它安全系统(防火墙、防病毒软件、密码等) 。即使运行·、SELinux，仍需要遵循好的安全实践，如保持软件更新、使用安全的密码、 使用防火墙。 SELinux 构架和软件包Red Hat Enterprise Linux 8 提供以下用于 SELinux 的软件包： 策略：selinux-policy-targeted、selinux-policy-mls 工具：policycoreutils、policycoreutils-gui、libselinux-utils、policycoreutils-python-utils、setools-console、 checkpolicy dnf -y install selinux-policy-targeted selinux-policy-mls policycoreutils policycoreutils policycoreutils-gui libselinux-utils policycoreutils-python-utils setools-console checkpolicy SELinux是一个内置在Linux内核中的Linux安全模块（LSM）。内核中的 SELinux子系统由安全策略驱动，该策略由管理员控制并在引导时载入。 系统中所有与安全性相关的、内核级别的访问操作都会被SELinux截取， 并在加载的安全策略上下文中检查。如果载入的策略允许操作， 它将继续进行。否则,操作会被阻断，进程会收到一个错误。 SELinux决策（如允许或禁止访问）会被缓存。这个缓存被称为 Access Vector Cache（AVC）。通过使用这些缓存的决定，可以 较少对SELinux策略规则的检查，这会提高性能。请记住，如果 DAC规则已首先拒绝了访问，则SELinux策略规则无效。原始审计 消息会记录到/var/log/audit/audit.log，它们以type=AVC字符串开头。 在Red Hat Enterprise Linux 8中，系统服务由systemd守护进程控制； systemd启动和停止所有服务，同时用户和进程使用systemctl工具与 systemd进行通信。systemd守护进程可以参考SELinux策略，检查 调用进程标签以及调用者试图管理的单元文件标签，然后询问SELinux是否 允许调用者的访问。这个方法可控制对关键系统功能的访问控制，其中包括启动 和停止系统服务。因此，为了避免不正确的SELinux标记以及后续问题， 请确定使用systemctl start命令启动服务 systemd守护进程也可以作为SELinux访问管理器使用。它会检索运行 systemctl的进程标签，或向systemd发送D-Bus信息的进程标签。 然后守护进程会查找进程要配置的单元文件标签。最后，如果SELinux 策略允许进程标签和单元文件标签之间的特定访问，systemd就可以从 内核中检索信息。这意味着，当需要通过systemd与特定服务进行交互 的应用程序被侵入时，这个应用程序也会被SELinux限制。策略作者也 可以使用这些精细的控制来限制管理员。 SELinux 状态和模式selinux有以下模式： enforcing(强制): 它是默认模式。SELinux可正常运行，并在整个系统中强制实施 载入的安全策略 permissive(宽容): selinux正常运行，但它并不会拒绝任何操作。而只是记录 AVC 信息，它们可用于故障排除、调试和SELinux策略改进。每个AVC在这个示例中仅记录 一次。 disabled(禁用): 关闭selinux，redhat不建议关闭，在关闭期间不会为任何持久 对象（如文件）添加标签，这使得在以后启用SELinux非常困难 为了防止不正确标记和未标记的文件造成问题，当从disabled状态改为permissive或 enforcing模式时会自动重新标记文件系统。在permissive模式中，以root用户身份 使用fixfiles -F onboot命令创建包含/.autorelabel选项的-F文件，以确保在下次 重启时重新标记文件。 ","date":"2022-01-18","objectID":"/selinux/:0:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 临时更改状态setenforce命令可以临时修改selinux模式，在系统重启后失效。有以下参数 Enforcing | 1: 使用enforcing模式 Permissive | 0: 使用permissive模式 使用getenforce命令可以查看当前selinux模式 在 Red Hat Enterprise Linux 中，您可以在系统处于 enforcing 模式时， 将独立的域设置为 permissive 模式。例如，使 httpd_t 域为 permissive 模式： # semanage permissive -a httpd_t ","date":"2022-01-18","objectID":"/selinux/:1:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 永久更改修改/etc/selinux/config文本中SELinux值，之后重启系统 [root@localhost ~]# sed -i '/^SELINUX=/ s/.*/SELINUX=permissive/g' /etc/selinux/config [root@localhost ~]# [root@localhost ~]# cat /etc/selinux/config # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=permissive # SELINUXTYPE= can take one of these three values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted [root@localhost ~]# reboot ","date":"2022-01-18","objectID":"/selinux/:2:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 在引导时更改 SELinux 模式在引导时，您可以设置几个内核参数来更改 SELinux 的运行方式： enforcing=0: 设置此参数可让系统以 permissive 模式启动，这在进行故障排除时非常有用。 在 permissive 模式中，只报告来自于同一拒绝的一系列操作的第一个拒绝信息 selinux=0: 内核不载入SELinux构架的任意部分。初始化脚本会创建/.autorelabel文件。 这会导致系统在下次使用SELinux enabled模式引导时自动重新标记 autorelabel=1: 参数强制系统重建/.autorelabel文件，并重启系统。如果文件系统中包含 大量错误标记的对象，以permissive模式启动系统，使autorelabel进程成功 有关 SELinux 的其他内核引导参数，如 checkreqprot，请查看在安装 kernel-doc 软件包时安装的 /usr/share/doc/kernel-doc-\u003cKERNEL_VER\u003e/Documentation/admin-guide/kernel-parameters.txt文件 selinux上下文SELinux上下文包括以下字段： user(用户) role(角色) type(类型) security level(安全级别) categories(策略) 在SELinux策略中，SELinux类型信息可能是最重要的。这是因为，最常用的、用于定义允许在进程和 系统资源间进行的交互的策略规则会使用SELinux类型而不是SELinux的完整上下文。 ","date":"2022-01-18","objectID":"/selinux/:3:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 查看selinux安全上下文通常查看使用的命令中，-Z选项用于显示selinux上下文 (格式：user:role:type:sensitivity:categories) [root@localhost ~]# ps -Z LABEL PID TTY TIME CMD unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 3158 pts/0 00:00:00 bash unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 3451 pts/0 00:00:00 ps [root@localhost ~]# [root@localhost ~]# ls -Z t unconfined_u:object_r:admin_home_t:s0 t [root@localhost ~]# [root@localhost ~]# id -Z unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 ","date":"2022-01-18","objectID":"/selinux/:4:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 修改selinux上下文 ## chcon 命令 $ touch /tmp/myfile $ ls -Z /tmp/myfile unconfined_u:object_r:user_tmp_t:s0 /tmp/myfile $ chcon -t user_home_t /tmp/myfile $ ls -Z /tmp/myfile unconfined_u:object_r:user_home_t:s0 /tmp/myfile ## semanage 命令 ## touch /var/cache/myfile ## ls -Z /var/cache/myfile unconfined_u:object_r:var_t:s0 /var/cache/myfile ## semanage fcontext -a -t user_home_t /var/cache/myfile ## restorecon /var/cache/myfile ## ls -Z /var/cache/myfile $ id -Z unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c255 $ newrole -r system_r -t unconfined_t Password: $ id -Z unconfined_u:system_r:unconfined_t:s0-s0:c0.c255 $ runcon system_u:system_r:crond_t:s0:c0.c255 /bin/bash $ id -Z system_u:system_r:crond_t:s0:c0.c255 ","date":"2022-01-18","objectID":"/selinux/:5:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 重置selinux上下文 $ restorecon /tmp/myfile ","date":"2022-01-18","objectID":"/selinux/:6:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" selinux用户linux用户可以使用selinux策略映射到selinux用户，这样可以允许 linux用户继承对selinux用户限制。通常以_u结尾(非强制) ","date":"2022-01-18","objectID":"/selinux/:7:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 查看selinux用户映射以root用户执行semanage login -l命令可以查看用户映射 [root@localhost ~]# semanage login -l Login Name SELinux User MLS/MCS Range Service __default__ unconfined_u s0-s0:c0.c1023 * root unconfined_u s0-s0:c0.c1023 * 上面__default__表示默认映射，即linux用户默认映射到selinux用户unconfined_u 。使用seinfo -u命令可以查看selinux用户 [root@localhost ~]# seinfo -u Users: 8 guest_u root staff_u sysadm_u system_u unconfined_u user_u xguest_u 当用户登录系统后，pam_selinux(PAM)模块会自动映射到selinux用户 (默认是unconfined_u),并设置selinux上下文。然后会使用这个上下文启动 linux用户的shell。id -Z命令可以查看当前用户的selinux`上下文 [root@localhost ~]# id -Z unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 ","date":"2022-01-18","objectID":"/selinux/:7:1","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 创建用户时指定映射selinux用户创建用户(useradd -Z)可以指定映射的selinux用户 [root@localhost ~]# useradd user -Z user_u [root@localhost ~]# semanage login -l | grep user user user_u s0 * [root@localhost ~]# su user ## id -Z 命令却没有更新？这是什么情况 [user@localhost root]$ id -Z unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 ","date":"2022-01-18","objectID":"/selinux/:7:2","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 修改selinux默认映射用户 [root@localhost ~]# semanage login -m -s user_u -r s0 __default__ [root@localhost ~]# semanage login -l Login Name SELinux User MLS/MCS Range Service __default__ user_u s0 * root unconfined_u s0-s0:c0.c1023 * user user_u s0 * system_u是系统进程和对象的特殊用户身份。它绝对不能和Linux用户关联。 另外, unconfined_u 和 root 是非限制的用户。 ","date":"2022-01-18","objectID":"/selinux/:7:3","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 角色selinux使用RBAC控制selinux用户对域的权限。用户可以与一个或多少角色关联， 每个角色可以与一个或多少类型域关联。通常角色名以_r结尾(非强制) linux用户 --\u003e selinux用户 --\u003e 角色(可以关联多个) --\u003e 类型(可以关联多个) ","date":"2022-01-18","objectID":"/selinux/:8:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 类型类型名称通常以_t结尾（非强制）。简单理解：selinux规则控制类型权限 SELinux使用一种特定的类型强制(TE) 来强制强制访问控制。这意味着所有主体和客体都有 一个与之关联的类型标识符，然后可以使用该标识符来执行策略制定的规则。类型标识符是一个 简单的可变长度字符串，它在策略中定义，然后与安全上下文相关联。它还用于大多数SELinux 语言语句和规则，用于构建策略，当加载到安全服务器中时，将通过对象管理器强制执行策略 如果一个未限制的Linux用户执行一个应用程序，这个应用程序被SELinux策略 定义为可以从unconfined_t域转换到其自身限制域的应用程序，则未限制的 Linux用户仍会受到那个受限制域的限制。这样做的安全优点是，即使Linux 用户的运行没有限制，但应用程序仍受限制。因此，对应用程序中漏洞的利用会被策略限制。 同样，我们可以将这些检查应用到受限制的用户。每个受限制的用户都受到受限用户域 的限制。SELinux策略还可定义从受限制的用户域转换到自己受限制的目标域转换。 在这种情况下，受限制的用户会受到那个目标限制的域的限制。重点是，根据用户的角色， 把特定的权限与受限制的用户相关联。 ","date":"2022-01-18","objectID":"/selinux/:9:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 安全级别 为使用非标准配置的应用程序和服务配置SELINUXsemanage port可以管理网络端口类(_port_t结尾) # -a 添加记录 # -t 指定对象 # -p 指定协议与端口 # -l 查看所有端口类信息 查看sshd允许监听的端口 # grep 筛选 [root@localhost ~]# semanage port -l | grep \"ssh\" ssh_port_t tcp 838, 22 为sshd添加允许监听的端口 [root@localhost ~]# semanage port -a -t ssh_port_t -p tcp 909 [root@localhost ~]# [root@localhost ~]# semanage port -l | grep \"ssh\" ssh_port_t tcp 909, 838, 22 为sshd减少允许监听的端口 # 默认在策略中的无法删除 [root@localhost ~]# semanage port -d -t ssh_port1 -p tcp 22 ValueError: Port tcp/22 is defined in policy, cannot be deleted [root@localhost ~]# semanage port -d -t ssh_port1 -p tcp 909 [root@localhost ~]# [root@localhost ~]# semanage port -l | grep \"ssh_port\" ssh_port_t tcp 838, 22 复制一个文件的selinux上下文到另一个文件 # 把 www 文件的selinux上下文复制给 test_www semanage fcontext -a -e /var/www /var/test_www 调整 SELinux 布尔值 查看与ssh相关的selinux布尔值说明 [root@localhost ~]# semanage boolean -l | grep \"^ssh\" ssh_chroot_rw_homedirs (off , off) allow ssh with chroot env to read and write files in the user home directories ssh_keysign (off , off) allow host key based authentication ssh_sysadm_login (off , off) Allow ssh logins as sysadm_r:sysadm_t ssh_use_tcpd (off , off) Allow sshd to use tcp wrappers 查看与ssh相关的selinux布尔值状态 [root@localhost ~]# getsebool -a | grep \"^ssh\" ssh_chroot_rw_homedirs --\u003e off ssh_keysign --\u003e off ssh_sysadm_login --\u003e off ssh_use_tcpd --\u003e off 修改selinux布尔值 # 临时修改 # -P选项可重启后保留更改，由于需要重建整个策略，且可能需要一些时间 # setsebool httpd_use_nfs on # setsebool httpd_use_cifs on 主体在selinux中，主体是一个活动进程，并关联selinux安全上下文(user:role:type[:range]) 。主体有以下分类： Trusted: 信任，已经支持selinux功能 Untrusted: 不受信任 对象在selinux中，通过进程（也称为主体）访问的资源称为对象，例如文件、套接字、管道或 网络接口。这些对象根据它们提供的资源进行分类，这些资源具有与其目的相关的访问权限 （例如读取、接收和写入），并分配了一个安全上下文(user:role:type[:range]) 故障排除与SELINUX相关的问题","date":"2022-01-18","objectID":"/selinux/:10:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 判断是否由selinux引起阻断操作在开始前临时禁用 dontaudit 规则，允许记录所有拒绝信息。避免AVC 中的拒绝信息被静默 # semodule -B 开启 semodule -DB [root@localhost ~]# date Fri Jan 21 15:03:06 CST 2022 # 再次运行阻断操作 [root@localhost ~]# systemctl restart nginx Job for nginx.service failed because the control process exited with error code. See \"systemctl status nginx.service\" and \"journalctl -xe\" for details. 方法1：查看selinux是否开启，如果开启则临时关闭，再次执行引发阻断操作。 如果操作没有阻断则是selinux问题 # 由selinux引发的阻断 [root@localhost ~]# getenforce Enforcing [root@localhost ~]# [root@localhost ~]# setenforce 0 [root@localhost ~]# [root@localhost ~]# systemctl restart nginx [root@localhost ~]# [root@localhost ~]# systemctl status nginx ● nginx.service - The nginx HTTP and reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; disabled; vendor preset: disabled) Active: active (running) since Fri 2022-01-21 14:46:48 CST; 7s ago [root@localhost ~]# setenforce 1 方法2：检查 systemd 日志提供的消息 # 还有操作提示 Jan 21 15:04:06 localhost.localdomain setroubleshoot[2593]: AnalyzeThread.run(): Cancel pending alarm Jan 21 15:04:07 localhost.localdomain setroubleshoot[2593]: SELinux is preventing /usr/bin/rm from using the siginh access on a process. Fo\u003e Jan 21 15:04:07 localhost.localdomain setroubleshoot[2593]: SELinux is preventing /usr/bin/rm from using the siginh access on a process. ***** Plugin catchall (100. confidence) suggests ************************** If you believe that rm should be allowed siginh access on processes labeled unc\u003e Then you should report this as a bug. You can generate a local policy module to allow this access. Do allow this access for now by executing: # ausearch -c 'rm' --raw | audit2allow -M my-rm # semodule -X 300 -i my-rm.pp Jan 21 15:04:07 localhost.localdomain setroubleshoot[2593]: AnalyzeThread.run(): Set alarm timeout to 10 Jan 21 15:04:07 localhost.localdomain setroubleshoot[2593]: AnalyzeThread.run(): Cancel pending alarm 方法3 ：查看询审计日志 当操作被SELinux阻止时，/var/log/audit/audit.log文件是第一个检查拒绝的更多 信息。要查询审计日志，使用ausearch工具。因为SELinux决策（如允许或禁止访问） 已被缓存，且这个缓存被称为Access Vector Cache(AVC)，所以对消息类型参数使用 AVC和USER_AVC值，例如： # Audit 守护进程没有在您的系统中运行的情况下 # dmesg 命令输出中搜索特定的 SELinux 信息 dmesg | grep -i -e type=1300 -e type=1400 # 必须要 auditd 守护进程 运行的情况下才有匹配项 # 启动之后重复拒绝操作，然后再次检查审计日志 # 看不懂 [root@localhost ~]# date Fri Jan 21 14:31:37 CST 2022 [root@localhost ~]# systemctl restart nginx Job for nginx.service failed because the control process exited with error code. See \"systemctl status nginx.service\" and \"journalctl -xe\" for details. [root@localhost ~]# ausearch -m AVC,USER_AVC,SELINUX_ERR,USER_SELINUX_ERR -ts recent ---- time-\u003eFri Jan 21 14:31:45 2022 type=PROCTITLE msg=audit(1642746705.962:164): proctitle=2F7573722F7362696E2F6E67696E78002D74 type=SYSCALL msg=audit(1642746705.962:164): arch=c000003e syscall=49 success=no exit=-13 a0=8 a1=564c551c4a30 a2=10 a3=7ffcd1996ba0 items=0 ppid=1 pid=2333 auid=4294967295 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=(none) ses=4294967295 comm=\"nginx\" exe=\"/usr/sbi n/nginx\" subj=system_u:system_r:httpd_t:s0 key=(null) type=AVC msg=audit(1642746705.962:164): avc: denied { name_bind } for pid=2333 comm=\"nginx\" src=880 scontext=system_u:system_r:httpd_t:s0 tcontext=system_u:object_r:hi_reserved_port_t:s0 tclass=tcp_socket permissive=0 ","date":"2022-01-18","objectID":"/selinux/:11:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 分析 SELinux 拒绝信息在确认 SELinux 会阻止您的场景后，可能需要在进行修复前分析根本原因 使用 sealert 命令列出有关日志拒绝的详情 # 如果没有包含清晰的建议，可以使用以下方法 # 1. 清除 setroubleshoot 缓存：rm -f /var/lib/setroubleshoot/setroubleshoot.xml # 2. 启用全路径审核查看访问对象的完整路径，并让其他 Linux Audit 事件字段可见： # auditctl -w /etc/shadow -p w -k shadow-write # 3. 再次执行出现阻断的操作 [root@localhost ~]# sealert -l \"*\" ... SELinux is preventing /usr/sbin/nginx from name_bind access on the tcp_socket port 880. ***** Plugin bind_ports (99.5 confidence) suggests ************************ If you want to allow /usr/sbin/nginx to bind to network port 880 Then you need to modify the port type. Do # semanage port -a -t PORT_TYPE -p tcp 880 where PORT_TYPE is one of the following: http_cache_port_t, http_port_t, jboss_management_port_t, jboss_messaging_port_t, ntop_port_t, p uppet_port_t. ***** Plugin catchall (1.49 confidence) suggests ************************** If you believe that nginx should be allowed name_bind access on the port 880 tcp_socket by default. Then you should report this as a bug. You can generate a local policy module to allow this access. Do allow this access for now by executing: # ausearch -c 'nginx' --raw | audit2allow -M my-nginx # semodule -X 300 -i my-nginx.pp Additional Information: Source Context system_u:system_r:httpd_t:s0 Target Context system_u:object_r:hi_reserved_port_t:s0 Target Objects port 880 [ tcp_socket ] Source nginx Source Path /usr/sbin/nginx Port 880 Host localhost.localdomain Source RPM Packages nginx-1.14.1-9.module+el8.4.0+542+81547229.x86_64 Target RPM Packages SELinux Policy RPM selinux-policy-targeted-3.14.3-80.el8_5.2.noarch Local Policy RPM selinux-policy-targeted-3.14.3-80.el8_5.2.noarch Selinux Enabled True Policy Type targeted Enforcing Mode Enforcing Host Name localhost.localdomain Platform Linux localhost.localdomain 4.18.0-348.7.1.el8_5.x86_64 #1 SMP Tue Dec 21 19:02:23 UTC 2021 x86_64 x86_64 Alert Count 7 First Seen 2022-01-21 14:17:38 CST Last Seen 2022-01-21 15:04:04 CST Local ID cb69fb9b-7d65-4fa0-bf11-be7c517235ae Raw Audit Messages type=AVC msg=audit(1642748644.311:195): avc: denied { name_bind } for pid=2591 comm=\"nginx\" src=880 scontext=system_u:system_r:httpd_t:s0 tcontext=system_u:object_r:hi_reserved_port_t:s0 tclass=tcp_socket permissive=0 type=SYSCALL msg=audit(1642748644.311:195): arch=x86_64 syscall=bind success=no exit=EACCES a0=8 a1=55d1adfe5a70 a2=10 a3=7ffd29a58f00 items =0 ppid=1 pid=2591 auid=4294967295 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=(none) ses=4294967295 comm=nginx exe=/usr/sbi n/nginx subj=system_u:system_r:httpd_t:s0 key=(null) Hash: nginx,httpd_t,hi_reserved_port_t,tcp_socket,name_bind ","date":"2022-01-18","objectID":"/selinux/:12:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 修复分析 SELinux 拒绝问题多数情况sealert命令或journalctl -t setroubleshoot命令输出中有提供的建议 [root@localhost ~]# semanage port -l | grep \"http\" http_cache_port_t tcp 8080, 8118, 8123, 10001-10010 http_cache_port_t udp 3130 http_port_t tcp 80, 81, 443, 488, 8008, 8009, 8443, 9000 pegasus_http_port_t tcp 5988 pegasus_https_port_t tcp 5989 [root@localhost ~]# [root@localhost ~]# semanage port -a -t http_port_t -p tcp 880 [root@localhost ~]# [root@localhost ~]# semanage port -l | grep \"http\" http_cache_port_t tcp 8080, 8118, 8123, 10001-10010 http_cache_port_t udp 3130 http_port_t tcp 880, 80, 81, 443, 488, 8008, 8009, 8443, 9000 pegasus_http_port_t tcp 5988 pegasus_https_port_t tcp 5989 [root@localhost ~]# [root@localhost ~]# systemctl restart nginx [root@localhost ~]# [root@localhost ~]# systemctl status nginx ● nginx.service - The nginx HTTP and reverse proxy server Loaded: loaded (/usr/lib/systemd/system/nginx.service; disabled; vendor preset: disabled) Active: active (running) since Fri 2022-01-21 18:42:57 CST; 15 ... ","date":"2022-01-18","objectID":"/selinux/:13:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 目录问题标记问题的常见原因是，当服务使用非标准目录时。例如，管理员可能想要使用 /srv/myweb/，而不是在网站中使用 /var/www/html/。在 Red Hat Enterprise Linux 中，使用 var_t 类型标记 /srv 目录。/srv 中创建的文件和目录继承这个类型。另外，顶层目录中新创建的对象（如 /myserver ）可以使用 default_t 类型进行标记。SELinux 可防止 Apache HTTP 服务器（httpd）访问这两个类型。要允许访问，SELinux 必须知道 /srv/myweb/ 中的文件可以被 httpd 访问： # semanage fcontext -a -t httpd_sys_content_t \"/srv/myweb(/.*)?\" 此 semanage 命令将 /srv/myweb/ 目录及其下的所有文件和目录添加到 SELinux 文件上下文中。semanage 实用程序不会更改上下文。以 root 用户身份，使用 restorecon 实用程序应用更改 # restorecon -R -v /srv/myweb ","date":"2022-01-18","objectID":"/selinux/:13:1","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 不正确的上下文matchpathcon 工具检查文件路径的上下文，并将其与该路径的默认标签进行比较。以下示例演示了在包含错误标记文件的目录中使用 matchpathcon： $ matchpathcon -V /var/www/html/* /var/www/html/index.html has context unconfined_u:object_r:user_home_t:s0, should be system_u:object_r:httpd_sys_content_t:s0 /var/www/html/page1.html has context unconfined_u:object_r:user_home_t:s0, should be system_u:object_r:httpd_sys_content_t:s0 在本例中，index.html 和 page1.html 文件使用 user_home_t 类型进行标识。这种类型用于用户主目录中的文件。使用 mv 命令从主目录中移动文件可能会导致文件使用 user_home_t 类型进行标记。这个类型不应存在于主目录之外。使用 restorecon 实用程序将这些文件恢复到其正确类型： # restorecon -v /var/www/html/index.html restorecon reset /var/www/html/index.html context unconfined_u:object_r:user_home_t:s0-\u003esystem_u:object_r:httpd_sys_content_t:s0 要恢复目录中所有文件的上下文，请使用 -R 选项： # restorecon -R -v /var/www/html/ restorecon reset /var/www/html/page1.html context unconfined_u:object_r:samba_share_t:s0-\u003esystem_u:object_r:httpd_sys_content_t:s0 restorecon reset /var/www/html/index.html context unconfined_u:object_r:samba_share_t:s0-\u003esystem_u:object_r:httpd_sys_content_t:s0 ","date":"2022-01-18","objectID":"/selinux/:13:2","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 以非标准方式配置受限应用程序服务可以以多种方式运行。要考虑这一点，您需要指定如何运行您的服务。您可以通过 SELinux 布尔值达到此目的，允许在运行时更改 SELinux 策略的部分。这启用了更改，比如允许服务访问 NFS 卷而无需重新载入或者重新编译 SELinux 策略。另外，在非默认端口号中运行服务需要使用 semanage 命令更新策略配置 例如：要允许 Apache HTTP 服务器与 MariaDB 通信，启用 httpd_can_network_connect_db 布尔值： # setsebool -P httpd_can_network_connect_db on 请注意，该 -P 选项可使系统重启后设置具有持久性。 如果特定服务无法访问，请使用 getsebool 和 grep 工具查看是否有布尔值可用于访问。例如，使用 getsebool -a | grep ftp 命令搜索 FTP 相关的布尔值： $ getsebool -a | grep ftp ftpd_anon_write --\u003e off ftpd_full_access --\u003e off ftpd_use_cifs --\u003e off ftpd_use_nfs --\u003e off ftpd_connect_db --\u003e off httpd_enable_ftp_server --\u003e off tftp_anon_write --\u003e off 要获得布尔值列表并找出是否启用或禁用它们，请使用 getsebool -a 命令。要获得包括布尔值的列表，并找出它们是否启用或禁用，请安装 selinux-policy-devel 软件包并以 root 用户身份使用 semanage boolean -l 命令。 ","date":"2022-01-18","objectID":"/selinux/:13:3","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 端口号根据策略配置，服务只能在某些端口号中运行。尝试更改服务在没有更改策略的情况下运行的端口可能会导致服务无法启动。例如，以 root 运行 semanage port -l | grep http 命令列出 http 相关端口： # semanage port -l | grep http http_cache_port_t tcp 3128, 8080, 8118 http_cache_port_t udp 3130 http_port_t tcp 80, 443, 488, 8008, 8009, 8443 pegasus_http_port_t tcp 5988 pegasus_https_port_t tcp 5989 http_port_t 端口类型定义了 Apache HTTP 服务器可侦听的端口，在本例中为 TCP 端口 80、443、488、8008、8009 和 8443。如果管理员配置了 httpd.conf，httpd 侦听端口 9876（Listen 9876），但没有更新策略来反应这一点，以下命令会失败： # systemctl start httpd.service Job for httpd.service failed. See 'systemctl status httpd.service' and 'journalctl -xn' for details. # systemctl status httpd.service httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; disabled) Active: failed (Result: exit-code) since Thu 2013-08-15 09:57:05 CEST; 59s ago Process: 16874 ExecStop=/usr/sbin/httpd $OPTIONS -k graceful-stop (code=exited, status=0/SUCCESS) Process: 16870 ExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUND (code=exited, status=1/FAILURE) 记录类似于 /var/log/audit/audit.log 的 SELinux 拒绝信息： type=AVC msg=audit(1225948455.061:294): avc: denied { name_bind } for pid=4997 comm=\"httpd\" src=9876 scontext=unconfined_u:system_r:httpd_t:s0 tcontext=system_u:object_r:port_t:s0 tclass=tcp_socket 要允许 httpd 侦听没有列出的 http_port_t 端口，使用 semanage port 命令为端口分配不同的标签： # semanage port -a -t http_port_t -p tcp 9876 ","date":"2022-01-18","objectID":"/selinux/:13:4","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["linux"],"content":" 审计日志中的 SELinux 拒绝Linux 审计系统默认在 /var/log/audit/audit.log 文件中存储日志条目。 要只列出与 SELinux 相关的记录，请使用将 message type 参数设置为 AVC 和 AVC_USER 的 ausearch 命令，例如： # ausearch -m AVC,USER_AVC,SELINUX_ERR,USER_SELINUX_ERR 审计日志文件中的 SELinux 拒绝条目类似如下： type=AVC msg=audit(1395177286.929:1638): avc: denied { read } for pid=6591 comm=\"httpd\" name=\"webpages\" dev=\"0:37\" ino=2112 scontext=system_u:system_r:httpd_t:s0 tcontext=system_u:object_r:nfs_t:s0 tclass=dir 这个条目最重要的部分是： avc: denied: SELinux 执行的操作，并在 AVC 中记录 { read }: 被拒绝的操作 pid=6591: 试图执行被拒绝操作的主体的进程识别符 comm=\"httpd\": 用于调用分析进程的命令名称 httpd_t: 进程的 SELinux 类型 nfs_t: 受进程操作影响的对象的 SELinux 类型 tclass=dir: 目标对象类 当 Apache HTTP 服务器试图访问使用 Samba 套件类型标记的目录时，会出现以下 SELinux 拒绝信息： type=AVC msg=audit(1226874073.147:96): avc: denied { getattr } for pid=2465 comm=\"httpd\" path=\"/var/www/html/file1\" dev=dm-0 ino=284133 scontext=unconfined_u:system_r:httpd_t:s0 tcontext=unconfined_u:object_r:samba_share_t:s0 tclass=file { getattr }: getattr 条目表示源进程正在尝试读取目标文件的状态信息。这在读取文件前发生。SELinux 会拒绝这个操作，因为进程会访问该文件，且没有适当的标签。通常的权限包括 getattr、read 和 write。 path=\"/var/www/html/file1\": 该进程试图访问的对象（目标）的路径。 scontext=\"unconfined_u:system_r:httpd_t:s0\": 试图拒绝动作的进程（源）的 SELinux 上下文。在这个示例中，它是 Apache HTTP 服务器的 SELinux 上下文，它使用 httpd_t 类型运行。 tcontext=\"unconfined_u:object_r:samba_share_t:s0\": 试图访问的进程的对象（目标）的 SELinux 上下文。在这个示例中，它是 file1 的 SELinux 上下文。 ","date":"2022-01-18","objectID":"/selinux/:14:0","tags":["selinux"],"title":"selinux","uri":"/selinux/"},{"categories":["文本处理"],"content":" 运行环境： centos: 7 内容来自以下文档： 一见_: awk给外部变量赋值 GNU-gawk帮助手册 gawkgawk 是 awk 繁衍的版本可用于文本排版 ","date":"2022-01-12","objectID":"/awk/:0:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 升级 从官网下载源码包 [root@c8 pag]# wget https://ftp.gnu.org/gnu/gawk/gawk-5.1.0.tar.xz --2020-07-13 08:29:17-- https://ftp.gnu.org/gnu/gawk/gawk-5.1.0.tar.xz Resolving ftp.gnu.org (ftp.gnu.org)... 209.51.188.20, 2001:470:142:3::b Connecting to ftp.gnu.org (ftp.gnu.org)|209.51.188.20|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3154564 (3.0M) [application/x-xz] Saving to: ‘gawk-5.1.0.tar.xz’ gawk-5.1.0.tar.xz 100%[=======================================================\u003e] 3.01M 1.28MB/s in 2.4s 2020-07-13 08:29:21 (1.28 MB/s) - ‘gawk-5.1.0.tar.xz’ saved [3154564/3154564] 解压 [root@c8 pag]# tar -Jxf gawk-5.1.0.tar.xz [root@c8 pag]# cd gawk-5.1.0 编译安装 [root@c8 gawk-5.1.0]# ./config config.guess config.rpath config.sub configure [root@c8 gawk-5.1.0]# ./configure checking for a BSD-compatible install... ./install-sh -c checking whether build environment is sane... yes checking for a thread-safe mkdir -p... /usr/bin/mkdir -p checking for gawk... gawk ... [root@c8 gawk-5.1.0]# make \u0026\u0026 make install make all-recursive make[1]: Entering directory '/root/pag/gawk-5.1.0' Making all in support ... 查看版本 # 如果没有生效，结束当前 ssh 进程，重新远程；本地登录的直接退出程序登陆 [root@c8 gawk-5.1.0]# gawk -V GNU Awk 5.1.0, API: 3.0 Copyright (C) 1989, 1991-2020 Free Software Foundation. This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/. ","date":"2022-01-12","objectID":"/awk/:1:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 命令行选项 使用格式： gawk [ POSIX or GNU style options ] -f program-file [ -- ] file ... gawk [ POSIX or GNU style options ] [ -- ] program-text file ... 常见选项： -F 指定分隔符，默认为空格，等效 FS 变量 -f 从指定文件读取程序 -v 定义变量，格式：变量名=变量值 -mf 指定要处理的数据文件中的最大字段数 -mr 指定数据文件中的最大数据行数 -W 指定gawk的兼容模式或警告等级 模式模式控制 awk 操作执行范围，当模式与输入记录匹配时，执行对应的操作，有以下几种模式： 正则表达式：当正则表达式能匹配记录时执行操作 普通表达式：当数值不为0或字符串不为空则执行操作 范围模式：“开始,结束” 形式指定范围 BEGIN：读取记录之前做的操作 END：对记录执行操作后的后续操作 BEGINFILE：读取记录之前执行 awk 脚本 ENDFILE：执行操作之后执行 awk 脚本 不指定：对每条记录都执行操作 ","date":"2022-01-12","objectID":"/awk/:2:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" gawk 中的正则表达式正则表达式写法：/regexp/ 正则表达式 元字符 说明 \\ 转义符 ^ 匹配字符串开头 $ 匹配字符串结尾 . 匹配任何单个字符，包括换行符 [ ] 方括号表达式，表示匹配其中任意单个字符 [^ ] 补充的方括号表达式，表示区分，不匹配方括号中任意单个字符 ` ` ( ) 分区，将表达式划分为一组 * 匹配前面的表达式任意次数，贪婪模式 + 匹配前面的表达式至少一次 ? 匹配前面的表达式0次或1次 {n} 匹配前面的表达式 n 次；n 为正整数 {n,} 匹配前面的表达式至少 n 次；n 为正整数 {n,m} 匹配前面的表达式至少 n 次，最多 m 次；n 和 m 都为正整数，且 m \u003e n \\\\ 单个字符串 \\ \\a 警报，即 \u003cBEL\u003e ; \u003cCtrl-g\u003e ASCII 为 7 \\b 退格，即 \u003cBS\u003e ；\u003cctrl-h\u003e ASCII 为 8 \\f 换页符，即 \u003cFF\u003e ; \u003cCtrl-l\u003e ASCII 为 12 \\n 换行符，即 \u003cLF\u003e ; \u003cCtrl-j\u003e ASCII 为 10 \\r 回车符，即 \u003cCR\u003e ; \u003cCtrl-m\u003e ASCII 为 13 \\t 水平制表符，即 \u003cTab\u003e ; \u003cCtrl-i\u003e ASCII 为 9 \\v 垂直制表符; \u003cCtrl-k\u003e ASCII 为 11 \\nnn 八进制 nnn \\xhh 十六进制 \\/ 字符 / 仅应用于正则表达式常量 \\\" 字符 \" 仅应用于正则表达式常量 [:alnim:] 字母数字字符；等效 [0-9a-zA-Z] [:alpha:] 字母字符；等效 [a-zA-Z] [:blank:] 空格或制表符 [:cntrl:] 控制字符 [:digit;] 数字字符；等效 [0-9] [:graph:] 可见字符 [:lower:] 小写字母字符 [:print:] 可见字符（包含空格） [:punct:] 标点字符 [:space:] 空白字符（包含空格、回车符、换行符之类的） [:upper:] 大写字母字符；等效 [A-Z] 正则表达式运算符 运算符 说明 示例 ~ 和 /regexp/ ~ $1 表示 $1 含有 regexp 时才满足 !~ 非 /regexp/ !~$1 表示 $1 含有 regexp 时不满足 特定与 GAWK 才有的表达式，其他 awk 不一定有 表达式 说明 \\s 匹配空白字符（包含空格、制表符、回车符之类的） \\S 匹配非空白字符，和 \\s 相反 \\w 匹配字母、数字、下划线 \\W 匹配非字母、数字、下划线，和 \\w 相反 \\\u003c 匹配单词的开头 \\\u003e 匹配单词的结尾 \\y 匹配单词边界 \\B 匹配字符边界都相同的字符 \\` 匹配缓冲区开头的字符串 \\' 匹配缓冲区结尾的字符串 ","date":"2022-01-12","objectID":"/awk/:3:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 特殊模式BEGIN{} 规则在读取记录之前执行一次；END{} 规则是对记录执行操作之后的清尾步奏。他们不能和运算符一起使用，当存在多个 BEGIN 或 END 规则时，按照顺序执行 gawk 读取输入","date":"2022-01-12","objectID":"/awk/:4:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 读取输入方式有以下读取方式 文件 标准输入 管道符 getline 变量名称 注释 $n(n为正整数和0) n 表示个字段，0 表示所有字段。字段以 FS 变量为分隔符 FS 指定读取文本的分隔符，默认是空白符 RS 指定读取文本的分号符，默认是换行符 OFS 指定输出文本的分隔符，默认是空白符 ORS 指定输出文本的分行符，默认是换行符 FIELDWIDTHS 指定输入字符宽度，忽略 FS 变量，定义之后不可修改 ARGC 当前命令行的参数 ARGIND 当前文件在 ARGV 中的参数 CONVFMT 数字转换格式，默认值为 %.6 g ENVIRON 当前shell环境变量及其值组成的关联组 ERRNO 当读取或关闭输入文件发送错误时的系统错误信号 FILENAME gawk 输入数据的文件名称 FNR 当前数据文件中的行数 IGNORECASE 设置为0时，忽略命令行中的字符大小写 NF 数据文件中的字段总数 NR 以处理的输入记录 OFMT 数字的输入格式，默认为 %.6 g RLENGTH 由 match 函数所匹配的子字符串长度 RSTART 由 match 函数所匹配的子字符起始位置 ","date":"2022-01-12","objectID":"/awk/:5:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 记录（Records）通常情况下 awk 通标准输入或文件中获取输入，如果指定输入文件，awk 会按照顺序读取和执行相关操作；输入以记录（records）为单位读取；并每次处理一个 “records” (默认为一行) ","date":"2022-01-12","objectID":"/awk/:6:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 记录分隔符（Record Splitting）记录（Record）由成为记录分隔符（Record Splitting）拆分，默认情况下记录分隔符为换行符，因此默认情况下 awk 每次读取一行 可以更改 RS 变量改变默认的记录分隔符； 当 RS 变量值为多个字符，则视为正则表达式 当 RS 变量在兼容模式下时，正则表达式不可用，仅用第一个字符作为记录分隔符 当 RS 变量值为空时，表示整个输入为一个记录 当 RS 变量值不存在时，RS 值自动设置为空字符串，也就是把整个输入当成一个记录处理 多行分隔记录方法：https://www.gnu.org/software/gawk/manual/html_node/Multiple-Line.html ","date":"2022-01-12","objectID":"/awk/:6:1","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 读取下一条记录之 nextnext 语句可以强制 awk 停止处理当前记录，并继续读取下一条记录，因此会放弃后续操作： 由于该next语句，该程序的后续规则将不会看到错误的记录。错误消息将被重定向到标准错误输出流，就像错误消息一样 如果该next语句导致到达输入的结尾，那么将END执行任何规则中的代码 该next声明是不允许在 BEGINFILE 和 ENDFILE 规则中定义（-根据POSIX标准，如果next在BEGIN或END规则中使用该语句，则行为是不确定的 。 gawk将其视为语法错误） next函数体内的一条语句读取下一条记录，并开始使用程序中的第一条规则对其进行处理 示例： [root@centos ~]# cat a 1 2 3 4 5 6 7 8 [root@centos ~]# awk '{print \"$1=\"$1;next;print \"$2=\"$2}' a $1=1 $1=3 $1=5 $1=7 ","date":"2022-01-12","objectID":"/awk/:6:2","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 读取下一条记录之 getline 示例： [root@centos ~]# cat a 1 2 3 4 5 6 7 8 [root@centos ~]# awk '{print \"$1=\"$1;getline;print \"$2=\"$2}' a $1=1 $2=4 $1=5 $2=8 ","date":"2022-01-12","objectID":"/awk/:6:3","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 字段（Fields）当 awk 读取输入的记录时，会自动分解为多个字段（filed）。默认情况下以一个或多个空白字符（仅限于空格、制表符、换行符）为分隔符 ","date":"2022-01-12","objectID":"/awk/:7:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 以字符划分字段可以使用 FS 变量（也可以使用 gawk -F 选项）改变默认的字段分隔符： FS 变量值默认为空字符（空格或制表符） FS 变量值可以使用正则表达式或单个字符或字符与正则表达式混合使用 FS 变量值为增则和字符串混用时，会先经过 awk 字符串处理，因此使用转义符时需使用双倍, \\\\ 第一个 \\ 会被 awk 字符串处理掉，在把 \\ 传递给该变量 FS 变量值为空时，FS=\"\" 每个字符都是一个字段，包括空格，但不包括换行符 FS 变量值为换行符时，$1 等效表示输入行中的一行文本 FS 在旧的版本中，记录拆分会在实际引用字段之前。即 在读取记录之后，使用引用字段操作之前更改该变量值会生效的 FS 在新的版本中（gawk:4.0.2 测试可以），读取记录时就会拆分字段，也就是说在读取记录之后，即便改了该变量值，使用引用字段操作还是默认值，因此，需要在读取记录之前修改该变量 示例：FS 变量值为正则表达式 [root@c8 gawk]# gawk 'BEGIN { FS = \"[2b].\" } {print $1}' file4 11 aa # 文本 [root@c8 gawk]# cat file4 11 22 39 45 02 aa bb cd os iw 示例：FS 变量值为正则表达式和字符混合使用 # [2b] 表示正则表达式，2或b # \\\\. 经过 awk 字符串处理之后为 \\. 在赋值给 FS变量，FS变量再把 \\. 转义为 . 字符 # FS 变量值不存在，使用默认的换行符 [root@c8 gawk]# gawk 'BEGIN { FS = \"[2b]\\\\.\" } {print $2}' file4 [root@c8 gawk]# gawk 'BEGIN { FS = \"[2b]\\\\.\" } {print $1}' file4 11 22 39 45 02 aa bb cd os iw # 文本 [root@c8 gawk]# cat file4 11 22 39 45 02 aa bb cd os iw 示例：读取每个字符串 [root@localhost ~]# echo a b | gawk 'BEGIN { FS = \"\" } {for (i = 1; i \u003c= NF; i = i + 1) print \"Field\", i, \"is\", $i }' Field 1 is a Field 2 is Field 3 is b ","date":"2022-01-12","objectID":"/awk/:7:1","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 以固定宽度分隔字段gawk提供了一种处理没有特定字段分隔符的固定宽度字段的功能，待补充，页面：https://www.gnu.org/software/gawk/manual/html_node/Constant-Size.html ","date":"2022-01-12","objectID":"/awk/:7:2","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 以内容样式分割字段待补充，原文：https://www.gnu.org/software/gawk/manual/html_node/Splitting-By-Content.html ","date":"2022-01-12","objectID":"/awk/:7:3","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 检查字段分割方式 if (PROCINFO[\"FS\"] == \"FS\") regular field splitting … else if (PROCINFO[\"FS\"] == \"FIELDWIDTHS\") fixed-width field splitting … else if (PROCINFO[\"FS\"] == \"FPAT\") content-based field splitting … else API input parser field splitting … (advanced feature) ","date":"2022-01-12","objectID":"/awk/:7:4","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 引用字段值字段可以被 $n 引用，其中 n 表示从左往右的字段编号，如果 n 大于实际的编号，则打印空格。还有以下特殊的编号： $0 表示记录中的所有段，也就是整个记录。当记录值重建时，$0 会去除记录开头和结尾的空格字符 $NF 表示记录中最后一个字段。$NF 是一个预定义变量，每次读取记录，$NF 变量值为该记录的字段数量，当 $NF 重建的值小于记录字段时，余下的字段被抛弃 n 可以以表达式形式书写，如 $( 2*2 ) 表示 $4 ; $( 2-2 ) 表示 $0；当字段作为数字做运算符记算时，会转换为数值，运算完成之后再转换为字符串 字段可以赋值给变量，同样也可以把值赋值给字段 示例： [root@c8 gawk]# awk '{Fs = $2; $2=10; print Fs,\"=\u003e\",$2}' file4 22 =\u003e 10 bb =\u003e 10 # 22+10 为 32 [root@c8 gawk]# awk '{Fs = $2; $2=$2+10; print Fs,\"=\u003e\",$2}' file4 22 =\u003e 32 bb =\u003e 10 # 文本 [root@c8 gawk]# cat file4 11 22 39 45 02 aa bb cd os iw [root@c8 gawk]# awk '{Fs = $2; $2=$2+$2+$3; print Fs,\"=\u003e\",$2}' file4 22 =\u003e 83 bb =\u003e 0 $NF 的变量值被修改之后，会抛弃余下的字段 [root@c8 gawk]# awk '{ print \"NF = \" NF; NF = 3; print $0}' file4 NF = 5 11 22 39 NF = 5 aa bb cd [root@c8 gawk]# cat file4 11 22 39 45 02 aa bb cd os iw $NF 变量值为表达式 ^ 时，有的 awk 是匹配整个记录的开头，有的是每个分割字段符都是新的字符串 [root@c8 gawk]# echo 'xxAA xxBxx C' | gawk -F '(^x+)|( +)' '{ for (i = 1; i \u003c= NF; i++) printf \"--\u003e%s\u003c--\\n\",$i }' --\u003e\u003c-- --\u003eAA\u003c-- --\u003exxBxx\u003c-- --\u003eC\u003c-- $0 重建时之前会丢弃记录开头和结尾的空格字符 # $2 被重建，因此 $0 也被重建 [root@c8 gawk]# echo ' a b c d' | awk '{ print; $2 = $2; print }' a b c d a b c d ","date":"2022-01-12","objectID":"/awk/:7:5","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 读取超时https://www.gnu.org/software/gawk/manual/html_node/Read-Timeout.html ","date":"2022-01-12","objectID":"/awk/:8:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 重试读取https://www.gnu.org/software/gawk/manual/html_node/Retrying-Input.html ","date":"2022-01-12","objectID":"/awk/:9:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 读取目录POSIX 标准中，是不能执行从目录读取的，当读取目录时，默认情况下 gawk 会忽略该警告，当使用 --posix 或 --traditional 会恢复警告 打印打印是最常见的操作，通常是输出一部分或全部内容，默认情况输出字段以空格作为分隔符，输出记录以换行符作为分隔符 ","date":"2022-01-12","objectID":"/awk/:10:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 简单打印 (print)print 是语句，并不是表达式。该语句简单，只是标准化格式输出。可以以逗号分隔打印多个项（字段） 字符或字符串 变量：自定义变量或 awk 变量 数值：数值会以转化为字符串再输出 \"\"：打印空行 \" \" ：引号包围的字符表示是一个项，且内容当成字符串处理；如果没有引号会当成 awk 表达式处理 示例： [root@c8 gawk]# gawk -F \"\\n\" '{print \"这是一行：\"$1}' file4 这是一行：11 22 39 45 02 这是一行：aa bb cd os iw 示例：冒号之中字符串当成字符处理 [root@c8 gawk]# gawk '{print \"内容行,$0=\",$0}' file4 内容行,$0= 11 22 39 45 02 内容行,$0= aa bb cd os iw ","date":"2022-01-12","objectID":"/awk/:11:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 高等打印（printf）printf 是语句，比 print 语句更精准地标准化格式输出 格式控制字符会按照指定格式输出字段 格式控制字符 说明 %a 格式为 [-]0xh.hhhhp+-dd 的浮点数，除 gawk 之外基本不支持 %A 格式为 [-]0xh.hhhhp+-dd （16进制）的浮点数，除 gawk 之外基本不支持 %c 打印数字作为字符， POSIX标准说要打印字符串的第一个字符。在具有多字节字符的语言环境中，gawk尝试将字符串的前导字节转换为有效的宽字符，然后打印该字符的多字节编码。同样，在打印数字值时，gawk允许该值在可以用宽字符保留的值的数字范围内。如果转换为多字节编码失败，请gawk 使用该值的低八位作为要打印的字符 %d 打印一个十进制整数 %i 打印一个十进制整数 %e 以科学计数法的指数打印数字 %E 以科学计数法的指数打印数字 %f 以浮点数打印数字 %F 以浮点数打印数字，但无穷大和非数值字符使用大写拼写 %g 以科学计数法或浮点数计数法打印字符，以较少的字符为准，如果也科学计数法打印，使用 e %G 以科学计数法或浮点数计数法打印字符，以较少的字符为准，如果也科学计数法打印，使用 E %o 打印无符号的八进制字符 %s 打印字符串 %u 打印无符号的十进制字符 %x 打印无符号的十六进制字符，字符使用小写 a-f %X 打印无符号的十六进制字符，字符使用大写 A-F %% 打印单个 %，且会忽略所有修饰符 n$ 一个整数常量，后跟一个 $ 是位置说明符。通常，格式规范按照格式字符串中给定的顺序应用于自变量。使用位置说明符，格式说明将应用于特定的参数，而不是列表中的下一个参数。位置说明符从一开始计数 - 表示左对齐 space 对于数值转换，正数前面留空格，负数前面使用 - 表示负数 + 格式化为正数，也始终为数字转换提供一个符号。+ 会覆盖空格修饰符 # 对某些控制字母使用“替代形式”。对于％o，提供前导零。对于％X和％X，提供领导0x 要么 0X表示非零结果。对于％e，％E，％F和％F，结果始终包含小数点。对于％G和％G`，则不会从结果中删除尾随零 0 领先的0’（零）用作标志，指示应在输出中填充零而不是空格。这仅适用于数字输出格式。仅当字段宽度大于要打印的值时，此标志才有效 ' 单引号或撇号字符是ISO C的POSIX扩展。它指示浮点值的整数部分或整数十进制值的整个部分中应包含一个千位分隔符。这仅在支持此类字符的语言环境中起作用 %n n 是一个数值，用于指定所需的最小字段宽度。在％符号和格式控制字符会强制字段扩展到该宽度。执行此操作的默认方法是在左侧填充空格；值是最小宽度，而不是最大宽度。如果项目值需要的宽度字符以上，则可以根据需要设置宽度 . . 后面更着一个常数，指定打印的精度，精度和以下控制字符有关 - %d，%i，%o，%u，%x，%X 这些打印最小位数 - %e，%E，%f，%F 这些指定小数点右边的位数 - %g， %G 这些有效最大位数 - %s 字符串中应打印的最大字符数 示例：左对齐第一列和第二列 # %-10s 表示左对齐10个字符串宽度，多余的字符串位置用空格填补 # %s\\n 表达打印换行符 [root@c8 gawk]# awk '{ printf \"%-10s %s\\n\", $1, $2 }' file4 11 22 aa bb # 文本 [root@c8 gawk]# cat file4 11 22 39 45 02 aa bb cd os iw ","date":"2022-01-12","objectID":"/awk/:12:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 字段输出分隔符默认情况下字段输出使用空格作为分隔符，可以使用 OFS 变量改变该值 ","date":"2022-01-12","objectID":"/awk/:13:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 记录输出分割符默认情况下记录输出使用换行符作为分隔符，可以使用 ORS 变量改变该值： ","date":"2022-01-12","objectID":"/awk/:14:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 输出重定向这里是指 print 或 printf 语句的输出重定向，有以下重定向方式： \u003e ：重定向到文件，如果文件不存在，则创建文件；可以使用 awk 表达式，awk 会转化为字符串作为文件名称 \u003e\u003e ： 追加到文件，如果文件不存在，则创建文件；可以使用 awk 表达式，awk 会转化为字符串作为文件名称 | ：管道符，将输出结果传递给另一个命令，重定向参数命令实际上是一个awk 表达式。其值将转换为字符串，其内容将给出要运行的 shell 命令 |\u0026 ：类似 | ，但以使用getline读取命令的输出。因此，命令是一个协同过程，它与awk程序一起工作但又作为其附属程序 使用重定向的一种特别有效的方法是构建命令行并将它们通过管道传递到Shell中sh 示例：假设您有一个从系统中移过来的文件列表，其中所有文件名都以大写形式存储，并且您希望将它们重命名为所有小写形式的名称。以下程序既简单又有效 { printf(\"mv %s %s\\n\", $0, tolower($0)) | \"sh\" } END { close(\"sh\") } 变量","date":"2022-01-12","objectID":"/awk/:15:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 自定义变量变量名必须是字母，数字或下划线的序列，并且不能以数字开头，变量不需要初始化，可以直接定义使用。变量值可以是字符串或数值，可以在变量周期内被改变，默认情况下变量初始化为空字符串，如果转换为数值，则为 0 变量可以使用 -v 选项定义，也可以在 awk 中定义，-v 选项可以把外部变量的值赋值给 awk 变量 示例：定义变量 # -v 定义了变量 n ，因此 file1 打印 $1 # 读取完 file1 之后 n=2 # 读取 File2 时打印 $2 [root@c8 gawk]# awk -v n=1 '{ print $n }' file1 n=2 file2 aa 12 b2 2b # 等效上述命令 [root@c8 gawk]# awk '{ print $n }' n=1 file1 n=2 file2 aa 12 b2 2b 示例：为初始化的变量 # n 没有定义，为空 [root@c8 gawk]# awk '{ print $n }' file2 a1 b2 c3 d4 1a 2b 3c 4d ","date":"2022-01-12","objectID":"/awk/:16:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 内置变量gawk 自带的变量 ","date":"2022-01-12","objectID":"/awk/:17:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 指定对所有 I/O使用二进制模式BINMODE 变量在非POSIX系统上，此变量指定对所有 I/O 使用二进制模式 数字值1、2或3指定输入文件，输出文件或所有文件分别应使用二进制I / O。小于零的数值视为零，大于三的数值视为三。或者，字符串值\"r\"或\"w\"指定输入文件和输出文件应分别使用二进制I / O。字符串值\"rw\"或 “wr\"表示所有文件应使用二进制I / O。其他任何字符串值都与相同\"rw”，但会导致gawk 生成警告消息 ","date":"2022-01-12","objectID":"/awk/:17:1","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 数字转换字符串CONVFMT 变量值为一个字符串，用于控制数值到字符串的转换。实际上是通过 sprintf()函数的第一个参数传递。 默认值为 %.6g 旧的版本中使用 0FMT 变量 ","date":"2022-01-12","objectID":"/awk/:17:2","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 固定列边界gawk 扩展 FIELDWIDTHS 变量值是用空格分隔的列表，以固定宽度显示字段，会覆盖 FS 和 FPAT 变量 从版本4.2开始，每个字段宽度都可以选择以冒号分隔的值开头，该值指定在字段开始之前要跳过的字符数 ","date":"2022-01-12","objectID":"/awk/:17:3","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 创建字段gawk 扩展 FPAT 变量值为正则表达式字，匹配该表达式的内容作为一个字段，会覆盖 FS 和 FIELDWIDTHS 变量 ","date":"2022-01-12","objectID":"/awk/:17:4","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 字段分隔符FS变量值为单字符或正则表达式，指定输入字段分隔符，如果值为空（\"\"），则每个字符串都是一个字段 默认值为单个空格，该值有特色情况，不仅仅表示单个空格，还包含制表符、换行符；记录开头和结尾处的空格、制表符、换行符都会被忽略 ","date":"2022-01-12","objectID":"/awk/:17:5","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 匹配时忽略大小写gawk 扩展 IGNORECASE 变量值非零或非空时，所有字符串比较和所有正则表达式匹配均不区分大小写 在 gawk 处于兼容模式时无效 ","date":"2022-01-12","objectID":"/awk/:17:6","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 输出字段分隔符OFS 变量值为字符串，指定输出字段分隔符，它在print语句打印的字段之间输出。它的默认值是由单个空格组成的字符串 ","date":"2022-01-12","objectID":"/awk/:17:7","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 输出记录分隔符RS 输出记录分隔符。在每个print语句的末尾输出 。其默认值为换行符 ","date":"2022-01-12","objectID":"/awk/:17:8","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 浮点数精度gawk 扩展 任意精度浮点数的工作精度，默认为53位 ","date":"2022-01-12","objectID":"/awk/:17:9","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 数字进度舍入模式gawk 扩展 默认情况下，用于数字上的任意精度算术的舍入模式\"N\" ","date":"2022-01-12","objectID":"/awk/:17:10","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 输入记录分隔符RS 变量的默认值是一个包含单个换行符的字符串，因此输入记录由一行文本组成。它也可以是空字符串，在这种情况下，记录由空白行分隔。如果它是一个正则表达式，则记录由输入文本中正则表达式的匹配项分隔 如果 gawk 处于兼容模式下，该变量值只能是一个字符 ","date":"2022-01-12","objectID":"/awk/:17:11","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 下标分隔符下标分隔符。它的默认值 \\034 =用于分隔多维数组的索引部分。因此，表达式foo [“ A”，“ B”] 确实可以访问 foo[\"A\\034B\"] ","date":"2022-01-12","objectID":"/awk/:17:12","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 源文本中特别标记的字符串常量默认的文本域用于该awk级别程序的国际化 。它设置在源文本中特别标记的字符串常量默认的文本域，以及为 dcgettext()，dcngettext()，和bindtextdomain()功能（见国际同gawk）。默认值TEXTDOMAIN是\"messages\"。 ","date":"2022-01-12","objectID":"/awk/:17:13","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 命令行参数awk程序可用的命令行参数存储在名为的数组中ARGV。 ARGC是存在的命令行参数的数量，与大多数awk数组不同， ARGV索引从0到ARGC-1 值ARGV[0]可能因系统而异。另外，您应该注意，程序文本不包含在中ARGV，任何awk的命令行选项也不包含 https://www.gnu.org/software/gawk/manual/html_node/ARGC-and-ARGV.html ","date":"2022-01-12","objectID":"/awk/:17:14","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 当前文件索引 gawk 扩展 ARGIND 变量值为正在处理文件索引，每次gawk打开一个新的数据文件进行处理时，它都会设置 ARGIND为ARGV文件名的索引。因此在gawk处理输入文件时，FILENAME == ARGV [ARGIND] 虽然可以ARGIND在awk 程序中更改的值，但在gawk打开下一个文件时会自动将其设置为新值 ","date":"2022-01-12","objectID":"/awk/:17:15","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 环境变量ENVIRON 变量包含环境值的关联数组。数组索引是环境变量名称。元素是特定环境变量的值。对于POSIX而言awk，更改此数组不会影响传递给任何awk可能通过重定向或system()功能产生的程序的环境 这也会影响正在运行的gawk程序，因为某些内置函数可能会注意某些环境变量 从4.2版开始，如果未处于POSIX兼容模式，则更改gawk时会更新其自身的环境 ENVIRON，从而更改其创建的程序所看到的环境 ","date":"2022-01-12","objectID":"/awk/:17:16","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 错误信息 gawk 扩展 如果在重定向getline期间，读取期间getline或close()操作期间发生系统错误，则 ERRNO变量包含描述错误的字符串 在打开每个命令行输入文件之前gawk清除ERRNO。这样可以检查文件在BEGINFILE模式内是否可读 ","date":"2022-01-12","objectID":"/awk/:17:17","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 输入文件名FILENAME 变量值为当前输入的文件名称，如果命令行上未列出任何数据文件，awk则从标准输入中读取并 FILENAME 设置为 -。 FILENAME每次读取新文件时都会更改内部BEGIN 规则，也就是 FILENAME 为空，因为没有输入文件被尚未处理。不过，在规则内使用getline BEGIN可以提供FILENAME值 ","date":"2022-01-12","objectID":"/awk/:17:18","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 当前记录号FNR 变量当前文件中的当前记录号。 每次读取新记录时都会awk递增 FNR（请参见如何将输入拆分为记录）。 每次启动新的输入文件时awk重置FNR为零 ","date":"2022-01-12","objectID":"/awk/:17:19","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 字段数量NF 当前输入记录中的字段数。 NF每次读取新记录，创建新字段或$0更改字段时都会设置设置（请参见检查字段） 与本小节中描述的大多数变量不同，为分配值NF可能会影响 awk的内部工作。特别是，分配to NF可以用于在当前记录中创建字段或从当前记录中删除字段 ","date":"2022-01-12","objectID":"/awk/:17:20","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 函数名称FUNCTAB 变量值是一个数组，其索引和对应值是程序中所有内置，用户定义和扩展函数的名称 表达式有空推到重写，内容缺失严重 表达式是 awk 模式和动作的基本构建块。表达式的计算结果为可以打印，测试或传递给函数的值。此外，表达式可以使用赋值运算符将新值赋给变量或字段 表达式本身可以用作模式或动作语句。大多数其他类型的语句包含一个或多个表达式，这些表达式指定要对其进行操作的数据。与其他语言一样，中的表达式awk可以包括变量，数组引用，常量和函数调用，以及它们与各种运算符的组合 常量： 数值：数字，可以是整数、十进制小数、科学计数法的指数形式 字符串：被冒号包含的字符，可以是任意长度，可以含有 8 bit 的 ASCII 码（包含 ASCII NU ","date":"2022-01-12","objectID":"/awk/:17:21","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 字符串和数字转换如果字符串做数学运算时，当成变量处理，会自动替换为变量值。数字转换为字符串需要使用引号；字符串转换为数字时，需要在字符串前面添加一个0，如果字符无法解析为数字，无法解析的字符会忽略掉 [root@c8 gawk]# gawk 'BEGIN{ ta=1; tb=2; print( tb ta ) - tb, 25fix, 025fix, 7ss, 1e3}' 19 25 21 7 1000 数字和字符转换时，由于地区不同小数点和千位分割符也不同（有的使用逗号，有的使用点）。POSIX 规范规定，awk 执行 awk 操作和读取文件时，用小数点作为分隔符,然而，解释输入数据，因为当 print 和 printf 输出，以及用于数到字符串的转换，则使用本地小数点字符，可以使用 --posix 或 POSIXLY_CORRECT 环境变量强制使用点作为分隔符 # 强制使用 POSIX 规范 [root@c8 gawk]# export POSIXLY_CORRECT=1 [root@c8 gawk]# gawk 'BEGIN { printf \"%g\\n\", 3.1415927 }' 3.14159 [root@c8 gawk]# LC_ALL=en_DK.utf-8 gawk 'BEGIN { printf \"%g\\n\", 3.1415927 }' 3,14159 [root@c8 gawk]# gawk 'BEGIN { printf \"%g\\n\", 3.1415927 }' 3.14159 [root@c8 gawk]# echo 4,321 | gawk '{ print $1 + 1 }' 5 [root@c8 gawk]# echo 4,321 | LC_ALL=en_DK.utf-8 gawk '{ print $1 + 1 }' 5,321 ","date":"2022-01-12","objectID":"/awk/:18:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 算术运算awk 按照从上往下的优先级运算 运算符 说明 x ^ y 求幂，在 POSIX 标准中规范使用，方便移植 x ** y 求幂 - x negation + x (优先级与 -x 相同) Unary plus; the expression is converted to a number x * y 乘法 x / y （优先级与乘法相同） 除法 x % y 求余（商）, x 为负数时，商为负数 x + y 加法 x - y （优先级与加法相同）减法 当混合运算时，需要使用跨号 [root@c8 gawk]# awk 'BEGIN { print -12 \" \" -24 }' -12-24 [root@c8 gawk]# [root@c8 gawk]# awk 'BEGIN { print -12 \" \" (-24) }' -12 -24 变量可以使用类似运算符方式赋值 表达式 说明 变量 += 值 变量值基础上增加值 变量 -= 值 变量值基础上减少值 变量 *= 值 变量值基础上乘以值 变量 /= 值 变量值基础上除以值 变量 ^= 值 变量值基础上求幂运算 变量 ** = 值 变量值基础上求幂运算 变量 %= 值 变量值基础上与值求余 变量++ 变量值+1，变量值不会变 ++变量 变量值+1，变量值会改变 --变量 变量值-1，变量值会改变 ++变量 变量值-1，变量值不会变 # 添加变量值 [root@c8 gawk]# awk 'BEGIN { ta = a; ta +=b ; print ta }' 0 [root@c8 gawk]# awk 'BEGIN { ta = 2; ta +=1 ; print ta }' 3 [root@c8 gawk]# awk 'BEGIN { ta = 3; b = ++ta ; print ta,b }' 4 4 [root@c8 gawk]# awk 'BEGIN { ta = 3; b = ta++ ; print ta,b }' 4 3 官方反馈递增不同版本结果不一样，要避免这种使用方式 [root@c8 gawk]# awk 'BEGIN { ta = 6; ta += ta++ + ++ta ; print ta }' 22 [root@c8 gawk]# awk 'BEGIN { ta = 6; ta += ta++ ; print ta }' 13 比较运算符表达式 表达式 说明 x\u003cy x 小于 y ，为 true x\u003ey x 大于 y ，为 true x==y x 等于 y ，为 true x!=y x 不等于 y ，为 true x\u003e=y x 大于或等于 y，为 true x\u003c=y x 小于或等于 y，为 true x~y 字符串 x 匹配表达式 y，为 true x!~y 字符串 x 不匹配表达式 y，为 true subscript in array 数值 array 中有下标 subscript ，为 true 通过比较每个字符串的第一个字符，然后比较每个字符串的第二个字符等来比较字符串。因此，“10\"小于\"9”。如果有两个字符串，其中一个是另一个的前缀，则较短的字符串小于较长的字符串。因此，“abc\"小于\"abcd” 示例 [root@c8 gawk]# echo 1e2 3 | awk '{ print ($1 \u003c $2) ? \"true\" : \"false\" }' false 由于 == 操作员检查字符串是否相同，而不是是否相等排序，因此需要检查字符串是否相等排序的应用程序可以使用以下方式 a \u003c= b \u0026\u0026 a\u003e = b ","date":"2022-01-12","objectID":"/awk/:19:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 字符串类型和数值类型比较看不懂：https://www.gnu.org/software/gawk/manual/html_node/Variable-Typing.html 用户输入的数字其实是字符串，但是“像”数值，因此当数值比较，看着“像”字符串当成字符串比较，这是故意“矫正”的 +---------------------------------------------- | STRING NUMERIC STRNUM --------+---------------------------------------------- | STRING | string string string | NUMERIC | string numeric numeric | STRNUM | string numeric numeric --------+---------------------------------------------- 判断输入是什么类型 [root@c8 gawk]# echo hello 37 | gawk '{ print typeof($1), typeof($2) }' string strnum 示例：字符串和数值比较 # 1 表示成立 # 0 表示不成立 [root@c8 gawk]# echo ' +3.14' | awk '{print typeof($1)}' strnum [root@c8 gawk]# echo ' +3.14' | awk '{ print($0 == \" +3.14\") }' 1 [root@c8 gawk]# echo ' +3.14' | awk '{ print($0 == \"+3.14\") }' 0 [root@c8 gawk]# echo ' +3.14' | awk '{ print($0 == \"3.14\") }' 0 [root@c8 gawk]# echo ' +3.14' | awk '{ print($0 == 3.14) }' 1 [root@c8 gawk]# echo ' +3.14' | awk '{ print($1 == \" +3.14\") }' 0 [root@c8 gawk]# echo ' +3.14' | awk '{ print($1 == \"+3.14\") }' 1 [root@c8 gawk]# echo ' +3.14' | awk '{ print($1 == \"3.14\") }' 0 [root@c8 gawk]# echo ' +3.14' | awk '{ print($1 == 3.14) }' 1 数组gawk 为了在单个变量中存储多个值，使用关联数组提供该功能。关联数组的索引值可以的任意文本的字符串 定义数组的格式：变量名称[索引] = 值 示例 capital[\"Illinois\"] = \"Springfield\" capital[\"Indiana\"] = \"Indianapolis\" capital[\"Ohio\"] = \"Columbus\" 引用方式也很简单，只需要使用变量时包含索引就行 示例 [root@localhost ~]# gawk 'BEGIN{ var[var1] = \"gawk\" print var[var1] }' gawk for 语句可以遍历数组，索引值不会按照特定顺序返回，但能够指向对应的数据元素值 for (变量名称 in 数组名称) { 操作 } 示例 # 如果索引为数值时，按从小到大排序 [root@xiaosi ~]# gawk 'BEGIN{ var[1]=\"a\"; var[2]=\"b\" ;var[3]=\"c\" ;for (i in var) { print \"index:\",i,\", value: \",var[i]}}' index: 1 , value: a index: 2 , value: b index: 3 , value: c 删除数组变量需要使用这种格式：delete 变量[索引] 陈述语句在 awk 中，任何非零数值或非空的字符串都是 ture；空字符串和数值0为 false [root@c8 gawk]# gawk -f gawk A strange truth value B strange truth value C strange truth value [root@c8 gawk]# cat gawk #xiaosi/2020-07-15 14:40:07 # 文件: gawk BEGIN { if (3.1415927) print \"A strange truth value\" if (\"Four Score And Seven Years Ago\") print \"B strange truth value\" if (j = 57) print \"C strange truth value\" } ","date":"2022-01-12","objectID":"/awk/:20:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" if-then 语句格式：if (condition) then-body [else else-body] 示例： if (x % 2 == 0) print \"x is even\" else print \"x is odd\" # if (x % 2 == 0) print \"x is even\"; else print \"x is odd\" # ","date":"2022-01-12","objectID":"/awk/:21:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" while 语句格式 while (condition){ body } 示例 awk ' { i = 1 while (i \u003c= 3) { print $i i++ } }' inventory-shipped ","date":"2022-01-12","objectID":"/awk/:22:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" do-whiledo 结构执行成功，则循环 while 语句 格式： do body while (condition) 示例 { i = 1 do { print $0 i++ } while (i \u003c= 10) } ","date":"2022-01-12","objectID":"/awk/:23:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" for格式： for (initialization; condition; increment) body 示例 awk ' { for (i = 1; i \u003c= 3; i++) print $i }' inventory-shipped # for (i = 1; i \u003c= 100; i *= 2) print i # # for 是 while 缩写 initialization while (condition) { body increment } # for 遍历 for (i in array) do something with array[i] ","date":"2022-01-12","objectID":"/awk/:24:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" switch格式： switch (expression) { case value or regular expression: case-body default: default-body } 示例； while ((c = getopt(ARGC, ARGV, \"aksx\")) != -1) { switch (c) { case \"a\": # report size of all files all_files = TRUE; break case \"k\": BLOCK_SIZE = 1024 # 1K block size break case \"s\": # do sums only sum_only = TRUE break case \"x\": # don't cross filesystems fts_flags = or(fts_flags, FTS_XDEV) break case \"?\": default: usage() break } } ","date":"2022-01-12","objectID":"/awk/:25:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" break该break语句跳转最里面出来for， while 或 do 包围它循环，是完全跳出了循环 示例： # find smallest divisor of num { num = $1 for (divisor = 2; divisor * divisor \u003c= num; divisor++) { if (num % divisor == 0) break } if (num % divisor == 0) printf \"Smallest divisor of %d is %d\\n\", num, divisor else printf \"%d is prime\\n\", num } # # find smallest divisor of num { num = $1 for (divisor = 2; ; divisor++) { if (num % divisor == 0) { printf \"Smallest divisor of %d is %d\\n\", num, divisor break } if (divisor * divisor \u003e num) { printf \"%d is prime\\n\", num break } } } ","date":"2022-01-12","objectID":"/awk/:26:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" continuecontinue 跳过了循环主体的其余部分，导致围绕循环的下一个循环立即开始 示例 BEGIN { for (x = 0; x \u003c= 20; x++) { if (x == 5) continue printf \"%d \", x } print \"\" } # BEGIN { x = 0 while (x \u003c= 20) { if (x == 5) continue printf \"%d \", x x++ } print \"\" } 退出状态码exit [return code] 可以指定退出状态码，当遇到 exit 时，立即停止 awk ，返回退出状态码。停止处理输入，余下的操作也会被忽略 当 exit 从一条 BEGIN 规则执行一条语句时，该程序立即停止处理所有内容。不会读取任何输入记录。但是，如果存在 END 规则，则作为执行 exit 语句的一部分，将执行该 END 规则如果 exit 在 END 规则主体中使用，它将导致程序立即停止 exit 不属于 BEGIN 或 END 规则的一部分的语句停止执行当前记录的所有其他自动规则，跳过读取所有剩余的输入记录，并在 END 有一个记录的情况下执行该规则。 gawk 也跳过任何ENDFILE 规则；他们不执行 如果将参数提供给 exit，则其值将用作 awk 流程的退出状态代码。如果未提供任何参数，则 exit导致awk返回“success”状态。如果将参数提供给第一条exit语句，然后exit从END没有参数的规则中第二次调用该参数，则 awk使用先前提供的退出值 为了方便移植，退出状态码应该在 0到126，负值或126以上的值在可能会在某些操作系统产生错误 示例 BEGIN { if ((\"date\" | getline date_now) \u003c= 0) { print \"Can't get system date\" \u003e \"/dev/stderr\" exit 1 } print \"current date is\", date_now close(\"date\") } 脚本","date":"2022-01-12","objectID":"/awk/:27:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 内建函数gawk编程语言提供了不少内置函数，可进行一些常见的数学、字符串以及时间函数运算 gawk数学函数 描述 atan2(x, y) x/y的反正切，x和y以弧度为单位 cos(x) x的余弦，x以弧度为单位 exp(x) x的指数函数 int(x) x的整数部分，取靠近零一侧的值 log(x) x的自然对数 rand( ) 比0大比1小的随机浮点值 sin(x) x的正弦，x以弧度为单位 sqrt(x) x的平方根 srand(x) 为计算随机数指定一个种子值 and(v1, v2) 执行值v1和v2的按位与运算 compl(val) 执行val的补运算 lshift(val, count) 将值val左移count位 or(v1, v2) 执行值v1和v2的按位或运算 rshift(val, count) 将值val右移count位 xor(v1, v2) 执行值v1和v2的按位异或运算 gawk 字符串函数 描述 asort(s [,d]) 将数组s按数据元素值排序。索引值会被替换成表示新的排序顺序的连续数字。另外，如果指定了d，则排序后的数组会存储在数组d中 asorti(s [,d]) 将数组s按索引值排序。生成的数组会将索引值作为数据元素值，用连续数字索引来表明排序顺序。另外如果指定了d，排序后的数组会存储在数组d中 gensub(r, s, h [, t]) 查找变量$0或目标字符串t（如果提供了的话）来匹配正则表达式r。如果h是一个以g或G开头的字符串，就用s替换掉匹配的文本。如果h是一个数字，它表示要替换掉第h处r匹配的地方 gsub(r, s [,t]) 查找变量$0或目标字符串t（如果提供了的话）来匹配正则表达式r。如果找到了，就全部替换成字符串s index(s, t) 返回字符串t在字符串s中的索引值，如果没找到的话返回0 length([s]) 返回字符串s的长度；如果没有指定的话，返回$0的长度 match(s, r [,a]) 返回字符串s中正则表达式r出现位置的索引。如果指定了数组a，它会存储s中匹配正则表达式的那部分 split(s, a [,r]) 将s用FS字符或正则表达式r（如果指定了的话）分开放到数组a中。返回字段的总数 sprintf(format,variables) 用提供的format和variables返回一个类似于printf输出的字符串 sub(r, s [,t]) 在变量$0或目标字符串t中查找正则表达式r的匹配。如果找到了，就用字符串s替换掉第一处匹配 substr(s, i [,n]) 返回s中从索引值i开始的n个字符组成的子字符串。如果未提供n，则返回s剩下的部分 tolower(s) 将s中的所有字符转换成小写 toupper(s) 将s中的所有字符转换成大写 gawk 时间函数 描述 mktime(datespec) 将一个按YYYY MM DD HH MM SS [DST]格式指定的日期转换成时间戳值 strftime(format[,timestamp]) 将当前时间的时间戳或timestamp（如果提供了的话）转化格式化日期（采用shell函数date()的格式） systime( ) 返回当前时间的时间戳 自定义函数格式： function name([variables]) { statements } ","date":"2022-01-12","objectID":"/awk/:28:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 函数库在 gawk 脚本文件中，可以通过 @include \"文件地址\" 引用其他 gawk 文件，其中文件地址可以是相对路径，也可以是绝对路径，同个目录下可以直接使用文件名 示例 file1 中引用 file2 [root@c8 gawk]# gawk -f file2 is file1 is file2 # file1 内容 [root@c8 gawk]# cat file1 BEGIN { print \"is file1\" } # file2 内容 [root@c8 gawk]# cat file2 @include \"./file1\" BEGIN { print \"is file2\" } 还可以嵌套使用 [root@c8 gawk]# gawk -f file3 is file1 is file2 is file3 [root@c8 gawk]# cat file3 @include \"./file2\" BEGIN { print \"is file3\" } # file2 内容 [root@c8 gawk]# cat file2 @include \"./file1\" BEGIN { print \"is file2\" } 实例 ","date":"2022-01-12","objectID":"/awk/:29:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看文本行数 [root@c8 gawk]# awk 'END{ print NR }' file4 2 ","date":"2022-01-12","objectID":"/awk/:30:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看偶数行内容 [root@c8 gawk]# awk 'NR % 2 == 0 ' file4 aa bb cd os iw ","date":"2022-01-12","objectID":"/awk/:31:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看奇数行内容 [root@c8 gawk]# awk 'NR % 2 == 1 ' file4 11 22 39 45 02 ","date":"2022-01-12","objectID":"/awk/:32:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看所有文件字节数 [root@c8 gawk]# ll vps##sshd* | gawk '{ x += $5 } END{ print \"总字节数：\" x }' 总字节数：8566221 ","date":"2022-01-12","objectID":"/awk/:33:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看文本行内容，不含空行 [root@c8 gawk]# gawk 'NF \u003e 0' ssh.log Jul 5 08:54:21 localhost sshd[29663]: pam_succeed_if(sshd:auth): requirement \"uid \u003e= 1000\" not met by user \"root\" Jul 5 08:54:23 localhost sshd[29663]: Failed password for root from 129.211.75.184 port 41502 ssh2 Jul 5 08:54:23 localhost sshd[29663]: Received disconnect from 129.211.75.184 port 41502:11: Bye Bye [preauth] Jul 5 08:54:23 localhost sshd[29663]: Disconnected from 129.211.75.184 port 41502 [preauth] Jul 5 08:54:26 localhost sshd[29669]: Invalid user irc from 118.24.89.243 port 49904 Jul 5 08:54:26 localhost sshd[29669]: input_userauth_request: invalid user irc [pr^C ... ","date":"2022-01-12","objectID":"/awk/:34:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看文件中最长的行宽度 [root@c8 gawk]# awk '{ if (length($0) \u003e max) max = length($0) } END{ print max }' vps##sshd.log 196 ","date":"2022-01-12","objectID":"/awk/:35:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 以字符e为分隔符，显示第一部分和第二部分 [root@yh ~]# awk ##Fe '{print $1,$2}' ena svch ck=1 svk y=https:// copr##b .cloud.f /r sults/libr ","date":"2022-01-12","objectID":"/awk/:36:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 以字符e为分隔符，格式显示第二部分 [root@yh ~]# awk ##Fe '{print \"echo：\",$2}' ena echo： ck=1 echo： y=https:// echo： .cloud.f echo： sults/libr ","date":"2022-01-12","objectID":"/awk/:37:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 以字符e为分隔符，显示第一部分和第二部分 [root@yh ~]# awk 'BEGIN{FS=\"e\"}{print \"echo：\",$2}' ena echo： ck=1 echo： y=https:// echo： .cloud.f echo： sults/libr ","date":"2022-01-12","objectID":"/awk/:38:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 指定显示分隔符 [root@yh ~]# awk ##Fe 'BEGIN{OFS=\"=\"}{print \"echo\",$2}' ena [root@yh ~]# awk 'BEGIN{FS=\"e\";OFS=\"=\"}{print \"echo\",$2}' ena echo=ck=1 echo=y=https:// echo=.cloud.f echo=sults/libr ","date":"2022-01-12","objectID":"/awk/:39:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 指定读取分隔符 [root@yh ~]# awk ##Fe 'BEGIN{RS=\"=\"}{print \"echo：\",$2}' ena echo： ck echo： y echo： .cloud.f ","date":"2022-01-12","objectID":"/awk/:40:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 指定输出分隔符 [root@yh ~]# awk ##Fe 'BEGIN{ORS=\"!!!\"}{print \"echo\",$2}' ena echo ck=1!!!echo y=https://!!!echo .cloud.f!!!echo sults/libr!!![root@yh ~]# ","date":"2022-01-12","objectID":"/awk/:41:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 统计文本的所有行 [root@yh ~]# awk ##Fe '{print \"第\"NR\"行\",$2}' ena enb 第1行 ck=1 第2行 y=https:// 第3行 .cloud.f 第4行 sults/libr 第5行 !o 第6行 23 第7行 a!c ","date":"2022-01-12","objectID":"/awk/:42:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 分开统计处理文本的所有行 [root@yh ~]# awk ##Fe '{print \"第\"FNR\"行\",$2}' ena enb 第1行 ck=1 第2行 y=https:// 第3行 .cloud.f 第4行 sults/libr 第1行 !o 第2行 23 第3行 a!c ","date":"2022-01-12","objectID":"/awk/:43:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" NF查看以e作为分隔符号，显示行号和最后一段 [root@yh ~]# awk ##Fe '{print NF,$NF}' ena 2 ck=1 2 y=https:// 4 ct.org 4 y.sv ","date":"2022-01-12","objectID":"/awk/:44:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 自定义变量示例 [root@yh ~]# awk ##Fe 'BEGIN{ec=\"echo：\"}{print ec,$1}' ena [root@yh ~]# awk ##v ec=\"echo：\" -Fe '{print ec,$1}' ena echo： svch echo： svk echo： copr##b echo： /r ","date":"2022-01-12","objectID":"/awk/:45:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 格式输出 [root@yh ~]# df ##Th |sed '1d' |awk '{printf \"%+1s %-23s %+s %-14s %+s %+4s %+7s %+5s \\n\",\"设备：\",$1,\"挂载点：\",$7,\"剩余空间：\",$5,\"总容量：\",$3}' 设备： /dev/mapper/centos##root 挂载点： / 剩余空间： 16G 总容量： 17G 设备： devtmpfs 挂载点： /dev 剩余空间： 900M 总容量： 900M 设备： tmpfs 挂载点： /dev/shm 剩余空间： 911M 总容量： 911M 设备： tmpfs 挂载点： /run 剩余空间： 902M 总容量： 911M 设备： tmpfs 挂载点： /sys/fs/cgroup 剩余空间： 911M 总容量： 911M 设备： /dev/sda1 挂载点： /boot 剩余空间： 831M 总容量： 1014M 设备： tmpfs 挂载点： /run/user/0 剩余空间： 183M 总容量： 183M ","date":"2022-01-12","objectID":"/awk/:46:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 正则表达式示例 [root@yh ~]# awk ##Fe '/^s/{print $1}' ena svch svk ","date":"2022-01-12","objectID":"/awk/:47:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 显示UID小于大于或等于3且小于7的用户 [root@yh ~]# awk ##F: '$3\u003e=5 \u0026\u0026 $3\u003c7{print $1}' /etc/passwd sync shutdown ","date":"2022-01-12","objectID":"/awk/:48:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看使用率大于10的磁盘和挂载点 [root@yh ~]# df ##Th | sed '1d' |awk '+$6\u003e10{print $1,$NF}' /dev/sda1 /boot ","date":"2022-01-12","objectID":"/awk/:49:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 匹配UID为0到第一次匹配nologin结尾的用户 [root@yh ~]# awk ##F: '$3==0,$7~\"nologin$\"{print $1}' /etc/passwd root bin ","date":"2022-01-12","objectID":"/awk/:50:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" BRGIN模式与END模式示例 [root@yh ~]# head ##n 5 /etc/passwd | awk -F: 'BEGIN{print \"user\",\"ID\",\"shell\"}{print $1,$3,$7}END{print\"===========\"}' user ID shell root 0 /bin/bash bin 1 /sbin/nologin daemon 2 /sbin/nologin adm 3 /sbin/nologin lp 4 /sbin/nologin =========== ","date":"2022-01-12","objectID":"/awk/:51:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" if语句示例 [root@yh ~]# head ##n 3 /etc/passwd | awk -F: '{if($3==0) {printf \"%-15s %-14s \\n\",$1,\"是超级用户\"} else{printf \"%-15s %-14s \\n\",$1,\"是普通用户\"}}' root 是超级用户 bin 是普通用户 daemon 是普通用户 ","date":"2022-01-12","objectID":"/awk/:52:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 变量示例 [root@yh ~]# head ##n 3 /etc/passwd | awk -F: -v i==0 '{if($3\u003c11) {i++}}END{print \"UID小于3的用户数量：\",i}' /etc/passwd UID小于3的用户数量： 9 ","date":"2022-01-12","objectID":"/awk/:53:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" BEGIN模式定义变量, [root@yh ~]# awk ##F: ' BEGIN{bh=0;nh=0}{if($NF==\"/bin/bash\"){bh++} else {nh++}} END{print \"bash用户数量：\",bh,\"nologin用户数量：\",nh}' /etc/passwd bash用户数量： 1 nologin用户数量： 18 ","date":"2022-01-12","objectID":"/awk/:54:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" while循环示例 [root@yh ~]# head ##n 3 /etc/passwd | awk '{i=1;while(i\u003c=3){print $0;i++}}' root:x:0:0:root:/root:/bin/bash root:x:0:0:root:/root:/bin/bash root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin bin:x:1:1:bin:/bin:/sbin/nologin bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin ","date":"2022-01-12","objectID":"/awk/:55:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" length函数示例 [root@yh ~]# head ##n 3 /etc/passwd | awk -v n=0 -F: '{i=1; while(i\u003c=NF) {if(length($i)\u003e4) {print $i;n++};i++}}END{print \"字符串长度大于4的数量：\"n}' /root /bin/bash /sbin/nologin daemon daemon /sbin /sbin/nologin 字符串长度大于4的数量：7 ","date":"2022-01-12","objectID":"/awk/:56:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" for循环遍历数组示例 [root@yh ~]# head ##n 3 /etc/passwd | awk -F: '{for(i=1;i\u003c=3;i++) {print $0}}' root:x:0:0:root:/root:/bin/bash root:x:0:0:root:/root:/bin/bash root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin bin:x:1:1:bin:/bin:/sbin/nologin bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin ","date":"2022-01-12","objectID":"/awk/:57:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" gawk 数组示例 [root@yh ~]# awk ##F: '{shell[$NF]++}END{for(i in shell) {print i,shell[i]}}' /etc/passwd /bin/sync 1 /bin/bash 1 /sbin/nologin 15 /sbin/halt 1 /sbin/shutdown 1 ","date":"2022-01-12","objectID":"/awk/:58:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 删除所有文件换行符 [root@master ~]# awk ##v RS=\"\" '{gsub(\"\\n\",\"\");print}' file ","date":"2022-01-12","objectID":"/awk/:59:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 特定宽度为8换行 [root@master ~]# awk 'NR{for(n=0;n\u003clength;n+=8)print substr($0,n+1,8)}' file ","date":"2022-01-12","objectID":"/awk/:60:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 打乱文本内容 awk 'BEGIN{10000*srand();} {printf \"%s %s\\n\", rand(), $0}' file | sort ##k1n | awk '{gsub($1FS,\"\"); print $0}' ","date":"2022-01-12","objectID":"/awk/:61:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 示例：以 pyh: 开头的行作为键，其余为值 [root@master yaml]# cat phy.txt phy:11111 21231321 23243920 phy:22222 sfds fsdw [root@master yaml]# [root@master yaml]# [root@master yaml]# awk '/phy/{a=$0}!/phy/{print a\"\\t\"$0}' phy.txt phy:11111 21231321 phy:11111 23243920 phy:22222 sfds phy:22222 fsdw ","date":"2022-01-12","objectID":"/awk/:62:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 千位分割 [root@master ~]# awk \"BEGIN{printf \\\"%'d\\n\\\",1234567890}\" 1,234,567,890 ","date":"2022-01-12","objectID":"/awk/:63:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看cpu型号 [root@localhost ~]# awk ##F: '/model name/ {name=$2} END {print name}' /proc/cpuinfo Intel(R) Xeon(R) CPU E5##2660 v2 @ 2.20GHz ","date":"2022-01-12","objectID":"/awk/:64:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看cpu核心数量 [root@localhost ~]# lscpu | awk ##F: '/model name/ {core++} END {print core}' /proc/cpuinfo 4 [root@localhost ~]# awk ##F: '/model name/ {core++} END {print core}' /proc/cpuinfo 4 ","date":"2022-01-12","objectID":"/awk/:65:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 非 risk-v2 和 risk-listener 部分添加#号注释 # 文本部分 [program:risk##v2] environment=DJANGO_SETTINGS_MODULE=risk.settings.{env},RULE_MODULE_CONFIG=configs.dev,NEW_RELIC_CONFIG_FILE=/data/www/risk##v2/configs/newrelic.ini directory=/data/www/%(program_name)s/configs command= newrelic##admin run-program /usr/local/bin/uwsgi --ini uwsgi-%(program_name)s.ini autostart=true autorestart=true stopsignal=QUIT killasgroup=true stdout_logfile=/data/logs/%(program_name)s/supervisor.stdout.log stderr_logfile=/data/logs/%(program_name)s/supervisor.stderr.log [program:risk##monitor] environment=RISK_MONITOR_CONFIG=monitor.settings.{env} directory=/data/www/risk##v2/ command=/data/www/risk##v2/monitor/venv/bin/python /data/www/risk-v2/monitor/app.py autostart=true autorestart=true stopsignal=QUIT killasgroup=true stdout_logfile=/data/logs/risk##v2/supervisor.stdout.log stderr_logfile=/data/logs/risk##v2/supervisor.stderr.log [program:risk##listener] environment=RISK_MONITOR_CONFIG=monitor.settings.{env} directory=/data/www/risk##v2/ command=/data/www/risk##v2/monitor/venv/bin/python /data/www/risk-v2/monitor/supervisor_listener.py autostart=true autorestart=true stdout_logfile=/data/logs/risk##v2/supervisor.stdout.log stderr_logfile=/data/logs/risk##v2/supervisor.stderr.log [program:risk##jxl-pull] environment=DJANGO_SETTINGS_MODULE=risk.settings.{env} directory=/data/www/risk##v2/ command=/data/www/risk##v2/venv/bin/python /data/www/risk-v2/scripts/jxl_data_pull.py autostart=true autorestart=true stopsignal=QUIT killasgroup=true stdout_logfile=/data/logs/risk##v2/supervisor.stdout.log stderr_logfile=/data/logs/risk##v2/supervisor.stderr.log # awk [root@centos7 ~]# awk '/program:risk##(v2|listener)/{p=1}NF==0{p=0;print;next}!p{$0=\"#\"$0}1' file.txt [program:risk##v2] environment=DJANGO_SETTINGS_MODULE=risk.settings.{env},RULE_MODULE_CONFIG=configs.dev,NEW_RELIC_CONFIG_FILE=/data/www/risk##v2/configs/newrelic.ini ... #[program:risk##monitor] #environment=RISK_MONITOR_CONFIG=monitor.settings.{env} ... ","date":"2022-01-12","objectID":"/awk/:66:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 每行后面增加一行空行 [root@centos7 ~]# awk '1;{print \"\"}' file.txt 等效 [root@centos7 ~]# awk 'BEGIN{ORS=\"\\n\\n\"};1' file.txt ","date":"2022-01-12","objectID":"/awk/:67:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 查看系统版本 [root@centos7 ~]# awk '{print ($1,$3~/^[0##9]/?$3:$4)}' /etc/redhat-release CentOS 7.8.2003 [root@centos7 ~]# awk ##F'[= \"]' '/PRETTY_NAME/{print $3,$4,$5}' /etc/os-release CentOS Linux 7 ","date":"2022-01-12","objectID":"/awk/:68:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 获取内存容量（总容量M） [root@centos7 shell]# free ##m | awk '/Mem/ {print $2}' 3770 ","date":"2022-01-12","objectID":"/awk/:69:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 获取交换分区容量（总容量M） [root@centos7 shell]# free ##m | awk '/Swap/ {print $2}' 2047 ","date":"2022-01-12","objectID":"/awk/:70:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 获取系统运行时长 [root@centos7 shell]# awk '{a=$1/86400;b=($1%86400)/3600;c=($1%3600)/60;d=$1%60} {printf(\"%ddays, %d:%d:%d\\n\",a,b,c,d)}' /proc/uptime 0days, 5:29:27 ","date":"2022-01-12","objectID":"/awk/:71:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 获取CPU频率（MHz） [root@centos7 shell]# awk ##F: '/cpu MHz/ {freq=$2} END {print freq}' /proc/cpuinfo | sed 's/^[ \\t]*//;s/[ \\t]*$//' 2495.999 ","date":"2022-01-12","objectID":"/awk/:72:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 获取系统平均负载统计时间 [root@centos7 ~]# w | head ##1 | awk -F'load average:' '{print $2}' | sed 's/^[ \\t]*//;s/[ \\t]*$//' 0.12, 0.05, 0.05 ","date":"2022-01-12","objectID":"/awk/:73:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 竖排调整为横排，去除感叹号 # 等效，但使用空格分隔：awk '/!/{$0=\"\";print a;a=\"\"}{a=a?a\" \"$0:$0}' file # 等效，但使用空格分隔：awk -v RS='!' 'NF+=0' OFS=' ' file # 等效：gawk 'BEGIN{ RS=\"!\"; OFS=\"\\t\"} {NF+=0; print $0}' file [root@localhost ~]# awk -v RS='!' 'NF+=0' OFS='\\t' file msgno=100004944 bind_house_type=2 bind_msg_type=16 bind_msg_no=100004944 bind_house_cnt=1 house_name=254 msgno=100022884 bind_house_type=2 bind_msg_type=16 bind_msg_no=100022884 bind_house_cnt=1 house_name=254 msgno=100047553 bind_house_type=2 bind_msg_type=16 bind_msg_no=100047553 bind_house_cnt=1 house_name=254 msgno=68768 bind_house_type=2 bind_msg_type=16 bind_msg_no=68768 bind_house_cnt=1 house_name=254 # 文本 [root@localhost ~]# cat file msgno=100004944 bind_house_type=2 bind_msg_type=16 bind_msg_no=100004944 bind_house_cnt=1 house_name=254 ! msgno=100022884 bind_house_type=2 bind_msg_type=16 bind_msg_no=100022884 bind_house_cnt=1 house_name=254 ! msgno=100047553 bind_house_type=2 bind_msg_type=16 bind_msg_no=100047553 bind_house_cnt=1 house_name=254 ! msgno=68768 bind_house_type=2 bind_msg_type=16 bind_msg_no=68768 bind_house_cnt=1 house_name=254 ! ","date":"2022-01-12","objectID":"/awk/:74:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["文本处理"],"content":" 第一列去除重复字符串，第二列统计数值之和 [root@centos7 ~]# awk '{a[$1]+=$2}END{for(i in a)print i,a[i]}' txt a 13 b 11 c 6 [root@centos7 ~]# cat txt a 13 b 2 c 5 b 9 c 1 给外部变量赋值 假设将值存在文件t中，文件t内容如下，只有一行：a b c 需要将a、b和c分别赋给外部变量x、y和z，则脚本可写成如下： eval $(awk '{ printf(\"x=%s\\ny=%s\\nz=%s\",$1,$2,$3); }' ./t) echo $x echo $y echo $z 请注意printf函数中的换行符\\n是必须的，起关键作用的是eval命令，它在很多场景有特别的用处。 ","date":"2022-01-12","objectID":"/awk/:75:0","tags":["awk"],"title":"gawk","uri":"/awk/"},{"categories":["linux"],"content":" 内容来自以下文档： taozj mikelLam 性能优化","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:0:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 性能指标高并发和响应快对应着性能优化的两个核心指标：吞吐和延时。 应用负载角度：直接影响了产品终端的用户体验 系统资源角度：资源使用率、饱和度等 性能问题的本质就是系统资源已经到达瓶颈，但请求的处理还不够快，无法支撑更多的请求。 性能分析实际上就是找出应用或系统的瓶颈，设法去避免或缓解它们。 选择指标评估应用程序和系统性能 为应用程序和系统设置性能目标 进行性能基准测试 性能分析定位瓶颈 性能监控和告警 对于不同的性能问题要选取不同的性能分析工具。 下面是常用的Linux Performance Tools以及对应分析的性能问题类型。 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:1:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 平均负载平均负载：在单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。 其中不可中断进程是正处于内核态关键流程中的进程（如常见的等待设备的I/O响应）。不可中断状态实际上是系统对进程和硬件设备的一种保护机制 实际生产环境中将系统的平均负载监控起来，根据历史数据判断负载的变化趋势。当负载存在明显升高趋势时，及时进行分析和调查。 当然也可以当设置阈值（如当平均负载高于CPU数量的70%时） 现实工作中我们会经常混淆平均负载和CPU使用率的概念，其实两者并不完全对等： CPU密集型进程，大量CPU使用会导致平均负载升高，此时两者一致 I/O密集型进程，等待I/O也会导致平均负载升高，此时CPU使用率并不一定高 大量等待CPU的进程调度会导致平均负载升高，此时CPU使用率也会比较高 平均负载高时可能是CPU密集型进程导致，也可能是I/O繁忙导致。具体分析时可以结合mpstat/pidstat工具辅助分析负载来源 CPU通过vmstat可以查看系统总体的上下文切换情况 # 每隔5s输出一组数据 vmstat 5 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 103388 145412 511056 0 0 18 60 1 1 2 1 96 0 0 0 0 0 103388 145412 511076 0 0 0 2 450 1176 1 1 99 0 0 0 0 0 103388 145412 511076 0 0 0 8 429 1135 1 1 98 0 0 0 0 0 103388 145412 511076 0 0 0 0 431 1132 1 1 98 0 0 0 0 0 103388 145412 511076 0 0 0 10 467 1195 1 1 98 0 0 1 0 0 103388 145412 511076 0 0 0 2 426 1139 1 0 99 0 0 4 0 0 95184 145412 511108 0 0 0 74 500 1228 4 1 94 0 0 0 0 0 103512 145416 511076 0 0 0 455 723 1573 12 3 83 2 0 # cs （context switch） 每秒上下文切换次数 # in （interrupt） 每秒中断次数 # r （runnning or runnable）就绪队列的长度，正在运行和等待CPU的进程数 # b （Blocked） 处于不可中断睡眠状态的进程数 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:2:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" CPU上下文切换CPU上下文切换，就是把前一个任务的CPU上下文（CPU寄存器和PC）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的位置，运行新任务。其中，保存下来的上下文会存储在系统内核中，待任务重新调度执行时再加载，保证原来的任务状态不受影响。 按照任务类型，CPU上下文切换分为： 进程上下文切换 线程上下文切换 中断上下文切换 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:3:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 进程上下文切换Linux进程按照等级权限将进程的运行空间分为内核空间和用户空间。从用户态向内核态转变时需要通过系统调用来完成。 一次系统调用过程其实进行了两次CPU上下文切换： CPU寄存器中用户态的指令位置先保存起来，CPU寄存器更新为内核态指令的位置，跳转到内核态运行内核任务； 系统调用结束后，CPU寄存器恢复原来保存的用户态数据，再切换到用户空间继续运行。 系统调用过程中并不会涉及虚拟内存等进程用户态资源，也不会切换进程。和传统意义上的进程上下文切换不同。因此系统调用通常称为特权模式切换 进程是由内核管理和调度的，进程上下文切换只能发生在内核态。 因此相比系统调用来说，在保存当前进程的内核状态和CPU寄存器之前，需要先把该进程的虚拟内存，栈保存下来。再加载新进程的内核态后，还要刷新进程的虚拟内存和用户栈 进程只有在调度到CPU上运行时才需要切换上下文，有以下几种场景： CPU时间片轮流分配 系统资源不足导致进程挂起 进程通过sleep函数主动挂起 高优先级进程抢占时间片 硬件中断时CPU上的进程被挂起转而执行内核中的中断服务 要查看每个进程的详细情况，需要使用pidstat来查看每个进程上下文切换情况 pidstat -w 5 14时51分16秒 UID PID cswch/s nvcswch/s Command 14时51分21秒 0 1 0.80 0.00 systemd 14时51分21秒 0 6 1.40 0.00 ksoftirqd/0 14时51分21秒 0 9 32.67 0.00 rcu_sched 14时51分21秒 0 11 0.40 0.00 watchdog/0 14时51分21秒 0 32 0.20 0.00 khugepaged 14时51分21秒 0 271 0.20 0.00 jbd2/vda1-8 14时51分21秒 0 1332 0.20 0.00 argusagent 14时51分21秒 0 5265 10.02 0.00 AliSecGuard 14时51分21秒 0 7439 7.82 0.00 kworker/0:2 14时51分21秒 0 7906 0.20 0.00 pidstat 14时51分21秒 0 8346 0.20 0.00 sshd 14时51分21秒 0 20654 9.82 0.00 AliYunDun 14时51分21秒 0 25766 0.20 0.00 kworker/u2:1 14时51分21秒 0 28603 1.00 0.00 python3 # cswch 每秒自愿上下文切换次数 （进程无法获取所需资源导致的上下文切换） # nvcswch 每秒非自愿上下文切换次数 （时间片轮流等系统强制调度） ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:3:1","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 线程上下文切换线程上下文切换分为两种： 前后线程同属于一个进程，切换时虚拟内存资源不变，只需要切换线程的私有数据，寄存器等； 前后线程属于不同进程，与进程上下文切换相同。 同进程的线程切换消耗资源较少，这也是多线程的优势。 示例 # 首先获取空闲系统的上下文切换次数 [root@localhost ~]# vmstat 1 1 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 3029568 3164 465476 0 0 30 11 165 2732 0 1 98 0 0 # 模拟多线程切换问题 sysbench --threads=10 --max-time=300 threads run # 新终端观察上下文切换情况 [root@localhost ~]# vmstat 1 10 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 8 0 0 3027612 3164 465612 0 0 25 9 1107 2069 2 4 93 0 0 5 0 0 3027352 3164 465612 0 0 0 0 58426 1125114 25 59 16 0 0 6 0 0 3027352 3164 465612 0 0 0 0 58767 1208424 24 60 17 0 0 8 0 0 3027320 3164 465612 0 0 0 0 58383 1186721 25 60 15 0 0 6 0 0 3027352 3164 465612 0 0 0 0 58615 1117853 26 58 16 0 0 5 0 0 3027352 3164 465612 0 0 0 0 55141 1290941 25 60 15 0 0 7 0 0 3027352 3164 465612 0 0 0 0 59211 1139840 25 58 17 0 0 7 0 0 3027352 3164 465612 0 0 0 0 56423 1193208 26 59 16 0 0 3 0 0 3027352 3164 465612 0 0 0 0 57889 1205147 26 59 15 0 0 6 0 0 3027352 3164 465612 0 0 0 0 58687 1162314 25 59 16 0 0 # 此时发现cs数据明显升高，同时观察其他指标： # r列： 远超系统CPU个数，说明存在大量CPU竞争 # us和sy列： sy列占比60%，说明CPU主要被内核占用 # in列： 中断次数明显上升，说明中断处理也是潜在问题 # 说明运行/等待CPU的进程过多，导致大量的上下文切换，上下文切换导致系统的CPU占用率高 # 查看到底哪个进程导致的问题 [root@localhost ~]# pidstat -w -u 1 -t Linux 4.18.0-348.12.2.el8_5.x86_64 (localhost.localdomain) 02/04/2022 _x86_64_ (4 CPU) 04:58:42 AM UID TGID TID %usr %system %guest %wait %CPU CPU Command 04:58:43 AM 0 3640 - 104.90 228.43 0.00 0.00 333.33 2 sysbench 04:58:43 AM 0 - 3641 10.78 21.57 0.00 20.59 32.35 0 |__sysbench 04:58:43 AM 0 - 3642 10.78 25.49 0.00 19.61 36.27 2 |__sysbench 04:58:43 AM 0 - 3643 13.73 22.55 0.00 21.57 36.27 1 |__sysbench 04:58:43 AM 0 - 3644 9.80 22.55 0.00 19.61 32.35 1 |__sysbench 04:58:43 AM 0 - 3645 9.80 23.53 0.00 19.61 33.33 2 |__sysbench 04:58:43 AM 0 - 3646 9.80 23.53 0.00 19.61 33.33 3 |__sysbench 04:58:43 AM 0 - 3647 9.80 21.57 0.00 21.57 31.37 3 |__sysbench 04:58:43 AM 0 - 3648 12.75 21.57 0.00 23.53 34.31 1 |__sysbench 04:58:43 AM 0 - 3649 8.82 23.53 0.00 15.69 32.35 3 |__sysbench 04:58:43 AM 0 - 3650 8.82 22.55 0.00 20.59 31.37 0 |__sysbench 04:58:43 AM 0 3651 - 0.00 0.98 0.00 0.00 0.98 0 pidstat 04:58:43 AM 0 - 3651 0.00 0.98 0.00 0.00 0.98 0 |__pidstat # 从结果中看出是sysbench导致CPU使用率过高， # 但是pidstat输出的上下文次数加起来也并不多。分析sysbench模拟的是线程的切换， # 因此需要在pidstat后加-t参数查看线程指标。 # 另外对于中断次数过多，我们可以通过/proc/interrupts文件读取 watch -d cat /proc/interrupts # 发现次数变化速度最快的是重调度中断（RES），该中断用来唤醒空闲状态的CPU来调度新的任务运行。 # 分析还是因为过多任务的调度问题，和上下文切换分析一致。 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:3:2","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 中断上下文切换中断上下文切换并不涉及到进程的用户态，因此中断上下文只包括内核态中断服务程序执行所必须的状态（CPU寄存器，内核堆栈，硬件中断参数等）。 中断处理优先级比进程高，所以中断上下文切换和进程上下文切换不会同时发生 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:3:3","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 性能分析工具perfLinux作为多任务操作系统，将CPU时间划分为很短的时间片，通过调度器轮流分配给各个任务使用。为了维护CPU时间，Linux通过事先定义的节拍率，触发时间中断，并使用全局变了jiffies记录开机以来的节拍数。时间中断发生一次该值+1. CPU使用率，除了空闲时间以外的其他时间占总CPU时间的百分比。可以通过/proc/stat中的数据来计算出CPU使用率。因为/proc/stat时开机以来的节拍数累加值，计算出来的是开机以来的平均CPU使用率，一般意义不大。可以间隔取一段时间的两次值作差来计算该段时间内的平均CPU使用率。 性能分析工具给出的都是间隔一段时间的平均CPU使用率，要注意间隔时间的设置。 分析进程的CPU问题可以通过perf，它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题 [root@localhost ~]# perf top -g -p 6170 Samples: 38K of event 'cpu-clock:pppH', 4000 Hz, Event count (approx.): 8550820289 lost: 0/0 drop: 0/0 Children Self Shared Object Symbol + 77.88% 7.25% [kernel] [k] do_syscall_64 + 54.46% 0.16% [kernel] [k] __x64_sys_futex + 54.29% 0.08% [kernel] [k] do_futex + 50.09% 0.55% libpthread-2.28.so [.] __lll_unlock_wake + 49.14% 0.11% [kernel] [k] futex_wake + 48.78% 0.03% [kernel] [k] wake_up_q + 48.75% 48.74% [kernel] [k] _raw_spin_unlock_irqrestore + 48.75% 0.01% [kernel] [k] try_to_wake_up + 39.24% 16.84% libc-2.28.so [.] __sched_yield + 37.96% 0.00% [unknown] [k] 0000000000000000 + 28.77% 0.00% [kernel] [k] entry_SYSCALL_64_after_hwframe + 15.50% 0.24% [kernel] [k] schedule + 15.26% 0.69% [kernel] [k] __sched_text_start + 14.46% 14.44% [kernel] [k] __raw_spin_unlock_irq + 13.76% 0.24% [kernel] [k] __x64_sys_sched_yield + 11.02% 0.11% [kernel] [k] finish_task_switch + 7.54% 1.57% libpthread-2.28.so [.] __lll_lock_wait + 5.07% 0.23% [kernel] [k] futex_wait + 4.54% 0.14% [kernel] [k] futex_wait_queue_me + 2.36% 2.36% [kernel] [k] do_sched_yield + 1.64% 1.64% libpthread-2.28.so [.] __pthread_mutex_unlock_usercnt + 1.48% 0.25% [kernel] [k] syscall_slow_exit_work + 1.23% 0.69% [kernel] [k] __audit_syscall_exit 0.89% 0.48% [kernel] [k] syscall_trace_enter + 0.71% 0.71% libpthread-2.28.so [.] __pthread_mutex_lock 0.30% 0.15% [kernel] [k] futex_wait_setup 0.27% 0.27% [kernel] [k] __audit_syscall_entry 0.24% 0.24% [kernel] [k] kfree 0.19% 0.19% sysbench [.] 0x000000000001ed7f 0.16% 0.16% sysbench [.] 0x000000000001ed89 0.14% 0.14% [kernel] [k] ktime_get_coarse_real_ts64 0.13% 0.09% [kernel] [k] _raw_spin_lock ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:4:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 进程状态 R Running/Runnable，表示进程在CPU的就绪队列中，正在运行或者等待运行； D Disk Sleep，不可中断状态睡眠，一般表示进程正在跟硬件交互，并且交互过程中不允许被其他进程中断； Z Zombie，僵尸进程，表示进程实际上已经结束，但是父进程还没有回收它的资源； S Interruptible Sleep，可中断睡眠状态，表示进程因为等待某个事件而被系统挂起，当等待事件发生则会被唤醒并进入R状态； I Idle，空闲状态，用在不可中断睡眠的内核线程上。 该状态不会导致平均负载升高； T Stop/Traced，表示进程处于暂停或跟踪状态（SIGSTOP/SIGCONT， GDB调试）； X Dead，进程已经消亡，不会在top/ps中看到。 对于不可中断状态，一般都是在很短时间内结束，可忽略。但是如果系统或硬件发生故障，进程可能会保持不可中断状态很久，甚至系统中出现大量不可中断状态，此时需注意是否出现了I/O性能问题。 僵尸进程一般多进程应用容易遇到，父进程来不及处理子进程状态时子进程就提前退出，此时子进程就变成了僵尸进程。大量的僵尸进程会用尽PID进程号，导致新进程无法建立。 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:5:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 性能工具平均负载案例 先用uptime查看系统平均负载 判断负载在升高后再用mpstat和pidstat分别查看每个CPU和每个进程CPU使用情况.找出导致平均负载较高的进程 上下文切换案例 先用vmstat查看系统上下文切换和中断次数 再用pidstat观察进程的自愿和非自愿上下文切换情况 最后通过pidstat观察线程的上下文切换情况 进程CPU使用率高案例 先用top查看系统和进程的CPU使用情况,定位到进程 再用perf top观察进程调用链,定位到具体函数 系统CPU使用率高案例 先用top查看系统和进程的CPU使用情况,top/pidstat都无法找到CPU使用率高的进程 重新审视top输出 从CPU使用率不高,但是处于Running状态的进程入手 perf record/report发现短时进程导致 (execsnoop工具) 不可中断和僵尸进程案例 先用top观察iowait升高,发现大量不可中断和僵尸进程 strace无法跟踪进程系统调用 perf分析调用链发现根源来自磁盘直接I/O 软中断案例 top观察系统软中断CPU使用率高 查看watch -d -n 1 'cat /proc/softirqs'找到变化速率较快的几种软中断 sar命令发现是网络小包问题 tcpdump找出网络帧的类型和来源, 确定SYN FLOOD攻击导致 内存","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:6:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 内存映射大多数计算机用的主存都是动态随机访问内存(DRAM)，只有内核才可以直接访问物理内存。Linux内核给每个进程提供了一个独立的虚拟地址空间，并且这个地址空间是连续的。这样进程就可以很方便的访问内存(虚拟内存)。 虚拟地址空间的内部分为内核空间和用户空间两部分，不同字长的处理器地址空间的范围不同。32位系统内核空间占用1G，用户空间占3G。 64位系统内核空间和用户空间都是128T，分别占内存空间的最高和最低处，中间部分为未定义。 并不是所有的虚拟内存都会分配物理内存，只有实际使用的才会。分配后的物理内存通过内存映射管理。为了完成内存映射，内核为每个进程都维护了一个页表，记录虚拟地址和物理地址的映射关系。页表实际存储在CPU的内存管理单元MMU中，处理器可以直接通过硬件找出要访问的内存。 当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存，更新进程页表，再返回用户空间恢复进程的运行。 MMU以页为单位管理内存，页大小4KB。为了解决页表项过多问题Linux提供了多级页表和HugePage的机制。 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:7:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 虚拟内存空间分布用户空间内存从低到高是五种不同的内存段： 只读段 代码和常量等 数据段 全局变量等 堆 动态分配的内存，从低地址开始向上增长 文件映射 动态库、共享内存等，从高地址开始向下增长 栈 包括局部变量和函数调用的上下文等，栈的大小是固定的。一般8MB ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:8:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 内存分配malloc对应到系统调用上有两种实现方式： brk() 针对小块内存(\u003c128K)，通过移动堆顶位置来分配。内存释放后不立即归还内存，而是被缓存起来。 **mmap()**针对大块内存(\u003e128K)，直接用内存映射来分配，即在文件映射段找一块空闲内存分配。 前者的缓存可以减少缺页异常的发生，提高内存访问效率。但是由于内存没有归还系统，在内存工作繁忙时，频繁的内存分配/释放会造成内存碎片。 ，后者在释放时直接归还系统，所以每次mmap都会发生缺页异常。在内存工作繁忙时，频繁内存分配会导致大量缺页异常，使内核管理负担增加。 上述两种调用并没有真正分配内存，这些内存只有在首次访问时，才通过缺页异常进入内核中，由内核来分配 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:9:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 内存回收内存紧张时，系统通过以下方式来回收内存： 回收缓存： LRU算法回收最近最少使用的内存页面； 回收不常访问内存： 把不常用的内存通过交换分区写入磁盘 杀死进程： OOM内核保护机制 （进程消耗内存越大oom_score越大，占用CPU越多oom_score越小，可以通过/proc手动调整oom_adj） echo -16 \u003e /proc/$(pidof XXX)/oom_adj ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:10:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 如何查看内存使用情况free来查看整个系统的内存使用情况 top/ps来查看某个进程的内存使用情况 VIRT 进程的虚拟内存大小 RES 常驻内存的大小，即进程实际使用的物理内存大小，不包括swap和共享内存 SHR 共享内存大小，与其他进程共享的内存，加载的动态链接库以及程序代码段 %MEM 进程使用物理内存占系统总内存的百分比 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:11:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 内存中的Buffer和Cachebuffer是对磁盘数据的缓存，cache是对文件数据的缓存，它们既会用在读请求也会用在写请求中 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:12:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 缓存命中率缓存命中率是指直接通过缓存获取数据的请求次数，占所有请求次数的百分比。命中率越高说明缓存带来的收益越高，应用程序的性能也就越好。 安装bcc包后可以通过cachestat和cachetop来监测缓存的读写命中情况。 ；安装pcstat后可以查看文件在内存中的缓存大小以及缓存比例 dd缓存加速 dd if=/dev/sda1 of=file bs=1M count=512 #生产一个512MB的临时文件 echo 3 \u003e /proc/sys/vm/drop_caches #清理缓存 pcstat file #确定刚才生成文件不在系统缓存中，此时cached和percent都是0 cachetop 5 dd if=file of=/dev/null bs=1M #测试文件读取速度 #此时文件读取性能为30+MB/s，查看cachetop结果发现并不是所有的读都落在磁盘上，读缓存命中率只有50%。 dd if=file of=/dev/null bs=1M #重复上述读文件测试 #此时文件读取性能为4+GB/s，读缓存命中率为100% pcstat file #查看文件file的缓存情况，100%全部缓存 O_DIRECT选项绕过系统缓存 cachetop 5 sudo docker run --privileged --name=app -itd feisky/app:io-direct sudo docker logs app #确认案例启动成功 #实验结果表明每读32MB数据都要花0.9s，且cachetop输出中显示1024次缓存全部命中 但是凭感觉可知如果缓存命中读速度不应如此慢，读次数时1024，页大小为4K，五秒的时间内读取了1024*4KB数据，即每秒0.8MB，和结果中32MB相差较大。说明该案例没有充分利用缓存，怀疑系统调用设置了直接I/O标志绕过系统缓存。因此接下来观察系统调用. strace -p $(pgrep app) #strace 结果可以看到openat打开磁盘分区/dev/sdb1，传入参数为O_RDONLY|O_DIRECT 这就解释了为什么读32MB数据那么慢，直接从磁盘读写肯定远远慢于缓存。找出问题后我们再看案例的源代码发现flags中指定了直接IO标志。删除该选项后重跑，验证性能变化。 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:13:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" 内存泄漏对应用程序来说，动态内存的分配和回收是核心又复杂的一个逻辑功能模块。管理内存的过程中会发生各种各样的“事故”： 没正确回收分配的内存，导致了泄漏 访问的是已分配内存边界外的地址，导致程序异常退出 虚拟内存分布从低到高分别是只读段，数据段，堆，内存映射段，栈五部分。其中会导致内存泄漏的是： 堆： 由应用程序自己来分配和管理，除非程序退出这些堆内存不会被系统自动释放。 内存映射段：包括动态链接库和共享内存，其中共享内存由程序自动分配和管理 内存泄漏的危害比较大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用。 内存泄漏不断累积甚至会耗尽系统内存. memleak检测内存泄漏 sudo docker run --name=app -itd feisky/app:mem-leak sudo docker logs app vmstat 3 # 可以看到free在不断下降，buffer和cache基本保持不变。 # 说明系统的内存一致在升高。但并不能说明存在内存泄漏。 # 此时可以通过memleak工具来跟踪系统或进程的内存分配/释放请求 /usr/share/bcc/tools/memleak -a -p $(pidof app) # 从memleak输出可以看到，应用在不停地分配内存， # 并且这些分配的地址并没有被回收。通过调用栈看到是 # fibonacci函数分配的内存没有释放。 # 定位到源码后查看源码来修复增加内存释放函数即可. ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:14:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" Swap原理Swap本质就是把一块磁盘空间或者一个本地文件当作内存来使用，包括换入和换出两个过程： 换出： 将进程暂时不用的内存数据存储到磁盘中，并释放这些内存 换入： 进程再次访问内存时，将它们从磁盘读到内存中 Linux如何衡量内存资源是否紧张？ 直接内存回收 新的大块内存分配请求，但剩余内存不足。此时系统会回收一部分内存； kswapd0 内核线程定期回收内存。为了衡量内存使用情况，定义了pages_min,pages_low,pages_high三个阈值，并根据其来进行内存的回收操作。 剩余内存 \u003c pages_min，进程可用内存耗尽了，只有内核才可以分配内存 pages_min \u003c 剩余内存 \u003c pages_low,内存压力较大，kswapd0执行内存回收，直到剩余内存 \u003e pages_high pages_low \u003c 剩余内存 \u003c pages_high，内存有一定压力，但可以满足新内存请求 剩余内存 \u003e pages_high，说明剩余内存较多，无内存压力 pages_low = pages_min 5 / 4 pages_high = pages_min 3 / 2 系统内存资源紧张时通过内存回收和OOM杀死进程来解决。其中可回收内存包括： 缓存/缓冲区，属于可回收资源，在文件管理中通常叫做文件页 被应用程序修改过暂时没写入磁盘的数据(脏页)，要先写入磁盘然后才能内存释放 在应用程序中通过fsync将脏页同步到磁盘 交给系统，内核线程pdflush负责这些脏页的刷新 内存映射获取的文件映射页，也可以被释放掉，下次访问时从文件重新读取 对于程序自动分配的堆内存，也就是我们在内存管理中的匿名页，虽然这些内存不能直接释放， 但是Linux提供了Swap机制将不常访问的内存写入到磁盘来释放内存，再次访问时从磁盘读取到内存即可。 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:15:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" NUMA 与 SWAP很多情况下系统剩余内存较多，但SWAP依旧升高，这是由于处理器的NUMA架构。 在NUMA架构下多个处理器划分到不同的Node，每个Node都拥有自己的本地内存空间。 在分析内存的使用时应该针对每个Node单独分析 numactl --hardware #查看处理器在Node的分布情况，以及每个Node的内存使用情况 内存三个阈值可以通过/proc/zoneinfo来查看，该文件中还包括活跃和非活跃的匿名页/文件页数。 当某个Node内存不足时，系统可以从其他Node寻找空闲资源，也可以从本地内存中回收内存。 通过/proc/sys/vm/zone_raclaim_mode来调整。 0表示既可以从其他Node寻找空闲资源，也可以从本地回收内存 1表示只回收本地内存， 2表示可以会回脏数据回收内存， 4表示可以用Swap方式回收内存。 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:16:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" swappiness在实际回收过程中Linux根据/proc/sys/vm/swapiness选项来调整使用Swap的积极程度， 从0-100，数值越大越积极使用Swap，即更倾向于回收匿名页；数值越小越消极使用Swap，即更倾向于回收文件页。 注意：这只是调整Swap积极程度的权重，即使设置为0，当剩余内存+文件页小于页高阈值时，还是会发生Swap。 Swap升高时定位分析示例 free #首先通过free查看swap使用情况，若swap=0表示未配置Swap #先创建并开启swap fallocate -l 8G /mnt/swapfile chmod 600 /mnt/swapfile mkswap /mnt/swapfile swapon /mnt/swapfile free #再次执行free确保Swap配置成功 dd if=/dev/sda1 of=/dev/null bs=1G count=2048 #模拟大文件读取 sar -r -S 1 #查看内存各个指标变化 -r内存 -S swap #根据结果可以看出，%memused在不断增长，剩余内存kbmemfress不断减少，缓冲区kbbuffers不断增大，由此可知剩余内存不断分配给了缓冲区 #一段时间之后，剩余内存很小，而缓冲区占用了大部分内存。此时Swap使用之间增大，缓冲区和剩余内存只在小范围波动 # 停下sar命令 cachetop5 #观察缓存 #可以看到dd进程读写只有50%的命中率，未命中数为4w+页，说明正式dd进程导致缓冲区使用升高 watch -d grep -A 15 ‘Normal’ /proc/zoneinfo #观察内存指标变化 #发现升级内存在一个小范围不停的波动，低于页低阈值时会突然增大到一个大于页高阈值的值 # 说明剩余内存和缓冲区的波动变化正是由于内存回收和缓存再次分配的循环往复。 # 有时候Swap用的多，有时候缓冲区波动更多。此时查看swappiness值为60， # 是一个相对中和的配置，系统会根据实际运行情况来选去合适的回收类型. 相关命令说明","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:17:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" toptop命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况 ，类似于Windows的任务管理器 [root@xiaosi bash]# top -h procps-ng 3.3.15 Usage: top -hv | -bcEHiOSs1 -d secs -n max -u|U user -p pid(s) -o field -w [cols] # 选项说明 -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i\u003c时间\u003e 设置间隔时间 -u\u003c用户名\u003e 指定用户名 -p\u003c进程号\u003e 指定进程 -n\u003c次数\u003e 循环显示的次数 # 交互界面中使用h键可获得以下交互按键信息 Help for Interactive Commands - procps-ng 3.3.15 Window 1:Def: Cumulative mode Off. System: Delay 3.0 secs; Secure mode Off. Z,B,E,e Global: 'Z' colors; 'B' bold; 'E'/'e' summary/task memory scale l,t,m Toggle Summary: 'l' load avg; 't' task/cpu stats; 'm' memory info 0,1,2,3,I Toggle: '0' zeros; '1/2/3' cpus or numa node views; 'I' Irix mode f,F,X Fields: 'f'/'F' add/remove/order/sort; 'X' increase fixed-width L,\u0026,\u003c,\u003e . Locate: 'L'/'\u0026' find/again; Move sort column: '\u003c'/'\u003e' left/right R,H,V,J . Toggle: 'R' Sort; 'H' Threads; 'V' Forest view; 'J' Num justify c,i,S,j . Toggle: 'c' Cmd name/line; 'i' Idle; 'S' Time; 'j' Str justify x,y . Toggle highlights: 'x' sort field; 'y' running tasks z,b . Toggle: 'z' color/mono; 'b' bold/reverse (only if 'x' or 'y') u,U,o,O . Filter by: 'u'/'U' effective/any user; 'o'/'O' other criteria n,#,^O . Set: 'n'/'#' max tasks displayed; Show: Ctrl+'O' other filter(s) C,... . Toggle scroll coordinates msg for: up,down,left,right,home,end k,r Manipulate tasks: 'k' kill; 'r' renice d or s Set update interval W,Y Write configuration file 'W'; Inspect other output 'Y' q Quit ( commands shown with '.' require a visible task display window ) Press 'h' or '?' for help with Windows, Type 'q' or \u003cEsc\u003e to continue 1：可监控每个逻辑CPU的状况 b：高亮显示当前运行进程 当前CPU百分比排序：P 查看CPU核心使用：1 查看cou信息：t 按内存使用率排序：M 关闭或开启第一行：l 按进程执行时间排序：T 修改刷新时间间隔：s（秒） 终止指定进程：k top输出 #解释 [root@xiaosi ~]# top # top -系统当前时间 up 运行时长，当前在线用户，CPU负载均衡：平均1分钟，平均5分钟，平均15分钟 top - 11:23:50 up 2:47, 1 user, load average: 0.00, 0.00, 0.00 # 任务进程：总进程，运行进程，进程睡眠，停止进程，僵死进程 Tasks: 165 total, 1 running, 164 sleeping, 0 stopped, 0 zombie # CPU平均使用率：用户进程，系统进程，调整优先级的进程，当前空闲率，等待磁盘IO完成进程时间，硬见中断，软中断，CPU处理时间 %Cpu(s): 0.0 us, 0.1 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.1 hi, 0.1 si, 0.0 st # (单位)物理内存：总大小，空闲大小，使用大小，缓冲大小 MiB Mem : 3710.0 total, 3220.0 free, 246.5 used, 243.5 buff/cache #(单位)交换分区：总大小，空闲大小，使用情况，缓冲大小 MiB Mem : 3710.0 total, 3220.0 free, 246.5 used, 243.5 buff/cache PID：进程id USER：进程所有者 PR：进程优先级 NI：nice值。负值表示高优先级，正值表示低优先级 VIRT：进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES：进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR：共享内存大小，单位kb S：进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU：上次更新到现在的CPU时间占用百分比 %MEM：进程使用的物理内存百分比 TIME+：进程使用的CPU时间总计，单位1/100秒 COMMAND：进程名称（命令名/命令行） PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5126 root 20 0 65436 4340 3664 R 0.7 0.1 0:00.04 top 11 root 20 0 0 0 0 I 0.3 0.0 0:08.33 rcu_sched 914 root 20 0 124992 5404 4772 S 0.3 0.1 0:00.81 irqbalance 922 root 20 0 278356 10584 8960 S 0.3 0.3 0:13.78 vmtoolsd 1 root 20 0 186352 14408 9716 S 0.0 0.4 0:03.12 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.03 kthreadd 3 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_gp 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_par_gp 6 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 kworker/0:0H-events_highpri 9 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 mm_percpu_wq 10 root 20 0 0 0 0 S 0.0 0.0 0:00.02 ksoftirqd/0 12 root rt 0 0 0 0 S 0.0 0.0 0:00.05 migration/0 13 root rt 0 0 0 0 S 0.0 0.0 0:00.03 watchdog/0 14 root 20 0 0 0 0 S 0.0 0.0 0:00.00 cpuhp/0 15 root 20 0 0 0 0 S 0.0 0.0 0:00.00 cpuhp/1 ... 第一行后面的三个值是系统在之前 1、5、15 的平均负载，也可以看出系统负载是上升、平稳、下降的趋势，当这个值超过 CPU 可执行单元的数目，则表示 CPU 的性能已经饱和成为瓶颈了。 第二行统计了系统的任务状态信息。running 很自然不必多说，包括正在 CPU 上运行的和将要被调度运行的；sleeping 通常是等待事件(比如 IO 操作)完成的任务，细分可以包括 interruptible 和 uninterruptible 的类型；stopped 是一些被暂停的任务，通常发送 SIGSTOP 或者对一个前台任务操作 Ctrl-Z 可以将其暂停；zombie 僵尸任务，虽然进程终止资源会被自动回收，但是含有退出任务的 task descriptor 需要父进程访问后才能释放，这种进程显示为 defunct 状态，无论是因为父进程提前退出还是未 wait 调用，出现这种进程都应该格外注意程序是否设计有误。 (us) user：CPU 在低 nice 值(高优先级)用户态所占用的时间(nice\u003c=0)。正常情况下只要服务器不是很闲，那么大部分的 CPU 时间应该都在此执行这类程序 (sy) system：CPU 处于内核态所占用的时间，操作系统通过系统调用(system call)从用户态陷入内核态，以执行特定的服务；通常情况下该值会比较小，但是当服务器执行的 IO 比较密集的时候，该值会比较大 (ni) nice：CPU ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:18:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" swap相关命令 swaplabel ：查看或更改 swap 的标签或 UID swapon ：开启交换分区（临时） swapoff ：关闭交换分区（临时） 要永久开启或关闭交换分区需要在 /etc/fstab 中的 swap 注释或添加挂载 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:19:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" /proc/meminfo/proc/meminfo 文件是了解Linux系统内存使用状况的主要接口，常用的 free、vmstat 等命令就是通过它获取数据的 [root@centos7 ~]# cat /proc/meminfo MemTotal: 3861300 kB 总物理内存。该值是系统初始化之后剩下可提供给内核支配的内存（初始化时firmware/BIOS要保留一些内存，kernel本身要占用一些内存，这些内存是没有释放的） 内核所用内存的静态部分，比如内核代码、页描述符等数据在引导阶段就分配掉了，并不计入MemTotal里 MemFree: 3188028 kB 剩余物理内存。该值是 MemTotal（总物理内存）-MemFree（已经使用物理内存）； 不能代表全部可用的内存，系统中有些内存虽然已被使用但是可以回收的，比如cache/buffer、slab都有一部分可以回收 MemAvailable: 3353960 kB 当前可用物理内存（估值，不准确）有些应用程序会根据系统的可用内存大小自动调整内存申请的多少，所以需要一个记录当前可用内存数量的统计值 /proc/meminfo中的MemAvailable是内核使用特定的算法估算出来的，要注意这是一个估计值，并不精确 MemAvailable=MemFree+可回收内存 Buffers: 2108 kB 块设备占用的缓存页，包含直接读写块设备、以及文件系统元数据(metadata)比如SuperBlock所使用的缓存页 Cached: 364184 kB 普通文件占用的缓存页 SwapCached: 0 kB Active: 193580 kB Inactive: 294048 kB Active(anon): 121064 kB Inactive(anon): 12108 kB Active(file): 72516 kB Inactive(file): 281940 kB Unevictable: 0 kB Mlocked: 0 kB SwapTotal: 2097148 kB SwapFree: 2097148 kB Dirty: 12 kB Writeback: 0 kB AnonPages: 121340 kB Mapped: 62988 kB Shmem: 11832 kB Slab: 101236 kB SReclaimable: 32132 kB SUnreclaim: 69104 kB KernelStack: 4640 kB PageTables: 4384 kB NFS_Unstable: 0 kB Bounce: 0 kB WritebackTmp: 0 kB CommitLimit: 4027796 kB Committed_AS: 713200 kB VmallocTotal: 34359738367 kB VmallocUsed: 183896 kB VmallocChunk: 34359310332 kB Percpu: 25600 kB HardwareCorrupted: 0 kB AnonHugePages: 38912 kB CmaTotal: 0 kB CmaFree: 0 kB HugePages_Total: 0 HugePages_Free: 0 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 2048 kB DirectMap4k: 124736 kB DirectMap2M: 3020800 kB DirectMap1G: 3145728 kB ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:20:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" iotop","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:21:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" lsof","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:22:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" sarsar 这个工具太强大了，什么 CPU、磁盘、页面交换啥都管 # -n 网络 TCP 协议，1是刷新时间 [root@localhost ~]# sar -n TCP 1 Linux 4.18.0-348.7.1.el8_5.x86_64 (localhost.localdomain) 01/23/2022 _x86_64_ (4 CPU) 01:06:37 AM active/s passive/s iseg/s oseg/s 01:06:38 AM 0.00 0.00 0.99 0.99 01:06:39 AM 0.00 0.00 1.00 1.00 01:06:40 AM 0.00 0.00 0.99 0.99 01:06:41 AM 0.00 0.00 1.00 1.00 01:06:42 AM 0.00 0.00 1.00 1.00 01:06:43 AM 0.00 0.00 2.00 2.00 01:06:44 AM 0.00 0.00 1.00 1.00 ^C Average: 0.00 0.00 1.14 1.14 active/s：本地发起的 TCP 连接，比如通过 connect()，TCP 的状态从CLOSED -\u003e SYN-SENT passive/s：由远程发起的 TCP 连接，比如通过 accept()，TCP 的状态从LISTEN -\u003e SYN-RCVD retrans/s(tcpRetransSegs)：每秒钟 TCP 重传数目，通常在网络质量差，或者服务器过载后丢包的情况下，根据 TCP 的确认重传机制会发生重传操作 isegerr/s(tcpInErrs)：每秒钟接收到出错的数据包(比如 checksum 失败) ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:23:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["linux"],"content":" sysbenchsysbench是一个开源的、模块化的、跨平台的多线程性能测试工具 https://github.com/akopytov/sysbench#linux 安装 ","date":"2021-12-12","objectID":"/linux%E6%80%A7%E8%83%BD/:24:0","tags":["linux","性能"],"title":"linux 性能","uri":"/linux%E6%80%A7%E8%83%BD/"},{"categories":["vim"],"content":" 下载nginx源码包中的nginx.vim [root@localhost ~]# find nginx-1.20.2 -name \"nginx.vim\" nginx-1.20.2/contrib/vim/ftdetect/nginx.vim nginx-1.20.2/contrib/vim/ftplugin/nginx.vim nginx-1.20.2/contrib/vim/indent/nginx.vim nginx-1.20.2/contrib/vim/syntax/nginx.vim 合并成一个文件（nginx.vim）后在vimrc添加以下配置 # autcomd 是自动事件 # BufReadPost读取文件之后，BufNewFile创建文件时 # ~/nginxDocker 是nginx配置文件目录 # source 指定 nginx.vim 位置 \" 定义nginx配置文件 au BufRead,BufNewFile *.nginx exec \":source ~/vimrc/nginx.vim\" au BufRead,BufNewFile *.nginx.conf exec \":source ~/vimrc/nginx.vim\" au BufRead,BufNewFile nginx.conf exec \":source ~/vimrc/nginx.vim\" ","date":"2021-09-13","objectID":"/vim-nginx/:0:0","tags":["vim","nginx"],"title":"vim中nginx配置文件高亮","uri":"/vim-nginx/"},{"categories":["nginx"],"content":" 内容来自以下文档： nginx面试题 cgi与fastcgi使用cgi时，nginx收到请求后生成新的子进程转发该请求到其它程序。 等待其它程序返回数据。收到数据后转发给父进程然后退出。 使用fastcgi时，主进程会创建一定数量的子进程用于转发到其它程序。 不会频繁的新建与销毁子进程 nginx中可以将502错误状态码替换为503?可以，使用error_page指令，在反向代理中还要开启与intercept_errors相关的指令。 如：http代理中是proxy_intercept_errors指令 # `502`表示错误网关；`503`表示服务器超载 [root@centos7 conf]# cat ngx_http_rewrite.conf server { listen 120.0.0.1:803; root html/; # 当状态码为 502 时，返回503.html页面 error_page 502 =503 /503.html; } nginx中url如何保持双全线?使用merge_slashes off指令禁止将URI中的两个或多个相邻斜杠压缩为单个斜杠 server { merge_slashes off; } ngx_http_upstream_module作用是什么?提供负载均衡相关配置指令。如ip_hash, hash, least_conn等 什么是c10k问题？指无法处理大量客户端(10 000)的网络套接字 stub_status指令和sub_filter指令有什么用?在content阶段后sub_filter 可以替换响应主体部分字符串。支持使用变量。 stub_status指令提供当前nginx状态信息 stub_status指令示例： [root@xiaosi conf.d]# cat 1000-stub_status.conf server { listen 172.11.11.2:1000; location = /basic_status { stub_status; } } # 重载配置文件 [root@xiaosi conf.d]# nginx -s reload 2021/09/14 10:26:32 [notice] 258#258: signal process started [root@xiaosi conf.d]# curl 172.11.11.2:1000/basic_status Active connections: 1 server accepts handled requests 44 44 44 Reading: 0 Writing: 1 Waiting: 0 sub_filter示例： [root@xiaosi conf.d]# cat 1002-sub_filter.conf server { listen 172.11.11.2:1002; location /sub_filter { sub_filter 'nginx' 'NGINX'; # 关闭值只替换一次，表示全部替换 sub_filter_once off; } } # nginx 以经被替换为 NGINX [root@xiaosi conf.d]# curl 172.11.11.2:1002/sub_filter \u003chtml\u003e \u003chead\u003e\u003ctitle\u003e404 Not Found\u003c/title\u003e\u003c/head\u003e \u003cbody\u003e \u003ccenter\u003e\u003ch1\u003e404 Not Found\u003c/h1\u003e\u003c/center\u003e \u003chr\u003e\u003ccenter\u003eNGINX/1.21.3\u003c/center\u003e \u003c/body\u003e \u003c/html\u003e 下面sub_filter指令为什么会失败? [root@xiaosi conf.d]# cat sub_filter.conf server { listen 172.11.11.2:80; location /sub_filter { alias /usr/share/nginx/html/index.html; sub_filter 'nginx' 'NGINX'; # 关闭值只替换一次，表示全部替换 sub_filter_once off; } } [root@xiaosi conf.d]# curl 172.11.11.2:1002/sub_filter 2\u003e/dev/null | grep \"NGINX\" nginx是否支持将请求压缩到上游?反向代理压缩请示发送服务端不知道，但服务端可以将响应报文压缩(gzip指令)发送给 反向代理。如果客户端不支持解压，则可以由反向代理解压(gunzip)之后发给客户端 nginx如何获取当前时间ngx_http_ssi_module模块提供了2个变量可以获取本地时间 [root@xiaosi conf.d]# cat 1005-ssi.conf server { listen 172.11.11.2:1005; location /date { add_header local-date \"$date_local\"; add_header gmt-date \"$date_gmt\"; return 200 \"本地时间：$date_local\\n格林威治标准时间：$date_gmt\\n\"; } } [root@xiaosi conf.d]# curl 172.11.11.2:1005/date 本地时间：Tuesday, 14-Sep-2021 16:45:35 CST 格林威治标准时间：Tuesday, 14-Sep-2021 08:45:35 GMT [root@xiaosi conf.d]# curl -I 172.11.11.2:1005/date 2\u003e/dev/null | grep \"date\" local-date: Tuesday, 14-Sep-2021 16:46:07 CST gmt-date: Tuesday, 14-Sep-2021 08:46:07 GMT nginx -s命令有什么用?可以重启进程、重新加载配置文件、重新开始记录日志文件 如何在nginx上添加模块? 将旧nginx文件换成新的nginx文件（注意备份） 向master进程发送USR2信号 master进程再pid文件添加后缀.oldbin master进程用新的nginx文件启动新的master进程 向旧的master进程发送QUIT信号，关闭master老进程 nginx如何实现高并发？进程模型+事件模型+IO多路复用模型epoll https://www.php.cn/nginx/421719.html 工作进程争抢到会话后使用线程处理该请求，如果期间发生了阻塞 则注册一个事件等待触发，继续处理其它请求。阻塞的事件被触发之后 接着处理该请求，在磁盘IO方面， nginx如何处理HTPP请求？ nginx起动时master进程会根据配置文件进行初始化，之后创建子进程 当客户端与nginx连接时主进程维护在连接池。 子进程竞争连接，竞争成功后得到与客户端建立的socket并处理该连接 nginx使用未定义的服务器名称来阻止处理请求？使用444状态码与default_server [root@xiaosi conf.d]# cat 1006-server_name.conf server { listen 172.11.11.2:1006 ; server_name a.b.c; return 200 \"$http_host\\n\"; } server { listen 172.11.11.2:1006 default_server; return 444; } [root@xiaosi conf.d]# curl -H \"host:a.b.c\" 172.11.11.2:1006 a.b.c [root@xiaosi conf.d]# curl -H \"host:a.a.a\" 172.11.11.2:1006 curl: (52) Empty reply from server 反向代理有什么优点？ nginx的master进程和worker进程是做什么的？ 如何通过非80端口开启nginx?在server指令块中修改或添加listen指令 [root@xiaosi conf.d]# cat 1000-stub_status.conf server { listen 172.11.11.2:1000; location = /basic_status { stub_status; } } nginx为什么不使用多线程？ 为什么是做动静分离？分离动态文件到其它服务去 nginx有哪些负载均衡策略？ 轮询算法，会按照顺序轮回访问上游服务器 一致性hash算法，是hash取模（取余数）的解决方式， 该方式可以减少上游服务器数量发送变化之后造成所有服务器缓存失效 最少连接算法：调度到最少连接数量的上游服务器 ","date":"2021-09-09","objectID":"/nginx-QA/:0:0","tags":["QA","nginx"],"title":"nginx问答","uri":"/nginx-QA/"},{"categories":["vim"],"content":" 运行环境： vim: 8 操作符操作符用于删除文本或改变文本，下面表格是所有操作符 操作符 说明 c 修改(删除并进入插入模式) d 删除 y 复制到寄存器 ~ 变换大小写(当tildeop选项置位时有效) \u003c 左移 \u003c 右移 g~ 变换大小写 gu 变换为小写 gU 变换为大写 gq 文本排版 gw 文本排版，但不移动光标 g? ROT13编码 g@ 调用operatorfunc选项定义的函数 zf 定义折叠 操作符与动作符动作符命令出现在操作符之后，从而使操作符作用于被该动作所跨越的文本之上。如果 动作包括一个次数而操作符之前也有一个的话，两者相乘。因此，2d3w效果是删除六个 单词 可视模式与操作符可视模式选中文本之后使用操作符，从而操作符作用于被选中的文本。 文本对象选择这些命令只能在可视模式中或在操作符之后使用，且只有在编译时加入+textobjects 特性后才有效。另见gn和gN，操作对象是前次搜索模式 命令 说明 aw 选择[count]个单词，包括开头或拖尾的空白，但不单独计算。在可视面向行的模式下，aw\"切换到可视面向字符的模式 iw 选择[count]个单词，单词之间的空白也算是一个单词。 在可视面向行的模式下，iw切换到可视面向字符的模式 aW 选择[count]个字串，包括开头或拖尾的空白，但不单独计算。在可视面向行的模式下，aW\"切换到可视面向字符的模式 iW 选择[count]个字串，单词之间的空白也算是一个单词。 在可视面向行的模式下，iW切换到可视面向字符的模式 as 选择[count]个句子，可视模式下它切换为面向字符的模式 is 选择[count]个句子，可视模式下它切换为面向字符的模式 ap 选择[count]个段落，空白行(只包含空白的行)也被视为段落边界。可视模式下它切换为面向行的模式 ip 选择[count]个段落，空白行(只包含空白的行)也被视为段落边界。可视模式下它切换为面向行的模式 a]或 a[ 选择[count]层[]块字符，可视模式下它切换为面向字符的模式 i]或 i[ 选择[count]层[]块之间的字符，视模式下它切换为面向字符的模式 a)或 a(或 ab 选择[count]层()块字符，可视模式下它切换为面向字符的模式 i)或 i(或 ib 选择[count]层()块之间的字符，可视模式下它切换为面向字符的模式 a\u003e或 a\u003c 选择[count]层\u003c\u003e块字符。可视模式下它切换为面向字符的模式 i\u003e或 i\u003c 选择[count]层\u003c\u003e块之间的字符。可视模式下它切换为面向字符的模式 at 选择[count]层html标签块字符。会忽略没有结束标签的标签 it 选择[count]层html标签块之间的字符。会忽略没有结束标签的标签 a} 或 a{ 或 aB 选择[count]层{}块字符，可视模式下它切换为面向字符的模式 i} 或 i{ 或 iB 选择[count]层{}块之间的字符，可视模式下它切换为面向字符的模式 a\" 或 a’ 或 a‘ 选择引号对字符，只在同一行有效。 在可视模式下重复此对象会包含另一个字符串。目前不使用计数 如果开始时光标在引号上，Vim 会从该行行首开始搜索，以决定哪个引号对构成字符串 i\" 或 i’ 或 i‘ 选择引号对之间字符，只在同一行有效 计数为2时包含引号，但不包括引号之外的空白字符 而重复也不会扩展可视选择区 在操作符之后： 对开非块对象，a相关的文本对象选择命令，操作符作用于对象与其后的空白。 如果其后没有空白或者光标位于对象之前的空白上的话，那么也包括对象之前的空白； i相关的文本对象选择命令，如果光标在对象之上，那么操作符作用于该对象。 如果光标在空白上，那么操作符作用于空白。简单说就是不含边界符以外的字符 对于块对象，a相关的文本象选择命令，包含了块字符；而i则不含块字符。 查找块方式如下： 反向查找第[count]个块字符(如\u003c) 找其对应的块字符 如果是a相关的文本对象选择命令，则包含块(如\u003caaa\u003e) 如果是i相关的文本对象选择命令，则不包含块(如aaa) 在可视模式中，如果可视区域的起始和结束点不同的情况下，若不是块对象， 该区域被对象或者下一个对象之前空白所扩展。扩展的方向决定于可视区域和光标的相对 位置。若是块对象，该块向外扩展一层 ","date":"2021-07-31","objectID":"/vim%E6%96%87%E6%9C%AC%E5%AF%B9%E8%B1%A1%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%AC%A6/:0:0","tags":["vim 操作符"],"title":"vim文本对象与操作符","uri":"/vim%E6%96%87%E6%9C%AC%E5%AF%B9%E8%B1%A1%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%AC%A6/"},{"categories":["vim"],"content":" 运行环境： vim: 8.0 vim: 9.0 内容来自以下文档： vim参考手册P620-P641 动作符动作符用于移动光标(从一个位置移到另一个位置)。动作符分为开动作或闭动作或行动作： 行动作：以文本行为单位移动，与操作符配合使用时会包含开始位置到结束位置的所有 文本行 闭动作：与操作符配合使用时，开始位置和结束位置都包含在操作范围内 开动作：与操作符配合使用时，开始位置和结束位置范围中，不包含靠近缓冲区尾端的 最后一个字符。但有以下特殊情况： 如果开动作的结尾在第一列，那么会移到上一行的结尾处，并转换为一个闭动作。 如}与d} 如果开动作的结尾在第一列且开始处在一行的第一个非空白字符之前或之上，那么会 转换为行动作。如一个段落以空白字符开头并在第一个非空白字符执行d}，那前面 的空白字符也会删除 左右动作 动作符 说明 动作类型 h或 \u003cLeft\u003e 或 \u003cBS\u003e或 \u003cCTRL-H\u003e 向左[count]个字符 开动作 l或 \u003cRight\u003e 或 \u003cSpace\u003e 向右[count]个字符 开动作 0 到文本行的第一个字符 开动作 \u003cHome\u003e 到文本行的第一个字符，如果一行以\u003cTab\u003e开头，则和0有区别 开动作 ^ 到文本行的第一个非空白字符 开动作 $或 \u003cEnd\u003e 到文本行尾部，如果给出[count]，则先往下走[count-1]行 1. 可视模式下，光标移到紧贴该行最后一个字符之后的位置 2. 如果置位了virtualedit选项，$可从行尾之后的空白后退到行尾 闭动作 g_ 往下[count-1]行并到该行的最后一个非空白字符 闭动作 g0或g\u003cHome\u003e 到屏幕行的第一个字符 开动作 g^ 到屏幕行的第一个非空白字符 开动作 gm 尽可能向右移到屏幕(行)显示宽度的中间位置 开动作 gM 到行文本的中间位置，带计数时: 行文本的此百分比位置 开动作 g$或 g\u003cEnd\u003e 往下[count-1]屏幕行并到该屏幕行的行尾 闭动作 ` ` 到当前行的[count]屏幕列 f{char} 到右侧第[count]次出现的字符{char}(可以输入二合字母), 光标放在{char}上 闭动作 F{char} 到左侧第[count]次出现的字符{char}(可以输入二合字母), 光标放在{char}上 开动作 t{char} 到右侧第[count]次出现的字符{char}(可以输入二合字母), 光标放在{char}之前 闭动作 T{char} 到左侧第[count]次出现的字符{char}(可以输入二合字母), 光标放在{char}之后 开动作 ; 重复上次的f、t、F或者T 命令[count]次 , 反向重复上次的f、t、F或者T 命令[count]次 上下动作 动作符 说明 动作类型 k或 \u003cUP\u003e或 \u003cCTRL-P\u003e 向上[count]文本行 行动作 j或 \u003cDown\u003e或 \u003cNL\u003e或 \u003cCTRL-J\u003e或 \u003cCTRL-N\u003e 向下[count]文本行 行动作 gk或 g\u003cUp\u003e 向上[count]屏幕行 开动作 gj或 g\u003cDown\u003e 向下[count]屏幕行 开动作 - 向上[count]文本行，停在第一个非空白字符上 行动作 +或 \u003cCTRL-M\u003e或 \u003cCR\u003e 向下[count]文本行，停在第一个非空白字符上 开动作 _ 向下[count] - 1文本行，停在第一个非空白字符上 行动作 G 到第[count]文本行，缺省是最后一行。如果startofline选项没有置位，则保持在相同的列上，不然，停在第一个非空白字符上 行动作 \u003cC-End\u003e 到第[count]文本行，缺省是最后一行并停在最后一个字符上 闭动作 gg或 \u003cC-Home\u003e 到第[count]文本行，缺省是第一行。如果startofline选项没有置位，保持在相同的列上，不然，停在第一个非空白字符上 行动作 :[range] 把光标移到[range]的最后一行(range可以是行号) 行动作 {count}% 到文件的{count}百分比处并停在行的第一个非空白字符上。新的行号=({count} * 总行数 + 99) / 100 行动作 :[range]go[to] [count]或 [count]go 到缓冲区的第[count]个字节。缺省的[count]是1。如果给定[range]，则最后的一个数字用作字节的序号。fileformat选项的当前设置决定如何计算换行符的个数 单词动作这些动作符在在单词或字串间移动： 一个单词由字符、数字和下划线序列或者其他的非空白字符的序列组成。单词间可以 空白字符(空格、制表、换行)分隔。这一规则可以用iskeyword选项改变。空行也被 认作单词 一个字串由非空白字符序列组成。字串以空白分隔。空行也被认作字串 特例: 如果光标在非空白字符上，cw和cW等价于ce和cE。这是因为cw被诠释为 修改-单词，而单词并不包括后续的空格 如果w动作带操作符并且该动作的最后一个单词在行尾，则该操作范围结束于行尾 而非下一行的第一个单词 原始Vi的e实现有问题。例如，如果前一行为空而光标停在后一行的第一个字符， 使用e就会卡在那里，但是你用2e就很正常 动作符 说明 动作类型 w或 \u003cS-Right\u003e 正向[count]个单词 开动作 b或 \u003cS-Left\u003e 反向[count]个单词 开动作 W或 \u003cC-Right\u003e 正向[count]个字串 开动作 B或 \u003cC-Left\u003e 反向[count]个字串 开动作 e 正向到第[count]个单词的尾部，不停留在空行上 闭动作 E 正向到第[count]个字串的尾部，不停留在空行上 闭动作 ge 反向到第[count]个单词的尾部 闭动作 gE 反向到第[count]个字串的尾部 闭动作 文本对像动作这些命令在三类文本对象上移动： 小节：一个小节从首列出现的换页符(\u003cC-L\u003e) 或某一个小节宏命令开始。小节宏由 sections选项里成对出现的字符所定义。它的缺省值是SHNHH HUnhsh，也就是说 小节可以从如下的nroff宏开始: .SH、.NH、.H、.HU、.nh 和 .sh 段落：一个段落从空行或某一个段落宏命令开始，段落宏由paragraphs选项里成对 出现的字符所定义。它的缺省值为IPLPPPQPP TPHPLIPpLpItpplpipbp，也就是宏 .IP、.LP等 (这些是nroff宏，所以句号一定要出现在第一列) 小节边界也被视为段落边界 空白行(只包含空白)不是段落边界 这不包括首列出现的{或}。如果cpoptions选项里包含{标志位，那么首列的 {用作段落边界 句子：一个句子以 .、! 或者 ? 结尾并紧随着一个换行符、空格或者制表符。 标点和空白字符之间可以出现任何数量的闭括号和引号: )、]、\" 和 ` 段落和小节的边界也视为句子的边界 如果cpoptions选项包含J标志位，那么标点之后的空格至少要出现两个，而且 制表符不被视为空白字符 动作符 说明 动作类型 ( 反向[count]个句子 开动作 ) 正向[count]个句子 开动作 { 反向[count]个段落 开动作 } 正向[count]个段落 开动作 ]] 正向[count]个小节或到出现在首列的 { 开动作 ][ 反向[count]个段落 开动作 [[ 反向[count]个小节或到出现在首列的 { 开动作 [] 反向[count]个小节或到出现在首列的 } 开动作 其它动作 命令 说明 动作类型 \u003cLeftMouse\u003e(鼠标左键) 到屏幕上鼠标点击的位置。如果鼠标在状态行上，则所属的窗口被激活但光标位置不改变。启用鼠标才有效 开动作 H 到窗口从顶部算第 [count] 行 (缺省: 窗口的第一行) 并停在第一个非空白字符上 行动作 L 到窗口从底部算第 [count] 行 (缺省: 窗口的最后一行) 并停在第一个非空白字符上 行动作 M 到窗口的中间一行并停在第一个非空白字符 行动作 % 找到本行的光标所在或其后的下一个项目，并跳转到它的匹配 闭动作 [( 反向第 [count] 个的未匹配的 ( 开动作 [{ 反向第 [count] 个的未匹配的 { 开动作 ]) 正向第 [count] 个的未匹配的 ) 开动作 ]m 正向第 [count] 个{位置。如果不在某个代码块开始处之前，则会跳转到{或}位置 开动作 ]M 正向第 [count] 个}位置。如果不在某个代码块开始处之前，则会跳转到{或}位置 开动作 [m 反向第 [count] 个{位置。如果不在某个代码块开始处之前，则会跳转到{或}位置 开动作 [M 反向第 [count] 个}位置。如果不在某个代码块开始处之前，则会跳转到{或}位置 开动作 [# 反向第 [count] 个未匹配的 #if 或 #else 开动作 ]# 正向第 [count] 个未匹配的 #if 或 #else 开动作 [* [/ 反向第 [count] 个类似C语言的注释开始处 开动作 ]* ]/ 正向第 [count] 个类似C语言的注释结束处 开动作 H、L、M 这三个命令受到startofline选项影响。此外光标还要根据scrolloff调整，除非某个操作符处于 等待状态，那时文本可能会滚动。例如yH从第一个可见行抽起，直到光标所在行为止 (闭区间) %、[(、[{、])、]} 以上四个命令用于转到当前代码块的开始或者结尾位置 ]m、]M、[m、[M这几个命令适用于用{和}包围的代码块，如下面java代码。 光标在method4时，使用]m会跳转到所在行的{,再使用]","date":"2021-07-30","objectID":"/vimNormalMovePosition/:0:0","tags":["vim 动作符","vim 位置标记","vim 跳转表","vim 改变表"],"title":"vim 普通模式下光标移动","uri":"/vimNormalMovePosition/"},{"categories":["vim"],"content":" scrolljump P876 简写: sj 作用域：全局 取值：数值型 默认值：如果置位(开启)compatible选项，则为1 光标离开屏幕时最少的滚动行数。如果设为 -1 到 -100 的负数，用作窗口高度的百分比。如： -50 表示滚动到窗口高度的一半。 ","date":"2021-07-30","objectID":"/vimNormalMovePosition/:1:0","tags":["vim 动作符","vim 位置标记","vim 跳转表","vim 改变表"],"title":"vim 普通模式下光标移动","uri":"/vimNormalMovePosition/"},{"categories":["vim"],"content":" scrolloff P876 简写：so 作用域：全局或局部于窗口 取值：数值型 默认值：0，defaults.vim 里设为 5 光标上下两侧最少保留的屏幕行数。这使你工作时总有一些可见的上下文。 如果你设置此选项为很大的值 (比如 999)，光标所在的行将总定位在窗口的中 间位置 (除非你非常靠近文件开始或者结束的地方，或者有长行回绕)。 使用局部值后，可用以下两者之一来回到全局值: setlocal scrolloff\u003c setlocal scrolloff=-1 ","date":"2021-07-30","objectID":"/vimNormalMovePosition/:2:0","tags":["vim 动作符","vim 位置标记","vim 跳转表","vim 改变表"],"title":"vim 普通模式下光标移动","uri":"/vimNormalMovePosition/"},{"categories":["vim"],"content":" virtualedit P909 置位 ’virtualedit’ 选项使得光标可以移动到还没有字符或者半个字符的位置 虚拟编辑意味着光标可以定位在没有实际字符的地方。这可以是制表的中间，也 可以是行尾之后的位置。可用于在可视模式下选择一个方块，还有表格的编辑。 “onemore” 不同，它只允许光标移动到刚刚超过行尾字符之后的位置。这使得有 些命令更加一致。以前，在空行上光标总是刚刚超过行尾。但这和 Vi 远远不兼 容，而且也有可能使一些插件或 Vim 脚本不能工作，比如因为 l可以移动光标到行尾字符之后。小心使用！$命令总是移动到行尾字符上，而不是超过它。这使光标可能实际向左移动！g$ 命令则移动到屏幕行尾。 组合使用 “all” 和 “onemore” 没有意义，但你不会因此得到警告。 注意 : 如果置位 ’compatible’，本选项被设为 “\"。 ","date":"2021-07-30","objectID":"/vimNormalMovePosition/:3:0","tags":["vim 动作符","vim 位置标记","vim 跳转表","vim 改变表"],"title":"vim 普通模式下光标移动","uri":"/vimNormalMovePosition/"},{"categories":["windows"],"content":" 内容来自以下文档： 官方文档 YuZhuQue: SSH 保持连接 ssh连接WindosTerminal只是个外壳，没有保存密码之类的功能。只是使用openssh ","date":"2021-07-30","objectID":"/WindwosTerminal/:0:0","tags":["terminal"],"title":"windows terminal","uri":"/WindwosTerminal/"},{"categories":["windows"],"content":" 使用密钥实现免密码登陆 客户端创建公钥与私钥 PS C:\\Users\\xiaosi\u003e ssh-keygen.exe Generating public/private rsa key pair. # 保存的私钥路径 Enter file in which to save the key (C:\\Users\\xiaosi/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: # 保存的公钥路径 Your identification has been saved in C:\\Users\\xiaosi/.ssh/id_rsa. Your public key has been saved in C:\\Users\\xiaosi/.ssh/id_rsa.pub. The key fingerprint is: SHA256:TzjxAthsEdqCvbFk5VTlmRgVfB9bOxPHJTL0/OBNfhs xiaosi@DESKTOP-EGH9CCU The key's randomart image is: +---[RSA 2048]----+ | =oo++o+ ..o| | o X . +.o.=.o+| | . O B o +. .++=| | o * . + .oX | | o S o .EB| | = +| | . . | | | | | +----[SHA256]-----+ 把客户端公钥内容添加到服务端的~/.ssh/authorized_keys文件中 PS C:\\Users\\xiaosi\u003e cat .\\.ssh\\id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC2bmrJ0z3fjHC5e6kE9FKs6EN0psZ8HWpXvOJjQcIFKNvAjP5aZyR72Z5AL3tBszhb739G5Ut4FURCmsOIpGq3P+LjrS7UYf8QHEhMQwYzVd1fVv7gZjC7qKEk/+5yoBHfGevYO25S34PM8f0aRyRvxQUqBs5Fo1cvEE8z5VdKeEHlSoweyCtiYdgYOcICy8lJNi2JUWxQBPf9ObLk76sm5ln58j7ZW1f4JFAuzhWqkBRgwboNQa6ylvl+nqKY1GQhC5R0MkE8DSyZnKsiFSYObofbKYmm7dzTmh0aqHCFAAQxfy8S9RpOtgjIPbb6HrU7RjsbBnHPqEblUX+cmTwX xiaosi@DESKTOP-EGH9CCU PS C:\\Users\\xiaosi\u003e ssh root@192.168.100.128 root@192.168.100.128's password: [root@localhost ~]# mkdir .ssh/ [root@localhost ~]# echo 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC2bmrJ0z3fjHC5e6kE9FKs6EN0psZ8HWpXvOJjQcIFKNvAjP5aZyR72Z5AL3tBszhb739G5Ut4FURCmsOIpGq3P+LjrS7UYf8QHEhMQwYzVd1fVv7gZjC7qKEk/+5yoBHfGevYO25S34PM8f0aRyRvxQUqBs5Fo1cvEE8z5VdKeEHlSoweyCtiYdgYOcICy8lJNi2JUWxQBPf9ObLk76sm5ln58j7ZW1f4JFAuzhWqkBRgwboNQa6ylvl+nqKY1GQhC5R0MkE8DSyZnKsiFSYObofbKYmm7dzTmh0aqHCFAAQxfy8S9RpOtgjIPbb6HrU7RjsbBnHPqEblUX+cmTwX xiaosi@DESKTOP-EGH9CCU' \u003e\u003e ~/.ssh/authorized_keys 在WindowsTerminal配置文件中添加以下内容 ... \"profiles\": { \"defaults\": {}, \"list\": [ { \"bellStyle\": \"c8\", \"commandline\": \"ssh root@192.168.100.128\", \"fontFace\": \"JetBrains Mono\", \"fontSize\": 11, \"name\": \"c8\" } ... ","date":"2021-07-30","objectID":"/WindwosTerminal/:1:0","tags":["terminal"],"title":"windows terminal","uri":"/WindwosTerminal/"},{"categories":["windows"],"content":" 保持连接客户端配置文件在 %programdata%\\ssh 目录下（即 C:\\ProgramData\\ssh），在配置文件 ssh_config 中加入以下配置文件实现保持连接 TCPKeepAlive=yes # Client每隔 60 秒发送一次请求给 Server，然后 Server响应，从而保持连接 ServerAliveInterval 60 # Client发出请求后，服务器端没有响应得次数达到3，就自动断开连接，正常情况下，Server 不会不响应 ServerAliveCountMax 3 ","date":"2021-07-30","objectID":"/WindwosTerminal/:2:0","tags":["terminal"],"title":"windows terminal","uri":"/WindwosTerminal/"},{"categories":["redis"],"content":" 运行环境： centos: 7 内容来自以下文档： redis 官方文档: 安装 redis docker 镜像 redisRedis 是一个开源（ BSD 许可）内存数据结构存储，用作数据库、缓存、消息代理和流引擎。它是用 ANSI C 编写的，适用于大多数 POSIX 系统。如 linux 安装","date":"2021-06-15","objectID":"/redis/:0:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 源代码编译安装","date":"2021-06-15","objectID":"/redis/:1:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 下载源码包 [root@localhost data]# wget https://download.redis.io/redis-stable.tar.gz --2022-12-31 10:38:02-- https://download.redis.io/redis-stable.tar.gz Resolving download.redis.io (download.redis.io)... 45.60.125.1 Connecting to download.redis.io (download.redis.io)|45.60.125.1|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3058445 (2.9M) [application/octet-stream] Saving to: ‘redis-stable.tar.gz’ 100%[==============================================================================\u003e] 3,058,445 8.22MB/s in 0.4s 2022-12-31 10:38:03 (8.22 MB/s) - ‘redis-stable.tar.gz’ saved [3058445/3058445] ","date":"2021-06-15","objectID":"/redis/:1:1","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 解压编译 [root@localhost data]# tar -zxf redis-stable.tar.gz [root@localhost data]# [root@localhost data]# cd redis-stable [root@localhost redis-stable]# make cd src \u0026\u0026 make all ... =============================================================================== jemalloc version : 5.2.1-0-g0 library revision : 2 CONFIG : --with-version=5.2.1-0-g0 --with-lg-quantum=3 --with-jemalloc-prefix=je_ 'CFLAGS=-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops ' LDFLAGS= CC : gcc CONFIGURE_CFLAGS : -std=gnu11 -Wall -Wextra -Wsign-compare -Wundef -Wno-format-zero-length -pipe -g3 -fvisibility=hidden -O3 -funroll-loops SPECIFIED_CFLAGS : -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops EXTRA_CFLAGS : CPPFLAGS : -D_GNU_SOURCE -D_REENTRANT CXX : g++ CONFIGURE_CXXFLAGS : -fvisibility=hidden -O3 SPECIFIED_CXXFLAGS : EXTRA_CXXFLAGS : LDFLAGS : EXTRA_LDFLAGS : DSO_LDFLAGS : -shared -Wl,-soname,$(@F) LIBS : -lm -pthread -ldl RPATH_EXTRA : XSLTPROC : false XSLROOT : PREFIX : /usr/local BINDIR : /usr/local/bin DATADIR : /usr/local/share INCLUDEDIR : /usr/local/include LIBDIR : /usr/local/lib MANDIR : /usr/local/share/man srcroot : abs_srcroot : /data/redis-stable/deps/jemalloc/ objroot : abs_objroot : /data/redis-stable/deps/jemalloc/ JEMALLOC_PREFIX : je_ JEMALLOC_PRIVATE_NAMESPACE : je_ install_suffix : malloc_conf : documentation : 1 shared libs : 1 static libs : 1 autogen : 0 debug : 0 stats : 1 experimetal_smallocx : 0 prof : 0 prof-libunwind : 0 prof-libgcc : 0 prof-gcc : 0 fill : 1 utrace : 0 xmalloc : 0 log : 0 lazy_lock : 0 cache-oblivious : 1 cxx : 0 =============================================================================== ... [root@localhost redis-stable]# make install ... 编译完成后有以下二进制文件 [root@localhost redis-stable]# redis-server -v Redis server v=7.0.7 sha=00000000:0 malloc=jemalloc-5.2.1 bits=64 build=7ce2fddae0c636d5 [root@localhost redis-stable]# redis- redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server redis-server: redis 服务 redis-cli: 与 redis 服务通信的 CLI 命令行工具 ","date":"2021-06-15","objectID":"/redis/:1:2","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 运行 redis 添加普通用户作为redis运行用户 [root@localhost data]# useradd redis -s /sbin/nologin -d /data/redis -c \"reids server\" [root@localhost data]# chown -R redis:redis /data/redis [root@localhost data]# mkdir /data/redis [root@localhost data]# cd /data/redis 修改配置文件 # 在源码包中找配置文件 [root@localhost redis]# find /data/redis-stable/ -name \"*.conf\" /data/redis-stable/tests/assets/default.conf /data/redis-stable/tests/assets/minimal.conf /data/redis-stable/tests/sentinel/tests/includes/sentinel.conf /data/redis-stable/redis.conf /data/redis-stable/sentinel.conf [root@localhost redis]# cp /data/redis-stable/redis.conf redis.conf # 修改配置文件 [root@localhost redis]# vim redis.conf ... # 修改监听地址 bind 103.106.246.17 # 修改监听端口 port 6973 # 以守护进程运行 daemonize yes # 指定redis工作目录 dir /data/redis/ # 指定redis pid 文件 pidfile /data/redis/redis.pid # 指定日志文件 logfile \"/data/redis/redis.log\" 为 redis 创建 systemctl unit 文件 # 在源码包中找systemctl service 配置文件 [root@localhost redis]# find /data/redis-stable/ -name \"*.service\" /data/redis-stable/utils/systemd-redis_multiple_servers@.service /data/redis-stable/utils/systemd-redis_server.service [root@localhost redis]# cat /data/redis-stable/utils/systemd-redis_server.service \u003e /usr/lib/systemd/system/redis.service # 修改后systemctl service 配置文件 [root@localhost redis]# cat /usr/lib/systemd/system/redis.service # example systemd service unit file for redis-server # # In order to use this as a template for providing a redis service in your # environment, _at the very least_ make sure to adapt the redis configuration # file you intend to use as needed (make sure to set \"supervised systemd\"), and # to set sane TimeoutStartSec and TimeoutStopSec property values in the unit's # \"[Service]\" section to fit your needs. # # Some properties, such as User= and Group=, are highly desirable for virtually # all deployments of redis, but cannot be provided in a manner that fits all # expectable environments. Some of these properties have been commented out in # this example service unit file, but you are highly encouraged to set them to # fit your needs. # # Please refer to systemd.unit(5), systemd.service(5), and systemd.exec(5) for # more information. [Unit] Description=Redis data structure server Documentation=https://redis.io/documentation #Before=your_application.service another_example_application.service #AssertPathExists=/var/lib/redis Wants=network-online.target After=network-online.target [Service] #ExecStart=/usr/local/bin/redis-server --supervised systemd --daemonize no ## Alternatively, have redis-server load a configuration file: #ExecStart=/usr/local/bin/redis-server /path/to/your/redis.conf # 指定 redis 运行配置文件 ExecStart=/usr/local/bin/redis-server /data/redis/redis.conf ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID LimitNOFILE=10032 NoNewPrivileges=yes #OOMScoreAdjust=-900 # 则为已执行的进程设置一个新的文件系统命名空间，可选 PrivateTmp=yes # 以守护进程方式运行 Type=forking # 指定启用超时时间 TimeoutStartSec=10 # 指定停止超时时间 TimeoutStopSec=10 UMask=0077 # 指定运行身份的用户 User=redis # 指定运行身份的用户组 Group=redis #WorkingDirectory=/var/lib/redis [Install] WantedBy=multi-user.target 运行 # 运行 [root@localhost redis]# systemctl daemon-reload [root@localhost redis]# systemctl start redis [root@localhost redis]# ps -ef | grep redis redis 2789 1 0 13:03 ? 00:00:00 /usr/local/bin/redis-server 103.106.246.17:6973 测试 # -h 指定地址 -p 指定端口 -u 指定用户名 -a 指定密码 [root@localhost redis]# redis-cli -h 103.106.246.17 -p 6973 103.106.246.17:6973\u003e ","date":"2021-06-15","objectID":"/redis/:1:3","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" docker 安装 创建目录用于存储 # data 目录存储数据 # conf 目录存储配置 [root@c8 ~]# mkdir -p redis/{data,conf} 创建容器 [root@c8 ~]# docker container run --name redis \\ \u003e -v /root/redis/data/:/data \\ \u003e -v /root/redis/conf/:/usr/local/etc/redis \\ \u003e -d redis fbc4af9ec097e38d5043a3e78c3422677ad039ba6bca40d42087f63abce49740 [root@c8 ~]# docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES fbc4af9ec097 redis \"docker-entrypoint.s…\" 7 minutes ago Up 7 minutes 6379/tcp redis 查看相关命令 [root@c8 ~]# docker container exec -it redis /bin/bash # redi # 2次 TAB键 root@fbc4af9ec097:/data# redis- redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server 创建alias别名 [root@c8 ~]# alias redis-cli=\"docker container exec -it redis redis-cli\" [root@c8 ~]# redis-cli --help redis-cli 6.2.4 Usage: redis-cli [OPTIONS] [cmd [arg [arg ...]]] Key Valueredis 是使用 k/v 结构存储数据的，这些数据是缓存在内存中。redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 redis 的 key 可以是任何二进制序列。大小最在为 512MB 。key 应该尽量简短，过长的 key 会带来额外的消耗 ","date":"2021-06-15","objectID":"/redis/:2:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 查看 key 的数量 DBSIZE Available since: 1.0.0 Time complexity: O(1) ACL categories: @keyspace, @read, @fast 103.106.246.17:6973\u003e DBSIZE (integer) 10 ","date":"2021-06-15","objectID":"/redis/:3:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 搜索 key KEYS pattern Available since: 1.0.0 Time complexity: O(N) # N 为 key 的数量，由于常量时间相当低。redis 可以在 40 毫秒扫描 100 万个 key ACL categories: @keyspace, @read, @slow, @dangerous pattern 是 go 风格的匹配模式： - ?: 匹配单个字符，如 a?c 可以匹配 abc acc aac 等等 - *: 匹配任意字符，如 a*c 可以匹配 ac acccc abcdsc 等等 - []: 匹配其中一个字符，如 a[bB]c 可以匹配 abc 与 aBc - [a-z]: 是[]字母集的缩写，如 1[a-c] 可以匹配 1a 1b 1c - [^]: 匹配以外的，如 1[^a-c] 结果与 1[a-c] 相反 - \\: 转义特殊字符，包括它本身，如 \\[ 匹配 [ , \\\\ 匹配 \\ 该指令用于调试和特殊操作，在生产环境中格外小心使用的命令。当它针对大型数据库执行时，它可能会破坏性能。 103.106.246.17:6973\u003e KEYS * 1) \"key2\" 2) \"key3\" 3) \"mykey\" 4) \"keyc\" 5) \"key6\" 6) \"key1\" 7) \"decrby\" 8) \"keyb\" 9) \"keya\" 10) \"key4\" 103.106.246.17:6973\u003e KEYS key1 1) \"key1\" 缓存穿透、击穿、雪崩","date":"2021-06-15","objectID":"/redis/:4:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 缓存穿透缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能导致数据库就挂掉，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。 ","date":"2021-06-15","objectID":"/redis/:5:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 缓存击穿缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。 ","date":"2021-06-15","objectID":"/redis/:6:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" 缓存雪崩缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至挂掉 error","date":"2021-06-15","objectID":"/redis/:7:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["redis"],"content":" redis.service start operation timed out. Terminating. [root@localhost data]# journalctl -u redis -- Logs begin at Thu 2022-12-29 12:33:34 CST, end at Sat 2022-12-31 11:22:34 CST. -- Dec 31 11:22:28 localhost.localdomain systemd[1]: Starting Redis data structure server... Dec 31 11:22:28 localhost.localdomain systemd[1]: redis.service start operation timed out. Terminating. Dec 31 11:22:28 localhost.localdomain systemd[1]: Failed to start Redis data structure server. Dec 31 11:22:28 localhost.localdomain systemd[1]: Unit redis.service entered failed state. Dec 31 11:22:28 localhost.localdomain systemd[1]: redis.service failed. 解决方法 [root@localhost redis]# cat /usr/lib/systemd/system/redis.service ... # 指定启动与停止超时时间，不能以infinity为值 TimeoutStartSec=20 TimeoutStopSec=20 #TimeoutStartSec=infinity #TimeoutStopSec=infinity ","date":"2021-06-15","objectID":"/redis/:8:0","tags":["redis","redis 安装"],"title":"redis","uri":"/redis/"},{"categories":["linux"],"content":" 运行环境： centos:7 curl:7.29 内容来自以下文档： curl官方示例 CURLcurl 命令可以在命令行或脚本中通过 URL 传输数据 查看当前版本 第一行显示版本相关信息 Preorcols：支持的协议 Features：支持的功能 [root@localhost ~]# curl --version curl 7.29.0 (x86_64-redhat-linux-gnu) libcurl/7.29.0 NSS/3.44 zlib/1.2.7 libidn/1.28 libssh2/1.8.0 Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp scp sftp smtp smtps telnet tftp Features: AsynchDNS GSS-Negotiate IDN IPv6 Largefile NTLM NTLM_WB SSL libz unix-sockets 获取帮助信息： curl官方帮助手册 url --help 命令 man url 命令 常见选项： -o,--output FILE # 把文件内容输出到指定的文件（下载并重命名） -O, --remote-name # 把文件保存到当前目录下，可以使用多个该选项 -u, --user \u003cuser:password\u003e 指定验证身份的用户名和密码： 1. 只提供 user 部分，则叫交互式中输入密码 2. 只提供 user: 部分，则通过环境变量获取用户名和密码 3. 如果使用多个该选项，则最后一个生效 4. 会覆盖这些选项： -n, --netrc, --netrc-optional -x, --proxy \u003c[protocol://][user:password@]proxyhost[:port]\u003e 使用代理 1. 如果缺省端口，则默认为 1080 2. 会覆盖现有代理环境变量 3. 如果有多个该选项，则最后一个生效 -U, --proxy-user \u003cuser:password\u003e 验证代理的用户 -C, --continue-at \u003coffset\u003e 断点续传，从断网出恢复传输 -T, --upload-file \u003cfile\u003e 上传文件 -f, --fail 如果下载失败，则退出并返回非零退出状态码 -s, --silent 不显示进度和错误信息 -S, --show-error 和 -s 一起使用，显示错误信息 -I 只显示响应头部 -#, --progress-bar 显示更多信息的进度条 -A, --user-agent \u003cagent string\u003e 指定 HTTP 的 User-Agent 信息 -r, --range \u003crange\u003e 获取部分文档字节，用于 HTTP/FTP/SFTP/FILE 协议 -w, --write-out \u003cformat\u003e 提取某些信息 -b, --cookie \u003cname=data\u003e 使用指定的 cookie 文件，用于 HTTP,HTTPS -c, --cookie-jar \u003cfile name\u003e 把 cookit 保存到文件，用于 HTTP,HTTPS -D, --dump-header \u003cfile\u003e 把 HTTP 头部信息保存到文件 -e, --referer \u003cURL\u003e 指定发起请求URL，也就是模拟 http 请求字段中的 referer 。可以检测是否被限制，实际上还是当前 IP 发起请求 -s, --silent # 静默模式，不显示进度 -w, --write-out \u003cformat\u003e # 输出额外指定格式的信息，有以下变量 # %{http_code}: 响应状态码 # %{json}: josn 中的 key # %{time_namelookup}: 请求开始到主机名称解析花费时间(秒) # %{time_appconnect}: 请求开始到SSL/SSH/etc connect/ 连接花费时间(秒) # %{time_connect}: 请求开始到完成建立连接(与主机或代理)花费时间(秒) # %{time_redirect}: 请求开始到最终事务开始之前花费的时间(秒) # 即所有重定向步骤（包括名称查找、连接、预传输和传输）所花费的时间 # %{time_pretransfer}: 请求开始到文件传输开始的时间(秒)，包含传输前的协议协商 # %{time_starttransfer}: 请求从开始到第一个字节即将被传输的时间(秒) # %{time_total}: 请求到结束完整的时间(秒) # ... # HTTP 相关 -d, --data \u003cdata\u003e # 发送的body内容 --data-ascii DATA --data-binary # 二进制格式，可以用 @/path/file 引用本地文本文件 -H, --header \u003cheader/@file\u003e # 添加请求头部 -X, --request \u003cmethod\u003e # 指定HTTP请求动词，默认为 GET -L, --location # 跟随跳转(响应码3XX) # HTTPS 相关 --key # 客户端密钥文件 --cert-type # 客户端证书文件类型 (DER/PEM/ENG) -E, --cert CERT[:PASSWD] # 客户端证书文件与密码 --capath # CA 机构的证书路径 --cacert # CA 机构的证书 -k, --insecure # 使用 SSL 时允许不安全的服务器连接，即 忽略证书警告 HTTP/HTTPS 示例 PS 2023/06/17 13:50:38 \u003e curl.exe -X GET https://192.168.232.100:6443/api --cert .\\localK8s\\xiaosi.crt --key .\\localK8s\\xiaosi.key --cacert .\\localK8s\\ca.crt -s { \"kind\": \"APIVersions\", \"versions\": [ \"v1\" ], \"serverAddressByClientCIDRs\": [ { \"clientCIDR\": \"0.0.0.0/0\", \"serverAddress\": \"192.168.232.103:6443\" } ] } PS 2023/06/18 22:41:05 \u003e curl.exe -s -w \"\\n响应状态码：%{http_code}\" ` \u003e\u003e --cert .\\localK8s\\xiaosi.crt --key .\\localK8s\\xiaosi.key --cacert .\\localK8s\\ca.crt ` \u003e\u003e -H \"Content-Type: application/yaml\" ` \u003e\u003e --data-binary \"@xiaosiNamespace.yaml\" ` \u003e\u003e -X POST https://192.168.232.100:6443/api/v1/namespaces { \"kind\": \"Namespace\", \"apiVersion\": \"v1\", \"metadata\": { ... } 响应状态码：201 获取文件 示例：获得网页响应状态码 [root@localhost ~]# curl -s -o /dev/null -w '响应状态码: %{http_code}\\n' baidu.com 响应状态码: 200 示例：获取 curl.haxx.se 网页内容 [root@localhost ~]# curl https://curl.haxx.se/ \u003c!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003ctitle\u003ecurl\u003c/title\u003e ... 示例：获取多个文件内容 [root@localhost ~]# curl http://site.{one,two,three}.com 示例：获取多个文件内容 ftp://ftp.numericals.com/file[1-100].txt 示例：使用重定向方式保存内容 [root@localhost ~]# curl https://curl.haxx.se/ \u003e curl.txt % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 8700 100 8700 0 0 48484 0 --:--:-- --:--:-- --:--:-- 48603 示例：使用重定向方式把内容追加到文件 [root@localhost ~]# curl https://curl.haxx.se/ \u003e\u003e curl.txt % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 8700 100 8700 0 0 49961 0 --:--:-- --:--:-- ","date":"2021-05-12","objectID":"/CMDcurl/:0:0","tags":["命令","curl 命令"],"title":"curl - 使用url进行传输数据的命令行工具","uri":"/CMDcurl/"},{"categories":["linux"],"content":" 获取部分内容 示例：获取文档前 100到200 字节 curl -r 99-199 http://www.get.this/ 示例：获取文件最后 500 个字节 curl -r -500 http://www.get.this/ 其他： ftp 中只能指定开始和结尾 ","date":"2021-05-12","objectID":"/CMDcurl/:1:0","tags":["命令","curl 命令"],"title":"curl - 使用url进行传输数据的命令行工具","uri":"/CMDcurl/"},{"categories":["linux"],"content":" 获取 sockie 信息 示例：将网页 sockie 保存在文件 curl -c cookiec.txt http://www.linux.com 示例：使用 sockie 信息 curl -b cookiec.txt http://www.linux.com ","date":"2021-05-12","objectID":"/CMDcurl/:2:0","tags":["命令","curl 命令"],"title":"curl - 使用url进行传输数据的命令行工具","uri":"/CMDcurl/"},{"categories":["linux"],"content":" 获取 header 信息 示例：获取 header 信息 curl -D cookied.txt http://www.linux.com 用户名和密码如果需通过用户名和密码进行身份验证，可以参考以下两种方式 [root@localhost ~]# curl ftp://name:passwd@machine.domain:port/full/path/to/file [root@localhost ~]# curl -u name:passwd ftp://machine.domain:port/full/path/to/file 其他： 如果是 HHTP ，由于 HTTP URL 规范中不能包含用户名和密码 ，因此只能使用 -u 选项 如果是 Ftps:// 作为隐式方式，官方建议通过显示方式 ftp:// 和 --ftp-ssl 选项 如果是需密钥使用 --key 如果是需要密码使用 --pass 如果是需要公钥使用 --pubkey 代理 示例：通过代理获取文件 [root@localhost ~]# curl -x 192.168.100.100:1080 http://www.baidu.com 示例：通过代理获取文件，但需身份验证 [root@localhost ~]# curl -u user:passwd -x my-proxy:888 http://www.get.this/ 示例：代理身份验证 curl -U user:passwd -x my-proxy:888 http://www.get.this/ 示例：部分文件使用代理 curl --noproxy localhost,get.this -x my-proxy:888 http://www.get.this/ 其他： --socks5 支持 socks4 和 --socks4 socks5 代理 返回状态码 示例：Linux 下获取网站状态码 [root@localhost ~]# echo `curl -o /dev/null -s -w %{http_code} www.baidu.com` 200 示例：win 下获取网站状态码 [e:\\~]$ curl -o C:\\$RECYCLE.BIN -s -w %{http_code} www.baidu.com 200 冒充访问源 示例：冒出访问源 curl -e \"www.coolsite.com\" http://www.showme.com/ 冒充浏览器 示例：冒充 chrome 浏览器 curl -A 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36' ","date":"2021-05-12","objectID":"/CMDcurl/:3:0","tags":["命令","curl 命令"],"title":"curl - 使用url进行传输数据的命令行工具","uri":"/CMDcurl/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.20.0 反向代理nginx支持以下7层反向代理： http/https uwsgi fastcgi scgi memecached websocket http/https 配置代理请求部分： 指定上游服务：proxy_pass 是否传递头部请求：proxy_pass_request_headers 是否传递请求主体部分：proxy_pass_request_body 指定请求方法：proxy_method 指定请求协议版本：proxy_http_version 增改请求头部：proxy_set_header 设置请求主体：proxy_set_body 是否缓存请求主体：proxy_requset_buffering 与上游服务建立连接并发送请求： 连接上游超时时间：proxy_connect_timeout 连接绑定地址：proxy_bind 使用tcp长连接：proxy_socket_keepalive 忽略客户端连接：proxy_ignore_client_abort 设置http头部用的hash表：proxy_headers_hash_bucket_size, proxy_headers_hash_bucket_max_size 发送请求超时时间：proxy_send_timeout 出错时更换上游服务：proxy_next_upstream 更换上游服务超时：proxy_next_upstream_timeout 更换上游服务重试次数：proxy_next_upstream_tries 接收上游服务返回的响应报文： 是否缓存上游响应：proxy_buffering 存放缓存的目录：proxy_temp_path 写入缓存文件的缓存大小：proxy_temp_file_write_size 缓存文件最大值：proxy_max_temp_file_size 接收响应头部缓存：proxy_buffer_size 接收响应主体缓存：proxy_buffers 缓存完成前转发主体：proxy_busy_buffers_size 持久化主体文件：proxy_store 读取响应超时时间：proxy_read_timeout 读取响应限速：proxy_limit_rate 连接上游错误响应：proxy_intercept_errors 向客户端发送响应： 减少发给客户端的响应头部：proxy_hide_header 禁用响应头部：proxy_ignore_header 传递头部到客户端：proxy_pass_header 替换Set-Cookie头部中的域名：proxy_cookit_domain 替换Set-Cookie头部中的URL：proxy_cookit_path 修改重定向中location的值：proxy_redirect 缓存类： 指定共享内存：proxy_cache 缓存文件存放目录：proxy_cache_path 设置哪些请求不使用缓存：proxy_cache_bypass 开启子请求更新过期缓存：proxy_cache_background 定义缓存关键字：proxy_cache_key 使用range协议的偏移：proxy_cache_max_range_offset 强制使用range协议：prxoy_force_ranges 缓存哪些请求方法：proxy_cache_min_uses 缓存哪些响应码以及缓存有效期：proxy_cache_valid 有过期缓存使用304：proxy_cache_revalidate 返回过期缓存：proxy_cache_use_stale 设置哪些响应不写如缓存：proxy_no_cache 加锁减少回源请求：proxy_cache_lock 回源请求超时放行时间：proxy_cache_lock_age 等待请求最长时间：proxy_cache_lock_timeout 将HEAD方法转换为GET方法：proxy_cache_convert_head 上游与代理使用SSL 配置代理(或上游服务nginx)证书：proxy_ssl_certificate 配置代理(或上游服务nginx)私钥：proxy_ssl_certificate_key 验证上游服务证书：proxy_ssl_trusted_certificate 是否验证上游服务证书：proxy_ssl_verify 安全套件：proxy_ssl_ciphers 指定吊销证书链CRL文件验证上游的证书：proxy_ssl_crl 指定域名验证上游证书的域名：proxy_ssl_name 当私钥有密码时指定密码文件：proxy_ssl_password_file 指定具体某个版本协议：proxy_ssl_protocols 传递SNI信息到上游服务：proxy_ssl_server_name 是否重用SSL连接：proxy_ssl_session_reuse 设置验证证书链深度：proxy_ssl_verify_depth ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:0:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" http反向代理流程 在content阶段的proxy_pass指令 是否命中缓存： 未命中缓存或没有开启缓存进入下一步 命中缓存直接进入第11步 通过指令生成头部和主体发给上游服务 判断proxy_requset_buffering指令是否开启 开启(默认)：缓存请求报文主体部分再进入下一步 关闭：进入下一步 更据负载均衡策略选择上游服务(upstream指令快) 更据参数连接上游服务 发送请求到上游服务， 如果proxy_requset_buffering指令关闭则会在此时边读主体部分边发送 接收上游服务返回的响应头部 处理上游响应头部 判断proxy_buffering指令是否开启： 开启：接收完整的响应主体部分再进入下一步 关闭：直接进入下一步 发送响应头部给客户端 发送响应主体部分给客户端， 如果proxy_buffering指令关闭则会在此时边读主体边发送 判断是否开启缓存： 开启：将主体部分加入缓存再进入下一步 关闭：直接进入下一步 关闭或复用连接，也就是长连接(保存连接) ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 第1步：反向代理http/https协议ngx_http_proxy_module模块默认编译进入nginx, 编译时可通过--without-ngx_http_proxy_module取消 proxy_pass {URL}指令： 对上游服务使用http/https协议进行反向第代理 处于nginx处理http请求的第10个阶段(content) 配置在location, if in location, limit_except指令块中 URL有以下部分组成： 必须的http://或https://开头， 域名,ip,unix socket,upstream名称之一， 域名或ip可以加端口，默认为80， 可选的URI，URI参数中可以有变量 有URI情况下，将location参数中匹配部分替换为该URI再发送给上游服务 无URI情况下，直接发送给上游服务 location后使用正则表达式、@时应该使用该方式 示例： upstream rb1 { server 127.0.0.1:821; } server { listen 830; access_log logs/830upstream_rb1.log upstream1; location / { ## 访问curl 127.0.0.1:830/abc/txt 得到：821 server uri:/abc/txt proxy_pass http://rb1; ## 访问curl 127.0.0.1:830/abc/txt 得到：821 server uri:/file/txt ##proxy_pass http://rb1/file/; proxy_http_version 1.1; proxy_set_header Connection \"\"; } } server { listen 821; default_type text/plain; return 200 '821 server uri:$uri \\n'; } ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:1","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 第3步：生成头部发送给上游服务proxy_method method指令 反向代理时修改http请求方法 配置在http，server，location指令块中 method代指http请求方法 proxy_http_version 1.0|1.1指令： 反向代理时修改http协议版本 配置在http，server，location指令块中 默认值为1.0 建议使用1.1(支持keepalive长连接和NTLM身份验证) porxy_set_header field value指令： 反向代理时修改http请求头部 配置在http，server，location指令块中 field代指请求头部名称 value代指请求头部名称对应的值，值为空时不发送对应的头部 该指令可以有多个 默认值： Host $proxy_hos Connection close proxy_pass_request_headers on|off指令： 是否向上游服务发送用户请求头部内容 配置在http，server，location指令块中 默认值:on proxy_pass_request_body on|off指令： 是否向上游服务发送请求报文的主体部分 配置在http，server，location指令块中 默认值:on proxy_set_body value指令： 反向代理时创建一个请求主体 配置在http，server，location指令块中 value代指请求主体内容字符串 示例： upstream rb1 { server 127.0.0.1:821; } server { listen 830; access_log logs/830upstream_rb1.log upstream1; location / { proxy_pass http://rb1; ## 以上配置使用curl -H 'name: lo' 127.0.0.1:830/file 的： ## 821 server,uri:/file,请求方法:GET,请求行:GET /file HTTP/1.0,name头部:lo ## 修改http版本为1.1 proxy_http_version 1.1; ## 去掉Connection头部（头部值为空时不发送该头部） proxy_set_header Connection \"\"; ## 修改请求方法为post proxy_method POST; } } server { listen 821; default_type text/plain; return 200 '821 server,uri:$uri,请求方法:$request_method,请求行:$request,name头部:$http_name\\n'; } ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:2","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 第4步：读取主体proxy_requset_buffering on|off指令： 是否现在读取(缓存)请求报文中的主体部分 配置在http，server，location指令块中 默认值:on on：现在读取，适合以下场景： 客户的网络慢 上游服务并发能力低 高吞吐量 off：第7步再读取直接发给上游不会，适合以下场景： 更快进入第5,6步，加快响应 降低nginx读写磁盘消耗（不用把主体写入磁盘） 一旦开始发送内容，proxy_next_upstream指令失效 client_body_buffer_size size指令： 用于保存主体的最大内存大小 配置在http，server，location指令块中 默认值:8k或16k 如果接收头部时已经收到所有主体(主体太小)则不分配 如果主体部分小于该指令值，则分配所需大小 如果主体大于该指令值，都是通过该段内存分段接收 该指令分配的内存用完时，写入临时文件，释放内容，接收下一段主体 client_body_in_single_buffer on|off指令： 是否把所有主体都放入内存中 配置在http，server，location指令块中 默认值:off client_max_body_size size指令： 限制最大主体部分长度 配置在http，server，location指令块中 默认值:1m 仅对请求报文中含有Content_Length头部值超过该指令值时返回413错误 client_bodu_temp_path path指令： 保存临时文件的主目录 配置在http，server，location指令块中 默认值:cilent_body_temp client_body_in_file_only on|clean|off指令： 是否把包体永久写入临时文件 配置在http，server，location指令块中 默认值:off(主体太小不用写入临时文件) clean表示请求完成之后文件会被删除 client_body_timeout time指令： 读取主体部分超时时间 配置在http，server，location指令块中 默认值:60s 超时会返回408错误 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:3","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 第5步：连接上游服务prixy_connect_timeout time指令： 与上游服务tcp三次握手超时时间 配置在http，server，location指令块中 默认值:60s 超时会向客户端返回502错误(此时还在代理服务器，没有与上游服务连接上) 可以通过proxy_next_upstream http_502指令选择其他上游服务解决该超时问题 proxy_send_timeout time指令: 向上游服务发送http请求超时时间 配置在http，server，location指令块中 默认值:60s proxy_socket_keepalive on|of指令： 连接上游服务时是否启用tcp连接中的keepalive 配置在http，server，location指令块中 默认值:off tcp中的keepalive： 数据传输之后进入倒计时定时器 在计时器之间没有收到数据包时发送探测包 等待探测包应答(超时则关闭) http中的keepalive: keepalive指令指定长连接数量 keepalive_requests指令指定每个长连接可以处理请求数量 proxy_bind address [transparent]|off指令： 修改tcp连接中的请求地址，即tcp报文中的请求地址(当前代理地址) 配置在http，server，location指令块中 address 表示ip地址，可以使用变量： $remote_addr：客户端地址 如果地址不是本机的，需要加transparent参数 (非linux操作系统要保证有root权限) proxy_ignore_client_abort on|off指令： 是否忽略客户端关闭的连接 配置在http，server，location指令块中 默认值:off 如果开启，代理与上游服务的连接不会断开 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:4","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 第8步：接收上游服务返回的响应报文头部proxy_buffer_size size指令： 上游服务返回头部的最大大小 配置在http，server，location指令块中 默认值:4k或8K 响应头部大小超过该指令值时会记录错误日志：upstream sent too big header ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:5","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 第9步：处理上游服务返回的响应报文头部proxy_ignore_header field..指令： 禁用上哟服务某些可以改变nginx行为的http头部 配置在http，server，location指令块中 可禁用的头部有以下： X-Accel-Readirect：上游服务指定在nginx内部重定向 X-Accel-Limit-Rate：上游服务设置发往客户端的限速，等效limit_rate指令 X-Accel-Buffering：上游服务设置是否缓存响应报文 X-Accel-Expires：设置响应报文在nginx中的缓存时间(秒),@开头表示一天内某刻 Expires：设置相应报文在nginx中的缓存时间(s)。优先级低于X-Accel-Expires Cache-Control：等效Expires头部 Set-Cookit：出现该响应则不缓存 Vary：值为*则不缓存 proxy_hide_header field指令： 不向客户端转发上游服务返回的某些头部 配置在http，server，location指令块中 该指令默认不会转发以下上游响应头部： Date: 上游服务发送响应头部时间，由ngx_http_header_filter_module模块填写 Server：上游服务nginx版本，由ngx_http_header_filter_module模块填写 X-Pad：通常是Apache为避免浏览器BUG生成的头部 X-Accel-开头头部 proxy_pass_header field指令： 向客户端转发上游服务返回的某些头部 配置在http，server，location指令块中 proxy_cookit_domain off|doamin replacemet指令： 修改上游服务返回(Set-Cookit)的域名记录 配置在http，server，location指令块中 默认值:off proxy_cookit_path off|path replacemet指令： 修改上游服务返回(Set-Cookit)的url 配置在http，server，location指令块中 默认值:off proxy_redirect off|default|redirect replacemet指令： 修改上游服务返回的location 配置在http，server，location指令块中 默认值:default ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:6","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 第10步：是否接收完整的主体proxy_buffering on|off指令： 是否接收(缓存)完整的响应主体 配置在http，server，location指令块中 默认值:on off优点：更快发送响应头部 该指令会被X-Accel-Buffering头部值替换： yes表示接受主体，no相反 proxy_buffers number size指令： 能缓存上游服务主体大小 配置在http，server，location指令块中 主体小于此指令值时写入内存否则写入磁盘 默认值: 8 4k或8k proxy_max_temp_file_size size指令： 临时文件的最大值 配置在http，server，location指令块中 默认值:1024m proxy_temp_file_write_size size指令： 单次写入临时文件的最大值 配置在http，server，location指令块中 默认值:8k或16k proxy_temp_path path指令： 临时文件存放主目录 配置在http，server，location指令块中 默认值:proxy_temp proxy_busy_buffers_size size指令： 到达阀值之后先转发主体 配置在http，server，location指令块中 默认值:8k或16k proxy_read_timeout time指令： tcp读取超时时间 配置在http，server，location指令块中 默认值:60s proxy_limit_rate rate指令： 读取上游服务的网络限速 配置在http，server，location指令块中 默认值:0(不限制) proxy_store_access users:permissions...指令： 临时文件永久保存的权限 配置在http，server，location指令块中 默认值:user:rw proxy_store on|off|string指令： 临时文件永久保存(另存为)的目录 配置在http，server，location指令块中 默认值:off on表示使用root指令目录 string代指自定义的目录字符串 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:7","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 上游服务错误时解决方案proxy_nex_upstream指令： 处理上游服务返回失败 配置在http，server，location指令块中 默认值:error timeout 该指令前提是还没有向客户端发送任何内容，也就是第11步之前 有以下取值： error：连接上游服务出错时，禁止调度到该服务 timeout：连接上游服务超时时，禁止调度到该服务 http_[500|502|503|504|404|429]：http响应码 invalid_header：请求头部不合法 non_idempotent：出错时重新选取上游服务 off：不处理任何上游服务返回的错误 proxy_next_upstream_timeout time指令： 选择上游服务超时时间 配置在http，server，location指令块中 默认值:0(不限制) proxy_next_upstream_tries number指令： 选取上游服务超时重试次数 配置在http，server，location指令块中 默认值:0(不限制) proxy_intercept_errors on|of指令： 是否处理上游服务响应状态码大于或等于300的情况 配置在http，server，location指令块中 默认值:off(响应码返回给客户端) 如果开启，由error_page指令处理 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:8","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 对上游服务器使用SSL连接如果nginx代理与上游服务都使用HTTPS，则需要双向认证： 代理(nginx)使用的证书： proxy_ssl_certificate proxy_ssl_certificate_key 代理(nginx)验证上游服务证书： proxy_ssl_verify：验证上游服务证书 proxy_ssl_trusted_certificate：验证上游证书颁发着 上游服务(nginx)使用的证书： ssl_certificate ssl_certificate_key 上游服务(nginx)验证反向代理证书： ssl_verify_client：验证代理证书 ssl_client_certificate：验证代理证书颁发者 后期补充 fastcgi 未分类： fastcgi_param fastcgi_index fastcgi_catch_stderr 配置代理请求部分： 指定上游服务：fastcgi_pass 是否传递头部请求：fastcgi_pass_request_headers 是否传递请求主体部分：fastcgi_pass_request_body 是否缓存请求主体：fastcgi_requset_buffering 与上游服务建立连接并发送请求： 连接上游超时时间：fastcgi_connect_timeout 连接绑定地址：fastcgi_bind 使用tcp长连接：fastcgi_socket_keepalive 忽略客户端连接：fastcgi_ignore_client_abort 发送请求超时时间：fastcgi_send_timeout 出错时更换上游服务：fastcgi_next_upstream 更换上游服务超时：fastcgi_next_upstream_timeout 更换上游服务重试次数：fastcgi_next_upstream_tries 接收上游服务返回的响应报文： 是否缓存上游响应：fastcgi_buffering 存放缓存的目录：fastcgi_temp_path 写入缓存文件的缓存大小：fastcgi_temp_file_write_size 缓存文件最大值：fastcgi_max_temp_file_size 接收响应头部缓存：fastcgi_buffer_size 接收响应主体缓存：fastcgi_buffers 缓存完成前转发主体：fastcgi_busy_buffers_size 持久化主体文件：fastcgi_store 读取响应超时时间：fastcgi_read_timeout 读取响应限速：fastcgi_limit_rate 连接上游错误响应：fastcgi_intercept_errors 向客户端发送响应： 减少发给客户端的响应头部：fastcgi_hide_header 禁用响应头部：fastcgi_ignore_header 传递头部到客户端：fastcgi_pass_header 缓存类： 指定共享内存：fastcgi_cache 缓存文件存放目录：fastcgi_cache_path 设置哪些请求不使用缓存：fastcgi_cache_bypass 开启子请求更新过期缓存：fastcgi_cache_background 定义缓存关键字：fastcgi_cache_key 使用range协议的偏移：fastcgi_cache_max_range_offset 强制使用range协议：prxoy_force_ranges 缓存哪些请求方法：fastcgi_cache_min_uses 缓存哪些响应码以及缓存有效期：fastcgi_cache_valid 有过期缓存使用304：fastcgi_cache_revalidate 返回过期缓存：fastcgi_cache_use_stale 设置哪些响应不写如缓存：fastcgi_no_cache 加锁减少回源请求：fastcgi_cache_lock 回源请求超时放行时间：fastcgi_cache_lock_age 等待请求最长时间：fastcgi_cache_lock_timeout ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:1:9","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_connect_timeout # 语法 fastcgi_connect_timeout time; # 默认值 fastcgi_connect_timeout 60s； # 配置上下文 http, server,location 定义与FastCGI服务器建立连接的超时时间。 通常该值不会超过75s ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:2:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_send_timeout # 语法 fastcgi_send_timeout time; # 默认值 fastcgi_send_timeout 60s； # 配置上下文 http, server,location 设置将请求传输到 FastCGI 服务器的超时时间， 如果 FastCGI 服务器在这段时间内没有收到任何内容，则关闭连接。 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:3:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_read_timeout # 语法 fastcgi_read_timeout time; # 默认值 fastcgi_read_timeout 60s； # 配置上下文 http, server,location 定义从 FastCGI 服务器读取响应的超时时间， 如果 FastCGI 服务器在这段时间内没有传输任何内容，则关闭连接。 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:4:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_buffer_size # 语法 fastcgi_buffer_size size; # 默认值 fastcgi_buffer_size 4k|8k; # 配置上下文 http, server,location 设置用于读取从 FastCGI 服务器接收的响应的第一部分的缓冲区的大小 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:5:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_buffers # 语法 fastcgi_buffers number size; # 默认值 fastcgi_buffers 8 4k|8k # 配置上下文 http, server,location 设置用于从 FastCGI 服务器读取响应的缓冲区的大小与数量 number 表示缓存连接数量 size 表示单个连接的缓冲区大小 ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:6:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_busy_buffers_size # 语法 fastcgi_busy_buffers_size size; # 默认值 fastcgi_busy_buffers_size 8k|16k; # 配置上下文 http, server,location 启用fastcgi_buffering指令时生效 当缓存大小超过该指令值时，先转发主体给客户端 (边缓存边转发) ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:7:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_temp_file_write_size # 语法 fastcgi_temp_file_write_size size; # 默认值 fastcgi_temp_file_write_size 8k|16k; # 配置上下文 http, server,location 启用fastcgi_buffering指令时生效 限制单次写入缓冲区大小， 表示在写入缓存文件时使用多大的数据块， ","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:8:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" fastcgi_intercept_errors # 语法 fastcgi_inercept_errors on|off # 默认配置 fastcgi_intercept_errors off; # 配置上下文 http, server,location FastCGI 服务器响应码大于300时是否交给error_page指令处理 值为on时，由error_page指令处理，如果error_page指令也没 有设置相应的状态码才有效 值为off时，直接发给客户端 uwsgi 未分类： uwsgi_modifier1 uwsgi_modifier2 uwsgi_param 配置代理请求部分： 指定上游服务：uwsgi_pass 是否传递头部请求：uwsgi_pass_request_headers 是否传递请求主体部分：uwsgi_pass_request_body 是否缓存请求主体：uwsgi_requset_buffering 与上游服务建立连接并发送请求： 连接上游超时时间：uwsgi_connect_timeout 连接绑定地址：uwsgi_bind 使用tcp长连接：uwsgi_socket_keepalive 忽略客户端连接：uwsgi_ignore_client_abort 发送请求超时时间：uwsgi_send_timeout 出错时更换上游服务：uwsgi_next_upstream 更换上游服务超时：uwsgi_next_upstream_timeout 更换上游服务重试次数：uwsgi_next_upstream_tries 接收上游服务返回的响应报文： 是否缓存上游响应：uwsgi_buffering 存放缓存的目录：uwsgi_temp_path 写入缓存文件的缓存大小：uwsgi_temp_file_write_size 缓存文件最大值：uwsgi_max_temp_file_size 接收响应头部缓存：uwsgi_buffer_size 接收响应主体缓存：uwsgi_buffers 缓存完成前转发主体：uwsgi_busy_buffers_size 持久化主体文件：uwsgi_store 读取响应超时时间：uwsgi_read_timeout 读取响应限速：uwsgi_limit_rate 连接上游错误响应：uwsgi_intercept_errors 向客户端发送响应： 减少发给客户端的响应头部：uwsgi_hide_header 禁用响应头部：uwsgi_ignore_header 传递头部到客户端：uwsgi_pass_header 缓存类： 指定共享内存：uwsgi_cache 缓存文件存放目录：uwsgi_cache_path 设置哪些请求不使用缓存：uwsgi_cache_bypass 开启子请求更新过期缓存：uwsgi_cache_background 定义缓存关键字：uwsgi_cache_key 使用range协议的偏移：uwsgi_cache_max_range_offset 强制使用range协议：prxoy_force_ranges 缓存哪些请求方法：uwsgi_cache_min_uses 缓存哪些响应码以及缓存有效期：uwsgi_cache_valid 有过期缓存使用304：uwsgi_cache_revalidate 返回过期缓存：uwsgi_cache_use_stale 设置哪些响应不写如缓存：uwsgi_no_cache 加锁减少回源请求：uwsgi_cache_lock 回源请求超时放行时间：uwsgi_cache_lock_age 等待请求最长时间：uwsgi_cache_lock_timeout 上游与代理使用SSL 配置代理(或上游服务nginx)证书：uwsgi_ssl_certificate 配置代理(或上游服务nginx)私钥：uwsgi_ssl_certificate_key 验证上游服务证书：uwsgi_ssl_trusted_certificate 是否验证上游服务证书：uwsgi_ssl_verify 安全套件：uwsgi_ssl_ciphers 指定吊销证书链CRL文件验证上游的证书：uwsgi_ssl_crl 指定域名验证上游证书的域名：uwsgi_ssl_name 当私钥有密码时指定密码文件：uwsgi_ssl_password_file 指定具体某个版本协议：uwsgi_ssl_protocols 传递SNI信息到上游服务：uwsgi_ssl_server_name 是否重用SSL连接：uwsgi_ssl_session_reuse 设置验证证书链深度：uwsgi_ssl_verify_depth scgi 未分类： scgi_param 配置代理请求部分： 指定上游服务：scgi_pass 是否传递头部请求：scgi_pass_request_headers 是否传递请求主体部分：scgi_pass_request_body 是否缓存请求主体：scgi_requset_buffering 与上游服务建立连接并发送请求： 连接上游超时时间：scgi_connect_timeout 连接绑定地址：scgi_bind 使用tcp长连接：scgi_socket_keepalive 忽略客户端连接：scgi_ignore_client_abort 发送请求超时时间：scgi_send_timeout 出错时更换上游服务：scgi_next_upstream 更换上游服务超时：scgi_next_upstream_timeout 更换上游服务重试次数：scgi_next_upstream_tries 接收上游服务返回的响应报文： 是否缓存上游响应：scgi_buffering 存放缓存的目录：scgi_temp_path 写入缓存文件的缓存大小：scgi_temp_file_write_size 缓存文件最大值：scgi_max_temp_file_size 接收响应头部缓存：scgi_buffer_size 接收响应主体缓存：scgi_buffers 缓存完成前转发主体：scgi_busy_buffers_size 持久化主体文件：scgi_store 读取响应超时时间：scgi_read_timeout 读取响应限速：scgi_limit_rate 连接上游错误响应：scgi_intercept_errors 向客户端发送响应： 减少发给客户端的响应头部：scgi_hide_header 禁用响应头部：scgi_ignore_header 传递头部到客户端：scgi_pass_header 缓存类： 指定共享内存：scgi_cache 缓存文件存放目录：scgi_cache_path 设置哪些请求不使用缓存：scgi_cache_bypass 开启子请求更新过期缓存：scgi_cache_background 定义缓存关键字：scgi_cache_key 使用range协议的偏移：scgi_cache_max_range_offset 强制使用range协议：prxoy_force_ranges 缓存哪些请求方法：scgi_cache_min_uses 缓存哪些响应码以及缓存有效期：scgi_cache_valid 有过期缓存使用304：scgi_cache_revalidate 返回过期缓存：scgi_cache_use_stale 设置哪些响应不写如缓存：scgi_no_cache 加锁减少回源请求：scgi_cache_lock 回源请求超时放行时间：scgi_cache_lock_age 等待请求最长时间：scgi_cache_lock_timeout memecached websocket","date":"2020-12-03","objectID":"/nginx-peverse-proxy/:9:0","tags":["反向代理","nginx"],"title":"nginx 反向代理","uri":"/nginx-peverse-proxy/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.20.0 nginx进程结构nginx由一个master进程产生多个work子进程和chche相关进程 master进程管理work子进程，work处理请求 进程之间通讯是使用共享内存， 进程之间是使用信号通讯 nginx进程管理可以通过向nginx进程发送信号，其实命令行就是发送进程信号 master进程能接收的信号： CHLD: 子进程终止时向master进程发送该信号 TERM,INT: 立即停止 QUIT: 优雅退出 HUP: 重载配置文件 USR1: 日志切割 USR2: 热部署 WINCH: 优雅暂停进程 worker进程能接收的信号，但通常是master进程管理 ","date":"2020-12-03","objectID":"/nginx-architecture/:0:0","tags":["架构","nginx"],"title":"nginx架构","uri":"/nginx-architecture/"},{"categories":["nginx"],"content":" 优雅关闭worker进程 设置定时器（worker_shutdown_timeout） 关闭监听句柄，不在处理新的连接 关闭空闲连接 在循环中等待全部关闭连接 退出进程 网络收发和nginx事件关系TCP协议与非阻塞接口: 读事件: ACCEPT建立连接： 请求建立tcp连接事件 read读消息 tcp连接可读事件 tcp连接关闭事件 写事件： ","date":"2020-12-03","objectID":"/nginx-architecture/:1:0","tags":["架构","nginx"],"title":"nginx架构","uri":"/nginx-architecture/"},{"categories":["nginx"],"content":" ","date":"2020-12-02","objectID":"/nginx-cache/","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.20.0 内容来自以下文档： MDN Web Docs: HTTP协议 陶辉：nginx 核心知识100讲 nginx官方文档: ngx_http_headers_module nginx官方文档: ngx_http_core_module 缓存缓存是提升访问速度最好的方法 客户端本地缓存(浏览器)： 优点： 存在有效缓存时，没有网络消耗，速度最快 缓存失效可以使用304响应状态码最小化网络消耗 缺点：只对当前客户端有效 服务端缓存： 优点： 提升所有用户访问速度 降低上游服务的负载 可以通过304响应状态码减少与上游服务之间的网络消耗 缺点：用户仍然需要保持网络消耗 通常同时使用客户端和服务端缓存 客户端缓存 ","date":"2020-12-02","objectID":"/nginx-cache/:0:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" nginx决定浏览器过期的缓存是否有效 etag on | off; 配置域：http，server，location 默认值：on etag 指令是否为静态资源生成 Etag 头部。on 表示生成 expires [modified] time; expires epoch | max | off; 配置域：http，server，location，if in location 默认值：off expires 指令用于指定客户端缓存过期时间，该指令有以下取值： max：永久有效，通过以下2个方式： Expires：值为绝对时间 Cache-Control：max-age 值为一个相对时间（n秒后） off：不添加或修改Expires和Cache-Control头部 epoch：不使用该缓存，通过以下2个方式： Expires：已经过去的绝对时间 Cache-Control：no-cache time代指一个具体的时间，可以携带单位： 一天内具体时间可以加@，如18点：@18h00m00s 设置Expires，自动计算Cache-Control 如果Expires值在当天已经过去了，则第二天才会生效 正数：更据设置Cache-Control时间，计算出Expires 负数：设置Cache-Control:no-cache，计算出Expires modified: 代指文件修改时间，如 modified +1h 表示文件修改时间的一小时后过期 状态码为以下时，启用缓存： nginx: 1.0.13 版本起增加：204，206，301，302，303，304，307 nginx: 1.3.0 版本起增加：308 nginx: 1.3.10 版本起增加：200，201 在 nginx: 1.7.9 版本起值可以是一个变量 示例 server { # 设置浏览器缓存时间 expires 1d; } 以下是官方文档示例，根据文件类型指定缓存时间 map $sent_http_content_type $expires { default off; application/pdf 42d; ~image/ max; } expires $expires; ","date":"2020-12-02","objectID":"/nginx-cache/:1:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" nginx检查客户端缓存是否过期当客户端有缓存，但不确定是否有效，会在请求头部添加 If-None-Match 或 If-Modified-Since 头部，not_modified 模块通过响应码的 Last_Modified 值(静态资源文件的最后编辑时间)做比较，决定返回 200 状态码(返回请求内容)还是 304状态码(表示之前缓存有效，可以使用) not-modified 模块有个前提是原本请求响应码必须是200 判断缓存是否过期 if_modified_since off | exact | before; 配置域：http，server，location 默认值：exact 该指令指定请求头部if_modified_since与响应头部Last_Modified比较方式。有以下取值： off：忽略请求报文中if_modified_since头部 exact：精确匹配，即 if_modified_since等于Last_Modified before：若if_modified_since大于等于Last_Modified，则返回304 nginx 反向代理流程反向代理服务器收到客户的请求之后： 检查否开启proxy_cache指令： 是：向上游服务发送请求，忽略后续步奏 否：进入下一步 请求方法是否匹配proxy_cache_methods指令指定的请求方法： 否：向上游服务发送请求，忽略后续步奏 是：进入下一步 更据proxy_cache_convert_head指令觉得是否把HEAD换为GET方法 更据proxy_cache_key指令生成关键字并执行md5 检查proxy_cache_pass指令是指定是否使用缓存 否：向上游服务发送请求，忽略后续步奏 是：进入下一步 共享内存中是否有该缓存 是：进入下一步 否：尝试共享内存中分配节点 成功：向上游服务发送请求，忽略后续步奏 失败：淘汰过期缓存，再分配共享内存内存， 之后向上游服务发送请求，忽略后续步奏 更新LRU链表节点计数 是否错误类且响应过期 是：向上游服务发送请求，忽略后续步奏 否：进入下一步 文件存在且使用次数是否超过proxy_cache_min_uses指令值 是：更据proxy_cache_background_update指令生成子请求， 再向客户发送缓存中的响应内容 否：直接向客户发送缓存中的响应内容 反向代理服务器收到上游服务返回的请求之后： 是否匹配proxy_no_cahce指令： 是：不更新缓存，直接响应客户端，忽略后续步奏 否：进入下一步 请求方法是否匹配proxy_cache_valid指令： 否：不更新缓存，直接响应客户端 是：进入下一步 判断响应状态码是否为200或206： 是：更新缓存中的etag和last_modified再进入下一步 否：进入下一步 处理缓存相关的响应头部，并检查是否有响应头部不使用缓存 是：不更新缓存，直接响应客户端，忽略后续步奏 否：进入下一步 读取并转发所有响应给客户端 临时文件改名到缓存目录 更新共享内存状态 proxy_chache zone|off指令： 存放反向代理缓存的key 配置在http，server，location指令块中 默认值:off zone代指定义的共享内存区域名称 proxy_chache_key string指令： 反向代理缓存关键字 配置在http，server，location指令块中 默认值:$scheme$proxy_host$request_uri string代指缓存关键字 proxy_cache_path path keys_zone=name:size指令： 反向代理缓存存放路径 配置在http指令块中 取值： path：代指存储缓存的文件路径 keys_zone是固定格式， name代指proxy_cache指令定义的共享内存名称， size代指分配大小，1M约存8000个key 以下是path取值可选的参数： levels=定义缓存路径的目录层级，最多3级，每层目录长度为1或2字节 use_temp_path [on|off]： on：使用proxy_temp_path指令定义的临时目录 off：直接使用该指令定义的临时目录 inactive=缓存有效期，默认10分钟，超时会被淘汰 max_size=缓存文件大小的最大值，超出后由cache manager进程按照lru链表淘汰 manager_files=cahe manager进程每次淘汰过程中，最大淘汰文件数量，默认100 manager_sleep=cache manager进程每次淘汰后休眠的时间，默认200毫秒 manager_threshold=cache manager进程每次淘汰最大消耗时间，默认50毫秒 loader_files=cache loader进程每次载入磁盘中缓存文件到共享内存的数量 loader_sleep=cache loader进程每次载入缓存文件后休眠的时间，默认200毫秒 loader_threshold=cache loader进程每次载入缓存文件到共享内存超时时间， 默认50毫秒 proxy_cache_valid [code...] time指令： 设置缓存响应码，即缓存该响应码的内容 配置在http，server，location指令块中 code代指响应码，time代指缓存时间： 取值方式： 对不同响应码缓存不等的时间，如 code 404 1m 如果只标示时间，仅对200,301,302这些状态码缓存 上游服务返回头部控制缓存时长 X-Accel-Expires：单位为秒，0表示不缓存，@表示一天中某个时间 含有Set-Cookit表示不缓存 Vary头部含有*值表示不缓存 proxy_no_cache string...指令： 参数string为真时，不缓存该响应 配置在http，server，location指令块中 string代指变量字符串 proxy_cache_bypass string...指令： 参数string为真时，不使用缓存的内容 配置在http，server，location指令块中 string代指变量字符串 proxy_chache_convert_head on|off指令： 反向代理是否把head方法转换为get方法 配置在http，server，location指令块中 默认值:on proxy_cache_methods GET|HEAD|POST...指令： 对指请求方法使用缓存内容响应给客户端 配置在http，server，location指令块中 默认值:GET HEAD $upstream_cache_status变量值： MISS：未命中缓存 HIT：命中缓存 EXPIRED：缓存过期 STALE：命中过期缓存 IPDATING：缓存过期，正在更新 REVALIDATED：缓存过期，但有效 BYPASS：响应是从原始服务器获取的 合并回源请求减少向上游请求缓存失效时，合并回源请求可以减少峰值流量下的压力 proxy_cache_lock on|off指令： 是否合并回源请求 配置在http，server，location指令块中 默认值:off 合并回源请求表示请求的缓存失效或没有时， 向上游转发请求获取资源响应给客户端并缓存， 在这期间， 其他与该请求相同时， 都会进入等待， 直到该响应内容缓存成功(其他请求使用该缓存响应)或失败 (后续请求转发给上游服务处理) proxy_cache_lock_timeout time指令： 合并回源时，第一个请求超时时间， 超时后，后续请求直接转发给上游服务，但不缓存这些响应 配置在http，server，location指令块中 默认值: 5s proxy_cache_lock_age time指令： 合并回源时，第一个请求超时后， 后续每个请求超时时间 配置在http，server，location指令块中 默认值: 5s 只有当前请求结束(成功、失败、超时)才会放行下一个请求 使用旧的缓存减少向上游请求proxy_cache_use_stale 指令： 使用过期缓存的情景 配置在http，server，location指令块中 默认值:off 该选项取值： off:关闭 error:与上游封连接、发送请求、读取头部等出错时 timeout:与上游服务连接、发送请求、读取头部等超时情况 invalid_header: updating:更新缓存时的情况，上游服务可通过以下方式控制该设置 Cahce-Control:max-age=600, stale-while-revalidate=30: 该头部表示缓存有效期为600s，在之后30秒中更新缓存时， 可以使用旧缓存，否则任然向上游服务请求资源 Cahce-Control:max-age=600, stale-if-error=300: 该头部表示缓存有效期内为600s，之后的300s内上游服务出错时， 可以使用旧缓存，否则仍然向上游服务请求资源 http_500|502|503|504|403|404|429|:缓存这些响应状态码的内容 proxy_cache_background_update on|off指令： proxy_cache_use_stale指令使用过期缓存响应客户端时， 是否同步生成子请求更新缓存 配置在http，server，location指令块中 默认值:off proxy_cache_revalida","date":"2020-12-02","objectID":"/nginx-cache/:2:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" if-None-Match 头部If-None-Match 是一个条件式请求首部，当与 If-Modified-Since 一同使用的时候，If-None-Match 优先级更高。对于 GETGET 和 HEAD 请求方法来说，当且仅当服务器上没有任何资源的 ETag 属性值与这个首部中列出的相匹配的时候，服务器端会才返回所请求的资源，响应码为 200 。对于其他方法来说，只有最终确认没有已存在的资源的 ETag 属性值与这个首部中所列出的相匹配的时候，才会对请求进行相应的处理。 对于 GET 和 HEAD 方法来说，当验证失败的时候，服务器端必须返回响应码 304 （Not Modified，未改变）。服务器端在生成状态码为 304 的响应的时候，必须同时生成以下会存在于对应的 200 响应中的首部： Cache-Control Content-Location Date ETag Expires Vary 对于能够引发服务器状态改变的方法，则返回 412 （Precondition Failed，前置条件失败）。 ","date":"2020-12-02","objectID":"/nginx-cache/:3:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" Last-ModifiedLast-Modified 是一个响应首部， 其中包含源头服务器认定的资源做出修改的日期及时间。 通常被用作一个验证器来判断接收到的或者存储的资源是否彼此一致。 于精确度比 ETag 要低， 所以这是一个备用机制。 包含有 If-Modified-Since 或 If-Unmodified-Since 首部的条件请求会使用这个字段 ","date":"2020-12-02","objectID":"/nginx-cache/:4:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" If-Modified-Since 头部If-Modified-Since 是一个条件式请求首部，If-Modified-Since 只可以用在 GET 或 HEAD 请求中。当与 If-None-Match 一同出现时，它（If-Modified-Since）会被忽略掉，除非服务器不支持 If-None-Match。 服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下,才会将资源返回状态码 200。如果请求的资源从那时起未经修改，那么返回一个不带有消息主体的 304 响应 ","date":"2020-12-02","objectID":"/nginx-cache/:5:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" If-Match 头部请求头部 If-Match 的使用表示这是一个条件请求，在请求方法为 GET 和 HEAD 的情况下服务器仅在请求的资源满足此首部列出的 ETag 值时才会返回资源。而对于 PUT 或其他非安全方法来说，只有在满足条件的情况下才可以将资源上传。 ETag 之间的比较使用的是强比较算法，即只有在每一个字节都相同的情况下，才可以认为两个文件是相同的。可以在 ETag 前面添加 W/ 前缀表示可以采用相对宽松的算法 ","date":"2020-12-02","objectID":"/nginx-cache/:6:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" Etag请求头部 Etag 值为资源的特定版本的标识符。这可以让缓存更高效，并节省带宽，因为如果内容没有改变，Web 服务器不需要发送完整的响应。而如果内容发生了变化，使用 ETag 有助于防止资源的同时更新相互覆盖（“空中碰撞”）。 ","date":"2020-12-02","objectID":"/nginx-cache/:7:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" X-Accel-Expires","date":"2020-12-02","objectID":"/nginx-cache/:8:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" Vay","date":"2020-12-02","objectID":"/nginx-cache/:9:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" Set-Cookie","date":"2020-12-02","objectID":"/nginx-cache/:10:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" If-Unmodified-Since请求头部 If-Unmodified-Since 只有当资源在指定的时间之后没有进行过修改的情况下，服务器才会返回请求的资源，或是接受 POST 或其他 non-safe 方法的请求。如果所请求的资源在指定的时间之后发生了修改，那么会返回 412 (Precondition Failed) 错误。 ","date":"2020-12-02","objectID":"/nginx-cache/:11:0","tags":["缓存","nginx"],"title":"nginx 缓存","uri":"/nginx-cache/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.23.0 配置文件配置文件由指令块与指令组成: server 指令块，由服务相关模块解析 ","date":"2020-11-15","objectID":"/nginx-conf/:0:0","tags":["conf","nginx"],"title":"nginx配置文件","uri":"/nginx-conf/"},{"categories":["nginx"],"content":" 分离配置文件http指令块中可以指定include指令指定其他配置文件（相对路径） [root@centos7 nginx]# cat conf/nginx.conf events { worker_connections 1024; } http { include html.conf; } [root@centos7 nginx]# [root@centos7 nginx]# cat conf/html.conf server { listen 801; location / { root html; index index.html; } } ","date":"2020-11-15","objectID":"/nginx-conf/:1:0","tags":["conf","nginx"],"title":"nginx配置文件","uri":"/nginx-conf/"},{"categories":["nginx"],"content":" 重载配置文件重载配置文件流程： 向master进程发送HUP信号，即nginx -s reload命令 master进程检擦配置文件是否正确 master进程打开新的监听端口 master进程用新配置文件启动新的worker子进程 master进程向旧的worker子进程发送QUIT信号 旧worker子进程优雅退出（关闭监听句柄，处理完连接之后再结束进程） 共享内存共享内存是worker进程之间通讯方式之一， 用于多个进程共享使用同个内存 slab是nginx共享内存管理器， bestfit分配方式： 优点： 适合小对象 避免碎片化 避免重复初始化 缺点：最多会消耗双倍内存 [ngx_slab_stat][]是第三方的模块， 用于统计slab使用状态, 该模块提供一个slab_stat指令用于返回统计数据。 location = /slab_stat { slab_stat; } curl url/slab_stat HTTP请求处理的11个阶段收到http请求之后进入以下11处理个阶段： POST_READ：读取请求头部之后，最原始的请求信息 SERVER_REWRITE： FIND_CONFIG： REWRITE： POST_REWRITE： PREACCESS ACCESS POST_ACCESS PRECONTENT CONTENT LOG nginx会按照这11个阶段依次调用相关http模块处理请求。 模块模块提供了nginx配置文件中的指令与变量： 指令可以出现在多个指令块中，出现多次时： 值为值时，生效范围越小，优先级越高 值为动作类型的指令不能合并记算 指令生效顺序与模块顺序以及处理请求顺序相关， 具体顺序看编译之后objs/ngx_modules.c中char *ngx_module_names[]排序， 在相同执行阶段， 通常, 排序规则是优先级从低到高 [root@centos7 nginx-1.18.0]# cat objs/ngx_modules.c #include \u003cngx_config.h\u003e #include \u003cngx_core.h\u003e ... char *ngx_module_names[] = { \"ngx_core_module\", \"ngx_errlog_module\", \"ngx_conf_module\", \"ngx_openssl_module\", ... \"ngx_stream_ssl_preread_module\", \"ngx_google_perftools_module\", NULL }; ","date":"2020-11-15","objectID":"/nginx-conf/:2:0","tags":["conf","nginx"],"title":"nginx配置文件","uri":"/nginx-conf/"},{"categories":["nginx"],"content":" 以编译的模块在源码编译之后(./con)， 在objs/ngx_modules.c文件中表示已经编译到源码中 [root@centos7 ~]# cat nginx-1.18.0/objs/ngx_modules.c #include \u003cngx_config.h\u003e #include \u003cngx_core.h\u003e ... ngx_module_t *ngx_modules[] = { \u0026ngx_core_module, \u0026ngx_errlog_module, \u0026ngx_conf_module, \u0026ngx_openssl_module, ... \u0026ngx_google_perftools_module, NULL }; ","date":"2020-11-15","objectID":"/nginx-conf/:3:0","tags":["conf","nginx"],"title":"nginx配置文件","uri":"/nginx-conf/"},{"categories":["nginx"],"content":" 动态模块动态模块可以直接放入动态库目录中， 不需要替换nginx二进制文件， 直接替换模块文件 动态模块可以在模块名称后面加=dynamic， 表示以动态模块方式编译 ","date":"2020-11-15","objectID":"/nginx-conf/:4:0","tags":["conf","nginx"],"title":"nginx配置文件","uri":"/nginx-conf/"},{"categories":["nginx"],"content":" 过滤模块http过滤模块是在CONTENT阶段之后LOG阶段之前， 对响应内容做加工处理 这些过滤模块名称带有filter关键字 变量提供变量的模块只提供变量名和获取该变量值的方法， 使用变量时再通过指定的方法获取变量值， 因此变量会在不同地方获取的值可能会不一样 variables_hash_bucket_size指令： 保存变量hash桶的大小 配置在http模块 默认值为64（单位字节，变量名过长时要加大） variables_hash_max_size指令： 保存变量最大哈希值大小 配置在http模块 默认值为1024（单位字节） 提高CPU使用率worker_processes number|auto指令： 设置woker进程数量 配置在main指令快中 number代指数字 auto表示与CPU核心数量相同 worker进程数量应该大于或等于CPU核心数量(无其他业务竞争CPU情况下) worker进程大于CPU核心数量时会争抢CPU资源，也会造成资源消耗 worker_cpu_affinity auto [cpumask]指令： worker进程与CPU核心进行绑定 配置在main指令快中 worker_priority number指令： 设置wirker进程静态优先级 配置在main指令快中 number代指数字 默认值为0 避免woker进程优先级过低 其他： worker进程不该调用API导致让出CPU情况 ","date":"2020-11-15","objectID":"/nginx-conf/:5:0","tags":["conf","nginx"],"title":"nginx配置文件","uri":"/nginx-conf/"},{"categories":["nginx"],"content":" ","date":"2020-11-14","objectID":"/nginx-directives/","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.23 内容来自以下文档： nginx 闲扯Nginx的accept_mutex配置 梦飞: Nginx限流应用 \u0026 漏桶/令牌桶算法原理 模块模块提供了nginx配置文件中的指令与变量： 指令可以出现在多个指令块中，出现多次时： 值为值时，生效范围越小，优先级越高 值为动作类型的指令不能合并记算 指令生效顺序与模块顺序以及处理请求顺序相关， 具体顺序看编译之后objs/ngx_modules.c中char *ngx_module_names[]排序， 在相同执行阶段， 通常, 排序规则是优先级从低到高 [root@centos7 nginx-1.18.0]# cat objs/ngx_modules.c #include \u003cngx_config.h\u003e #include \u003cngx_core.h\u003e ... char *ngx_module_names[] = { \"ngx_core_module\", \"ngx_errlog_module\", \"ngx_conf_module\", \"ngx_openssl_module\", ... \"ngx_stream_ssl_preread_module\", \"ngx_google_perftools_module\", NULL }; ","date":"2020-11-14","objectID":"/nginx-directives/:0:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" 以编译的模块在源码编译之后(./con)， 在objs/ngx_modules.c文件中表示已经编译到源码中 [root@centos7 ~]# cat nginx-1.18.0/objs/ngx_modules.c #include \u003cngx_config.h\u003e #include \u003cngx_core.h\u003e ... ngx_module_t *ngx_modules[] = { \u0026ngx_core_module, \u0026ngx_errlog_module, \u0026ngx_conf_module, \u0026ngx_openssl_module, ... \u0026ngx_google_perftools_module, NULL }; ","date":"2020-11-14","objectID":"/nginx-directives/:1:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" 动态模块动态模块可以直接放入动态库目录中， 不需要替换nginx二进制文件， 直接替换模块文件 动态模块可以在模块名称后面加=dynamic， 表示以动态模块方式编译 ","date":"2020-11-14","objectID":"/nginx-directives/:2:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" 过滤模块http过滤模块是在CONTENT阶段之后LOG阶段之前， 对响应内容做加工处理 这些过滤模块名称带有filter关键字 变量提供变量的模块只提供变量名和获取该变量值的方法， 使用变量时再通过指定的方法获取变量值。 ngx_http_secure_link_module该模块默认没有编译进nginx， 编译时通过--with-http_secure_link_module选项加入 该模块提供以下变量： $secure_link：值有以下： 空字符串：验证失败 0：加密的url过期 1：验证通过 $secure_link_expires：时间戳 服务端生成hash加密的url返回给客户端， 客户端使用该url访问nginx， nginx再通过$secure_link变量判断是否通过 加密url的服务器和验证url的nginx都有hash之前的原始url， 该url有以下部分组成： 资源位置 用户信息 时间戳：hash加密的url有效期 密钥 ","date":"2020-11-14","objectID":"/nginx-directives/:3:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" expires #语法 expires [modified] time; expires epoch | max | off; # 默认值 expires off; # 配置上下文 http, server, location, if in location 出现以下状态码是否要修改或添加响应头部Expires和Cache-Control 200 201(1.3.10版本起) 204 206 301 302 303 304 307(1.1.1版本起) 使用off时：不修改或添加响应头部Expires和Cache-Control 使用epoch时: 修改为：expires: Thu, 01 Jan 1970 00:00:01 GMT 修改为：cache-control: no-cache 使用max时: 修改为：expores: Thu, 31 Dec 2037 23:55:55 GMT 修改为：cache-control: 10y(10年) time值有以下情况： 以@开头指定时间表示每天的某个时间 ，会自动计算出值算出Expires与Cache-Control的值。 如：@15h20m29s表示每天15:20:29客户端缓存过期 时间是正的，如2s,3h,3m. 则响应头部为Cache-control: max-age=t t是自动计算出的值，单位为秒 时间是负的，如-1. 则响应头部为Cache-Control:no-cache 变量。如下示例 map $sent_http_content_type $expires { default off; application/pdf 42d; ~image/ max; } expires $expires; 响应头部Expires设置客户端缓存到期时间 响应头部Cache-control设置客户端缓存持续时间 ","date":"2020-11-14","objectID":"/nginx-directives/:4:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" secure_link 定义时间戳变量和哈希值 配置在http,server,location指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:5:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" secure_link_md5 构成原始字符串变量顺序 配置在http,server,location指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:6:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" secure_link_secret 配置在location指令块中 示例1： ngx_http_referer_module该模块默认编译进nginx， 编译时通过--without-http_referer_module选项移除 该模块提供以下变量： $invalid_referer：满足valid_referer指令时为1，否则为空 referer头部：当前请求来源 通过判断http请求头部中的referer值， 具体某些网站访问 ","date":"2020-11-14","objectID":"/nginx-directives/:7:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" valid_referer 配置在server,location指令块中 取值至少一个： none：允许缺省referer请求头部 block：允许referer请求头部的值为空 server_names：referer请求头部与server_name中某个主机名匹配时允许访问 自定义主机名和可选的URI(前后缀可用*号)：referer请求头部匹配该字符串时， 允许访问 正则表达式：referer请求头部满足该表达式则允许访问 示例： server_name www.web.com location / { valid_referer none block server_names *.baidu.com ~\\.bilibili\\.; if ($invalid_referer) { return 403; } } ","date":"2020-11-14","objectID":"/nginx-directives/:8:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" referer_hash_bucket_size 存放valid_referer指令值的hash桶大小 配置在server,location指令块中 默认值：64 ","date":"2020-11-14","objectID":"/nginx-directives/:9:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" referer_hash_max_size valid_referer指令值的最大hash值 配置在server,location指令块中 默认值：2048 ngx_core_module","date":"2020-11-14","objectID":"/nginx-directives/:10:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" include #语法 include file | mask; # 默认值 — # 配置上下文 any 加载其它nginx配置文件 ","date":"2020-11-14","objectID":"/nginx-directives/:11:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" use # 语法 use method; # 默认值：无 # 配置上下文 events 配置使用的处理连接方式， 默认情况下nginx将使用最有效的方法， 不需要指定方式 有以下方式 select: poll: kqueue: epoll: select: eventport: ","date":"2020-11-14","objectID":"/nginx-directives/:12:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" worker_rlimit_nofile # 语法 worker_rlimit_nofile number; # 配置上下文 main 单个工作进程打开文件描述符最大数量(文件句柄) ","date":"2020-11-14","objectID":"/nginx-directives/:13:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" worker_connections # 语法 worker_connections number; # 默认值 worker_connections 512; # 配置上下文 events 工作进程可以同时打开的最大连接数(所有连接) ","date":"2020-11-14","objectID":"/nginx-directives/:14:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" multi_accept # 语法 multi_accept on | off; # 默认值 multi_accept off; # 配置上下文 events 如果为off工作进程将一次接受一个新连接； 如果为on工作进程将一次接受所有新连接 如果使用kqueue连接处理方法(use指令)， 则忽略该指令 ， 因为它报告等待接受的新连接数 ","date":"2020-11-14","objectID":"/nginx-directives/:15:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" worker_processes # 语法 worker_processes number | auto; # 默认值 worker_processes 1; # 配置上下文 main 工作进程数量 值为auto: 表示由nginx自动设置工作进程数量 ","date":"2020-11-14","objectID":"/nginx-directives/:16:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" user # 语法 user user [group]; # 默认值 user nobody nobody; # 配置上下文 main 工作进程用户与组。当组缺省时与用户同名 ","date":"2020-11-14","objectID":"/nginx-directives/:17:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" PID # 语法 pid file; # 默认值 pid logs/nginx.pid; # 配置上下文 main 进程 PID 文件位置 ","date":"2020-11-14","objectID":"/nginx-directives/:18:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" error_log error_log file [level]; 默认值：logs/error.log error; 配置域：main, http, mail, stream, server, location 该指令指定错误日志与记录级别，可以在同一配置级别上指定多个 errir_log。记录级别由高到低为：debug, info, notice, warn, error, crit, alert, emerg。级别越高优先级越大，记录也越详细。debug 级别需要 nginx 编译时指定 --with-debug 选项 ","date":"2020-11-14","objectID":"/nginx-directives/:19:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" accept_mutex # 语法 accept_mutex on | off; # 默认值： # 在1.11.3 版本之前为 on accept_mutex off; 配置在events指令块中 工作进程获取新请求(socket队列)方式 on: 工作进程将依次接受新连接(主进程派发)，如果在超时(accept_mutex_delay指令指定) 由下一个进程接受请求，以此类推。由于是串行方式，在高并发的情况下效率低。 off: 主进程将通知所有工作进程有关新连接的信息，让所有工作进程争抢请求。 虽然会出现惊群问题，但工作进程数量不多(通常与CPU核心数量相同)，不会造成太大影响。 在高并发的情况下是可接受的。 此外Linux的epoll-and-accept负载均衡算法采取了类似LIFO的行为 (刚刚返回事件循环的进程优先接收新连接)， 这种行为会导致有的进程干活多，有的干活少。 进程与CPU核心是绑定的，因此出现有的CPU核心使用率(cpu time)很高，有的很低 惊群问题：是指系统中有多个进程在等待同一个资源，当资源可用的时候，系统会唤醒所有或部分处于休眠状态的进程去争抢资源， 但是最终只会有一个进程能够成功的响应请求并获得资源，其余进程再次进入休眠状态。 在这个过程中由于系统要对全部的进程唤醒，导致了需要对这些进程进行不必要的切换，从而会产生系统资源的浪费。 ","date":"2020-11-14","objectID":"/nginx-directives/:20:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" accept_mutex_delay # 语法 accept_mutex_delay time; # 默认 accept_mutex off; 配置在events指令块中 accept_mutex on时工作进程接收请求超时时间 ngx_events_module连接池数量表示连接的总量， 对上游服务器的连接， 对下游客户端的连接， 因此， 如果是代理情况下， 连接数量会讲一半。 每个连接都有这对应的编号， 该编号用于读事件和写事件。 每个连接在64bit中是232个字节， 不同版本可以有些差距。 每个连接有着对应这读写事件， 读写事件都是96字节， 因此， 一个连接占内存大小为：232+96*2（424）个字节 每个连接的初始内存大小可以通过connection_pool_size指令修改 如果连接超出内存池大小时， 在分配一个相同大小的内存池， 以此类推， 直到满足。 与内存块逻辑一样 请求内存与连接内存类似， 请求内存初始大小通过request_pool_size指令修改 ngx_http_core_module该模块为nginx-http核心模块，无法移除。该模块提供以下变量： $gar_name：请求行中的参数name $query_string：请求行中的所有参数 $args：请求行中的所有参数，即 ? 后面的信息 $is_args：如果请求URL中有参数则返回?， 否则返回空 $content_length：(HTTP请求中标识主体长度)Content-Length头部的值 $content_type：(HTTP请求中标识请求主体类型)Content-Type头部的值 $uri: 响应的URI（不含参数的URL） $document_uri：与$uri相同 $request_uri：请求的URL $scheme：请求协议，值为 https 或 http $request_method：请求方法 $request_length：请求内容大小，包含请求行，头部，主体等 $remote_user：由HTTP Basic Authentication协议传输的用户名 $request_body_file：存放请求主体的临时文件 如果请求主体太小则不会保存 clent_body_in_file_only指令会强制保存所有请求主体 $request_body：请求中的主体， 仅使用反向代理且设定用内存暂存主体时有效 $request：原始的URL请求（含协议版本与方法） $host：请求的主机器名，取值优先级从上往下： 从host头部取值 从请求行中获取 从匹配的server_name指令获取 $hostname: 主机名称 $http_HeadName：HeadName是http请求头部名称， 通常可以取到对应的头部值， 但有以下几个特殊变量： $http_host $http_user_agent $http_referer $http_via $http_x_forwarded_for $http_cookie $connection：递增的TCP连接序号 $connection_requests：当前TCP连接上执行过的请求数 $connection_time：当前TCP连接时间（秒） $proxy_protocol_addr：proxy_protocol协议返回协议中的地址， 空表示没有使用该协议 $proxy_protocol_port：proxy_protocol协议返回协议中的端口， 空表示没有使用该协议 $proxy_protocol_server_port: 来自 PROXY 协议标头的服务器端口，必须在 listen 指令中指定 proxy_protocol 参数来启用代理协议 $proxy_protocol_server_addr: 来自 PROXY 协议标头的服务器地址，必须在 listen 指令中指定 proxy_protocol 参数来启用代理协议 $binary_remote_addr：二进制形式的客户端地址，对于 IPv4 地址，值的长度始终为 4 字节，对于 IPv6 地址，值的长度始终为 16 字节 $remote_addr：客户端地址 $remote_port：客户端端口 $server_addr：服务端地址 $server_port：服务端端口 $server_name：匹配的server_name指令的值 $server_protocol：服务端协议 $tcpinfo_rtt： $tcpinfo_rttvar： $tcpinfo_snd_cwnd： $tcpinfo_rcv_space： $request_time：处理请求已经消耗的时间(秒) $https：如果开启TLS/SSL返回on，否则返回空 $request_completion：处理完请求值为ok，否则为空 $trequest_id：随机生成16字节的id(16进制) $request_filename：待访问文件的完整路径 $document_root：由RUI和root,alias指令生成的文件夹路径 $realpath_root：把$document_root中的软链接换成真实路径 $limit_rate：客户端响应时的速度上限（字节/秒）， 可以通过set指令修改对请求产生效果 $body_bytes_sent：响应请求的主体部分长度 $bytes_sent：全部http响应的长度 $status：响应状态码 $sent_trailter：响应结尾内容的值 $sent_http_HeadName：HeadName为响应头部名称， 通常去对应响应头部的值， 但以下几个列外： $sent_http_content_type： $sent_http_content_length $sent_http_location $sent_http_last_modified $sent_http_connection $sent_http_keep_alive $sent_http_transfer_encoding $sent_http_link $time_local：本地标准时间 $time_iso8601：ISO 8601标准时间 $nginx_version：nginx版本号 $pid：所属工作进程id $pipe：如果使用管道则值为p，否则为. $hosname：所在服务器的主机名，与hostname命令输出相同 $msec：从1907-1-1到现在的时间(秒) ","date":"2020-11-14","objectID":"/nginx-directives/:21:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" keepalive_timeout # 语法 keepalive_timeout timeout [header_timeout]; # 默认值 keepalive_timeout 75s; # 指令上下文 http, server, location 长连接超时时间，在此期间保持客户端连接处于活动状况 当值为0时禁用长连接 header_timeout是为Keep-Alive: timeout=time头部设置一个值， 不同的客户端处理该头部方式不一样 ","date":"2020-11-14","objectID":"/nginx-directives/:22:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" listen # 语法1 listen address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; # 语法2 listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; # 语法3 listen unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; # 默认值 # 默认值 listen *:80 | *:8000; # 配置上下文 server 指令用于监听服务端口 address代指ip地址 port代指网络端口 deferred参数，可以延迟处理新链接 default_server参数可以设置默认服务(如果没有显式声明default server, 则 第一个server会被隐式的设为default server。没有匹配到server_name时生效 reuseport: 为每个工作进程创建一个单独的侦听套接字，由内核分配连接请求。 此选项虽然让更多的cpu核心利用起来，由于接受队列不是共享的，如果该进程发生阻塞， 后续的请求无法转移给其它进程，只会等待。直到超时返回客户端错误。因此在高并发情况下 不推荐使用 示例： # 监听特定地址+端口样式 listen 127.0.0.1:8000; # 监听特定地址 listen 127.0.0.1; # 监听特定端口 listen 8000; # 同上 listen *:8000; # 添加特定主机名+端口 listen localhost:8000; # sock 文件，只能用于linux本地通讯 listen unix:/var/run/nginx.sock; # 访问172.11.11.2:801没有server_name生效时使用该server listen 172.11.11.2:801 default_server; ","date":"2020-11-14","objectID":"/nginx-directives/:23:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" server_name #语法 server_name name ...; # 默认值 server_name \"\"; # 配置上下文 server 支持正则表达式，需要用~作为前缀 支持泛域名符号*，只能用于开头或结尾 可以绑定多少主机名，使用空格分开 示例： # 绑定多个域名 server_name example.com www.example.com; # *表示泛域名（任意非空字符串） server_name example.com *.example.com www.example.*; # 以.开头表示域名本身与*.开头 # 下面示例等效：server_name example.com *.example.com server_name .example.com; # 正则表达式 server_name ~^www\\d+\\.example\\.com$; # 正则表达式变量位置取值 erver_name ~^(www\\.)?(.+)$; location / { # $2 为第二个跨号内容.+所匹配的字符串 root /sites/$2; } # 正则表达式自定义变量名称 # ?\u003c自定义变量名\u003e server_name ~^(www\\.)?(?\u003cdomain\u003e.+)$; location / { root /sites/$domain; } # 匹配主机名为_ server_name _; 匹配顺序优先级从高到底： 精确匹配 以*开头 以*结尾 出现在文件中的顺序 默认值，listen指令指定的server块或第一个server块 ","date":"2020-11-14","objectID":"/nginx-directives/:24:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" server_name_in_redirect-用于server指令绑定多个主机名时， 使用第一个域名作为地址： 取值为off(默认)或on 可以在http,server,location指令块中配置 ","date":"2020-11-14","objectID":"/nginx-directives/:25:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" erroe_page #语法 error_page code ... [=[response]] uri; # 默认值 — # 配置上下文 http, server, location, if in location 更据状态码返回url以状态码 状态码444：表示关闭连接，nginx自带的状态码 状态码301表示永久重定向 状态码302表示临时重定向，禁止被缓存 http1.1标准中，303表示临时重定向，允许改变方法，禁止被缓存 http1.1标准中，307表示临时重定向，不允许改变方法，禁止被缓存 http1.1标准中，308表示永久重定向，不允许改变方法 示例 [root@centos7 conf]# cat ngx_http_rewrite.conf server { listen 803; root html/; # 当状态码为 403 时，返回403.html页面 error_page 403 /403.html; # 当状态码为这些时，返回50x.htmml页面 error_page 500 503 504 /50x.htnl; # 当状态码为404 时，返回 200 状态码和 403.html error_page 404 =200 /403.html; } ","date":"2020-11-14","objectID":"/nginx-directives/:26:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" location # 语法 location [ = | ~ | ~* | ^~ ] uri { ... } location @name { ... } # 默认值 — # 配置上下文 server, location 处于处理HTTP请求的第3个（FIND_CONFIG）阶段 根据url地址配置 url匹配规： 常规字符串作为前缀 =作为前缀表示精确匹配 ^~作为前缀表示匹配之后禁止其他正则表达式匹配 ~作为前缀表示区分大小写的正则表达式 ~*作为前缀表示不分大小写的正则表达式 @作为前缀表示跳转到内部到其他location 匹配优先级过程： 遍历所有前缀字符串 匹配=作为前缀 匹配^~作为前缀 按照配置文件中出现顺序依次使用正则表达式匹配 匹配最长的常规字符串 示例 root@centos7 conf]# cat ngx_http_core.conf server { listen 804; root html/; location ~ /test/$ { return 200 \"locathon 1\\n\"; } location /test { return 200 \"locathon 2\\n\"; } # 精确匹配 localhost:804/test location = /test { return 200 \"locathon 3\\n\"; } # ^~匹配 localhost:804/test/ location ^~ /test/ { return 200 \"locathon 4\\n\"; } # 最长字符串匹配 localhost:804/test/h1/ location /test/h1 { return 200 \"locathon 5\\n\"; } # 正则表达式匹配 localhost:804/test/h1 location ~* /test/(\\w+)$ { return 200 \"locathon 6\\n\"; } } ","date":"2020-11-14","objectID":"/nginx-directives/:27:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" merge_slashes 用于合并location指令中url地址斜杠 处于处理HTTP请求的第3个（FIND_CONFIG）阶段 值为on（默认）或off 配置在http,server指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:28:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" satisfy 判断access阶段模块是否放行 处于处理HTTP请求的第7个（ACCESS）阶段 配置在http,server,location指令块中 值为all（默认）或any： all：依次判断所有模块，全部通过才放行 nay：依次判断所有模块，任何一个通过就放行 ","date":"2020-11-14","objectID":"/nginx-directives/:29:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" root # 语法 root path; # 默认值 root html; # 配置上下文 http, server, location, if in location 把url映射为完整的文件路径， 以返回静态文件内容 示例： server { root www; location /web1/html { # 访问文件为：test_root/web1/html # 该 root 指令优先与 server 指令块的root指令 root test_root; } ","date":"2020-11-14","objectID":"/nginx-directives/:30:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" alias 把url映射为文件路径， 以返回静态文件内容 配置在location指令块中 示例： server { root www; location /web2/html { # 访问文件为：test_root # 该 alias 指令优先与 server 指令块的root指令 alias test_root; } ","date":"2020-11-14","objectID":"/nginx-directives/:31:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" merge_slashes 启用或禁用将URI中的两个或多个相邻斜杠压缩为单个斜杠 配置在http,server指令块中 取值： on: 启用 off: 禁止 默认值：on 示例 merge_slashes on; # 能匹配：//scripts/one.php location /scripts/ { ... } ngx_http_realip_module模块编译时需要使用--with-http_realip_module启用， 键入变量： $realip_remote_addr: 原始客户端地址 $realip_remote_port：原始客户端端口 [set_real_ip_from][set_real_ip_from]指令： 用于修改上一个客户端地址 值为地址，可以是主机名、IP、IP段、UNIX套接字 出现在http,server,location指令块中 可以使用多次 默认值：不修改 修改会改变X-Forwarded-For头部值 [real_ip_header][real_ip_header]指令： 从指定头部中获取想要的IP 值多选一：X-Real-IP；X-Forwarded-For；proxy_protocol 默认值： X-Real-IP 如果值为X-Forwarded-For，则取最后一个地址 出现在http，server，location指令块中 [real_ip_recursive][real_ip_recursive]指令： 是否启用递归排除 值为：on或off 默认值：off 如果为on， 从右往左排除set_real_ip_form的值， 如果某个值不在set_real_ip_form时， 认为是客户端地址。 ngx_http_rewrite_module","date":"2020-11-14","objectID":"/nginx-directives/:32:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" return #语法 return code [text]; return code URL; return URL; # 默认值 — # 配置上下文 server, location, if 返回状态码、字符串、url 状态码444：表示关闭连接，nginx自带的状态码 状态码301表示永久重定向 状态码302表示临时重定向，禁止被缓存 http1.1标准中，303表示临时重定向，允许改变方法，禁止被缓存 http1.1标准中，307表示临时重定向，不允许改变方法，禁止被缓存 http1.1标准中，308表示永久重定向，不允许改变方法 示例：SERVER_REWRITE阶段比EWRITE阶段优先执行， 因此返回no file1 [root@centos7 conf]# cat ngx_http_rewrite.conf server { listen 803; root html/; # 在SERVER_REWRITE阶段执行 return 404 \"no file1\\n\" ; location /{ # 在REWRITE阶段执行 return 404 \"no file\\n\"; } } ","date":"2020-11-14","objectID":"/nginx-directives/:33:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" rewrite # 语法 rewrite regex replacement [flag]; # 默认值 — # 配置上下文 server, location, if 用于替换url 支持正则表达式和变量 当新的url以http,https,$schema开头，则返回302重定向 新的url更据以下选项处理： --last: 用新的url进行location匹配 --break: 停止当前脚本指令的执行，即终止rewrite redirect: 返回302重定向 permanent: 返回301重定向 示例： server { listen 803; root html/; location /rewrite1 { # 用新的URL继续匹配 rewrite /rewrite1(.*) /rewrite2$1 last; return 200 'r1\\n'; } location /rewrite2 { # 访问 127.0.0.1:803/rewrite1/r3.html # 结果为 rewrite2/r3.html， # 后续的return指令也被停止， # 也不会继续匹配 # 如果不带 break 会匹配得到 r2 # 虽然URL被修改，但没有继续匹配 rewrite /rewrite2(.*) /rewrite3$1 break; return 200 'r2\\n'; } location /rewrite3 { return 200 'r3\\n'; } } ","date":"2020-11-14","objectID":"/nginx-directives/:34:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" rewrite_log 关闭或开启rewrite指令重写记录 默认值：off 可在http,server,location,if指令块中配置 ","date":"2020-11-14","objectID":"/nginx-directives/:35:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" if 用于逻辑判断 处于SERVER_REWRITE和REWRITE阶段 配置在server.location指令块中 条件为真时，执行后面的指令 变量值为空或0时为假 变量与字符串比较时使用=或!= 变量与正则表达式比较时： 区分大小写使用：~或!~ 不分大小写使用：~*或!~* 检查文件是否存在使用-f或!-f 检查目录是否存在使用-d或!-d 检查是否为可执行文件使用-x或-!x 检查文件，目录，软连接是否存在使用-e或!-e ngx_http_limit_req_module该模块默认编译进nginx，可用--without-http_limit_req_module禁用。 使用leaky bucket算法把流量拦截在连接池中， 再从连接池中按照速率处理流量； 如果限制速率小于流量速率则响应变慢（延迟处理）， 如果连接池满了则返回客户端错误状态码 ","date":"2020-11-14","objectID":"/nginx-directives/:36:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_req_zone limit_req_zone key zone=name:size rate=rate [sync]; 配置域：http 处于处理HTTP请求的第6个（PREACCESS）阶段 定义limit_req指令共享内存大小以及key关键字和速率（单位为r/s或r/m） key: 判断速率的关键字，比如客户端 ip zone: 共享内存大小（多个 worker 进程共享），该内存中保存了 $limit_req_status 变量值 与 key 定义的值。当存储空间耗尽的时候，如果需要记录新的值，那么就会通过LRU算法移除旧的变量来腾出空间，如果这样腾出来的空间还是不足以接纳新的记录值，那么nginx就会返回状态码503 (Service Temporarily Unavailable)。此外，为了防止内存耗尽，nginx每次创建一个新记录值的时候就会清理掉两个60秒内没被使用过的旧记录值。 rate: nginx 处理速率 sync: 商业版本可用的选项 # 根据客户端 IP 地址限制延迟处理速率，每秒最多处理 10 个请求 # $binary_remote_add 比 $remote_addr 更节约内存空间 limit_req_zone $binary_remote_addr zone=limit_req:30m rate=10r/s; ","date":"2020-11-14","objectID":"/nginx-directives/:37:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_req limit_req zone=name [burst=number] [nodelay | delay=number]; 配置域：http，server，location 处于处理HTTP请求的第6个（PREACCESS）阶段 该指令定义连接池的数量，即超过 limit_req_zone 限制的请求会放入该请求池中，延迟处理。有以下参数 burst: 连接池数量，默认为0 nodelay: 表示不延迟处理过多请求，即超过 burst 值就反回错误，而不是等到超过 limit_req_zone 定义的内存空间容量才反回错误 delay: 延迟处理阀值，即不做速率限制请求的并发数量 示例 # 定义内存空间 limit_req_ip , 有 30m 大小 # 限制速率为每秒处理10个请求 limit_req_zone $binary_remote_addr zone=limit_req_ip:30m rate=10r/s; server { listen 80; location / { # 连接池20个大小，其中前12个不做限制直接处理， # 剩下的按速率处理，即能处理 20+12 数量请求，其它反回错误 # 假设某IP突然并发有 40 个，其中前12个正常处理，13~22 按速率处理 # 其余返回错误 limit_req zone=limit_re_ip burst=20 delay=12; ... } } ","date":"2020-11-14","objectID":"/nginx-directives/:38:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_req_dry_run limit_req_dry_run on | off; 默认值：off 配置域：http，server，location 处于处理HTTP请求的第6个（PREACCESS）阶段 是否启用试用模式，模式下不做速率限制，其它一样，占用内存，计算速率，记录相关日志 ","date":"2020-11-14","objectID":"/nginx-directives/:39:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_req_log_level limit_req_log_level info | notice | warn | error; 默认值：error 配置域：http，server，location 处于处理HTTP请求的第6个（PREACCESS）阶段 定义限制速率日志记录级别，info 最详细，error 信息最少 ","date":"2020-11-14","objectID":"/nginx-directives/:40:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_red_status limit_req_status code; 默认值：503 配置域：http，server，location 处于处理HTTP请求的第6个（PREACCESS）阶段 定义超过连接池大小或超共享内存大小时返回的错误状态码 ngx_http_limit_conn_module该模块默认编译进nginx， 可用--without-http_limit_conn_module禁用。 依赖POST_READ阶段的realip模块获取IP ","date":"2020-11-14","objectID":"/nginx-directives/:41:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_conn_zone # 语法 limit_conn_zone key zone=name:size; # 默认值：元 # 配置上下文 http 处于处理HTTP请求的第6个（PREACCESS）阶段 定义内存空间与限制key关键字 可以使用多少该指令 ","date":"2020-11-14","objectID":"/nginx-directives/:42:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_conn 基于limit_conn_zone指令限制key的并发数量 处于处理HTTP请求的第6个（PREACCESS）阶段 配置在http,server,location指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:43:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_conn_log_level 记录限制并发日志级别 处于处理HTTP请求的第6个（PREACCESS）阶段 值多选一：info,notice,warn,error(默认) 配置在http,server,location指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:44:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" limit_conn_status 定义限制并发时返回客户端的错误状态码 默认值为503 配置在http,server,location指令块中 示例： http { limit_conn_zone $binary_remote_addr zone=addr :10m; server { listen localhost:805; root html/; error_log logs/805.log info; location / { # 触发并发之后返回客户端的错误状态码 limit_conn_status 500; # 并发日志级别 limit_conn_log_level info; # 限制返回客户端并发数量 limit_conn addr 10; # 返回速度字节/s limit_rate 50; } } } ngx_http_access_module该模块默认编译进nginx， 可用--without-http_access_module禁用。 ","date":"2020-11-14","objectID":"/nginx-directives/:45:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" allow 用于开放某些地址访问 处于处理HTTP请求的第7个（ACCESS）阶段 配置在http,server,location,limit_execpt指令块中 该指令可以用多个，值可以为all表示允许所有地址访问 满足之后不再继续往下匹配 ","date":"2020-11-14","objectID":"/nginx-directives/:46:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" deny 用于拒绝某些地址访问 处于处理HTTP请求的第7个（ACCESS）阶段 配置在http,server,location,limit_execpt指令块中 该指令可以用多个，值可以为all表示拒绝所有地址访问 满足之后不在继续往下匹配 location / { # 拒绝这个IP访问 deny 192.168.186.12; # 允许这个IP段访问 allow 192.168.186.0/24; # 拒绝所有IP访问 deny all; } ","date":"2020-11-14","objectID":"/nginx-directives/:47:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" server_tokens # 语法 server_tokens on | off | build | string; # 默认值 server_tokens on; # 配置上下文 http, server, location 是否在错误页面或响应报文server显示nginx版本 on: 显示 off: 关闭，只显示nginx,不显示版本号 build: 显示构建名称及其版本 string: 自定义字符串 ngx_http_auth_basic_module该模块默认编译进nginx, 可用--without-http_auth_basic_module禁用。 该模块使用FRC2617定义的HTTP Basic Authentication协议， 当客户端访问服务时， 返回401状态码（客户端不会显示）， 以及WWW-Authentication头部。 客户端会弹出客户端等待用户输入密码， 客户输入之后以明文方式发送给客户端， 验证成功则允许访问， 验证失败则拒绝访问。 ","date":"2020-11-14","objectID":"/nginx-directives/:48:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" auth_basic 基于密码的访问权限验证 处于处理HTTP请求的第7个（ACCESS）阶段 配置在http,server,location,limit_execpt指令块中 值为自定义字符串（用于提示用户输入）或off(表示关闭，默认) 验证成功才能访问 示例： location / { # 添加输入密码提示框 auth_basic \"请输入用户名和密码\" # 用于验证用户密码的文件 auth_basic_user_file conf/user.passwd } ","date":"2020-11-14","objectID":"/nginx-directives/:49:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" auth_basic_user_file 存储验证auth_basic指令的密码文件 处于处理HTTP请求的第7个（ACCESS）阶段 配置在http,server,location,limit_execpt指令块中 文件每行以用户名:MD4加密之后的密码形式表示 可以使用httpd-tools包提供的htpasswd命令： 格式：htpaaswd 选项 文件名 [用户名 密码] -c选项情况文件内存， 如果文件不存在，则创建该文件 -b选项以命令行方式创建用户以及密码， 或更据用户名修改密码 -D选项删除指定用户名 示例： [root@centos7 ~]# yum install -y httpd-tools Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.cn99.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com base | 3.6 kB 00:00:00 ... [root@centos7 ~]# htpasswd -bc user.pass user01 Asd2020 Adding password for user user01 [root@centos7 ~]# [root@centos7 ~]# cat user.pass user01:$apr1$S.wv/3Po$Fd.sQRLhtGmDsqmKXSaek ngx_http_auth_request_module该模块默认没有编译进nginx， 可用--with-http_auth_requset_module启用 收到客户的请求后， 生成子请求通过反向代理技术发送给上游服务器， 如果上游服务器返回响应码为2XX则通过认证， 如果上游服务器返回响应码为401或403， 则将状态码响应给客户端。 ","date":"2020-11-14","objectID":"/nginx-directives/:50:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" auth_requset 开启或关闭统一验证用户访问权限 处于处理HTTP请求的第7个（ACCESS）阶段 配置在http,server,location指令块中 值为uri地址或off(默认) 示例： location / { # 开启验证 auth_requset /request; } # 配置反向代理 location = /request { # 反向代理 proxy_pass http://192.168.186.12:808/user_request; # 不发送代理主体部分（没必要） # 向代理发送头部信息用于验证 proxy_set_header Content-Length \"\"; proxy_set_header X-original-URI $request_uri; } # 验证服务部分 server { listen 192.168.186.12:808; location /user_request { # 不验证，直接拒绝（返回401或403） return 401 \"no no no\" } } ","date":"2020-11-14","objectID":"/nginx-directives/:51:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" auth_reuset_set 用于auth_reuset创建变量 处于处理HTTP请求的第7个（ACCESS）阶段 配置在http,server,location指令块中 ngx_http_try_files_module该模块是nginx框架中的，因此无法取消 ","date":"2020-11-14","objectID":"/nginx-directives/:52:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" fry_files 对url提供多个备用url， 主url不能访问时依次访问这些url， 直到某个url访问成功， 如果所有url访问失败， 则返回访问最后一个url的结果或指定的状态码 处于处理HTTP请求的第9个（PRECONTENT）阶段 配置在server.location指令块中 示例： server { root html; location /test { # 访问顺序：1 try_files /www/rooo/html # 2 $uri # 3 $uri/index.html # 4 @test1; } location /test1 { # 5 fry_files /www/root/html # 6，返回 404 错误状态码 = 404 } } ngx_http_mirror_module该模块默认编译进nginx， 可用--without-http_mirror_module禁用。 ","date":"2020-11-14","objectID":"/nginx-directives/:53:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" mirror 收到请求时， 复制该请求通过反向代理发给其他服务， 但对其他服务所返回的结果不做处理， 响应客户端的还是当前服务。 处于处理HTTP请求的第9个（PRECONTENT）阶段 配置在http,server,location指令块中 值为url(代理地址)或off(默认) 示例： location /mirror { # 复制流量到 /test mirror /test； # 不不复制 body 部分 mirror_request_body off; # 正常处理请求 } location /test { internal; # 接收复制流量的代理服务器 proxy_pass http://192.168.186.12:808/user_request; proxy_set_request_body off; proxy_set_header Content-Length \"\"; proxy_set_header X-original-URI $request_uri; } ","date":"2020-11-14","objectID":"/nginx-directives/:54:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" mirror_request_body mirror指令是否复制请求主体部分 处于处理HTTP请求的第9个（PRECONTENT）阶段 配置在http,server,location指令块中 值为on(默认)或off ngx_http_concat_module该模块为tengine提供的， 点击： [ngx_http_concat_module][ngx_http_concat_module] 查看更多信息 由于是第三方模块， 因此编译时需要--add-module选项添加 ","date":"2020-11-14","objectID":"/nginx-directives/:55:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" concat 是否将多个小文件合并到一个响应报文中(可以减少响应报文数量) 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为：on或off(默认) 需要在请求url地址后面使用??分隔url和合并的文件 带有参数的url需要把参数移到最后面 location /concat { # 开启合并 concat on; # 重写url # ??之后是用,分隔的concat合并文件 alias /concat??1.txt,2.txt; } ","date":"2020-11-14","objectID":"/nginx-directives/:56:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" concat_delimiter concat指令开启时， 用于指定多个文件之间的分隔符 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:57:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" concat_types concat指令开启时， 指定能合并的文件类型 配置在http,server,location指令块中 默认值：text/css application/x-javascript ","date":"2020-11-14","objectID":"/nginx-directives/:58:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" concat_unique concat指令开启时， 是否对多种文件类型进行合并 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on(默认，只能对相同文件类型进行合并)或off ","date":"2020-11-14","objectID":"/nginx-directives/:59:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" concat_ignore_file_error concat指令开启时， 出现合并文件出错是否忽略 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为：on或off(默认) ","date":"2020-11-14","objectID":"/nginx-directives/:60:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" concat_max_files concat指令开启时， 最多合并多少个文件 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 默认值为10 ngx_http_random_index_modul ngx_http_index_module","date":"2020-11-14","objectID":"/nginx-directives/:61:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" index # 语法 index file ...; # 默认值 index index.html; # 配置上下文 http, server, location 处于处理HTTP请求的第10个（CONTENT）阶段 访问目录时默认返回的文件 文件路径可以使用变量 在location中可能会导致内部重定向，如果有其它相同路径的location, 则继续处理相同路径的下一个location.但index不再生效且不会继续匹配location. 如下示例，处理完第一个location后继续处理第二个location server { listen 192.168.204.129:80; root /mnt/hgfs/note/vmware/nginx/web/; location = / { server_tokens on; index index.html; } location / { # 响应报文 server 不显示nginx版本号 server_tokens off; # 会忽略该 index 指令 index systemctl.html; } } # 访问结果为 index.html 文件 [root@localhost conf]# curl http://127.0.0.1:80/ \u003c!DOCTYPE html\u003e \u003chtml\u003e ... # 响应报文 Server 值没有显示 nginx 版本号 [root@localhost conf]# curl http://127.0.0.1:80/ -I HTTP/1.1 200 OK Server: nginx ... ngx_http_autoindex_module该模块默认编译进nginx， 可用--without-http_autoindex_module禁用。 ","date":"2020-11-14","objectID":"/nginx-directives/:62:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" authoindex 访问的url以/结尾（目录）时， 指定返回的内容格式 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on或off(默认) 由于index指令优先于该指令， 因此需要使用index指定一个不存在的文件 ","date":"2020-11-14","objectID":"/nginx-directives/:63:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" autoindex_exact_size authoindex指令开启时是否显示文件文件大小单位 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on(默认)或off（以字节显示） ","date":"2020-11-14","objectID":"/nginx-directives/:64:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" autoindex_format authoindex指令开启时返回客户端的文本样式 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值多选一：html(默认),xml,json,jsonp ","date":"2020-11-14","objectID":"/nginx-directives/:65:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" autoindex_localtime authoindex指令开启时是否使用本地时间 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on或off(默认) ngx_http_static_module该模块 用来读取磁盘上的文件并把读取的数据当做内容输出. 是nginx框架中的， 因此无法取消。 该模块提供以下变量： request_fialname：待访问文件的完整路径 document_root：由url和root,alias指令生成的文件路径 realpath_root：将document_root比那里中的软连接缓存真实路径 ","date":"2020-11-14","objectID":"/nginx-directives/:66:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" types 更据文件扩展名返回content-type头部 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 默认值：`{text/html html; image/git git; image/jpeg jpg;} ","date":"2020-11-14","objectID":"/nginx-directives/:67:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" default_type # 语法 default_type mime-type; # 默认值 default_type text/plain; # 配置上下文 http, server, location 定义响应的默认 MIME 类型。 可以使用types指令设置文件扩展名到MIME类型的映射 处于处理HTTP请求的第10个（CONTENT）阶段 ","date":"2020-11-14","objectID":"/nginx-directives/:68:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" server_names_hash_bucket_size # 语法 server_names_hash_bucket_size size; # 默认值 server_names_hash_bucket_size 32|64|128; # 配置上下文 http 设置服务器名称哈希表的存储桶大小。 默认值取决于处理器缓存线的大小 ","date":"2020-11-14","objectID":"/nginx-directives/:69:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" client_header_buffer_size # 语法 client_header_buffer_size size; # 默认值 client_header_buffer_size 1k； # 配置上下文 http,server 设置读取客户端请求头部的缓冲区大小， 如果请求头部大于该分配的缓冲区， 则使用large_client_header_buffers指令重新分配缓冲区。 ","date":"2020-11-14","objectID":"/nginx-directives/:70:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" large_client_header_buffers # 语法 large_client_header_buffers number size; # 默认值 large_client_header_buffers 4 8k； # 配置上下文 http,server 设置读取客户端请求头部的缓冲区大小， 当请求头部大小超过client_header_buffer_size大小时 使用该指令分配 number表示缓存个数 size表示单个缓存区最大值 如果请求行超过size则返回状态码414错误 如果请求头超过size则返回状态码400错误 在请求处理结束后连接转换为保持活动状态，则释放这些缓冲区 ","date":"2020-11-14","objectID":"/nginx-directives/:71:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" client_max_body_size # 语法 client_max_body_size size; # 默认值 client_max_body_size 1m； # 配置上下文 http, server,location 设置客户端请求主体的最大值， 如果超过该值，则返回状态码413 size如果为0则不限制请求主体大小 ","date":"2020-11-14","objectID":"/nginx-directives/:72:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" sendfile # 语法 sendfile on | off; # 默认值 sendfile off; # 配置上下文 http, server, location, if in location 启用或禁用sendfile()(零拷贝) 值为off时，服务器通过网络传输一个文件到客户端有以下步骤： read系统调用， 从磁盘中读取文件内容，存储在内核空间的缓冲区。 （从用户空间切换到内核空间） 系统调用read返回， 文件内容从内核空间的缓冲区复制到用户空间的缓冲区 （从内核空间切换到用户空间） send函数调用write系统调用， 文件内容从用户空间缓冲区被复制到内核空间socket缓冲区 （从用户空间切换到内核空间） write系统调用返回， 文件内容从socket缓冲区复制到网卡，由网卡发送给客户端 （从内核空间切换到用户空间） 值为on时，服务器通过网络传输一个文件到客户端有以下步骤： 系统调用sendfile(), 通过 DMA`硬盘数据拷贝到内核缓冲区， 从内核缓冲区拷贝到socket缓冲区(都是内核态) 文件内容从socket缓冲区复制到网卡，由网卡发送给客户端 ","date":"2020-11-14","objectID":"/nginx-directives/:73:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" tcp_nopush # 语法 tcp_nopush on | off; # 默认值 tcp_nopush off; # 配置上下文 http, server, location 是否启用TCP_CORK套接字选项， 如果是FreeBSD系统则是TCP_NOPUSH选项 启用senfile指令时才生效 值为off时，启用Nagle。内核将阻塞完整的报文，最多阻塞200ms. 此处的不完整指的是应用层发送的数据长度不足一个MSS长度。 该方试在报文小而多的情况下可以增加通信性能 值为on时，禁用Nagle。内核将不阻塞报文 该方式可以立即响应客户端，而不用等待报文满足一定的长度 ","date":"2020-11-14","objectID":"/nginx-directives/:74:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" tcp_nodelay # 语法 tcp_nodelay on | off; # 默认值 tcp_nodelay on; # 配置上下文 http, server, location 是否启用TCP_NODELAY套接字选项。 以下情况该选项生效： 当连接转换为保持活动状态时 当连接使用SSL连接 使用upstream时 WebSocket代理时 无缓冲代理时 值为on时，启用Nagle 内核将阻塞完整的报文，最多阻塞200ms. 此处的不完整指的是应用层发送的数据长度不足一个MSS长度。 该方试在报文小而多的情况下可以增加通信性能 值为off时，禁用Nagle 内核将不阻塞报文。oooo 该方式可以立即响应客户端，而不用等待报文满足一定的长度 types_hash_bucket_size指令 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 默认值为64 ","date":"2020-11-14","objectID":"/nginx-directives/:75:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" types_hash_max_size 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 默认值1024 ","date":"2020-11-14","objectID":"/nginx-directives/:76:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" log_not_found 文件或目录不存在时是否记录日志 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on(默认)或off ","date":"2020-11-14","objectID":"/nginx-directives/:77:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" absolute_redirect 客户端访问目录时没有以/结尾时， 返回301重定向时新地址是否带主机名 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on(默认)或off ","date":"2020-11-14","objectID":"/nginx-directives/:78:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" server_name_in_redirect 客户端访问目录时没有以/结尾时， absolute_redirect指令返回的主机名为主域名而不是host头部 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on或off(默认) ","date":"2020-11-14","objectID":"/nginx-directives/:79:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" server_in_redirect 客户端访问目录时没有以/结尾时， absolute_redirect指令否带端口 处于处理HTTP请求的第10个（CONTENT）阶段 配置在http,server,location指令块中 值为on(默认)或off ngx_http_sub_filter_module该模块默认编译进nginx， 编译时通过--with-http_sub_module选项加入 ","date":"2020-11-14","objectID":"/nginx-directives/:80:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" sub_filter 替换响应主体部分字符串 处于CONTENT阶段之后LOG阶段之前 配置在http,server,location指令块中 匹配时忽略大小写 ","date":"2020-11-14","objectID":"/nginx-directives/:81:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" sub_filter_last_modified 是否在返回Last-Modified头部（sub_filter指令替换时间） 处于CONTENT阶段之后LOG阶段之前 配置在http,server,location指令块中 值为on或off(默认) ","date":"2020-11-14","objectID":"/nginx-directives/:82:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" sub_filter_once sub_filter指令是否只替换一次 处于CONTENT阶段之后LOG阶段之前 配置在http,server,location指令块中 值为on(默认)或off ","date":"2020-11-14","objectID":"/nginx-directives/:83:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" sub_filter_types sub_filter指令能替换的类型 处于CONTENT阶段之后LOG阶段之前 配置在http,server,location指令块中 默认值：text/html 如果值为*表示对所有类型都可以进行替换 示例： server { listen localhost:809; root html; location / { # 把响应字符串中的 nginx 替换为 ngx sub_filter 'nginx' 'ngx'; # 关闭值只替换一次，表示全部替换 sub_filter_once off; # 返回Last-Modified头部，值为字符串替换时间 sub_filter_last_modified on; } } ngx_http_addition_filter_module该模块默认没有编译进nginx， 编译时通过--with-http_addition_module选项加入 ","date":"2020-11-14","objectID":"/nginx-directives/:84:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" add_before_body 在响应主体之前添加内容（产生新的子请求访问uri响应的内容） 处于CONTENT阶段之后LOG阶段之前 配置在http,server,location指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:85:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" add_after_body 在响应主体之后添加内容（产生新的子请求访问uri响应的内容） 处于CONTENT阶段之后LOG阶段之前 配置在http,server,location指令块中 ","date":"2020-11-14","objectID":"/nginx-directives/:86:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" addition_types 指定某些类型才能使用add_before_body和add_after_body指令 处于CONTENT阶段之后LOG阶段之前 配置在http,server,location指令块中 默认值：text/html; server { listen 810; root html; location / { # 响应之前在响应主体部分前面添加该地址返回的主体 add_before_body /add_body1; # 响应之前在响应主体部分后面添加该地址返回的主体 add_after_body /add_body2; } location /add_body1 { return 200 '=============================== \\n'; } location /add_body2 { return 200 '++++++++++++++++++++++++++++++ \\n'; } } ngx_http_log_module该模块无法禁用 ","date":"2020-11-14","objectID":"/nginx-directives/:87:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" log_format # 处于处理HTTP请求的第11个（LOG）阶段 log_format name [escape=default|json|none] string ...; 配置域：http 默认值：combined '$remote_addr - $remote_user [$time_local] ' '\"$request\" $status $bytes_sent ' '\"$http_referer\" \"$http_user_agent\" \"$gzip_ratio\"' 该指令指定 access_log 指令记录格式，格式必须在引用之前定义。可以多次使用该指令配置多个格式 ","date":"2020-11-14","objectID":"/nginx-directives/:88:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" access_log # 处于处理HTTP请求的第11个（LOG）阶段 access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 默认值：logs/access.log combined; 配置域：http，server，location，if in location，limit_except 该指令指定记录访问日志位置。可以在同一配置级别指定多个日志。有以下参数： path 代指保存路径，可以包含变量 buffer 指定缓存空间大小，默认为 64k。超过时将定入磁盘 gzip 指定压缩内存中的日志级别，减少缓存空间占用。默认压缩级别为1（1-9，级别越大压缩率越高但压缩越慢）。该功能依赖于 zlib 库 flush 指定日志缓存时间。超时将写入磁盘 if 用于满足指定条件才写入磁盘 off 表示不记录访问日志 此外，worker 进程正在被关闭或执行 reopen 命令时也会把日志写入文件 示例 # 日志压缩级别为 1，每隔1分钟或超过缓存空间限值时写入磁盘 access_log logs/note.xiaosi.host.nginx.access.log note gzip flush=1m; ","date":"2020-11-14","objectID":"/nginx-directives/:89:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" open_log_file_cache # 处于处理HTTP请求的第11个（LOG）阶段 open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; 默认值：off 配置域：http，server，location 该指令配置缓存日志文件句柄。当没用开启时每次记录日志都需要打开和关闭日志文件。有以下参数： max 指定缓存数量，如果缓存数量已满，则使用淘汰关闭最近最少（LRU）使用的文件句柄 inactive 指定缓存时间，默认为 10s min_uses 指定在 inactive 时间内活跃次数。默认为 1 小于该值时将关闭文件句柄 valid 指定检测缓存时间间隔。默认为 60s off 关闭该功能 示例 # 缓存 3 个日志文件句柄，10秒内没有写入1次日志将关闭该文件句柄 open_log_file_cache max=3 ; ngx_http_stub_status_module默认情况下不构建此模块，编译安装时应使用 --with-http_stub_status_module 配置参数启用它 ","date":"2020-11-14","objectID":"/nginx-directives/:90:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" stub_status 提供nginx基本状态数据 配置在server, location 有以下基本状态信息： Active connections: 当前活动客户端连接数，包括Waiting连接数 accepts: 接受的客户端连接总数 handled: 处理的连接总数 requests: 客户端请求的总数 Reading: 正在读取请求头的当前连接数 Writing: 将响应写回客户端的当前连接数 Waiting: 当前等待请求的空闲客户端连接数 该ngx_http_stub_status_module模块支持以下嵌入变量 $connections_active: 与Active connections相同 $connections_reading: 与Reading相同 $connections_writing: 与Writing相同 $connections_waiting: 与Waiting相同 示例： [root@xiaosi nginxNode1]# cat conf/conf.d/1000_stub_status.conf server { listen 172.11.12.127:1000; location = /basic_status { stub_status; } } [root@xiaosi nginxNode1]# curl 172.11.12.127:1000/basic_status Active connections: 1 server accepts handled requests 6 6 6 Reading: 0 Writing: 1 Waiting: 0 ngx_http_ssl_module http://nginx.org/en/docs/http/ngx_http_ssl_module.html 该模块提供https支持 默认不编译，编译时使用--with-http_ssl_module启用 该模块需要openssl库 为了减少处理器负载，建议使用以下设置 将工作进程数量（worker_processes指令）设置为CPU核心数量。 启用长连接（keepalive_timeout指令） 启用共享会话缓存（ssl_session_cache指令） 增加会话生命周期(ssl_session_timeout指令） 示例： server { listen 192.168.204.129:8802 ssl; server_name xiaosi.com; root /mnt/hgfs/note/vmware/nginx/web/; ssl_certificate /mnt/hgfs/note/vmware/tls/server.crt ; ssl_certificate_key /mnt/hgfs/note/vmware/tls/server.key; ssl_protocols TLSv1.3 TLSv1 TLSv1.1 TLSv1.2; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; } ","date":"2020-11-14","objectID":"/nginx-directives/:91:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" ssl_session_timeout # 语法 ssl_session_timeout time; # 默认值 ssl_session_timeout 5m; # 配置上下文 http,server 指定客户端可以重用https会话参数时间 ","date":"2020-11-14","objectID":"/nginx-directives/:92:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" ssl_session_cache # 语法 ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; # 默认值 ssl_session_cache none; # 配置上下文 http, server 设置存储https会话参数的缓存的类型和大小 off: 严格禁止使用会话缓存：nginx 明确告诉客户端会话可能不会被重用 none: 温和地禁止使用会话缓存：nginx 告诉客户端会话可以被重用， 但实际上并未将会话参数存储在缓存中 builtin: OpenSSL 中内置的缓存；仅由一个工作进程使用。缓存大小在会话中指定。 如果未给出大小，则等于20480 个会话。使用内置缓存会导致内存碎片。 shared: 所有工作进程之间共享的缓存。缓存大小以字节为单位指定； 一兆字节可以存储大约 4000 个会话。每个共享缓存都应该有一个任意名称。 同名缓存可用于多个虚拟服务器。 ","date":"2020-11-14","objectID":"/nginx-directives/:93:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" ssl_protocols # 语法 ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3]; # 默认值： ssl_protocols TLSv1 TLSv1.1 TLSv1.2； # 配置上下文 http,server 支持SSL或TLS协议版本，，可以有多少版本 TLSv1.1和TLSv1.2需要OpenSSL 1.0.1版本或更高版本 TLSv1.13.0需要OpenSSL 1.1.1版本或更高版本 ","date":"2020-11-14","objectID":"/nginx-directives/:94:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" ssl_certificate # 语法 ssl_certificate file; # 配置上下文 http,server 指定pem格式证书，如果除了主证书之外还应指定中间证书。则以“服务器证书,中间证书”格式 从 1.11.0 版本开始，可以多次指定该指令以加载不同类型的证书，例如 RSA 和 ECDSA ngx_http_gzip_module使用gzip方法压缩响应报文，减少带宽使用 ","date":"2020-11-14","objectID":"/nginx-directives/:95:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip # 语法 gzip on|off; # 默认值 gzip off; # 配置上下文 http, server, location, if in location 是否gzip方法压缩响应报文 gzip很消耗cpu的性能 ","date":"2020-11-14","objectID":"/nginx-directives/:96:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_min_length # 语法 gzip_min_length length; # 默认值 gzip_min_length 20； # 配置上下文 http, server, location 设置将被压缩的响应的最小长度。 长度仅由响应头字段Content-Length确定。 ","date":"2020-11-14","objectID":"/nginx-directives/:97:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_buffers # 语法 gzip_buffers number size; # 默认值 gzip_buffers 32 4k|16 8k； # 配置上下文 http, server,location 设置用于gzip压缩响应报文的缓冲区数量与大小 ","date":"2020-11-14","objectID":"/nginx-directives/:98:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_http_version # 语法 gzip_http_version 1.0 | 1.1; # 默认值 gzip_http_version 1.1； # 配置上下文 http, server,location gzio压缩所需的http最低版本 ","date":"2020-11-14","objectID":"/nginx-directives/:99:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_comp_level # 语法 gzip_comp_level level; # 默认值 gzip_comp_level 1; # 配置上下文 http, server,location gzip压缩级别(1-9) 级别越底压缩速度越快文件压缩比越小， 反之速度越慢文件压缩比越大 随着压缩级别的升高，处理时间明显变慢; ","date":"2020-11-14","objectID":"/nginx-directives/:100:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_types # 语法 gzip_types mime-type ...; # 默认值 gzip_types text/html; # 配置上下文 http, server, location 设置需要压缩的MIME类型,如果不在设置类型范围内的请求不进行压缩 ","date":"2020-11-14","objectID":"/nginx-directives/:101:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_vary # 语法 gzip_vary on | off; # 默认值 gzip_vary off; # 配置上下文 http, server, location 当以下指令启用时，是否增加响应头部字段Vary: Accept-Encoding gzip gzip_static gunzip ","date":"2020-11-14","objectID":"/nginx-directives/:102:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_proxied # 语法 gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...; # 默认值 gzip_proxied off; # 配置上下文 http, server, location 做为代理时根据响应头部决定是否启用gzip， 多个值用空格分隔 off: 关闭 any: 启用压缩 expired: 如果header中包含”Expires”头信息，启用压缩 o-cache: 如果header中包含”Cache-Control:no-cache”头信息，启用压缩 no-store: 如果header中包含”Cache-Control:no-store”头信息，启用压缩 private: 如果header中包含”Cache-Control:private”头信息，启用压缩 no_last_modified: 如果header中不包含”Last_Modified”头信息，则启用压缩 no_etag: 如果header中不包含“ETag”头信息，启用压缩 auth: 如果header中不包含“Authorization”头信息，启用压缩 ","date":"2020-11-14","objectID":"/nginx-directives/:103:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" gzip_disable # 语法 gzip_disable regex ...; # 配置上下文 http, server,location User-Agent头部满足该指令设置的正则时，禁止使用gzip ","date":"2020-11-14","objectID":"/nginx-directives/:104:0","tags":["nginx 指令"],"title":"nginx模块与指令","uri":"/nginx-directives/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.18 centos: 7 安装nginx三步骤 从nginx官网下载源码包 [root@centos7 ~]# wget http://nginx.org/download/nginx-1.18.0.tar.gz [root@centos7 ~]# tar -zxf nginx-1.18.0.tar.gz root@centos7 ~]# cd nginx-1.18.0 编译安装 [root@c8 nginx-1.18.0]# ./configure --help # --help 选项是查看帮助信息 # 这列是选项 # 这列是选项描述 --help print this message --prefix=PATH set installation prefix --sbin-path=PATH set nginx binary pathname --modules-path=PATH set modules path --conf-path=PATH set nginx.conf pathname --error-log-path=PATH set error log pathname --pid-path=PATH set nginx.pid pathname --lock-path=PATH set nginx.lock pathname --user=USER set non-privileged user for worker processes --with-debug enable debug logging ... # 查看默不会编译的模块，加入这些选项时，加入编译 [root@localhost nginx-1.18.0]# ./configure --help | grep enable --with-select_module enable select module --with-poll_module enable poll module ... # 查看默认会编译的模块，加入这些选项时，取消编译 [root@localhost nginx-1.18.0]# ./configure --help | grep disable --without-select_module disable select module --without-poll_module disable poll module # 安装依赖包 dnf install epel-release -y \u0026\u0026 dnf config-manager --set-enabled powertools dnf -y install pcre-devel openssl openssl-devel geoip-devel gperftools-devel gcc gcc-c++ autoconf automake make # 编译 [root@centos7 nginx-1.18.0]# ./configure \\ --add-module=/home/web/ngx_cache_purge/ \\ --add-module=/home/web/nginx-http-concat/ \\ --with-http_auth_request_module \\ --with-http_realip_module \\ --with-http_v2_module \\ --with-debug \\ --with-http_random_index_module \\ --with-http_sub_module \\ --with-http_addition_module \\ --with-http_secure_link_module \\ --with-http_geoip_module \\ --with-http_ssl_module \\ --with-stream_ssl_module \\ --with-stream_realip_module \\ --with-stream_ssl_preread_module \\ --with-stream \\ --with-http_slice_module \\ --with-google_perftools_module \\ --with-threads \\ --with-ld-opt=-ltcmalloc \\ --with-http_gzip_static_module \\ --with-http_gunzip_module \\ --with-http_stub_status_module [root@centos7 nginx-1.18.0]# make \u0026\u0026 make install [root@centos7 nginx-1.18.0]# echo $? 0 加入系统模块和命令 [root@centos7 nginx-1.18.0]# /usr/local/nginx/sbin/nginx -v [root@centos7 nginx-1.18.0]# ln /usr/local/nginx/sbin/nginx /usr/bin/nginx [root@centos7 nginx-1.18.0]# cat \u003c\u003c EOF \u003e /usr/lib/systemd/system/nginx.service [Unit] # 描述名称 Description=The nginx HTTP and reverse proxy server # 服务类别 After=network.target remote-fs.target nss-lookup.target [Service] # 运行方式，forking 表示后台运行 Type=forking # pid 文件 PIDFile=/usr/local/nginx/logs/nginx.pid # 启动 nginx 之前执行的命令 ExecStartPre=/usr/bin/rm -f /usr/local/nginx/logs/nginx.pid ExecStartPre=/usr/local/nginx/sbin/nginx -t # 启动 nginx 执行的命令 ExecStart=/usr/local/nginx/sbin/nginx # 重新加载 nginx 配置文件的命令 ExecReload=/usr/local/nginx/sbin/nginx -s reload # 关闭 nginx 执行的命令 ExecStop=/usr/local/nginx/sbin/nginx -s stop KillSignal=SIGQUIT TimeoutStopSec=5 KillMode=process # 分配独立的临时空间 PrivateTmp=true Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target EOF 加载 systemctl 配置 [root@c8 ~]# systemctl daemon-reload 加入开机启动 [root@c8 ~]# systemctl enable nginx Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service. 源码目录结构 [root@centos7 nginx-1.18.0]# tree -L 2 . ├── auto # 环境判断之类的文件 │ ├── cc │ ├── define │ ├── endianness │ ├── feature │ ├── have │ ├── have_headers │ ├── headers │ ├── include │ ├── init │ ├── install │ ├── lib │ ├── make │ ├── module │ ├── modules │ ├── nohave │ ├── options │ ├── os │ ├── sources │ ├── stubs │ ├── summary │ ├── threads │ ├── types │ └── unix ├── CHANGES ├── CHANGES.ru ├── conf │ ├── fastcgi.conf │ ├── fastcgi_params │ ├── koi-utf │ ├── koi-win │ ├── mime.types │ ├── nginx.conf │ ├── scgi_params │ ├── uwsgi_params │ └── win-utf ├── configure ├── contrib │ ├── geo2nginx.pl │ ├── README │ ├── unicode2nginx │ └── vim ├── html │ ├── 50x.html │ └── index.html ├── LICENSE ├── Makefile ├── man │ └── nginx.8 ├── objs │ ├── addon │ ├── autoconf.err │ ├── Makefile │ ├── nginx │ ├── nginx.8 │ ├── ngx_auto_confi","date":"2020-11-14","objectID":"/nginx-install/:0:0","tags":["nginx 安装"],"title":"安装nginx","uri":"/nginx-install/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.23 error: the invalid value in –with-ld-opt=\"-ltcmalloc\" 编译时安装出错 [root@centos7 nginx-1.18.0]# ./configure \\ --with-http_auth_request_module \\ --with-http_realip_module \\ --with-http_v2_module \\ --with-debug \\ --add-module=/home/web/nginx-http-concat/ \\ --with-http_random_index_module \\ --with-http_sub_module \\ --with-http_addition_module \\ --with-http_secure_link_module \\ --with-http_geoip_module \\ --with-http_ssl_module \\ --with-stream_ssl_module \\ --with-stream_realip_module \\ --with-stream_ssl_preread_module \\ --with-stream \\ --add-module=/home/web/ngx_cache_purge/ \\ --with-http_slice_module \\ --with-google_perftools_module \\ --with-threads \\ --with-ld-opt=-ltcmalloc \\ --with-http_gzip_static_module \\ --with-http_gunzip_module \\ --with-http_stub_status_module checking for OS + Linux 3.10.0-1127.10.1.el7.x86_64 x86_64 checking for C compiler ... found + using GNU C compiler + gcc version: 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) checking for gcc -pipe switch ... found checking for --with-ld-opt=\"-ltcmalloc\" ... not found ./configure: error: the invalid value in --with-ld-opt=\"-ltcmalloc\" 解决方法：安装 tcmalloc # gperftools 有 tcmalloc [root@localhost nginx-1.23.0]# yum install gperftools 原因：缺少TcMalloc库 error: the HTTP rewrite module requires the PCRE library. 编译出错 [root@centos7 nginx-1.18.0]# ./configure \\ --with-http_auth_request_module \\ --with-http_realip_module \\ --with-http_v2_module \\ --with-debug \\ --with-http_random_index_module \\ --with-http_sub_module \\ --with-http_addition_module \\ --with-http_secure_link_module \\ --with-http_geoip_module \\ --with-http_ssl_module \\ --with-stream_ssl_module \\ --with-stream_realip_module \\ --with-stream_ssl_preread_module \\ --with-stream \\ --with-http_slice_module \\ --with-google_perftools_module \\ --with-threads \\ --with-http_gzip_static_module \\ --with-http_gunzip_module \\ --with-http_stub_status_module ... ./configure: error: the HTTP rewrite module requires the PCRE library. You can either disable the module by using --without-http_rewrite_module option, or install the PCRE library into the system, or build the PCRE library statically from the source with nginx by using --with-pcre=\u003cpath\u003e option. 解决方法：yum -y install pcre-devel [root@centos7 nginx-1.18.0]# yum -y install pcre-devel Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.cn99.com * extras: mirrors.163.com ... 原因：缺少依赖 pcre-devel error: SSL modules require the OpenSSL library. 错误 ./configure: error: SSL modules require the OpenSSL library. You can either do not enable the modules, or install the OpenSSL library into the system, or build the OpenSSL library statically from the source with nginx by using --with-openssl=\u003cpath\u003e option. 解决方法 yum -y install openssl openssl-devel 原因：缺少依赖 error: the GeoIP module requires the GeoIP library. 错误 ./configure: error: the GeoIP module requires the GeoIP library. You can either do not enable the module or install the library. 解决 yum install geoip-devel -y error: the Google perftools module requires the Google perftools library. 错误： ./configure: error: the Google perftools module requires the Google perftools library. You can either do not enable the module or install the library. 解决 yum install gperftools-devel -y error: no /home/web/nginx-http-concat//config was found ./configure: error: no /home/web/nginx-http-concat//config was fou access_log 日志记录位置 访问80:/为什么记录在1.log中，而不是2.log？ server { listen 80; access_log logs/1.log combined; location = / { access_log logs/2.log combined; } } nginx: error while loading shared libraries: libgd.so.3: cannot open shared object file: No such file or directory [root@localhost ~]# nginx -t nginx: error while loading shared libraries: libgd.so.3: cannot open shared object file: No such file or directory # 缺少gd库 [root@localhost ~]# yum install gd -y worker process xxxx exited on signal 25？ 来自：https://www.nginx.org.cn/question/detail/6423 nginx 使用的版本是 nginx1.20.1， 网站页面突然访问不了，查看nginx报了 worker process xxxx exite","date":"2020-11-13","objectID":"/nginx-error/:0:0","tags":["error","nginx"],"title":"nginx运行错误","uri":"/nginx-error/"},{"categories":["golang"],"content":" 运行环境： go: 1.15 内容来自以下文档： Go语言圣经-入门：Hello, World 打印 hello, world将下面代码保存到一个.go 结尾的文件文件中，如 HelloWorld.go // 打印 Hello, world package main // 导如 fmt 包 import \"fmt\" func main() { fmt.Println(\"Hello, World\") } ","date":"2020-08-26","objectID":"/go-hello-world/:0:0","tags":["hello world"],"title":"go run hello world","uri":"/go-hello-world/"},{"categories":["golang"],"content":" package main上面代码中，package main 表示当前文件是属于一个叫 main 包的文件， 多个文件可以同时属于同一个包。 main 包是一个特殊的包，表示该包可以通过 go build 命令构建成 二进制可执行文件。（win系统下是 .exe 结尾的文件） ","date":"2020-08-26","objectID":"/go-hello-world/:1:0","tags":["hello world"],"title":"go run hello world","uri":"/go-hello-world/"},{"categories":["golang"],"content":" import “fmt”import \"fmt\" 表示导入一个叫 fmt 的包，导入包之后就可以使用该包 定义的功能，一个文件中，不能导入多余的包，也不能少导入包 fmt 包实现格式化输入和输出的功能 ","date":"2020-08-26","objectID":"/go-hello-world/:2:0","tags":["hello world"],"title":"go run hello world","uri":"/go-hello-world/"},{"categories":["golang"],"content":" func mainfunc main 定义了一个叫 main 的函数，后面的 () 以及跨域2行的 {} 都是 函数的结构。它们是一个整体 main 函数是特殊的函数，它表示一个包执行入口，也就是 main 函数定义的功能 就是整个程序的功能 ","date":"2020-08-26","objectID":"/go-hello-world/:3:0","tags":["hello world"],"title":"go run hello world","uri":"/go-hello-world/"},{"categories":["golang"],"content":" fmt.Printlnfmt.Println() 表示 Println() 是 fmt 包提供的功能，因此， 必须是 import 导入了 fmt 包，才能正常使用。 Println() 也是函数，该函数会将参数 （也就是 Hello, World，引号引起来表示他们是一个整体） 输入到屏幕。这就是：fmt.Println(\"Hello, World\") 的含义 ","date":"2020-08-26","objectID":"/go-hello-world/:4:0","tags":["hello world"],"title":"go run hello world","uri":"/go-hello-world/"},{"categories":["golang"],"content":" 注释// 开头的行表示注释，是程序代码是说明信息， 是给查看代码的人看的，不会被执行。 注释信息通常都卸载代码是正上方 运行在命令行中，使用 go run HelloWorld.go 会得到 Hello, World 的输出信息 D:\\ftp\\go\u003ego run HelloWorld.go Hello, World 可执行程序如果某个 .go 文件是属于 main 包，那么可以使用 go bulid 命令构建成 一个可执行的二进制文件，也就是windows系统上的 .exe 结尾的文件 D:\\ftp\\go\u003ego build HelloWorld.go D:\\ftp\\go\u003eHelloWorld.exe Hello, World ","date":"2020-08-26","objectID":"/go-hello-world/:5:0","tags":["hello world"],"title":"go run hello world","uri":"/go-hello-world/"},{"categories":["nginx"],"content":" 运行环境： nginx: 1.21.0 负载均衡扩展类型：可以综合使用 水平扩展：对无状态服务有用 round robin 算法 least connected 算法 基于功能(url)分发 基于用户(ip,用户名等)分发 ","date":"2020-08-13","objectID":"/nginx-load-balance/:0:0","tags":["负载均衡","nginx"],"title":"nginx 负载均衡","uri":"/nginx-load-balance/"},{"categories":["nginx"],"content":" round robin 算法round robin（轮询算法）会按照顺序轮回访问上游服务器， 加权 round robin 算法是在其基础上添加优先级（权重）， 是默认集成在nginx的upstream框架中， 无法移除 有以下权重指令： weight：服务器访问权重，默认为1，相同权重按照上到下的顺序 max_conns：server 最大并发连接数量， 仅作用于单个worker进程，默认值为0（无限制） fail_timeout：超时时间，单位为秒，默认值10 max_fails：在fail_timeout时间内，最大失败的次数， 超过之后fail_timeout时间内不会调度到这台服务器 对上游服务器长连接通过复用使用长连接（keepalive）， 可以减少http请求与关闭连接的次数， 从而减少延迟， 提示网络吞吐量 需要对上游连接的http头部设置： proxy_http_version:1.1(1.0不支持长连接，避免1.0版本) proxy_set_header Connection: \"\" keepalive指令： 对上游服务器保持长连接个数 配置在http指令块中 keepalive_requests指令： 一条对上游tcp长连接中，最多支持多少个http请求 配置在upstream指令块中 默认值100 keepalive_timeout指令： 一条对上游tcp长连接中，空闲多少时间后关闭 配置在upstream指令块中 默认值60s DNS服务resolver指令： dns服务 配置在http,server,location指令块中 resolver_timeout指令： resolver指令超时时间 配置在http,server,location指令块中 默认值30s ngx_http_upstream_moduleupstream指令块： 负载均衡相关配置 配置在http指令块中 server指令： 指定上游服务器地址： ip 主机名 端口（不指定时默认为80） unix socke ip:端口 主机名:端口 配置在upstream指令块中 地址后面可以有以下参数： backup：备用服务地址，当其他地址不可用时生效 down：标示不可用 权重指令 # rb1 是自定义名称 upstream rb1 { # 10秒内失败3次，则之后10秒不调用到该服务器 server 127.0.0.1:820 max_fails=3; # 权重为2,优先与上面的服务器，最大并发连接为31 server 127.0.0.1:821 weight=2 max_conns=31; # 每个worker进程保持连接数量为21 keepalive 21; } server { listen 830; location / { # 代理到 rb1 proxy_pass http://rb1; # 修改头部 proxy_http_version 1.1; proxy_set_header Connection \"\"; } } hash 算法问题hash算法选中上游服务器规则：key%上游服务器数量， 也就是取余数 基于hash算法可以将某类请求固定调度到某台上游服务， 但无论是hash关键字(key)还是上游服务节点数量发送变化， 都会重新进行hash记算， 会造成所有连接失效和所有缓存失效 ","date":"2020-08-13","objectID":"/nginx-load-balance/:1:0","tags":["负载均衡","nginx"],"title":"nginx 负载均衡","uri":"/nginx-load-balance/"},{"categories":["nginx"],"content":" 一致性hash算法一致性hash算法是hash取模（取余数）的解决方式， 该方式可以减少上游服务器数量发送变化之后造成所有服务器缓存失效 ","date":"2020-08-13","objectID":"/nginx-load-balance/:2:0","tags":["负载均衡","nginx"],"title":"nginx 负载均衡","uri":"/nginx-load-balance/"},{"categories":["nginx"],"content":" 基于客户端 IP hash 负载ip_hash指令： 以客户端的IP地址作为hash算法关键字， 映射到特定的上游服务器 配置在upstream指令块中 ipv4：使用前3个字节作为关键字 ipv6：使用完整字符串作为关键字 基于realip模块修改用于执行算法的IP 示例： upstream ip_hash { # 开启基于客户端ip hash作为负载均衡关键字 ip_hash; # 虽然有权重，但是没有生效 server 127.0.0.1:820 max_fails=3; server 127.0.0.1:821 weight=2 max_conns=31; } server { listen 831; location / { proxy_pass http://ip_hash; proxy_http_version 1.1; proxy_set_header Connection \"\"; } } ","date":"2020-08-13","objectID":"/nginx-load-balance/:3:0","tags":["负载均衡","nginx"],"title":"nginx 负载均衡","uri":"/nginx-load-balance/"},{"categories":["nginx"],"content":" 基于任意关键字 hash 负载hash指令： 通过指定关键字基于hash算法映射到特定的上游服务器 配置在upstream指令块中 关键字可以含义变量、字符串 选项consistent：一致性hash算法 示例： upstream ip_hash { # 更据请求的urL hash $request_uri; server 127.0.0.1:820 max_fails=3; server 127.0.0.1:821 weight=2 max_conns=31; } server { listen 831; location / { proxy_pass http://ip_hash; proxy_http_version 1.1; proxy_set_header Connection \"\"; } } 优先选择最少连接算法least_conn指令： 调度到最少连接数量的上游服务器 配置在upstream指令块中 如果有多台都是最少连接则使用round robin算法 负载均衡策略对所有worker进程生效默认情况下， 负载均衡策略只对一个work工作进程生效 zone指令： 使用共享内存， 将其他的upstream模块定义的负载均衡策略、 运行时的每个上游服务的状态放在该共享内存中， 使其对所有worker进程生效 配置在upstream指令块中 与upstream相关模块生效顺序有关， grep '^.*\u0026.*http_upstream'ngx_modules.c输出结果优先级从上往下 变量upstream模块提供的部分变量： $upstream_addr：上游服务器的IP地址 $upstream_connect_time：与上游服务建立连接所消耗时间(秒) $upstream_header_time：接收上游服务响应报文头部所消耗时间(秒) $upstream_response_time：接收上游响应报文所消耗的时间(秒) $upstream_http_name：name是代指响应头部名称 $upstream_bytes_received：接收到上游服务响应报文的长度(字节) $upstream_response_length：接收到上游服务响应报文主体的长度(字节) $upstream_cookie_name：name是代指上游服务响应报文Set-Cookit的名称， 该变量值为响应的cookit值 $upstream_trailer_name：name是代指从上游服务响应尾部名称， 该变量的值为对应尾部值 ","date":"2020-08-13","objectID":"/nginx-load-balance/:4:0","tags":["负载均衡","nginx"],"title":"nginx 负载均衡","uri":"/nginx-load-balance/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.14 内容来自以下文档： k8s 官方文档: 使用 CoreDNS 进行服务发现 k8s 官方文档: 自定义 DNS 服务 k8s官方文档-Pod 与 Service 的 DNS k8s官方文档-Kubernetes DNS-Based Service Discovery k8s 中 DNS 规范Kubernetes的任何基于DNS的服务发现解决方案都必须提供以下所述的资源记录 ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:0:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" Pod 和 Service 的 DNSk8s DNS 在集群商调度 DNS Pod 和服务，并配置 kubelet 以告知各个容器使用 NDS 服务的 IP 来解析 DNS 名称 ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:1:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" 获取 DNS 名称在集群中定义的每个 Service （包括 DNS 服务本身）都会被指定一个 DNS 名称。默认一个客户端 Pod 的 DNS 搜索列表将包含该 Pod 自己的名称空间和集群默认域 官方示例：假设在 k8s 集群的名称空间 bar 中，定义了一个Service foo。 运行在名称空间 bar 中的一个 Pod，可以简单地通过 DNS 查询 foo 来找到该 Service。 运行在名称空间 quux 中的一个 Pod 可以通过 DNS 查询 foo.bar 找到该 Service ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:2:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" 版本架构记录必须有一个 TXT 的记录架构版本 记录格式：dns-version.\u003czone\u003e. \u003cttl\u003e IN TXT \u003cschema-version\u003e zone：集群域 ttl：标准 DNS 解析缓存有效期 cshema-version：解析的值 示例：dns-version.cluster.local. IN TXT 解析记录：dns-version.cluster.local. 28800 IN TXT \"1.1.0\" ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:3:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" 集群服务记录在给定集群 IP 的服务中，必须有以下记录 ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:4:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" A/AAAA 记录IPV4 记录格式：\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN A \u003ccluster-ip\u003e service：服务名称 ns：名称空间 zone；集群域 ttl：标准 DNS 解析缓存有效期 cluser-ip：后端提供服务的 Pod IP 示例：kubernetes.default.svc.cluster.local. IN A 解析记录：kubernetes.default.svc.cluster.local. 4 IN A 10.3.0.1 如果是 IPV6 则需使用 AAAA 记录：\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN AAAA \u003ccluster-ip\u003e ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:4:1","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" SRV 记录对于服务中具体协议名称和命名端口号的服务，必须使记录格式：_\u003cport\u003e._\u003cproto\u003e.\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN SRV \u003cweight\u003e \u003cpriority\u003e \u003cport-number\u003e \u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. port：端口名称或协议名称 proto：协议 service：服务名称 ns：名称空间 zone：集群域 weight：权重 priority：优先级 prot-number：端口号 示例：_https._tcp.kubernetes.default.svc.cluster.local. IN SRV 解析记录：_https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 kubernetes.default.svc.cluster.local. SRV 记录响应部分还可以引用 A/AAAA 记录 SRV 解析值示例：_https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 kubernetes.default.svc.cluster.local. 引用 A 记录的解析值：_https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 10.3.0.1. ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:4:2","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" PTR 记录对于给定的 IPV4 服务的集群IP , PTR 记录格式：\u003cd\u003e.\u003cc\u003e.\u003cb\u003e.\u003ca\u003e.in-addr.arpa. \u003cttl\u003e IN PTR \u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. d：IP D 段 c：IP C 段 b：IP B 段 a：IP A 段 ttl：标准 DNS 缓存有效期 service：服务名称 ns：名称空间 zone：集群区域 示例：1.0.3.10.in-addr.arpa. IN PTR 解析记录：1.0.3.10.in-addr.arpa. 14 IN PTR kubernetes.default.svc.cluster.local. 对于给定的 IPV6 ，PTR 记录格式：h4.h3.h2.h1.g4.g3.g2.g1.f4.f3.f2.f1.e4.e3.e2.e1.d4.d3.d2.d1.c4.c3.c2.c1.b4.b3.b2.b1.a4.a3.a2.a1.ip6.arpa \u003cttl\u003e IN PTR \u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. h4：H 段的第 4 个字符 h3：H 段的第 3 个字符 … a1：A 段的第 1 个字符 ttl：标准 DNS 缓存有效期 service：服务名称 ns：名称空间 示例：1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa. IN PTR 解析记录：1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa. 14 IN PTR kubernetes.default.svc.cluster.local. ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:4:3","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" 无头服务记录在给定的无头服务中（没有配置集群 IP），必须存在以下记录 ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:5:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" A/AAAAIPV4 记录格式：\u003chostname\u003e.\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN A \u003cendpoint-ip\u003e hostname：Pod 主机名称 (可以没有，则返回全部后端，如果指定，则返回固定的后端) service：服务名称 ns：名称空间 zone：集群名称 ttl：标准 DNS 解析缓存有效期 endpoint ip：具体提供服务 Pod 的 ip，每个 Pod 都有单独的一条记录 示例：my-pet.headless.default.svc.cluster.local. IN A 解析记录：headless.default.svc.cluster.local. 4 IN A 10.3.0.2 示例：headless.default.svc.cluster.local. IN A 可能有以下解析记录，看具体有多少个后端： headless.default.svc.cluster.local. 4 IN A 10.3.0.1 headless.default.svc.cluster.local. 4 IN A 10.3.0.2 headless.default.svc.cluster.local. 4 IN A 10.3.0.3 headless.default.svc.cluster.local. 4 IN A 10.3.0.4 IPV6 记录格式：\u003chostname\u003e\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN AAAA \u003cendpoint-ip\u003e ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:5:1","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" ARV 记录记录格式：_\u003cport\u003e._\u003cproto\u003e.\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN SRV \u003cweight\u003e \u003cpriority\u003e \u003cport-number\u003e \u003chostname\u003e.\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. port：端口名称 proto：协议 service：服务名称 ns：名称空间 zone：集群域 weight：权重 priority：优先级 prot-number：端口号 hostname：Pod 主机名 示例：_https._tcp.kubernetes.default.svc.cluster.local. IN SRV 解析记录数量具体看有多少后端： _https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 my-pet1.kubernetes.default.svc.cluster.local. _https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 my-pet2.kubernetes.default.svc.cluster.local. _https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 my-pet3.kubernetes.default.svc.cluster.local. SRV 记录响应部分还可以引用 A/AAAA 记录 SRV 解析值示例：_https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 my-pet1.kubernetes.default.svc.cluster.local. 引用 A 记录的解析值：_https._tcp.kubernetes.default.svc.cluster.local. 30 IN SRV 10 100 443 10.3.0.1. 如果有有 N 个后端端点，M 个端口名称，则有 N*M 条 ARV 记录 ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:5:2","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" PTR 记录IPV4 格式：\u003cd\u003e.\u003cc\u003e.\u003cb\u003e.\u003ca\u003e.in-addr.arpa. \u003cttl\u003e IN PTR \u003chostname\u003e.\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. d：IP D 段 c：IP C 段 b：IP B 段 a：IP A 段 ttl：标准 DNS 缓存有效期 hostname：主机名 service：服务名称 ns：名称空间 zone：集群区域 示例：100.0.3.10.in-addr.arpa. IN PTR 解析记录：100.0.3.10.in-addr.arpa. 14 IN PTR my-pet.headless.default.svc.cluster.local. IPV6 格式：h4.h3.h2.h1.g4.g3.g2.g1.f4.f3.f2.f1.e4.e3.e2.e1.d4.d3.d2.d1.c4.c3.c2.c1.b4.b3.b2.b1.a4.a3.a2.a1.ip6.arpa \u003cttl\u003e IN PTR \u003chostnmae\u003e.\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:5:3","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" ExternalName 服务记录也就是DNS CNAME 记录 ExternalName 服务类型记录格式（IPV4）：\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN CNAME \u003cextname\u003e. service：服务名称 sn：名称空间 zone：集群域 ttl：标准 DNS 缓存有效期 exname：指向的域名 示例：foo.default.svc.cluster.local. IN A 解析记录：foo.default.svc.cluster.local. 10 IN CNAME www.example.com. IPV6 格式：\u003cservice\u003e.\u003cns\u003e.svc.\u003czone\u003e. \u003cttl\u003e IN CNAME \u003cextname\u003e. Pod","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:6:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" Pod 的主机名和子域名pod 有以下字段设置主机名，优先级从高到低： Pod.spec.hostname Pod.metadata.name Pod 的子域名由 Pod.spec.subdomain 字段设置 端点对象可用为任意端点地址及其 IP 指定 hostname 因为没有为 Pod 名称创建 A 记录，因此创建 Pod 的 A 记录需要 Pod.spec.hostanme 字段 没有 Pod.spec.hostname 字段但有 Pod.spec.subdomain 字段的 Pod 只会为执行 Pod 的 IP 地址的 HeadlessService 创建 A 记录 除非服务上设置了 Service.sepc.publishNotReadyAddresses 值为 True 否则 Pod 需要准备 A 记录 ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:7:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" Pod 的 DNS 设置Pod 的 DNS 配置 Pod.spec.dnsPolicy 字段可以自定义 DNS 策略，有以下取值： Default ：从所在节点继承解析配置 ClusterFirst ：默认配置，与集群域后缀不匹配的 DNS 查询都转发到从节点继承的上游名称服务器。 群集管理员可能配置了额外的存根域和上游DNS服务器 ClusterFirstWithHostNet ：使用 Pod.spec.hostNetwork 字段时必须指定该策略 None ：忽略 k8s 环境中的 DNS 配置，使用 Pod.spec.dnsConfig 字段所定义的配置 Pod.spec.dnsConfig 字段中指定以下字段： nameservice：用于 Pod 的 DNS 服务 IP 地址列表，最多有 3 个，当 Pod.spec.dnsPolicy 为 none 是必须指定一个，该字段为可选字段；列出的服务器将合并到从指定的 DNS 策略生成的基本名称服务器，并删除重复的地址 searches：用于查找 pod 主机名的 DNS 搜索域的列表。该字段是可选字段，最多指定 6 个。指定后，提供的列表将合并到根据所选 DNS 策略生成的基本搜索域名中。 重复的域名将被删除 options：对象的可选列表，其中每个对象可能具有 name 属性（必需）和 value 属性（可选）。 此属性中的内容将合并到从指定的 DNS 策略生成的选项。 重复的条目将被删除 官方示例: apiVersion: v1 kind: Pod metadata: namespace: default name: dns-example spec: containers: - name: test image: nginx dnsPolicy: \"None\" dnsConfig: nameservers: - 1.2.3.4 searches: - ns1.svc.cluster-domain.example - my.dns.search.suffix options: - name: ndots value: \"2\" - name: edns0 上面示例中，创建 Pod 后，容器 test 在 /etc/resolv.conf 文件中读取以下内容 nameserver 1.2.3.4 search ns1.svc.cluster-domain.example my.dns.search.suffix options ndots:2 edns0 ","date":"2020-03-18","objectID":"/k8s-DNS%E6%9C%8D%E5%8A%A1/:8:0","tags":["k8s","k8s dns"],"title":"k8s NDS 服务","uri":"/k8s-DNS%E6%9C%8D%E5%8A%A1/"},{"categories":["k8s"],"content":" 运行环境： k8s: 1.17 内容来自以下文档： k8s 官方文档: Secret k8s 官方文档: 使用 Secret 安全地分发凭证 k8s 官方文档: Kubernetes Secret 良好实践 secret 对象secret 对象是用于保存敏感信息（如：密码、key 等），比放在 Pod.spec 字段中或镜像中可以更好的控制，并降低意外暴露的风险 系统自建了一些 secret ,也可以手动创建 secret。默认情况下，Kubernetes Secret 未加密地存储在 API 服务器的底层数据存储（etcd）中。 任何拥有 API 访问权限的人都可以检索或修改 Secret，任何有权访问 etcd 的人也可以。 此外，任何有权限在命名空间中创建 Pod 的人都可以使用该访问权限读取该命名空间中的任何 Secret； 这包括间接访问，例如创建 Deployment 的能力。 限制Secret 资源使用有以下限制 无法被静态 pod 引用 每个Secret 资源最大为 1MB，是为了避免用户创建非常大的 Secret， 进而导致 API 服务器和 kubelet 内存耗尽。不过创建很多小的 Secret 也可能耗尽内存。 Secret.metadata.name 字段必须满足DNS 子域名约束 Secret.{ data | stringData } 字段键名只能由字母、数字、-、_、.组成 Secret.stringData 字段中的所有键值对都会在内部被合并到 Secret.data 字段中。 如果某个主键同时出现在 data 和 stringData 字段中，stringData 所指定的键值具有高优先级。 secret 对象字段清单文件创建 Secret 资源常见字段注释 kind: Secret # 必须字段，指定 Secret 字段 apiVersion: v1 # 必须字段，Secret 资源所在的 API 组 metadata: # 元数据信息字段，必须存在 name: my-secret # Secret 资源名称，必须存在 type: # 数据类型 data: # 数据，键值对方式存储 stringData # 未加密的数据 如果 Secret.date 字段和 Secret.stringData 字段都存在，则使用 stringData 字段值 data 和 stringData 的键必须由字母数字字符 -, _ 或者 . 组成 Secret.date 字段值被视为经过 base64 编码的字符串。 换行符在这些字符串中无效，因此必须省略 Secret.stringData 字段值被视为普通字符串，它会在创建时用 base64 编码，该字段只是写时便利 Secret.type 字段类型有以下取值： Opaque：用户定义的任意数据，默认类型 kubernetes.io/service-account-token：服务帐户令牌（Token）使用， base64 编码 kubernetes.io/dockerconfigjson：~/.docker/config.json 文件的序列化形式 kubernetes.io/dockercfg: ~/.dockercfg 文件的序列化形式 kubernetes.io/basic-auth: 用于基本身份认证的凭据 kubernetes.io/ssh-auth: 用于 SSH 身份认证的凭据 kubernetes.io/tls: 用于 TLS 客户端或者服务器端的数据 bootstrap.kubernetes.io/token: 启动引导令牌数据 Darwin / macOS 上使用 base64 实用程序时，用户应避免使用 -b 选项来分隔长行 Linux 在 base64 命令中添加选项 -w 0， 或者，如果 -w 选项不可用的情况下， 执行 base64 | tr -d '\\n' 类型Kubernetes 在 v1.22 版本之前都会自动创建用来访问 Kubernetes API 的凭据。 这一老的机制是基于创建可被挂载到运行中 Pod 内的令牌 Secret 来实现的。 在最近的版本中，API 凭据是直接通过 TokenRequest API 来获得的，这一凭据会使用投射卷挂载到 Pod 中。使用这种方式获得的令牌有确定的生命期，并且在挂载它们的 Pod 被删除时自动作废。但仍然可以手动创建 服务账号令牌。只有在无法使用 TokenRequest API 来获取令牌， 并且能够接受因为将永不过期的令牌凭据写入到可读取的 API 对象而带来的安全风险时， 才应该创建服务账号令牌 Secret 对象。使用这种 Secret 类型时，需要确保对象的注解 kubernetes.io/service-account-name 被设置为某个已有的服务账号名称。 如果同时负责 ServiceAccount 和 Secret 对象的创建，应该先创建 ServiceAccount 对象。当 Secret 对象被创建之后，某个 Kubernetes控制器会填写 Secret 的其它字段，例如 kubernetes.io/service-account.uid 注解以及 data 字段中的 token 键值，使之包含实际的令牌内容。 官方示例 kubectl apply -f - \u003c\u003cEOF apiVersion: v1 kind: Secret metadata: name: secret-sa-sample annotations: kubernetes.io/service-account.name: \"sa-name\" # 服务账户名称 type: kubernetes.io/service-account-token data: # 可以像 Opaque Secret 一样在这里添加额外的键/值偶对 extra: YmFyCg== EOF ","date":"2020-03-11","objectID":"/k8sSecret/:0:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" Opaque 类型相比 Opaque 类型，使用预定义的、特定类型有助于帮助其他用户理解 Secret 的目的，并且对其中存在的主键形成一种约定。 API 服务器会检查 Secret 配置中是否提供了所需要的主键。 官方示例 apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: username: YWRtaW4= password: MWYyZDFlMmU2N2Rm 上述官方示例中，Secret.date.username 字段和 Secret.date.password 字段中的字符串是 base64 编码之后的结果 echo -n 'admin' | base64 YWRtaW4= echo -n '1f2d1e2e67df' | base64 MWYyZDFlMmU2N2Rm 如果是 Secret.stringDate 字段，可以不用 base64 编码的字符串，它会在创建时编码，该字段只是写时便利，检索 Secret 时不会输出 官方示例 apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque stringData: config.yaml: |- apiUrl: \"https://my.api.com/api/v1\" username: {{username}} password: {{password}} 上面的官方示例中，可以被应用程序中以下配置文件使用 apiUrl: \"https://my.api.com/api/v1\" username: \"user\" password: \"password\" 这种操作可以执行 kubectl apply 替换 {{username}} 和 {{password}} 变量 ","date":"2020-03-11","objectID":"/k8sSecret/:1:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" docker 仓库凭据以下类型用以存放用于访问容器镜像仓库的凭据： kubernetes.io/dockercfg: 是一种保留类型，用来存放 ~/.dockercfg 文件的序列化形式。 该文件是配置 Docker 命令行的一种老旧形式。使用此 Secret 类型时，你需要确保 Secret 的 data 字段中包含名为 .dockercfg 的主键，其对应键值是用 base64 编码的某 ~/.dockercfg 文件的内容。示例： apiVersion: v1 kind: Secret metadata: name: secret-dockercfg type: kubernetes.io/dockercfg data: .dockercfg: | \"\u003cbase64 encoded ~/.dockercfg file\u003e\" kubernetes.io/dockerconfigjson: 被设计用来保存 JSON 数据的序列化形式， 该 JSON 也遵从 ~/.docker/config.json 文件的格式规则，而后者是 ~/.dockercfg 的新版本格式。使用此 Secret 类型时，Secret 对象的 data 字段必须包含 .dockerconfigjson 键，其键值为 base64 编码的字符串包含 ~/.docker/config.json 文件的内容。 当你使用清单文件来创建这两类 Secret 时，API 服务器会检查 data 字段中是否存在所期望的主键， 并且验证其中所提供的键值是否是合法的 JSON 数据。 不过，API 服务器不会检查 JSON 数据本身是否是一个合法的 Docker 配置文件内容。 ","date":"2020-03-11","objectID":"/k8sSecret/:2:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" 基于身份认证使用基本身份认证 Secret时，data 字段必须包含以下两个键之一： username: 用于身份认证的用户名 password: 用于身份认证的密码或令牌 apiVersion: v1 kind: Secret metadata: name: secret-basic-auth type: kubernetes.io/basic-auth stringData: username: admin # kubernetes.io/basic-auth 类型的必需字段 password: t0p-Secret # kubernetes.io/basic-auth 类型的必需字段 ","date":"2020-03-11","objectID":"/k8sSecret/:3:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" SSH 身份认证 apiVersion: v1 kind: Secret metadata: name: secret-ssh-auth type: kubernetes.io/ssh-auth data: # 此例中的实际数据被截断，ssh-privatekey 键值对是 ssh-auth 类型必须的 ssh-privatekey: | MIIEpQIBAAKCAQEAulqb/Y ... ","date":"2020-03-11","objectID":"/k8sSecret/:4:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" TLS SecretTLS Secret类型 用来存放通常要使用的TLS证书及其相关密钥场合。一种典型用法是为 Ingress 资源配置传输过程中的数据加密，不过也可以用于其他资源或者直接在负载中使用。 apiVersion: v1 kind: Secret metadata: name: secret-tls type: kubernetes.io/tls data: # 此例中的数据被截断， tls.key 和 tls.crt 键值对是必须的 # 不要包含证书中 --------BEGIN CERTIFICATE----- 和 -------END CERTIFICATE---- 这两行 tls.crt: | MIIC2DCCAcCgAwIBAgIBATANBgkqh ... tls.key: | MIIEpgIBAAKCAQEA7yn3bRHQ5FHMQ ... 如果是命令行创建，钥证书必须是 RFC 7468 中 5.1节中所规定的 DER 格式，私钥必须是 DER 格式的 PKCS（11节） kubectl create secret tls my-tls-secret \\ --cert=path/to/cert/file \\ --key=path/to/key/file ","date":"2020-03-11","objectID":"/k8sSecret/:5:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" 启动引导令牌 Secret启动引导令牌 Secret 清单文件可能看起来像下面这样： apiVersion: v1 kind: Secret metadata: # name 必须是 \"bootstrap-token-\u003ctoken id\u003e\" 格式的 name: bootstrap-token-07401b # 令牌必须存在于 kube-system 名字空间中 namespace: kube-system # type 必须是 'bootstrap.kubernetes.io/token' type: bootstrap.kubernetes.io/token stringData: # 供人阅读的描述，可选。 description: \"The default bootstrap token generated by 'kubeadm init'.\" # 令牌 ID 和秘密信息，它们必须符合正则表达式 [a-z0-9]{6}\\.[a-z0-9]{16}。必需 token-id: 07401b token-secret: f395accd246ae52d # 可选的过期时间字段，一个使用 RFC3339 来编码的 UTC 绝对时间。可选 expiration: 2017-03-10T03:22:11Z # 允许的用法（可选） usage-bootstrap-authentication: \"true\" # 可用于 authentication （身份认证） usage-bootstrap-signing: \"true\" # 用于 cluster-info ConfigMap 的签名 # 令牌要认证为的额外组，必须以 \"system:bootstrappers:\" 开头 auth-extra-groups: system:bootstrappers:worker,system:bootstrappers:ingress 禁止更改 SecretSecret.immutable 字段值为 true 时，创建的 Secret 资源不可被更改，只能删除并重新创建且现有的 Pod 将维持对已删除 Secret 的挂载点，也是需要重建这些 pod pod 中使用 SecretSecret 可以以数据卷的形式挂载或作为环境变量暴露给 Pod 中的容器使用。 pod 以数据卷引用 Secret 资源是必须的（pod.spec.volumes.secret.optional 值为 false），当无法读取Secret资源内容（Secret资源不存在、缺少指定的键、临时性地出现 API 服务器网络连接问题等）时kubelet会根据重启策略周期性重启pod，kubelet 也会为该 Pod 报告 Event 事件，给出读取 Secret 时遇到的问题细节。 通常被 pod 以数据卷引用的 Secret 资源数据被更新时，Kubernetes 会跟踪到这一操作并更新卷中的数据。这功能取决于存储卷类型，如 subPath 形式挂载的容器就收不到Secret 更新。更新的方式是保证最终一致性，从 Secret 被更新到新的主键被投射到 Pod 中，中间存在一个延迟。 这一延迟的上限是 kubelet 的同步周期加上缓存的传播延迟。这种数据更新是由 kubelet 完成，configMapAndSecretChangeDetectionStrategy 配置字段可以指定更新方式，它有以下值： Watch: 默认值，使用 watch 机制获取更新，这种方式更新延迟最长 Get: 从集群的 API 服务器上轮询获取，这种方式更新延迟取觉于网络 Cache: 使用 TTL 缓存，这种方式在缓存有效期内最快 以下是一个数据卷示例，在 pod 中 /etc/secret-volume/ 目录（原本的目录和文件会被覆盖）下会根据secret.data的健创建文件，其值其会解码为文件内容 --- apiVersion: v1 kind: Secret metadata: name: test-secret data: username: bXktYXBw password: Mzk1MjgkdmRnN0pi --- apiVersion: v1 kind: Pod metadata: name: secret-test-pod spec: containers: - name: test-container image: nginx volumeMounts: # name 必须与下面的卷名匹配 - name: secret-volume mountPath: /etc/secret-volume readOnly: true # 指定为 true # Secret 数据通过一个卷暴露给该 Pod 中的容器 volumes: - name: secret-volume secret: secretName: test-secret # 指定使用 Secret 对象名称 如果想修改默认的映射路径，可使用 pod..spec.volumes[].secret.items.path 字段改变。下面是官方示例 apiVersion: v1 kind: Pod metadata: name: mypod spec: containers: ... - name: mypod image: redis volumeMounts: - name: foo mountPath: \"/etc/foo\" readOnly: true volumes: - name: foo secret: secretName: mysecret items: - key: username # 只用指定的 key 才会被挂载 path: my-group/my-username # 挂载在 /etc/foo/my-groug/my-username Secret 文件默认的权限为 0644，可以通过 Pod.spec.volunes.secret.defaultMode 字段修改。该字段值是 8 进制，但 json 不支持，因此要用 10 进制。yaml 是支持的 apiVersion: v1 kind: Pod metadata: name: mypod spec: containers: - name: mypod image: redis volumeMounts: - name: foo mountPath: \"/etc/foo\" volumes: - name: foo secret: secretName: mysecret defaultMode: 256 # 等效 0400 可以通过 Pod.spec.containers.env[].valueFrom.secretKeyRef 字段使用Secret资源数据，如果变量名称不满足规范，则无法创建其变量，但 pod 仍然可以启用 kubectl create secret generic backend-user --from-literal=backend-username='backend-admin' kubectl create secret generic db-user --from-literal=db-username='db-admin' apiVersion: v1 kind: Pod metadata: name: envvars-multiple-secrets spec: containers: - name: envars-test-container image: nginx env: - name: BACKEND_USERNAME valueFrom: secretKeyRef: name: backend-user key: backend-username - name: DB_USERNAME valueFrom: secretKeyRef: name: db-user # Secret 资源名称 key: db-username # 键名 # kubectl exec -i -t envvars-multiple-secrets -- /bin/sh -c 'env | grep _USERNAME' DB_USERNAME=db-admin BACKEND_USERNAME=backend-admin 在 k8s v1.6 之后 Pod.spec.containers.envFrom.secretRef.name 可以直接引用 Secret资源 kubectl create secret generic test-secret --from-literal=username='my-app' --from-literal=password='39528$vdg7Jb' apiVersion: v1 kind: Pod metadata: name: envfrom-secret spec: containers: - name: envars-test-container image: nginx envFrom: - secretRef: name: test-secret # kubectl exec -i -t envfrom-secret -- /bin/sh -c 'echo \"username: $username\\npassword: $password\\n\"' username: my-app pass","date":"2020-03-11","objectID":"/k8sSecret/:6:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" 使用 kubectl 命令创建kubectl create secret \u003c类型\u003e \u003c名称\u003e [选项] 命令可以创建 Secret 对象 有以下类型： TLS：TLS 证书加密 docker-registry： docker 仓库 generic：引用本地文件、目录、文字 generic 类型选项： --from-file=文件名 引用文件，可以使用多次本选项引用多个文件。文件名称为键，内容为值 --from-file=键=文件名 引用文件内容，可以使用多次本选项引用多个文件。内容为值 --from-litera=键=值 直接指定键值对，可以多次本选项，如存在特殊字符，则需要转义符 （\\） --from-env-file= 引用文件作中的内容对作为环境变量。有以下要求： 1： 不能和 --from-file 或 --from-litera 选项组合使用 2： 文本内容以等号作为键值对的分隔符，即 键=值 的形式 3： 使用多个本选项时，最后一个生效 Secret 对象以键值对方式存储这些信息在 Secret.data 字段中： 键：文件名或自定义的字符 值：文件内容或自定义的字符，为了安全，默认情况下以加密方式存储。 kubectl get 和 kubectl describe 命令只会显示经过 base64 编码得出的字符串 示例：下面示例中 --from-literal 选项值含义 \\ 表示转义符； \\\\ 表示单纯的 \\ (转义了转义符)；pa.file 文件内容则不需要转义 [root@master yaml]# cat pa.file mw\\%k\\@2\\*fwwxg5j0t [root@master yaml]# cat va.file wanglaojinll [root@master yaml]# kubectl create secret generic my-secret --from-file=va.file --from-file=account=pa.file --from-literal=lil4zxmtjd=CQ5b5\\@NW\\\\6hu\\^qhwLY5 secret/my-secret created [root@master yaml]# kubectl get secrets my-secret -o yaml apiVersion: v1 data: account: bXdcJWtcQDJcKmZ3d3hnNWowdAo= lil4zxmtjd: Q1E1YjVATldcNmh1XnFod0xZNQ== va.file: d2FuZ2xhb2ppbmxsCg== kind: Secret ... [root@master yaml]# echo \"bXdcJWtcQDJcKmZ3d3hnNWowdAo=\" | base64 --decode mw\\%k\\@2\\*fwwxg5j0t [root@master yaml]# echo 'Q1E1YjVATldcNmh1XnFod0xZNQ==' | base64 --decode CQ5b5@NW\\6hu^qhwLY5 示例：指定多个 --from-env-file 选项只有最后一个生效 [root@master yaml]# cat env.file data-2020=file2020 [root@master yaml]# cat env2.file Meiyou=mima9HE [root@master yaml]# kubectl create secret generic my-secret-env --from-env-file=env.file --from-env-file=env2.file secret/my-secret-env created [root@master yaml]# kubectl get secrets my-secret-env -o yaml apiVersion: v1 data: Meiyou: bWltYTlIRQ== kind: Secret ... ","date":"2020-03-11","objectID":"/k8sSecret/:7:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" 编辑 Secret使用 kubectl edit secret \u003csecret名称\u003e 直接更新相应的字段（ Secret.data 或 Secret.stringData） 从生成器创建 Secretk8s v1.14 开始可以使用 kustomize 管理对象 安全相关","date":"2020-03-11","objectID":"/k8sSecret/:8:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" 保护因为 Secret 对象可以独立与使用它们的 Pod 创建，因此 ，在创建、查看、编辑 Pod 的流程中 Secret 被暴露的风险较小。系统还可以争对 Secret 对象采取额外的预防措施，例如避免写入磁盘容易暴露的位置。当节点上的 Pod 使用 Seret 时，对应的 Secret 才会发送到该节点上，但不会写入磁盘，而是存储在 tmpfs 中。Pod 被删除时，存储在 tmpfs 中的数据也会删除。同一节点上的很多个 pod 可能拥有多个 secret。但是，只有 pod 请求的 secret 在其容器中才是可见的。因此，一个 pod 不能访问另一个 Pod 的 secret。Pod 中有多个容器。但是，pod 中的每个容器必须请求其挂载卷中的 secret 卷才能在容器内可见 用户与 API 服务之间的通信以及从 API 服务到 kubelet 的通信都受到 SSL/TLS 的保护。通过这些通道传输时，secret 受到保护 ","date":"2020-03-11","objectID":"/k8sSecret/:9:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["k8s"],"content":" 风险API 服务的 的 secret 数据以纯文本的方式存储在 etcd 中，因此 管理员应该为集群数据开启静态加密（至少需要 k8s:1.13 版本） 管理员应该限制 admin 用户访问 etcd 管理员可以在不再使用时删除 etcd 使用的磁盘 如果 etcd 运行在集群内，管理员应该确保 etcd 之间的通信使用 SSL/TLS 进行加密 将 secret 数据编码为 base64 的清单文件，共享该文件或将其检入代码库，这样的话该密码将会被泄露。 Base64 编码不是一种加密方式，一样也是纯文本 应用程序在从卷中读取 secret 后仍然需要保护 secret 的值，例如不会意外记录或发送给不信任方 可以创建和使用 secret 的 pod 的用户也可以看到该 secret 的值。即使 API server 策略不允许用户读取 secret 对象，用户也可以运行暴露 secret 的 pod 任何节点的 root 用户都可以通过模拟 kubelet 来读取 API server 中的任何 secret ","date":"2020-03-11","objectID":"/k8sSecret/:10:0","tags":["k8s","secret"],"title":"k8s Secret 对象","uri":"/k8sSecret/"},{"categories":["markdown"],"content":" [url]: markdown 语法Markdown 是一种轻量级标记语言，使用易读易写的纯文本格式编写文档，然后可以使用简单的方法转换成有效的 XHTML（或者HTML）文档。该语法只对应 HTML 标记中的一小部分功能，只覆盖纯文本可以涵盖的范围。可以在 Markdown 中直接添加 html 标签。在 html 标签的前后一行要保留一行空行，且标签中不能使用 Markdown 语法 索引：markdown语法基础操作 ","date":"2019-11-16","objectID":"/markdown/:0:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 特殊字符要显示以下字符需要使用转义符 \\ ： \\ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 ## 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 ","date":"2019-11-16","objectID":"/markdown/:1:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 段落和换行一个 Markdown 段落是有一个或多个连续的文本组成，前后都是空行（可以有空格和制表符） Markdown 不会按照文本排版一样换行，多行文本显示为 1 行，如果想要换行需要使用 \u003cbr /\u003e 标签或连续输入 2 个以上的空格再回车 ","date":"2019-11-16","objectID":"/markdown/:2:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 标题Markdown 支持 2 种标题的语法: Setext 样式和 atx 样式 Setext 样式是用底线的方式构成，利用 = 表示最高阶级标题；- 表示第二阶标题，不限制数量 示例 这是最高阶级标题 = 这是第二阶级标题 - 这是最高阶级标题","date":"2019-11-16","objectID":"/markdown/:3:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 这是第二阶级标题Atx 样式是在行首插入 1 到 6 个 # 号对应 1 到 6 阶级标题 闭合式的 Atx 样式 （在标题左右凉边都使用 # 号）只是纯粹让排版看起来好看一些，没有实际差别；行尾的 # 号后面的数量可以是任意个。还可以加入文本，这些都是不显示的 示例： ##### 这是第四阶级标题 # fdsfd ###### 这是第五阶级标题 ####### 这是第六阶级标题 这是第四阶级标题 这是第五阶级标题####### 这是第六阶级标题 ","date":"2019-11-16","objectID":"/markdown/:4:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 区块引用在行首使用 \u003e 可以建立一个区块引用。引用的区块可以使用其他的 Markdown 语法 一个区块引用段落可以在每行行首都使用 \u003e ，也可以只在段落首行行首使用 \u003e ，这两种看起来是没有差别的，还可以嵌套使用 示例 ： \u003e 第一行 \u003cbr /\u003e 第二行 \u003e 第一行 \u003cbr /\u003e \u003e 第二行 \u003e 第一行 \u003cbr /\u003e 第二行 \u003e\u003e 第三行 \u003e 第一行 \u003cbr /\u003e \u003e 第二行 \u003e\u003e 第三行 第一行 第二行 第一行 第二行 第一行 第二行 第三行 第一行 第二行 第三行 ","date":"2019-11-16","objectID":"/markdown/:5:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 列表Markdown 支持无序列表和有序列表 无序列表在行首使用 * 、+ 、- 作为列表标记 示例 ： - aaa + bbb * ccc aaa bbb ccc 有序列表在行首使用 数字+. 作为列表标记，数字不影响输出结果 示例： 1. aaa 111. bbb 0. ccc aaa bbb ccc 列表项目可以包含多个段落或区块，每个项目中的段落或区块必须是 4 个空格或 1 个制表符（段落或区块首行行首必须缩进，其他行可以不用缩进） 示例： 1. 第 1 段 aaa \u003cbr /\u003e bbb 2. 第 2 段 \u003e aaa \u003cbr /\u003e bbb 第 1 段 aaa bbb 第 2 段 aaa bbb ","date":"2019-11-16","objectID":"/markdown/:6:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 代码如果要标记一小段行内代码，你可以用反引号把它包起来（`），例如： abc 如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段： ``sd`f`s`` ","date":"2019-11-16","objectID":"/markdown/:7:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 代码区块代码区块内的文本会按照原本内容显示 建立代码区块方法： 在首行使用 4 个空格或 1 个制表符，这种方式会自动减少行首的 4 个空格或 1 个制表符 建立代码的方式包含多行（只需要在代码块上一行和下一行加入反引号） 示例： 在首行使用 4 个空格或 1 个制表符 在上一行缩进的基础再次缩进 在首行使用 4 个空格或 1 个制表符 在上一行缩进的基础再次缩进 ","date":"2019-11-16","objectID":"/markdown/:8:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 分割线一行行首用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格 示例： * * * *** ***** - - - ---- ","date":"2019-11-16","objectID":"/markdown/:9:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 强调可以使用任意符号作为标记强调字词，使用什么符号开始就需要使用什么符号结束，符号数量没有限制 常用样式： 加粗：** 倾斜：_ 划线：~~ 示例： **加粗** \u003cbr /\u003e _倾斜_ \u003cbr /\u003e ~~划线~~ \u003cbr /\u003e 加粗 倾斜 划线 ","date":"2019-11-16","objectID":"/markdown/:10:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 链接Markdown 支持两种形式的链接语法： 行内式和参考式两种形式 链接内容定义的形式为： 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字 接着一个冒号 接着链接的网址 选择性地接着 title 内容，可以用单引号、双引号或是括弧包着 要建立一个行内式的链接，只要在方块括号后面紧接着圆括号并插入 URL 地址链接即可，如果你还想要加上链接的 title 文字，只要在地址后面，用双引号把 title 文字包起来即可 示例： 这是[百度](https://www.baidu.com \"baidu\")地址 这是百度地址 参考式的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记： 示例： [百度]:https://www.baidu.com \"baidu\" 这是[百度]地址 或者 这是[引用链接][百度]地址 这是百度地址 或者 这是[引用链接] 链接百度地址地址 还有一种直接使用链接方式，这种方式会转换为 html 的 a 标签 示例： \u003chttp://baidu.com\u003e \u003ca href=\"http://baidu.com\"\u003ebaidu\u003c/a\u003e \u0026lt;https://www.baidu.com\u0026gt; http://baidu.com baidu \u003chttps://www.baidu.com\u003e ","date":"2019-11-16","objectID":"/markdown/:11:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 图片和 连接 使用方式类似，只是调用时需要使用 ! 调用 图片定义的形式为： 一个惊叹号 ! 接着一个方括号，里面放上图片的替代文字 接着一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上选择性的 ’title’ 文字 Markdown 还没有办法指定图片的宽高，如果你需要的话，你可以使用普通的 \u003cimg\u003e 标签 ![markdown](http://note.youdao.com/iyoudao/wp-content/uploads/2016/09/8881.jpg \"Optional title\") [markdown]:http://note.youdao.com/iyoudao/wp-content/uploads/2016/09/8881.jpg \"baidu\" ![markdown] markdown markdown ","date":"2019-11-16","objectID":"/markdown/:12:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 文本内跳转需要使用 html 标签实现 //span 标签可以放在任意位置 // id号必须是唯一的，可以是文本与字符串 // 显示文本可以为空：\u003cspan id=\"10\"\u003e\u003c/span\u003e // \u003cspan id=\"10\"\u003e显示的文本\u003c/span\u003e \u003cspan id=\"10\"\u003e索引：markdown语法基础操作\u003c/span\u003e // 跳转显示内容不能为空 [跳转显示内容](#ID号) 跳转到id为10的位置 ","date":"2019-11-16","objectID":"/markdown/:13:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["markdown"],"content":" 折叠 \u003cdetails\u003e \u003csummary\u003e这是标题，点击展开内容\u003c/summary\u003e 这是内容 \u003c!-- 这是注释 --\u003e \u003c/details\u003e 这是标题，点击展开内容 这是内容 页内跳转需要使用 HTML 标签 ","date":"2019-11-16","objectID":"/markdown/:14:0","tags":["markdown"],"title":"markdown 语法","uri":"/markdown/"},{"categories":["linux"],"content":" 环境： cneots：7 bash：4.2.46 以下内容来自： 艾欧里亚ゞ-灵活使用getconf命令来获取系统信息 张映-stty 说明本文大部分都是简单易用的命令，多数为 bash 内置命令 标注的内部命令或外部命令都是以 bash 为基础 命令有哪个安装包提供 语法格式 可选的常见选项 可选的常见操作 示例，如果有必须带注释信息 查看命令是否为 shell 内置命令type 命令被用于判断另外一个命令是否是内置命令 # bash 内置命令 使用方式：type [option] command 常见选项 -a 显示一个名字的所有可能 -t 判断一个名字当前是否是alias、keyword、function、builtin、file -p 查看一个外部命令的执行路径 -P 查看内部命令路径 查看 cd 命令是否为 shell 内置命令 [root@localhost ~]# type -a cd cd is a shell builtin cd is /usr/bin/cd [root@localhost ~]# type -a wget wget is /usr/bin/wget 查看和清除命令哈希表hash 命令用于查看和清除命令哈希表，当执行命令的时候，系统将先查询哈希表 # bash 内置命令 使用方式：hash [-lr] [-p pathname] [-dt] [name ...] 常见选项： -l 显示哈希表 -r 清除哈希表 -d\u003c名称\u003e 清除哈希表 -p\u003c路径\u003e 向哈希表中增加内容 -t\u003c命令\u003e 显示命令的完整路径 查看当前缓存外部命令 [root@localhost ~]# hash hits command 2 /usr/bin/man 1 /usr/bin/info [root@localhost ~]# hash -l builtin hash -p /usr/bin/man man builtin hash -p /usr/bin/info info 清除 hash 记录 [root@localhost ~]# hash -r [root@localhost ~]# type man man is /usr/bin/man 查找命令的二进制文件，源文件和 man 手册文件whereis 命令可以查找命令的二进制执行文件路径、源文件、和 man 手册路径 # 非bash内置命令 使用方式： whereis [options] [-BMS directory... -f] name... 常见选项 -b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件的路径 -S 指定搜索源代码文件的路径 查看 whereis 命令的二进制文件路径 [root@localhost ~]# whereis -b whereis whereis: /usr/bin/whereis 查看命令的二进制文件位置which 命令用于查找 $PATH 变量内的命令的完整二进制路径 # 外部命令 使用方式：which [options] [--] COMMAND [...] -a 查找全部内容，而非第一个文件 -n \u003c文件名长度\u003e 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名 -p \u003c文件名长度\u003e 与-n参数相同，但此处的\u003c文件名长度\u003e包括了文件的路径 -w 指定输出时栏位的宽度 -V 显示版本信息 查看 docker 命令的二进制文件位置 [root@c8 pag]# which docker /usr/bin/docker 帮助手册页面man 命令可以查看命令使用帮助信息和文件帮助信息 # 非bash内置命令 使用方式：man [OPTION...] [SECTION] PAGE... 常见选项： -C, --config-file=文件 使用该用户设置文件 -d, --debug 输出调试信息 -D, --default 将所有选项都重置为默认值 --warnings[=警告] 开启 groff 的警告 -f, --whatis 等同于 whatis 命令 -k, --apropos 等同于 apropos 命令 -w, --where, --path, --location 查看手册页的物理位置 -l, --local-file 把“手册页”参数当成本地文件名来解读 -L, --locale=区域 定义本次手册页搜索所采用的区域设置 -m, --systems=系统 指定其他操作系统 -M, --manpath=路径 设置搜索手册页的路径为“路径” -i, --ignore-case 查找手册页时不区分大小写字母 (默认) -I, --match-case 查找手册页时区分大小写字母 查看 man 命令的 man 手册 [root@localhost ~]# man man 查看 man 手册页描述whatis命令是用于查询一个命令执行什么功能，并将查询结果打印到终端上。 等效 man -f 命令 # 非 bash 内置命令 使用方式： whatis [options] command 常见选项： -w 使用通配符 -r 使用正则表达式 示例 ls 命令帮助手册信息 [root@localhost ~]# man -f ls ls (1) - list directory contents 搜索 man 手册名称和描述apropos 命令可以在 whatis 数据库中查找字符串 # 待补充 查看内置命令帮助信息help 命令可以查看内置命令帮信息 # bash内置命令 使用方法：help [-dms] [pattern ... 查看 help 命令帮助 [root@localhost ~]# help help help: help [-dms] [pattern ...] Display information about builtin commands. ... GUN 项目帮助手册info 包含大量的 GUN 项目帮助信息，因此，查看 GUN 项目帮助信息时建议使用该命令 # 非bash内置命令 使用方式： info [OPTION]... [MENU-ITEM...] 常见选项： -k, --apropos=STRING 在所有手册页的索引中查找 STRING。 -d, --directory=DIR 将 DIR 添加至 INFOPATH。 --dribble=FILENAME 将用户的击键条目在 FILENAME 中。 -f, --file=FILENAME 指定想浏览的 Info 文件。 -h, --help 显示此帮助并退出。 --index-search=STRING 跳转至索引条目 STRING 所指的节点。 -n, --node=NODENAME 在首个浏览过的 Info 文件中指定节点。 -o, --output=FILENAME 将选中的节点全输出至 FILENAME。 -R, --raw-escapes 输出“原始”的 ANSI 转义符(默认)。 --no-raw-escapes 将转义符输出为普通文本。 --restore=FILENAME 从 FILENAME 中读取初始击键条目。 -O, --show-options, --usage 跳转至命令行选项节点。 --subnodes 递归输出菜单项。 --vi-keys 使用类似于 vi 和 less 的按键绑定。 --version 显示版本信息并退出。 -w, --where, --location 打印 Info 文件在系统中的位置。 常见快捷键： ? 查看info的常用快捷键。 N 显示（相对于本节点的）下一节点的文档内容。 P 显示（相对于本节点的）前一节点的文档内容。 U 进入当前命令所在的主题。 M 敲M键后输入命令的名称就可以查看该命令的帮助文档了。 G 敲G键后输入主题名称，进入该主题。 L 回到上一个访问的页面。 SPACE 向前滚动一页。 BACKUP或DEL键 向后滚动一页。 Q 退出info。 ？ 显示帮助窗口，在帮助窗口中有以下操作： Ctrl-x 0 闭帮助窗口 Ctrl-x Ctrl-c 关闭整个 Info q 退出 info n 打开与本 Node 关联的下一个 Node p 打开与本 Node 关联的前一个 Node u 打开与本 Node 关联的上一个 Node l 回到上一次访问的 Node m或g 选择一个菜单项（Node 的名字）输入指定菜单的名字后按回车，打开指定菜单项关联的 Node 空格键 下一页（PageDown 也可以，下一页从当前页的最后两行开始算起）下一个 Node （若当前页在 Node 文档的末尾） Del 键 上一页（PageUp 也可以，上一页从当前页的开始两行开始算起）上一个 Node （若当前页 Node 文档的开始） b 或 t 或 Home 文档的开始（b 是 begining 的意思） e 或 End 文档的末尾（b 是 ending 的意思） Ctrl-l 刷新当前页，若当前文档显示情况有问题时 Ctrl-g 取消所键入的指令 查看 info 文件位置 [root@localhost ~]# info -w info /usr/share/info/info.info.gz 查看 sed 命令帮助信息 [root@localhost ~","date":"2019-01-26","objectID":"/cmd/:0:0","tags":["linux","命令"],"title":"部分linux命令集合","uri":"/cmd/"},{"categories":["linux"],"content":" ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" xiaosi/2018-12-10 使用环境： centos:7 内容来自以下文档： sinat_38723234: 容器内TCP并发连接数参数解释 187J3X1: backlog参数对TCP连接建立的影响 服务器需要连接网络需要几个必要的信息 IP和掩码 路由（网关） 配置网络方式（命令行临时有效、配置文件永久有效） centos6：ipconfig家族、配置文件 centos7：ip家族、配置文件、ss、tc ipcofnigcentos7使用ipcofnig家族命令 [root@vps ~]# yum install -y net-tools 语法：ifconfig [options] [interface] 常用选项 -a：显示所有 ifconfig interface options | address … 常用选项 up/dowm：启动或关闭 IP/MASK：修改IP和掩码 DNS配置文件：/etc/resolv.conf nameserver IP 查看DNS解析 正向解析 dig -t A hostname host -t A hostname 反向解析 dig -x IP host -x PIR IP netstat netstat：查看网络连接，路由表，接口统计信息，伪装连接和组播成员 语法：netstat 选项 -t：TCP协议 -n：数值 -u：UDP协议 -w：裸套接字 -l：监听状态 -e：拓展格式 -p：显示进程及PID -a：显示所有 -r：内核路由表 -i：显示接口数据统计 IP Ip命令用于显示/配置 路由，设备，策略路由和隧道 语法：ip [ OPTIONS ] OBJECT { COMMAND | help } link：管理设备 #查看ip link命令帮助 [root@m1 ~]# man ip-link 语法：ip link { COMMAND | help } [root@m1 ~]# man ip-link #启用网卡设备 [root@m1 ~]# ip link set dev ens33 up #禁用网卡设备 [root@m1 ~]# ip link set dev ens33 down #查看设备属性 [root@m1 ~]# ip link show dev ens33 查看活动的设备 [root@m1 ~]# ip link show up addr：IP管理 语法：ip address { add |del |show] ip/mask [其他命令] label \"name\"： 指定网卡别名 scope {global |link |host}：指定作用域（全局|链接|本机） broadcast ADDRESS：指定广播地址 #查看帮助 [root@m1 ~]# man ip-addres #添加ip [root@m1 ~]# ip addr add 192.168.150.129/24 dev ens33 #删除IP [root@m1 ~]# ip addr del 192.168.150.129/24 dev ens33 #清除网卡所有地址 [root@m1 ~]# ip addr flush dev ens33 #查看所有地址 [root@m1 ~]# p address show #查看活动的地址 [root@vps ~]# ip address show up #查看echo0的地址 [root@vps ~]# ip address show dev eth0 #添加路由（主机路由可以缺省mask） [root@m1 ~]# ip ro add 192.168.150.12 via 192.168.150.2 dev ens33 #添加默认路由 [root@m1 ~]# ip route add default via 192.168.150.22 dev ens33 #删除路由 [root@m1 ~]# ip ro del default via 192.168.150.22 #清空路由表 [root@m1 ~]# ip ro del flush #查看路由表 [root@m1 ~]# ip ro show centos7网卡命令方式 （1）以Firmware或BIOS主板上集成设备提供的索引信息命名：en0* （2）以Firmware或BIOSPCI-E扩展槽提供的索引信息和虚拟设备命名：ens* （3）以硬件接口物理位置信息命名：enp* （4）以用户显示启动或MAC命令：enx* （5）以上都不可用，使用传统方式：eth* en：enthernet wl：wlan ww：wwan NetworkManagercetos7使用NetworkManager控制网络 图形化配置网络 [root@localhost ~]# nmtui nmcli命令是用于控制NetworkManager的命令行工具 # 查看简单的命令帮助 [root@localhost ~]# nmcli --help Usage: nmcli [OPTIONS] OBJECT { COMMAND | help } #查看connetion使用帮助 [root@localhost ~]# nmcli c -h #查看device使用帮助 [root@localhost ~]# nmcli d -h OBJECT和COMMAND可以用全称也可以用简称 connection 与device用法差不多 #查看设备状态。一块网卡可以有多个配置文件，但只能有一个生效 [root@localhost ~]# nmcli device status #显示所有连接状态连接 [root@localhost ~]# nmcli c s #只显示活动的连接 [root@localhost ~]# nmcli c s -a #只显示活动的设备 [root@localhost ~]# nmcli d s -a #查看设备属性 [root@localhost ~]# nmcli device show ens33 #查看链接属性 [root@localhost ~]# nmcli c s ens33 #添加一个配置文件。（con-name 文件配置名称； ifname 网卡设备名称；ip4 ipv4 ；gw4 ipv4网关） [root@localhost ~]# nmcli c add type ethernet con-name ens3a ifname ens33 ip4 192.168.157.132/24 gw4 192.168.157.3 Connection 'ens3a' (4a486c58-6dde-499a-b2e7-0d8bca75d10b) successfully added. #查看新键的配置文件 [root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens3a TYPE=Ethernet BOOTPROTO=none IPADDR=192.168.157.132 PREFIX=24 GATEWAY=192.168.157.3 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=ens3a UUID=4a486c58-6dde-499a-b2e7-0d8bca75d10b DEVICE=ens33 ONBOOT=yes 修改语法：nmcli c mod 连接名称 属性 值 （属性值+-表示曾减，如添加ip +ipv4 ） #修改IPV4 （ip4=ipv4.addresses） [root@localhost ~]# nmcli c modify ens3a ip4 \"192.168.157.131/24\" #修改网关 (gw4=ipv4.gateway) [root@localhost ~]# nmcli c modify ens3a gw4 \"192.168.157.2\" #修改DNS [root@localhost ~]# nmcli c modify ens3a ipv4.dns \"8.8.8.8\" 其他修改： ipv4.method 修改连接方式(manual=none,auto=dhcp) connection.autoconnect 是否开机启动 connection.id 连接名称 connection.interface-name 设备名称 #重新加载 、启用，使ens3a配置文件生效 [root@localhost ~]# nmcli c reload [root@localhost ~]# nmcli c up ens3a #删除配置文件 [root@localhost ~]# nmcli c del 配置文件名称 修改主机名： [root@yh ~]# hostnamectl set-hostname yh.c7.cc 网卡配置文件信息： [root@m1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=\"Ethernet\" #网卡接口类型 P","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:0:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 配置网卡多队列 其他工具","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:1:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" wget # 断点续传下载文件 wget -c $url ## 下载整站 wget -r -p -np -k $url ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:2:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" cur # 发送网络连接（常用) curl -XGET $url ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:3:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 连通性检测ping google.com ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:4:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 到对端路由检测tracepath google.com ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:5:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 域名检测dig google.com nslookup google.com ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:6:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 网络扫描工具nmap ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:7:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 压力测试iperf ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:8:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 全方位监控工具（好东西)nmon ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:9:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 压力测试wrk ab webbench http_load tcp 连接内核参数说明有以下参数 [root@localhost ~]# ll /proc/sys/net/ipv4/tcp_* | awk -F'/' '{print \"net.ipv4.tcp_\"$NF}' net.ipv4.tcp_tcp_abort_on_overflow net.ipv4.tcp_tcp_adv_win_scale net.ipv4.tcp_tcp_allowed_congestion_control net.ipv4.tcp_tcp_app_win net.ipv4.tcp_tcp_autocorking net.ipv4.tcp_tcp_available_congestion_control net.ipv4.tcp_tcp_available_ulp net.ipv4.tcp_tcp_base_mss net.ipv4.tcp_tcp_challenge_ack_limit net.ipv4.tcp_tcp_comp_sack_delay_ns net.ipv4.tcp_tcp_comp_sack_nr net.ipv4.tcp_tcp_congestion_control net.ipv4.tcp_tcp_dsack net.ipv4.tcp_tcp_early_demux net.ipv4.tcp_tcp_early_retrans net.ipv4.tcp_tcp_ecn net.ipv4.tcp_tcp_ecn_fallback net.ipv4.tcp_tcp_fack net.ipv4.tcp_tcp_fastopen net.ipv4.tcp_tcp_fastopen_blackhole_timeout_sec net.ipv4.tcp_tcp_fastopen_key net.ipv4.tcp_tcp_fin_timeout net.ipv4.tcp_tcp_frto net.ipv4.tcp_tcp_fwmark_accept net.ipv4.tcp_tcp_invalid_ratelimit net.ipv4.tcp_tcp_keepalive_intvl net.ipv4.tcp_tcp_keepalive_probes net.ipv4.tcp_tcp_keepalive_time net.ipv4.tcp_tcp_l3mdev_accept net.ipv4.tcp_tcp_limit_output_bytes net.ipv4.tcp_tcp_low_latency net.ipv4.tcp_tcp_max_orphans net.ipv4.tcp_tcp_max_reordering net.ipv4.tcp_tcp_max_syn_backlog net.ipv4.tcp_tcp_max_tw_buckets net.ipv4.tcp_tcp_mem net.ipv4.tcp_tcp_min_rtt_wlen net.ipv4.tcp_tcp_min_snd_mss net.ipv4.tcp_tcp_min_tso_segs net.ipv4.tcp_tcp_moderate_rcvbuf net.ipv4.tcp_tcp_mtu_probe_floor net.ipv4.tcp_tcp_mtu_probing net.ipv4.tcp_tcp_no_metrics_save net.ipv4.tcp_tcp_notsent_lowat net.ipv4.tcp_tcp_orphan_retries net.ipv4.tcp_tcp_pacing_ca_ratio net.ipv4.tcp_tcp_pacing_ss_ratio net.ipv4.tcp_tcp_probe_interval net.ipv4.tcp_tcp_probe_threshold net.ipv4.tcp_tcp_recovery net.ipv4.tcp_tcp_reordering net.ipv4.tcp_tcp_retrans_collapse net.ipv4.tcp_tcp_retries1 net.ipv4.tcp_tcp_retries2 net.ipv4.tcp_tcp_rfc1337 net.ipv4.tcp_tcp_rmem net.ipv4.tcp_tcp_rx_skb_cache net.ipv4.tcp_tcp_sack net.ipv4.tcp_tcp_slow_start_after_idle net.ipv4.tcp_tcp_stdurg net.ipv4.tcp_tcp_synack_retries net.ipv4.tcp_tcp_syncookies net.ipv4.tcp_tcp_syn_retries net.ipv4.tcp_tcp_thin_linear_timeouts net.ipv4.tcp_tcp_timestamps net.ipv4.tcp_tcp_tso_win_divisor net.ipv4.tcp_tcp_tw_reuse net.ipv4.tcp_tcp_tx_skb_cache net.ipv4.tcp_tcp_window_scaling net.ipv4.tcp_tcp_wmem net.ipv4.tcp_tcp_workaround_signed_windows 查看方式 使用 sysctl -a | grep 查看 /proc/sys/net/ipv4/tcp_* 相关文件内容。如 cat /proc/sys/net/ipv4/tcp_max_syn_backlog 修改方式： 临时修改： 直接修改 /proc/sys/net/ipv4/ 目录下文件值。如 echo 3 \u003e /proc/sys/net/ipv4/tcp_syn_retries 使用 sysctl -w 修改，如 sysctl -w net.ipv4.tcp_max_syn_backlog=256 永久修改：在以下配置文件中加入参数与值，再使用 sysctl -p filename 加载文件 /etc/sysctl.conf /etc/sysctl.d/ /usr/lib/sysctl.d/00-system.conf /usr/lib/sysctl.d/ ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:10:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_abort_on_overflow # 0 表示关闭，1表示开启 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_abort_on_overflow 0 当TCP连接已经建立，并塞到程序监听backlog队列时，如果检测到backlog队列已经满员后，TCP连接状态会回退到SYN+ACK状态，假装TCP三次握手第三次客户端的ACK包没收到，让客户端重传ACK，以便快速进入ESTABLISHED状态。如果设置了net.ipv4.tcp_abort_on_overflow 参数，那么在检测到监听backlog 队列已满时，直接发RST包给客户端终止此连接，此时客户端程序会收到104 Connection reset by peer错误。 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:11:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_adv_win_scale","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:12:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_allowed_congestion_control","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:13:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_app_win","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:14:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_autocorking","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:15:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_available_congestion_control","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:16:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_available_ulp","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:17:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_base_mss","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:18:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_challenge_ack_limit","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:19:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_comp_sack_delay_ns","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:20:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_comp_sack_nr","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:21:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_congestion_control","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:22:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_dsack","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:23:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_early_demux","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:24:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_early_retrans","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:25:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_ecn","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:26:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_ecn_fallback","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:27:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_fack","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:28:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_fastopen","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:29:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_fastopen_blackhole_timeout_sec","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:30:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_fastopen_key","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:31:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_fin_timeoutTIME-WAIT 会持续 2MSL 时间，RFC 793 中规定 MSL 为2分钟，实际应用中可能不一样 # 查看 MSL 时间 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_fin_timeout 60 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:32:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_frto","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:33:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_fwmark_accept","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:34:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_invalid_ratelimit","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:35:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_keepalive_intvl","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:36:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_keepalive_probes","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:37:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_keepalive_time","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:38:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_l3mdev_accept","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:39:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_limit_output_bytes","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:40:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_low_latency","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:41:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_max_orphans","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:42:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_max_reordering","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:43:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_max_syn_backlog [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_max_syn_backlog 256 控制系统中处于 SYN_RECV 状态的 TCP 连接数量 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:44:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_max_tw_buckets","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:45:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_mem","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:46:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_min_rtt_wlen","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:47:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_min_snd_mss","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:48:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_min_tso_segs","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:49:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_moderate_rcvbuf","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:50:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_mtu_probe_floor","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:51:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_mtu_probing","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:52:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_no_metrics_save","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:53:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_notsent_lowat","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:54:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_orphan_retries","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:55:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_pacing_ca_ratio","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:56:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_pacing_ss_ratio","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:57:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_probe_interval","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:58:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_probe_threshold","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:59:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_recovery","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:60:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_reordering","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:61:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_retrans_collapse","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:62:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_retries1","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:63:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_retries2","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:64:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_rfc1337","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:65:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_rmem","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:66:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_rx_skb_cache","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:67:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_sack","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:68:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_slow_start_after_idle","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:69:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_stdurg","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:70:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_synack_retries [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_synack_retries 5 处于 SYN_RECV 状态时重传 SYN+ACK(第二次) 包的次数 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:71:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_syncookies # 1 表示开启 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_syncookies 1 是否打开 TCP 同步标签（SYN_COOKIES） 当该参数被设置为 1 且 SYN_RECV 队列满了之后，内核会对 SYN 包的回复做一定的修改，即，在响应的 SYN+ACK 包中，初始的序列号是由源 IP:Port、目的 IP:Port 及时间这五个参数共同计算出一个值组成精心组装的 TCP 包。由于 ACK 包中确认的序列号并不是之前计算出的值，恶意攻击者无法响应或误判，而请求者会根据收到的 SYN+ACK 包做正确的响应。启用 net.ipv4.tcp_syncookies 后，会忽略 net.ipv4.tcp_max_syn_backlog。 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:72:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_syn_retries [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_syn_retries 6 第一次握手的 SYN 超时重传次数 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:73:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_thin_linear_timeouts","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:74:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_timestamps # 打开 TCP 时间戳 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_timestamps 1 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:75:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_tso_win_divisor","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:76:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_tw_reuse # 值为 0 禁止将处于TIME-WAIT状态超过1秒的socket（TIME-WAIT的端口）用于新的TCP连接 # 值为 1 表示允许，但需要 net.ipv4.tcp_timestamps=1 # 2是只处理本机的lookback 流量 [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_tw_reuse 2 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:77:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_tw_recycle # 值为 1 表示开启，允许处于 TIME_WAIT 状态的连接被快速回收 # net.ipv4.tcp_timestamps = 1 才有效，注意时在 NAT 的网络下是不安全的! ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:78:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_tx_skb_cache","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:79:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_window_scaling","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:80:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_wmem","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:81:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.ipv4.tcp_workaround_signed_windows","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:82:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" net.core.somaxconn [root@localhost ~]# cat /proc/sys/net/core/somaxconn 4096 tcp listen 队列长度。 ","date":"2018-12-18","objectID":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/:83:0","tags":["ip","ipcofnig","ss","netstat","NetworkManager","网络配置"],"title":"网络配置","uri":"/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/"},{"categories":["linux"],"content":" 文件（打包）归档：tar 语法：tar [OPTION...] [自定义名称] FILE… -c 创建打包 -C 解压到指定目录 -x 从打包的文件中还原文件 -v 显示各个归类文档名称 -t 列出已经归类的文档 -z 调用gzip 压缩或解压 -j 调用bzip2 压缩或解压 -J 调用 xz 压缩或解压 -f 文档的存储设备，此选项必须为最后一项 --one-file-system 创建归档时保存在本地文件系统中 zip/unzip 压缩/解压 默认后缀名.zip 语法：zip [option...] [file...] -r：递归压缩，将指定目录下所有子目录或文件全部压缩 -F：尝试修复损坏的压缩文件 -n：压缩级比为n（0\u003e=n\u003c=9 -d：解压到指定目录 -v：查询压缩文件信息 并不解压 #只能对文件压缩，即便压缩目录 也只能压缩目录内的文件 gzip/gunzip,/zcat压缩/解压/，默认后缀名.gz 语法：gzip [option...] [file...] -d：对压缩文件进行解压，同效guzip -l：查看压缩文件信息 -c：将压缩结果标准输出 -n：压缩级比为n（0\u003e=n\u003c=9） zcat FILE 查看文件内存但不压缩 #只能对文件压缩，即便压缩目录 也只能压缩目录内的文件 bzip2 压缩， 默认后缀.bz2 语法：bzip2 [option...] [file...] -d：对压缩文件解压，同效bunzip2 -v：压缩或解压时显示详情信息 -k：保留原文件 -n：压缩比为n（0\u003e=n\u003c=9 bzcat FILE 查看文件内存但不压缩 #只能对文件压缩，即便压缩目录 也只能压缩目录内的文件 xz 压缩，默认后缀.xz 语法：xz [option...] [file...] -d：对压缩文件解压，同效bunzip2 -v：压缩或解压时显示详情信息 -k：保留原文件 -n：压缩比为n（0\u003e=n\u003c=9 xzcat FILE 查看文件内存但不压缩 ","date":"2018-12-12","objectID":"/%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%89%93%E5%8C%85/:0:0","tags":["压缩","打包"],"title":"linux 中压缩与打包","uri":"/%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%89%93%E5%8C%85/"},{"categories":["linux"],"content":"linuxFirewalld","date":"2018-12-10","objectID":"/linuxFirewalld/","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 使用环境： centos: 7 centos: 8 firewalld: 0.8 内容来自以下文档： firewalld官方文档 Netfilter官网文档 nttables维基 防火墙Linux防火墙是由Netfilter组件提供的，Netfilter工作在内核空间，集成在linux内核中 ，Netfilter 是Linux2.4.x之后新一代的Linux防火墙机制，有以下前端工具 iptables：工作在用户空间，用来编写规则，写好的规则被送往netfilter firewalld：从CentOS 7 版开始引入了新的前端管理工具 nftables：CentOS 8 新特性，它在 Linux 内核 \u003e= 3.13 中可用。 firewalld 概述firewalld 提供了动态管理的防火墙方式，支持定义网络连接或接口的信任级别的网络防火墙区域；支持 ipv4, ipv6, 以太网等设置。为服务或应用程序提供一个接口，可以直接添加防火墙规则 centos 系统从 7 版本开始使用 优点： 可以实时更改，不需要重新启动服务 可以通过 D-Bus 接口添加防火墙规则 firewalld 命令行 使用方式：firewalld [option] 常见选项： -h, --help 查看帮助 --debug-gc 查看垃圾收集器泄露信息，收集器每10秒运行一次 --debug [level] 调试级别，默认为 level，级别由低到高为1-10,调试输出会被记录到日志文件中 `//var/log/firewalld` --default-config 指定默认配置文件路径，默认为 `/usr/lib/firewalld` --nofork 以前台方式运行 firewalld，默认为后台运行 --nopid 禁止写入pid文件。默认情况下，程序将写入一个pid文件。如果使用此选项调用程序，则不会检查现有服务器进程 --system-config 指定系统配置文件路径，默认为 `/etc/firewalld` ","date":"2018-12-10","objectID":"/linuxFirewalld/:0:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 概念firewalld 具有两层设计： 核心层：处理配置和后端模块加载 D-Bus层：修改防火墙的接口 firewalld设计结构示意图 firewalld 的 D-Bus 接口是更改防火墙配置是主要方法，该接口可以通过 firewalld 提供的工具（firewall-cmd，firewall-config, firewall-applet）使用 firewall-offline-cmd 不是在与 firewalld 通信，而是直接使用带有 IO 处理程序的 firewalld 核心来更改和创建 firewalld 配置文件，虽然可以在 firewalld 运行中使用，但需要5秒左右才生效 firewalld 提供了对 zone，service, IPSete，ICMP 类型的支持 firewalld 不依赖 NetworkManager ，但未使用时 firewalld 不会收到有关网络设备重命名通知，如果 firewalld 在 network 启动之后才运行，则需要手动添加到区域中 添加方式： firewall-cmd [--permanent] --zone=zone --add-interface=interface 要重新加载防火墙，您可以使用命令行工具，也可以使用firewall-cmd --reload来将SIGHUP信号发送到防火墙(killall -HUP firewalld) ","date":"2018-12-10","objectID":"/linuxFirewalld/:1:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 配置firewalld 的配置存储在配置目录中的各种 XML 文件中，为后备和系统替代提供了极大的灵活性 firewalld 支持2个配置目录，优先级由上到下： /etc/firewalld/：系统配置目录，如果不存在，则使用默认目录 /usr/lib/firewalld/：默认配置目录，更新时会被替换掉 /usr/lib/firewalld/ 目录中的配置文件会在 firewalld 更新时被替换掉，因此，如果需要更改默认配置，则需要在 /etc/firewalld/ 目录中定义 ","date":"2018-12-10","objectID":"/linuxFirewalld/:2:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 运行时配置和永久配置运行时配置（通常成为临时配置）是实际有效配置，且应用在内核防火墙中。在防火墙服务启动时，永久配置会变为运行时配置，运行时配置被修改之后，不会自动保存到永久配置中，防火墙服务停止之后运行时配置被丢弃 永久配置存储在配置文件中，并且每次防火墙服务重新加载或启动时被加载为运行时配置，运行时配置可以通过修改配置文件或使用 firewall-cmd --runtime-to-permanent 等方式保存为永久配置 如果防火墙设置不起作用，则简单的防火墙重新加载/重启将重新应用正常工作的永久配置 ","date":"2018-12-10","objectID":"/linuxFirewalld/:2:1","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 配置值有以下配置选项： DefaultZone=public：默认区域，未指定区域时，使用 public 区域 MinimalMark=100 ：最小标记，已弃用 CleanupOnExit=yes：停止firewalld时是否清除规则，如果为no或false ，则在 退出或停止时保留规则。默认值为yes或true Lockdown=no：关闭限制名单，如果设置为启用，则通过D-Bus界面进行的防火墙更改将 仅限于锁定白名单中列出的应用程序。锁定白名单文件是 lockdown-whitelist.xml 。默认值为 no 或 false。 IPv6_rpfilter=yes：对用于IPv6的数据包执行反向路径筛选器测试。如果将通过与到达数据包相同的接口发送对数据包的答复，则该数据包将匹配并被接受，否则将被丢弃。使用 sysctl 控制 IPv4 的 rp_filte IndividualCalls=no：不要使用组合的-restore调用，而要使用单个调用。这增加了应用更改和启动守护程序所需的时间，但对于调试很有用 LogDenied=off ：在默认规则的 INPUT，FORWARD 和 OUTPUT 链中的拒绝和丢弃规则之前添加日志记录规则，并在区域中最终拒绝和丢弃规则。可能的值有：all，unicast，broadcast，multicast,off AutomaticHelpers FirewallBackend。防火墙规则实现方式。值为nftables(默认值)或iptables 。直接和直通规则，它们总是使用传统的 iptables、ip6tables 和 ebtables 后端。 FlushAllOnReload：在重新加载时刷新所有运行时规则。新版本值为yes，旧版本为 no RFC3964_IPv4：是否根据 RFC 3964，使用 6to4 目标地址过滤 IPv6 流量。默认为 yes AllowZoneDrifting：是否允许数据包进入多个区域。如果为yes，数据包将仅从基于 源的区域漂移到基于接口的区域（包括默认区域） ","date":"2018-12-10","objectID":"/linuxFirewalld/:2:2","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 区域firewalld 区域(zone)定义了连接。接口或源地址的信任级绑定，这是一对多关系。因此，接口或源只能是区域的一部分 这些区域是 firewalld 提供的，从不信任到信任排序（信任级别越越危险）： drop：任何传入的网络数据包都会被丢弃，没有回复，但可以传出网络数据包 block：对于 IPV4，使用 icmp-host 禁止消息来拒绝任何网络连接传入；对于 IPV6，使用 icmp6-adm 禁止消息来拒绝任何传入网络连接。但由系统内核发起的网络可以传入 public：仅接收允许通过的网络连接才能传入，也是默认区域，适用于公共场合 external：仅接收允许通过的网络连接才能传入，适用于伪造了外部网络的场合 dmz：仅接收允许通过的网络连接才能传入，但对内部网络的访问权限有限 work：仅接收允许通过的网络连接才能传入，对所有传入网络都认为是安全的，适用于办公场合 home：仅接收允许通过的网络连接才能传入，对所有传入网络都认为是安全的，适用于家庭场合 internal：仅收允许通过的网络连接才能传入，对所有传入网络都认为是安全的，适用于内部网络 trusted：接收所有网络传入 ","date":"2018-12-10","objectID":"/linuxFirewalld/:3:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 网络接口网络卡通过配置文件/etc/sysconfig/network-scripts/ifcfg-的zone选项指定区域 ","date":"2018-12-10","objectID":"/linuxFirewalld/:3:1","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 区域配置文件zone配置文件目录： /etc/firewalld/zones/ /usr/lib/firewalld/zones/ 区域配置文件包含区域的信息。这些是 XML 文件格式的区域描述、服务、端口、协议、 icmp 块、伪装、转发端口和丰富的语言规则。文件名必须是*.xml，其中的长度目前限制 为 17 个字符。 格式如下： \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e # \u003czone\u003e...\u003c/zone\u003e(必须，唯一)：强制区域开始和结束标记 # version=\"string\"(可选): zone版本 # target(可选): 对不匹配任意规则数据包处理方式： # - ACCEPT: 接受 # - %%REJECT%%: 拒绝 # - DROP: 丢弃 \u003czone [version=\"versionstring\"] [target=\"ACCEPT|%%REJECT%%|DROP\"]\u003e # (可选，可重复): 绑定网卡接口 [ \u003cinterface name=\"string\"/\u003e ] # \u003csource .../\u003e(可选): 源地址信息： # - address=\"address[/mask]\": IP地址 # - mac=\"MAC\": MAC地址，格式必须是`XX:XX:XX:XX:XX:XX` # - ipset=\"ipset\": [ \u003csource address=\"address[/mask]\"|mac=\"MAC\"|ipset=\"ipset\"/\u003e ] # (可选，唯一): 只仅接受启用的 ICMP 类型，并且拒绝该区域中的所有其他类型 [ \u003cicmp-block-inversion/\u003e ] # (可选): 简短的名称 [ \u003cshort\u003eshort description\u003c/short\u003e ] # (可选): 描述 [ \u003cdescription\u003edescription\u003c/description\u003e ] # (可选，可重复): 启用的服务名称 [ \u003cservice name=\"string\"/\u003e ] # (可选，可重复): 端口范围与协议类型 [ \u003cport port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\"/\u003e ] # (可选，可重复): 启用的网络协议，查看系统支持的协议：/etc/protocols [ \u003cprotocol value=\"protocol\"/\u003e ] # (可选，可重复): 禁止ICMP类型名称 [ \u003cicmp-block name=\"string\"/\u003e ] # (可选，唯一): 启用IP伪装 [ \u003cmasquerade/\u003e ] # (可选，可重复): 端口转发 # - port(必须): 源端口 # - protocol(必须): 源协议 # - to-port(可选): 目标端口 # - address(可选): 目标地址 [ \u003cforward-port port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\" [to-port=\"portid[-portid]\"] [to-addr=\"IP address\"]/\u003e ] # (可选，可重复): 源信息： # - port(必须): 端口 # - protocol(必须): 协议 [ \u003csource-port port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\"/\u003e ] # (可选，可重复): 富语言规则，默认规则优先级从上往下 [ # priority 表示规则优先级。在 -32768 到 32767 的范围内： # - 较低的值具有较高的优先级 # - 未定义具有相同优先级值的规则的排序 # - 一个正的优先级值将在其他 firewalld 原语之后执行 # - 默认值为-1 # - 0 保留供内部使用 \u003crule [family=\"ipv4|ipv6\"] [priority=\"priority\"] \u003e # 限制源地址, not表示取反， [ \u003csource [not] address=\"address[/mask]\"|mac=\"MAC\"|ipset=\"ipset\" [invert=\"True\"]/\u003e ] # 限制目标地址，not 表示取反 [ \u003cdestination [not] address=\"address[/mask]\" [invert=\"True\"]/\u003e ] [ # 服务名，服务列表使用firewall-cmd --get-services查看 # 如果服务提供了目的地址，它会与规则中的目的地址发生冲突，从而 # 导致错误。 \u003cservice name=\"string\"/\u003e | # 端口 \u003cport port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\"/\u003e | # 协议 \u003cprotocol value=\"protocol\"/\u003e | # 指定icmp名，规则名查看firewall-cmd --get-icmptypes \u003cicmp-block name=\"icmptype\"/\u003e | \u003cicmp-type name=\"icmptype\"/\u003e | # 是否启用伪装，IP转发将被隐式启用 \u003cmasquerade/\u003e | # 转发端口 \u003cforward-port port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\" [to-port=\"portid[-portid]\"] [to-addr=\"address\"]/\u003e | # 源端口 \u003csource-port port=\"port value\" protocol=\"tcp|udp\"\u003e ] # 日志，prefix表示前缀文本，level表示日志级别，默认为warning # limit表示限速，rate表示数值，duration表示时间，\"s\", \"m\", \"h\", \"d\"， # 最大值为2d [ \u003clog [prefix=\"prefixtext\"] [level=\"emerg|alert|crit|err|warn|notice|info|debug\"]\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/log\u003e ] # 满足速率后执行某些操作 [ \u003caudit\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/audit\u003e ] [ # 接受 \u003caccept\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/accept\u003e | # 拒绝 \u003creject [type=\"rejecttype\"]\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/reject\u003e | # 丢弃 \u003cdrop\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/drop\u003e | # 标记 \u003cmark set=\"mark[/mask]\"\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/mark\u003e ] \u003c/rule\u003e ] \u003c/zone\u003e ","date":"2018-12-10","objectID":"/linuxFirewalld/:3:2","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 策略策略是用于跨区域之间流动的流量规则。如允许 zoneA 到 zoneB。策略与区域的关系是通 过分配一组入口区域和一组出口区域来定义的。仅当满足以下所有条件时，策略才会生效： 入口区域列表至少包含一个常规区域或单个符号区域 出口区域列表至少包含一个常规区域或一个符号区域 对于非符号区域，该区域必须处于活动状态。即，必须具有分配给它的接口或源 常规区域不足以表达每种形式的数据包过滤。例如，没有区域来表示流入或流出运行 firewalld 的主机的流量。因此，有一些象征性的区域可以填补这些空白。但是，符号区域的独特之处在于它们是入口或出口区域集中唯一允许的区域。 host:此符号区域用于流入或流出运行 firewalld 的主机的流量。如果在出口区域列表中使用，它将应用于netfilter的INPUT 链上的流量；如果在入口区域列表中使用，它将应用于 OUTPUT 链上的流量 ANY: 如果在入口区域列表中使用，它将适用于来自任何区域的流量；如果在出口区域列表中使用，它将适用于发往任何区域的流量 ","date":"2018-12-10","objectID":"/linuxFirewalld/:4:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 策略配置配置文件 /etc/firewalld/policies/ /usr/lib/firewalld/policies/ 配置文件名以.xml结尾，长度限制为 17 个字符。格式如下： # https://firewalld.org/documentation/man-pages/firewalld.policy.html \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cpolicy [version=\"versionstring\"] [target=\"CONTINUE|ACCEPT|REJECT|DROP\"] [priority=\"priority\"]\u003e [ \u003cingress-zone name=\"zone\"/\u003e ] [ \u003cegress-zone name=\"zone\"/\u003e ] [ \u003cshort\u003eshort description\u003c/short\u003e ] [ \u003cdescription\u003edescription\u003c/description\u003e ] [ \u003cservice name=\"string\"/\u003e ] [ \u003cport port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\"/\u003e ] [ \u003cprotocol value=\"protocol\"/\u003e ] [ \u003cicmp-block name=\"string\"/\u003e ] [ \u003cmasquerade/\u003e ] [ \u003cforward-port port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\" [to-port=\"portid[-portid]\"] [to-addr=\"IP address\"]/\u003e ] [ \u003csource-port port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\"/\u003e ] [ \u003crule [family=\"ipv4|ipv6\"]\u003e [ \u003csource address=\"address[/mask]\"|mac=\"MAC\"|ipset=\"ipset\" [invert=\"True\"]/\u003e ] [ \u003cdestination address=\"address[/mask]\" [invert=\"True\"]/\u003e ] [ \u003cservice name=\"string\"/\u003e | \u003cport port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\"/\u003e | \u003cprotocol value=\"protocol\"/\u003e | \u003cicmp-block name=\"icmptype\"/\u003e | \u003cicmp-type name=\"icmptype\"/\u003e | \u003cmasquerade/\u003e | \u003cforward-port port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\" [to-port=\"portid[-portid]\"] [to-addr=\"address\"]/\u003e ] [ \u003clog [prefix=\"prefixtext\"] [level=\"emerg|alert|crit|err|warn|notice|info|debug\"]\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/log\u003e ] [ \u003caudit\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/audit\u003e ] [ \u003caccept\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/accept\u003e | \u003creject [type=\"rejecttype\"]\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/reject\u003e | \u003cdrop\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/drop\u003e | \u003cmark set=\"mark[/mask]\"\u003e [\u003climit value=\"rate/duration\"/\u003e] \u003c/mark\u003e ] \u003c/rule\u003e ] \u003c/policy\u003e ","date":"2018-12-10","objectID":"/linuxFirewalld/:4:1","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 服务firewalld 中 service 可以是本地端口和目标的列表，可以自动加载预定服务配置 配置文件目录： /etc/firewalld/services/ /usr/lib/firewalld/services/ 服务配置文件的结构: \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cservice\u003e # (可选)简短名称 \u003cshort\u003eMy Service\u003c/short\u003e # (可选)描述 \u003cdescription\u003edescription\u003c/description\u003e # (可选，可重复)，端口与协议都是必须的 \u003cport port=\"137\" protocol=\"tcp\"/\u003e # (可选，可重复)协议 \u003cprotocol value=\"igmp\"/\u003e # 新版本已弃用 \u003cmodule name=\"nf_conntrack_netbios_ns\"/\u003e # (可选，可重复): 源信息： # - port(必须): 端口 # - protocol(必须): 协议 \u003csource-port port=\"portid[-portid]\" protocol=\"tcp|udp|sctp|dccp\"/\u003e # (可选，唯一)将目标网络指定为网络 IP 地址 \u003cdestination ipv4=\"224.0.0.251\" ipv6=\"ff02::fb\"/\u003e # (可选，可重复) 包含有有效的服务规则 \u003cinclude service=\"ssdp\"/\u003e # 标签 \u003chelper name=\"ftp\"/\u003e \u003c/service\u003e ","date":"2018-12-10","objectID":"/linuxFirewalld/:5:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" IPSetipset 可用于将多个IP或MAC地址组合在一起。IP地址的ipset可用于IPv4或IPv6。这是由ipset的系列设置定义的。它可以是inet（默认值）或inet6 https://firewalld.org/documentation/man-pages/firewalld.ipset.html 目录 /usr/lib/firewalld/ipsets/ /etc/firewalld/ipsets/ ","date":"2018-12-10","objectID":"/linuxFirewalld/:6:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" helper https://firewalld.org/documentation/man-pages/firewalld.helper.html /etc/firewalld/helpers/ /usr/lib/firewalld/helpers/ ","date":"2018-12-10","objectID":"/linuxFirewalld/:7:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" ICMP 类型 https://firewalld.org/documentation/man-pages/firewalld.icmptype.html /etc/firewalld/icmptypes/ /usr/lib/firewalld/icmptypes/ ","date":"2018-12-10","objectID":"/linuxFirewalld/:8:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" direct直接配置文件 https://firewalld.org/documentation/man-pages/firewalld.direct.html /usr/etc/firewalld/ ","date":"2018-12-10","objectID":"/linuxFirewalld/:9:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 白名单配置文件 https://firewalld.org/documentation/man-pages/firewalld.lockdown-whitelist.html /usr/etc/firewalld/ ","date":"2018-12-10","objectID":"/linuxFirewalld/:10:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 接口描述 https://firewalld.org/documentation/man-pages/firewalld.dbus.html ","date":"2018-12-10","objectID":"/linuxFirewalld/:11:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" firewall-cmdfirewall-cmd 是 firewalld 的主要命令行攻击，可以获取关于 firewalld 的状态信息、配置信息、更改配置操作，仅在 firewalld 运行时才能使用 更据使用策略，经过身份验证之后才能更改或访问配置 使用方式：firewall-cmd [OPTIONS...] ","date":"2018-12-10","objectID":"/linuxFirewalld/:12:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 常见选项 -h, --help 获取帮助 -V, --version 查看firewalld版本，不能和其他选项配合使用 -q, --quiet 不显示状态信息 --state 检查 firewalld 守护程序是否处于活动状态（即正在运行）： - 如果处于活动状态，`RUNNING_BUT_FAILED` 则返回退出代码0 - 如果启动失败，`NOT_RUNNING` 则返回退出状态码为 0 - “退出代码”部分还将状态打印到 STDOUT --reload 重新加载防火墙规则，并保留状态信息： - 通过直接接口应用的运行时更改不会受到影响，因此将保留在原位置，直到将firewalld守护程序完全重新启动 --complete-reload 完全重新加载防火墙，甚至是netfilter内核模块： - 因为状态信息会丢失，因此会终止活动连接（仅在严重的防火墙问题时才应使用此选项。例如，如果存在状态信息问题，则使用正确的防火墙规则无法建立连接） - 通过直接接口应用的运行时更改不会受到影响，因此将保留在原配置，直到将firewalld守护程序完全重新启动 --runtime-to-permanent 把运行时配置覆盖永久配置保存 --check-config 对永久配置运行检查。这包括XML有效性和语义 --get-log-denied 查看拒绝日志设置 --set-log-denied= 日志记录级级别，在默认规则的 INPUT，FORWARD 和 OUTPUT链中，在拒绝和丢弃规则 之前添加日志记录规则，对于已配置的链路层数据包类型，在区域中最后添加拒绝和 丢弃规则，有以下取值： - all - unicast - broadcast - multicast - off：关闭日志记录 这是一个运行时和永久的配置，还将重新加载防火墙以能够添加日志记录规则 --permanent 该选项设置永久配置，仅在服务重新启动或加载之后才生效 - 当缺少该选项时，大部分选项只对运行时配置生效 - 当使用该选项时，大部分选项只对永久配置生效 --panic-on 启用恐慌模式。所有传入和传出的数据包都被丢弃，活动连接将过期。 --panic-off 禁用恐慌模式后建立的连接可能会再次工作 --query-panic 如果启用恐慌模式，则返回 0，否则返回 1 ","date":"2018-12-10","objectID":"/linuxFirewalld/:12:1","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 区域相关选项 --list-all 查看启用区域信息 [ --permanent]--info-zone=zone 查看区域信息 [ --permanent]--list-all-zones 查看所有启用区域的信息 [ --permanent]--get-zones 查看自带区域（以空格为分隔符） --get-default-zone 查看默认接口和连接区域 --set-default-zone=zone 设置默认区域，这是运行时和永久配置 --get-active-zones 查看当前活动的区域，如果没有接口或源绑定到该区域，则将省略相应的行 [ --permanent] --get-icmptypes 查看自带的 icmp 类型（以空格为分隔符） --permanent --new-zone=zone 添加一个区域 - 区域名称必须为字符和数字，可以使用下划线`_` 和连字符 `-` --permanent --new-zone-from-file= filename[ --name=zone ] 从区域配置文件覆盖另一个区域，如果不指定区域，则覆盖默认区域 --permanent --permanent --delete-zone= 删除一个区域 --permanent --path-zone= 查看区域配置文件路径 --permanent --load-zone-defaults=zone 加载区域默认设置或查看 NO_DEFAULTS 错误 [ --permanent] --get-zone-of-interface=interface 查看网卡接口绑定的区域 [ --permanent] --get-zone-of-source= source[ /mask ]| MAC|ipset:ipset 打印源绑定到的区域的名称 [ --permanent] [ --zone=zone ]--list-interfaces 将绑定到区域的接口以空格分隔的列表形式列出 [ --permanent] [ --zone=zone ] --add-interface=interface 把接口绑定到区域，如果接口在 NetworkManager 的控制下，首先连接它以更改使用 该接口的连接的区域。如果失败，则在 firewalld 中创建区域绑定，并应用以下限制 。对于不受 NetworkManager 控制的接口，firewalld 会尝试更改 ifcfg 文件中的 ZONE 设置（如果该文件存在） [ --permanent] [ --zone=zone ] --change-interface=interface 更改接口绑定的区域 [ --permanent] [ --zone=zone ] --query-interface=interface 查询接口是否绑定到区域 [ --permanent] --remove-interface=interface 删除接口绑定的区域 [ --permanent] [ --zone=zone ]--add-icmp-block-inversion 启用 ICMP 块反转 [ --permanent] [ --zone=zone ]--remove-icmp-block-inversion 禁用 ICMP 块反转 [ --permanent] [ --zone=zone ]--query-icmp-block-inversion 返回是否启用 ICMP 块反转。如果为真则返回 0，否则返回 1 [ --permanent] [ --zone=zone ]--add-forward 启用区域内转发 [ --permanent] [ --zone=zone ]--remove-forward 禁用区域内转发 [ --permanent] [ --zone=zone ]--query-forward 返回是否启用区域内转发。如果为真则返回 0，否则返回 1 [ --permanent] [ --zone=zone ]--list-sources 将绑定到区域的源列表以空格分隔 - 将源绑定到区域意味着此区域设置将用于限制来自此源的流量 [ --permanent] [ --zone=zone ] --add-source= source[ /mask ]| MAC|ipset:ipset 将源绑定到 zone - 将源绑定到区域意味着此区域设置将用于限制来自此源的流量 [ --zone=zone ] --change-source= source[ /mask ]| MAC|ipset:ipset 更改源地址绑定的区域 - 将源绑定到区域意味着此区域设置将用于限制来自此源的流量 [ --permanent] [ --zone=zone ] --query-source= source[ /mask ]| MAC|ipset:ipset 查询源是否绑定到zone。如果为真则返回 0，否则返回 1 --permanent] --remove-source= source[ /mask ]| MAC|ipset:ipset 从先前添加到的区域中删除源的绑定。 - 将源绑定到区域意味着此区域设置将用于限制来自此源的流量 ","date":"2018-12-10","objectID":"/linuxFirewalld/:12:2","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 政策选项 --get-policies 打印预定义策略，以空格分隔 --info-policy= 打印有关政策的信息 --list-all-policies 列出为所有策略添加或启用的所有内容 --permanent --new-policy= 添加新的永久策略 - 称必须是字母数字，并且可以另外包含字符：“_”和“-” --permanent --new-policy-from-file= filename[ --name=policy ] 从准备好的策略文件中添加一个新的永久策略，并带有可选的名称覆盖。 --permanent --path-policy=policy 策略配置文件的打印路径 --permanent --delete-policy=policy 删除现有的永久策略 --permanent --load-policy-defaults=policy 加载策略的出厂默认值。仅适用于 firewalld 附带的策略。 不适用于用户定义的策略。 ","date":"2018-12-10","objectID":"/linuxFirewalld/:12:3","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 调整和查询区域和策略的选项这些选项仅影响一个特定区域或策略。如果与--zone=zone或--policy=policy选项一 起使用，它们会影响指定的区域或策略。如果省略这两个选项，它们会影响默认区域 [ --permanent] [ --zone=zone ] [ --policy=policy ]--list-all 列出添加或启用的所有内容 --permanent[ --zone=zone ] [ --policy=policy ]--get-target 查看目标 --permanent[ --zone=zone ] [ --policy=policy ] --set-target=zone 设定目标： - 对于区域target是以下之一：default, ACCEPT, DROP,REJECT - 对于策略target是以下之一：CONTINUE, ACCEPT, DROP,REJECT - default与 类似REJECT，但在以下场景中具有特殊含义： 1. ICMP 明确允许，在区域规则集的末尾，明确允许 ICMP 数据包 2. 转发的数据包遵循target出口区域，在转发数据包的情况下，如果入口区域使用 default那么是否允许数据包将由出口区域确定。对于入口 zoneA 和出口 zoneB 的转发数据包： - 如果 zoneAtarget是ACCEPT, DROP, 或REJECT则数据包分别被接受、丢弃或 拒绝。 - 如果 zoneAtarget是default，则根据 zoneB 接受、丢弃或拒绝数据包target 。如果 zoneB 的target也是default，则数据包将被 firewalld 的全部拒绝 3. 从源区漂移到界面区，这仅在AllowZoneDrifting启用时适用，如果一个数据包 进入一个带有targetof的基于源的区域default，它仍然可能进入一个基于接口的 区域（包括默认区域） --permanent[ --zone=zone ] [ --policy=policy ] --set-description= 设置说明 --permanent[ --zone=zone ] [ --policy=policy ]--get-description 查看区域说明 --permanent[ --zone=zone ] [ --policy=policy ] --set-short=description 设置简短描述 --permanent[ --zone=zone ] [ --policy=policy ]--get-short 打印简短描述 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ]--list-services 以空格分隔的列表形式查看服务列表 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --add-service= service[ --timeout=timeval ] 添加服务。可以多次指定此选项。如果提供了超时，则规则将在指定的时间内处于活动 状态，之后将自动删除。 - timeval是数字（秒）或数字后跟字符s（秒）、m（分钟）、h（小时）之一 - 该服务是防火墙提供的服务之一。要获取支持的服务列表，请使用 firewall-cmd --get-services - --timeout选项不能与该--permanent选项组合 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --remove-service=service 删除服务。可以多次指定此选项 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --query-service=service 返回是否service已添加。如果为真则返回 0，否则返回 1 --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ]--list-ports 列出添加为空格分隔列表的端口。端口的格式为portid[ -portid ]/ protocol， 它可以是端口和协议对，也可以是带有协议的端口范围。 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --add-port= portid[ -portid ]/ protocol[ --timeout=timeval ] 添加端口。可以多次指定此选项。如果提供了超时，则规则将在指定的时间内处于活动 状态，之后将自动删除 - timeval是数字（秒）或数字后跟字符s（秒）、m（分钟）、h（小时）之一 - 端中可以是单个端口号或端口范围portid- portid。 - 协议可以是tcp、udp或。 sctpdccp - --timeout选项不能与该--permanent选项组合 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --remove-port= portid[ -portid ]/protocol 移除端口。可以多次指定此选项 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --query-port= portid[ -portid ]/protocol 返回是否添加了端口。如果为真则返回 0，否则返回 1 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ]--list-protocols 查看以空格分隔的协议列表 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --add-protocol= protocol[ --timeout=timeval ] 添加协议。可以多次指定此选项。如果提供了超时，则规则将在指定的时间内处于活动 状态，之后将自动删除。 - timeval是数字（秒）或数字后跟字符s（秒）、m（分钟）、h（小时）之一 - 协议可以是系统支持的任何协议。请查看/etc/protocols支持的协议 - --timeout选项不能与该--permanent选项组合 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --remove-protocol=protocol 删除协议。可以多次指定此选项 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --query-protocol=protocol 返回是否添加了协议。如果为真则返回 0，否则返回 1 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ]--list-source-ports 列出添加为空格分隔列表的源端口 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --add-source-port= portid[ -portid ]/ protocol[ --timeout=timeval ] 添加源端口。可以多次指定此选项。如果提供了超时，则规则将在指定的时间内处于活 动状态，之后将自动删除。 - timeval是数字（秒）或数字后跟字符s（秒）、m（分钟）、h（小时）之一 - 端口可以是单个端口号或端口范围portid- portid - 协议可以是tcp、udp、sctp、dccp - --timeout选项不能与该--permanent选项组合 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --remove-source-port= portid[ -portid ]/protocol 删除源端口。可以多次指定此选项。 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --query-source-port= portid[ -portid ]/protocol 返回是否添加了源端口。如果为真则返回 0，否则返回 1 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ]--list-icmp-blocks 以空格分隔列出 Internet 控制消息协议 (ICMP) 类型列表 [ --permanent] [ --zone=zone ] [ --permanent] [ --policy=policy ] --add-icmp-block= icmptype[ --timeout=timeval ] 为 icmptype 添加一","date":"2018-12-10","objectID":"/linuxFirewalld/:12:4","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 调整和查询策略的选项 --permanent --policy=policy --get-priority 获得优先权 --permanent --policy=policy --set-prioritypriority 设置优先级\"priority\"。优先级决定了策略的相对顺序 [ --permanent] --policy=policy --list-ingress-zones 列出作为空格分隔的列表添加的入口区域 [ --permanent] --policy= =policy --add-ingress-zonezone 添加入口区域。可以多次指定此选项，值为预定义区域、HOST或ANY [ --permanent] --policy= =policy --remove-ingress-zonezone 删除入口区域。可以多次指定此选项 [ --permanent] --policy= =policy --query-ingress-zonezone 返回是否zone已添加。如果为真则返回 0，否则返回 1 [ --permanent] --policy=policy --list-egress-zones 列出作为空格分隔的列表添加的出口区域 [ --permanent] --policy= =policy --add-egress-zonezone 添加一个出口区域。可以多次指定此选项 [ --permanent] --policy= =policy --remove-egress-zonezone 移除一个出口区域。可以多次指定此选项 --permanent] --policy= =policy --query-egress-zonezone 返回是否zone已添加。如果为真则返回 0，否则返回 1 ","date":"2018-12-10","objectID":"/linuxFirewalld/:12:5","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" firewall-cmd 退出状态码 firewall-cmd 命令退出状态码默认情况下成功返回0；失败时输出为红色；命令行错误返回2。如果使用 --query 选项则成功为0,失败为1。都有以下退出状态码 退出状态码 字符串 说明 11 ALREADY_ENABLED 待补充 12 NOT_ENABLED 待补充 13 COMMAND_FAILED 待补充 14 NO_IPV6_NAT 待补充 15 PANIC_MODE 待补充 16 ZONE_ALREADY_SET 待补充 17 UNKNOWN_INTERFACE 待补充 18 ZONE_CONFLICT 待补充 19 BUILTIN_CHAIN 待补充 20 EBTABLES_NO_REJECT 待补充 21 NOT_OVERLOADABLE 待补充 22 NO_DEFAULTS 待补充 23 BUILTIN_ZONE 待补充 24 BUILTIN_SERVICE 待补充 25 BUILTIN_ICMPTYPE 待补充 26 NAME_CONFLICT 待补充 27 NAME_MISMATCH 待补充 28 PARSE_ERROR 待补充 29 ACCESS_DENIED 待补充 30 UNKNOWN_SOURCE 待补充 31 RT_TO_PERM_FAILED 待补充 32 IPSET_WITH_TIMEOUT 待补充 33 BUILTIN_IPSET 待补充 34 ALREADY_SET 待补充 35 MISSING_IMPORT 待补充 36 DBUS_ERROR 待补充 37 BUILTIN_HELPER 待补充 38 NOT_APPLIED 待补充 100 INVALID_ACTION 待补充 101 INVALID_SERVICE 待补充 102 INVALID_PORT 待补充 103 INVALID_PROTOCOL 待补充 104 INVALID_INTERFACE 待补充 105 INVALID_ADDR 待补充 106 INVALID_FORWARD 待补充 107 INVALID_ICMPTYPE 待补充 108 INVALID_TABLE 待补充 109 INVALID_CHAIN 待补充 110 INVALID_TARGET 待补充 111 INVALID_IPV 待补充 112 INVALID_ZONE 待补充 113 INVALID_PROPERTY 待补充 114 INVALID_VALUE 待补充 115 INVALID_OBJECT 待补充 116 INVALID_NAME 待补充 117 INVALID_FILENAME 待补充 118 INVALID_DIRECTORY 待补充 119 INVALID_TYPE 待补充 120 INVALID_SETTING 待补充 121 INVALID_DESTINATION 待补充 122 INVALID_RULE 待补充 123 INVALID_LIMIT 待补充 124 INVALID_FAMILY 待补充 125 INVALID_LOG_LEVEL 待补充 126 INVALID_AUDIT_TYPE 待补充 127 INVALID_MARK 待补充 128 INVALID_CONTEXT 待补充 129 INVALID_COMMAND 待补充 130 INVALID_USER 待补充 131 INVALID_UID 待补充 132 INVALID_MODULE 待补充 133 INVALID_PASSTHROUGH 待补充 134 INVALID_MAC 待补充 135 INVALID_IPSET 待补充 136 INVALID_ENTRY 待补充 137 INVALID_OPTION 待补充 138 INVALID_HELPER 待补充 139 INVALID_PRIORITY 待补充 140 INVALID_POLICY 待补充 200 MISSING_TABLE 待补充 201 MISSING_CHAIN 待补充 202 MISSING_PORT 待补充 203 MISSING_PROTOCOL 待补充 204 MISSING_ADDR 待补充 205 MISSING_NAME 待补充 206 MISSING_SETTING 待补充 207 MISSING_FAMILY 待补充 251 RUNNING_BUT_FAILED 待补充 252 NOT_RUNNING 待补充 253 NOT_AUTHORIZED 待补充 254 UNKNOWN_ERROR 待补充 ","date":"2018-12-10","objectID":"/linuxFirewalld/:12:6","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" firewall-configfirewall-config 是 firewalld 图形化配置工具 ","date":"2018-12-10","objectID":"/linuxFirewalld/:13:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" firewall-appletfirewall-applet 是托盘管理程序（类似 win 任务栏右下角小图标） ","date":"2018-12-10","objectID":"/linuxFirewalld/:14:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" firewall-offline-cmdfirewall-offlime-cmd 可以在 firewalld 未运行时进行配置，它不经过 D-Bus 接口，而是使用带文件 IO 处理程序的 firewalld 核心 需要 root 用户才能使用 只提供永久配置相关信息更改 firewalld 运行时需要 5 秒左右才生效 使用方式：firewall-offline-cmd [OPTIONS...] 常见选项： -h, --help 获取帮助 -V, --version 查看firewalld版本 -q, --quiet 不显示状态信息 --system-config 设置系统防火墙配置文件目录，默认为：/etc/firewalld/ --default-config 设置默认配置目录，默认为：/usr/lib/firewalld/ 示例","date":"2018-12-10","objectID":"/linuxFirewalld/:15:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看firewalld版本 [root@localhost ~]# firewall-cmd --version 0.6.3 ","date":"2018-12-10","objectID":"/linuxFirewalld/:16:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看firewalld状态 [root@localhost ~]# firewall-cmd --state running ","date":"2018-12-10","objectID":"/linuxFirewalld/:17:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看当前活动的区域 [root@localhost ~]# firewall-cmd --get-active-zones public interfaces: eth0 ","date":"2018-12-10","objectID":"/linuxFirewalld/:18:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看支持的服务类型 [root@c8 ~]# firewall-cmd --get-services | sed 's/ /\\n/g' RH-Satellite-6 amanda-client amanda-k5-client amqp ... ","date":"2018-12-10","objectID":"/linuxFirewalld/:19:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看所有的区域名称（运行时配置，如果启动之后是新加的，需要加载永久配置） [root@c8 ~]# firewall-cmd --get-zones | sed 's/ /\\n/g' block dmz drop external home internal public trusted work ","date":"2018-12-10","objectID":"/linuxFirewalld/:20:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看支持的 icmp 类型 [root@c8 ~]# firewall-cmd --get-icmptypes | sed 's/ /\\n/g' address-unreachable bad-header beyond-scope ... ","date":"2018-12-10","objectID":"/linuxFirewalld/:21:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看带有 ftp 字符的协议 [root@c8 ~]# firewall-cmd --get-services | grep -o '[^ ]*ftp[^ ]*' ftp tftp tftp-client ","date":"2018-12-10","objectID":"/linuxFirewalld/:22:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看是否支持 ftp 协议 [root@c8 ~]# firewall-cmd --get-services | grep -o '\\\u003cftp\\\u003e' ftp ","date":"2018-12-10","objectID":"/linuxFirewalld/:23:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看网卡 ens33 在哪个区域 [root@c8 ~]# firewall-cmd --get-zone-of-interface=ens33 public ","date":"2018-12-10","objectID":"/linuxFirewalld/:24:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" public 添加端口 [root@centos7 ~]# firewall-cmd --zone=public --add-port=801-880/tcp \u0026\u0026 firewall-cmd --runtime-to-permanent success ","date":"2018-12-10","objectID":"/linuxFirewalld/:25:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 服务添加通行 添加MySQL通行 [root@localhost ~]# firewall-cmd --zone=public --add-service=mysql \u0026\u0026 firewall-cmd --runtime-to-permanent ","date":"2018-12-10","objectID":"/linuxFirewalld/:26:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 本地端口转发 把本地默认区域的5211/tcp端口转发到本地的5212/tcp端口 firewall-cmd --add-forward-port=port=5211:proto=tcp:toport=5212 \u0026\u0026 firewall-cmd --runtime-to-permanent 跨区域好像要开启IP伪装 firewall-cmd --zone=public --add-maspuerade ","date":"2018-12-10","objectID":"/linuxFirewalld/:27:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 富规则配置端口转发 firewall-cmd --add-rich-rule='rule family=ipv4 destination address=100.0.0.254/24 forward-port port=443 protocol=tcp to-addr=192.168.2.10' ","date":"2018-12-10","objectID":"/linuxFirewalld/:28:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 禁止ping firewall-cmd --add-icmp-block=echo-request \u0026\u0026 firewall-cmd --runtime-to-permanent ","date":"2018-12-10","objectID":"/linuxFirewalld/:29:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 允许指定IP访问指定端口 允许119.123.148.20访问8291端口 [root@localhost ~]# firewall-cmd --add-rich-rule='rule family=\"ipv4\" source address=\"119.123.148.20\" port port=\"8291\" protocol=\"tcp\" accept' success [root@localhost ~]# firewall-cmd --runtime-to-permanent success ","date":"2018-12-10","objectID":"/linuxFirewalld/:30:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 放行指定的ip:port 允许访问103.106.246.17:8022 [root@localhost ~]# firewall-cmd --add-rich-rule='rule family=ipv4 destination address=\"103.106.246.17\" port port=\"8022\" protocol=\"tcp\" accept ' success [root@localhost ~]# firewall-cmd --runtime-to-permanent success ","date":"2018-12-10","objectID":"/linuxFirewalld/:31:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 查看所有配置 [root@localhost ~]# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: eth0 sources: services: dhcpv6-client ssh ports: 8730/tcp 8886/tcp 80/tcp 443/tcp protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: ","date":"2018-12-10","objectID":"/linuxFirewalld/:32:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" 禁止某个IP访问 [root@localhost ~]# firewall-cmd --add-rich-rule 'rule family=\"ipv4\" source address=\"103.106.246.61\" drop' success ","date":"2018-12-10","objectID":"/linuxFirewalld/:33:0","tags":["firewalld","防火墙"],"title":"firewalld - centos7 默认使用的防火墙服务","uri":"/linuxFirewalld/"},{"categories":["linux"],"content":" ","date":"2018-12-10","objectID":"/linux_iptables/","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 使用环境： centos: 7 centos: 8 firewalld: 0.8 内容来自以下文档： Netfilter官网文档 Oskar Andreasson: iptables 教程 nttables维基 运维派: iptables教程 防火墙Linux防火墙是由Netfilter组件提供的，Netfilter工作在内核空间，集成在linux内核中 ，Netfilter 是Linux2.4.x之后新一代的Linux防火墙机制，有以下前端工具 iptables：工作在用户空间，用来编写规则，写好的规则被送往netfilter firewalld：从CentOS 7 版开始引入了新的前端管理工具 nftables：CentOS 8 新特性，它在 Linux 内核 \u003e= 3.13 中可用。 iptables 概述iptables由表(table)与链(chain)以及一些规则组成。 内置链，流量由高到低的顺序如下： PREROUTING: 在进行路由选择前处理数据包 INPUT: 处理入站的数据包 OUTPUT: 处理出站的数据包 POSTROUTING: 在进行路由选择后处理数据包 FORWARD: 处理转发的数据包 内置表，优先级由高到低的顺序如下： security：用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现 raw：关闭启用的连接跟踪机制，加快封包穿越防火墙速度 mangle：修改数据标记位规则表 nat表：network address translation 地址转换规则表 filter表：过滤规则表，根据预定义的规则过滤符合条件的数据包 iptables 规则上这些链表上定义规则， 对匹配成功的报文根据规则定义的处理动作作出处理， 规则在链接上的次序即为其检查时的生效次序。 ","date":"2018-12-10","objectID":"/linux_iptables/:0:0","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" ipbtals命令iptables命令选项： iptables [-t table] {-A|-C|-D} chain rule-specification ip6tables [-t table] {-A|-C|-D} chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name rule-specification = [matches...] [target] match = -m matchname [per-match-options] target = -j targetname [per-target-options] ","date":"2018-12-10","objectID":"/linux_iptables/:1:0","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 常见用法 -t # 指定规则表，缺省时为 filter 表 -j # 指定规则处理动作 -p # 隐式扩展匹配条件 -m # 显式扩展匹配条件 ","date":"2018-12-10","objectID":"/linux_iptables/:1:1","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 规则管理选项 -A # 追加规则（默认在尾部） -I # 在指定序号插入规则，默认为1 -D # 删除规则，指明规则序号或指明规则本身 -R # 替换指定链上的指定规则编号 -F # 清空指定的规则链 -Z # 计数器置零， iptables的每条规则都有两个计数： # - 器匹配到的报文的个数 # - 匹配到的所有报文的大小之和 -N # 创建自定义链 -P # 规则链的默认策略，只有内置链才能设置且目标不能是链才有效 ","date":"2018-12-10","objectID":"/linux_iptables/:1:2","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 自定义规则链管理选项 -N # 自定义一条新的规则链 -E # 重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除 -X # 删除自定义的空的规则链 -P # 设置默认处理动作 ","date":"2018-12-10","objectID":"/linux_iptables/:1:3","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 查看规则选项 -S, --list-rules [chain] # 以配置文件形式查看规则，默认为 filter 表，缺省链为所有链 -t, --table table # 查看指定表，缺省为 filter 表 -L, --list [chain] # 查看规则链，缺省链则查看所有链，缺省 -t 默认为 filter 表 --line-numbers # 查看规则序列号，在开头规则所在某链某表的位置，不能和 -S 使用 -n, --numeric # ip和端口都用数字显示，默认情况下，以主机名，服务，网络名称显示 -v, --verbos # 查看详细内容， V 数量越多显示越详细，与 -L 关联使用 -x, --exact # 查看详细数字，而不是以 M（1000K）G （1000M）等方式，与 -L 选项管理使用 ","date":"2018-12-10","objectID":"/linux_iptables/:1:4","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 地址匹配 [!] -s, --source address[/mask][,...] # 源地址，!表示取反，可以是 IP 范围（ip/掩码）；主机名（只会被解析一次） [!] -d, --destination address[/mask][,...] # 目标地址，!表示取反，可以是 IP 范围（ip/掩码）；主机名（只会解析一次） [!] -p, --protocol protocol # 数据包的协议，!表示取反，可以使用协议号，可以使用 all表示所有协议。 # 协议列表在/etc/protocols可查看 [!] -i, --in-interface name # 报文流入的接口；只应用于INPUT、FORWARD、PREROUTING链 [!] -o, --out-interface name # 报文流出的接口，只应用于FORWARD、OUTPUT、POSTROUTING链 -f, --fragment # 匹配数据包的第二部分和第三部分 ","date":"2018-12-10","objectID":"/linux_iptables/:1:5","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 扩展匹配条件扩展匹配条件：需要加载扩展模块（/usr/lib64/xtables/*.so），方可生效。 使用man iptables-extensions查看扩展模块帮助文档。扩展匹配条件有以下方式： 隐式扩展：使用-p选项时自动使用相应扩展模块 显式扩展：使用-m或--match选项指定扩展模块。 部分扩展匹配模块,还有更多的匹配模块没有记录。查看文档：https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#EXPLICITMATCHES ","date":"2018-12-10","objectID":"/linux_iptables/:2:0","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" TCP匹配 -p tcp --sport, --source-port # 指定tcp源端口号，缺省时为所有TCP端口。可以是/etc/services中的服务名 --dport, --destination-port # 指定tcp目标端口号，缺省时为所有TCP端口。可以是/etc/services中的服务名 --tcp-flags # 指定tcp标志，多个标志使用逗号分隔，缺省时为所有TCP标识 --tcp-option # tcp报文中option部分长度 ","date":"2018-12-10","objectID":"/linux_iptables/:2:1","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" UDP匹配 -p tcp --sport, --source-port # 指定udp源端口号，缺省时为所有udp端口。可以是/etc/services中的服务名 -p tcp --dport, --destination-port # 指定udp目标端口号，缺省时为所有udp端口。可以是/etc/services中的服务名 # ICMP扩展匹配，即 -p icmp 的子命令 -p tcp --icmp-type # 指定 ICMP 类型 # STCP扩展匹配，即 -p sctp 的子命令 https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#SCTPMATCHES ","date":"2018-12-10","objectID":"/linux_iptables/:2:2","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 地址类型匹配 # 地址类型匹配，地址类型如下： # - ANYCAST # - BLACKHOLE # - BROADCAST # - LOCAL # - MULTICAST # - NAT # - PROHIBIT # - THROW # - UNICAST # - UNREACHABLE # - UNSPEC # - XRESOLVE -m addrtype --src-type UNICAST # 源地址类型 为UNICAST -m addrtype --dst-type UNICAST # 目标地址类型为UNICAST ","date":"2018-12-10","objectID":"/linux_iptables/:2:3","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 状态匹配 -m --state # 匹配连接状态，目前有以下可有状态： # - INVALID: 表示数据包与未知的流或连接相关联， # 并且它可能包含错误的数据或标头 # - ESTABLISHED: 已建立并开始传输数据 # - NEW: 新建连接，NEW 状态不会在尝试启动新连接的 TCP 数据包中查找 SYN 位 # - RELATED: 已建立连接 # 更多状态相关文档：https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#STATEMACHINE ","date":"2018-12-10","objectID":"/linux_iptables/:2:4","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 注释匹配 -m comment --comment \"A comment\" # 注释最多可包含 256 个字符 ","date":"2018-12-10","objectID":"/linux_iptables/:2:5","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" IP 范围匹配 -m iprange --src-range # 源IP范围，如：192.168.1.13-192.168.2.19 -m iprange --dst-range # 目标IP范围，如：192.168.1.13-192.168.2.19 ","date":"2018-12-10","objectID":"/linux_iptables/:2:6","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 速率限制匹配 -m limit --limit n/time # 速率限制，限制规定时间内处理多少个连接，time有单位有：/second /minute /hour /day -m limit --limit-burst # 速率令牌桶大小与初始值，每个连接消耗1个令牌，当令牌数量为0时，阻止连接 # 示例：-m limit --limit 5/second --limit-burst 10/second. # - 令牌桶初始值为10个，最大值为10个 # - 每秒最多通过5个连接 # - 1/5s没有使用令牌时，增加1个。最多增加到10个 ","date":"2018-12-10","objectID":"/linux_iptables/:2:7","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" mark地址匹配MAC 匹配仅在 PREROUTING、FORWARD 和 INPUT 链中有效 -m mac --mac-source XX:XX:XX:XX:XX:XX # mark源地址 -m mark --mark n # 匹配mark标记 ","date":"2018-12-10","objectID":"/linux_iptables/:2:8","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 多端口匹配 -m multiport --source-port ports # 多个源端口匹配，最多可以指定 15 个单独的端口。端口必须用逗号分隔， -m multiport --destination-port ports # 多个目标端口匹配，最多可以指定 15 个单独的端口。端口必须用逗号分隔， -m multiport --port ports # 多个端口匹配，最多可以指定 15 个单独的端口。端口必须用逗号分隔， ","date":"2018-12-10","objectID":"/linux_iptables/:2:9","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 动作匹配规则后执行的动作 ","date":"2018-12-10","objectID":"/linux_iptables/:3:0","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 跳转 - j name # 跳转到同表的其它链，name 为自定义链名称。遍历指定链之后返回到当前链继续遍历 -j RETURN # 目标将导致当前数据包停止通过它遇到规则的链。 # 如果它是另一条链的子链，则数据包将继续通过上级链，就好像什么都没发生一样 # 如果链是主链，例如 INPUT 链，则数据包将采用默认策略 -j CLUSTERIP # 跳转到集群，https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html#CLUSTERIPTARGET ","date":"2018-12-10","objectID":"/linux_iptables/:3:1","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 接受与拒绝 -j ACCEPT # 规则接受，直接进入下一个链 -j DROP # 丢弃，不往后续处理。也不返回提示 -j REJECT --reject-with tcp-reset # 拒绝，但会向源返回错误信息。仅在 INPUT、FORWARD 和 OUTPUT链或其子链中有效 # --reject-with 该选项可以告知当前可接受的数据包类型 ","date":"2018-12-10","objectID":"/linux_iptables/:3:2","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 进行分类 -j CLASSIFY --set-class # 进行分类，https://www.lartc.org/manpages/ ","date":"2018-12-10","objectID":"/linux_iptables/:3:3","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 标记 # connmark 针对是连接 -j CONNMARK --set-mark n # 添加连接标记n，n为0~4294967295l -j CONNMARK --save-mark # 把数据包中的标记保存到连接标记中 -j CONNMARK --restore-mark # 恢复数据包的标志值，此目标选项仅对在 mangle 表中使用有效。 -j CONNMARK --mask # 重新设置make值，必须与 --save-mark 或 --restore-mark 选项一起使用 # mark 只在mangle 表中有效，只标记单个数据包 -j MARK --set-mark 2 # 设置数据包的标记 -j NOTRACK # 关闭所有匹配此规则的数据包的连接跟踪 ","date":"2018-12-10","objectID":"/linux_iptables/:3:4","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" selinux相关 -j SECMARK --selctx httpcontext # 在单个数据包上设置selinux安全上下文标记，仅在 mangle 表中有效。 -j CONNSECMARK --save # 如果之前没有标记连接，则将数据包中的selinux安全上下文标记保存到连接。 -j CONNSECMARK --restore # 如果数据包上没有设置selinux安全上下文标记， # 则 --restore 选项将设置与数据包上的连接关联的安全上下文标记。 ","date":"2018-12-10","objectID":"/linux_iptables/:3:5","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 地址转换 -j SNAT --to-source 194.236.50.155-194.236.50.160:1024-32000 # SNAT 目标仅在 POSTROUTING 链NAT 表中有效 # 修改源IP、端口 # 默认使用第1个有效IP -j DNAT --to-destination # 目标地址转换，可以指定连续的IP范围或连续的端口范围 -o interfaceName -j MASQUERADE [--to-ports n~n] # 伪装源地址， IP 地址是自动从特定网卡接口的信息中获取的，网卡有多IP情况下，获取方式IP未知 # MASQUERADE 目标仅在 nat 表中的 POSTROUTING 链内有效 # --to-ports 选项是可选的且仅在规则匹配部分指定 TCP 或 UDP 协议与端口匹配时才有效 -s 192.168.1.0/24 -j NETMAP --to 10.5.6.0/24 # 1:1的IP地址转换，192.168.1段转换为10.5.6段 # SAME 目标将尝试始终对网络上单个主机发起的所有连接使用相同的传出 IP 地址 -j SAME --to 10.5.6.7-10.5.6.9 # 使用目标 IP 地址和源 IP 地址的组合 -j SAME --to 10.5.6.7-10.5.6.9 --nodst # 使用 --nodst 选项，它只使用源 IP 地址来找出 NAT 功能应该为特定连接使用 # 哪个传出 IP ","date":"2018-12-10","objectID":"/linux_iptables/:3:6","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 修改头部字段 -j DSCP --set-dscp 1 # 修改 DSCP 值，与--set-dscp-class 命令是互斥的 -j DSCP--set-dscp-class EF # 将根据预定义的 DiffServ 类设置 DSCP 字段。与--set-dscp 命令是互斥的 -j ECN --ecn-tcp-remove # 删除 TCP 标头内的 ECN 位。 -j TCPMSS --set-mss 1460 # 修改 MSS 大小 -j TCPMSS --clamp-mss-to-pmtu # 自动修改MSS值(PMTU-40bByte) -j TOS --set-tos 0x10 # 修改IP头部的TOS字段，值可以是16进制或10进制 # 只在mangle 表内有效，不能在表外使用 # TTL 目标仅在 mangle 表中有效 -j TTL --ttl-set 64 # 修改IP头部的TTL值为64 -j TTL --ttl-dec 1 # 修改IP头部的TTL值-1 -j TTL --ttl-inc 1 # 修改IP头部的TTL值+1 ","date":"2018-12-10","objectID":"/linux_iptables/:3:7","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 日志记录 -j LOG --log-level debug # 记录日志级别，日志文件在/var/log/iptables -j LOG --log-prefix \"INPUT packets\" # 在日志文件中添加头部 -j LOG --log-tcp-sequence # 记录TCP序列号 -j LOG --log-tcp-options # 记录TCP选项 -j LOG --log-ip-options # 记录IP选项 # ULOG 目标用于提供匹配数据包的用户空间日志记录。如果一个数据包匹配并且设置了 # ULOG 目标，则数据包信息与整个数据包一起通过 netlink 套接字进行多播。然后， # 一个或多个用户空间进程可以订阅各种多播组并接收数据包 -j ULOG --ulog-nlgroup 2 # 目标将数据包发送到哪个网络链路组。netlink 组有 32 个，默认为1 -j ULOG --ulog-prefix \"SSH: \" # 在日志条目添加前缀 -j ULOG --ulog-cprange 100 # 每次复制多少字节数据到ULOG 的用户空间守护进程。默认为0，表示全部 -j ULOG --ulog-qthreshold 10 # 发送队列大小，如队列中有10个数据包一起发送到进程 ","date":"2018-12-10","objectID":"/linux_iptables/:3:8","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 队列 -j QUEUE # 目标用于将数据包排队到用户级程序和应用程序 -j NFQUEUE --queue-num 30 # 选项指定使用哪个队列并将队列数据发送到。如果跳过此选项，则使用默认队列 0 # 队列号是一个 16 位无符号整数，这意味着它可以取 0 到 65535 之间的任何值。 # QUEUE 目标也使用默认的 0 队列。 ","date":"2018-12-10","objectID":"/linux_iptables/:3:9","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 流量重定向到机器本身 -j REDIRECT --to-ports # 将数据包和流重定向到机器本身，主机根本不知道 # REDIRECT 目标仅在 nat 表的 PREROUTING 和 OUTPUT 链中有效。 # 它在仅从这些链调用的用户定义链中也有效，在其他任何地方都没有。 # --to-ports 选项指定要使用的目标端口或端口范围。如果没有 --to-ports 选项， # 目标端口永远不会改变。 ","date":"2018-12-10","objectID":"/linux_iptables/:3:10","tags":["防火墙","iptables"],"title":"iptables","uri":"/linux_iptables/"},{"categories":["linux"],"content":" 运行环境： centos: 7 centos: 8 Rocky Linux 8.5 内容来自以下文档： systemd介绍 systemd文档主页 systemd官网 systemd项目帮助手册索引 systemd-github systemdsystemd 是 linux 系统的一组基本构建块，它提供了一个系统和服务管理器，作为超级守护进程（PID=1）运行，同时也是启动并维护用户空间服务的系统初始化。为登陆用户启动单独实例服务 systemd 通常不是由用户直接启动，而是作为 /sbin/init 符号链接安装并在系统引导期间启动。为了和 SysV 兼容，如果二进制文件叫 Init 而不是计算机上的第一个进程（PID 不为 1），它将执行 telint 并传递所有未修改的命令行参数。因此，正常登陆会话调用中，init 和 telinit 几乎等效 当作为系统实例运行时，配置文件为 system.conf 和 system.conf.d 目录中的文件；当作为用户运行实例时，配置文件为 user.conf 和 user.con.d 目录中的文件 单元systemd 有 11 种不同的单元类型（“unit”）的各种实体之间提供依赖系统，它封装了与系统启动和维护相关的各种对象： 系统服务：文件名以.service为后缀 标识进程之间通信使用的socket文件：文件名以.socket为后缀 启动目标：文件名以.target为后缀 设备：文件名以.device为后缀 系统快照：文件名以.snapshot为后缀 系统挂载点：文件名以.moount为后缀 系统自动挂载点：文件名以.automount为后缀 交换分区：文件名以.swap为后缀 计划任务：文件名以.timet为后缀 文件路径：文件名以.path为后缀 资源管理：文件名以.slice为后缀 外部创建的进程：文件名以.scopr为后缀 特征： 基于socket的激活机制，systemd为支持此机制的服务监听socket，当接收到来自客户端的socket通信时，由systemd激活对应的服务，应答客户端的请求； 基于bus的激活机制。 基于device的激活机制，当有设备接入到系统时，systemd会自动激活device、mount、automount等unit来识别、挂载、接入对应的设备 基于path的激活机制，当某个文件路径变得可用时或路径出现相应的文件时，激活相应的服务； 系统快照机制，保存各unit的当前状态信息到持久存储中，在下次开机时可恢复之前某次快照时的系统状态，必要时可自动载入； 兼容Centos 5的SysV init 以及Centos 6的upstart机子，能够继续使用/etc/rc.d/init.d目录中的服务管理脚本。 系统引导时，其服务的启动时并行的； 按需激活进程； 基于依赖关系定义了服务控制逻辑； unit是用于对相关配置文件进行标识、识别和配置，unit文件中主要包含了系统服务、监听的socket接口、保存的快照以及其他与init启动相关的信息。 相关文件： 软件包安装的单元：/usr/lib/systemd/systemd/ /run/systemd/system/ 系统管理员安装的单元：/etc/systemd/system/ ","date":"2018-12-10","objectID":"/linuxSystemd/:0:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 单元管理命令唯一的单元名称可以省略单元类型。 如果sshd只有.service单元类型，则以下命令等效: systemctl status sshd #等效 systemctl status sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 查看单元使用帮助 systemctl help sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:1","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 查看单元文件与状态 # 相关目录：/usr/lib/systemd/system/， /etc/systemd/system/ # 默认是查找所有单元文件 systemctl list-unit-files # 参数 --type=timer # 指定单元类型，缺省该选项为查看所有单元 ","date":"2018-12-10","objectID":"/linuxSystemd/:1:2","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 启动一个单元 # systemctl start sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:3","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 停止一个单元 #（停止sshd单元） systemctl stop sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:4","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 重新加载一个单元的配置文件 systemctl reload nginx.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:5","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 重新启动一个单元 # systemctl restart sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:6","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 查看单元运行状态 # systemctl status sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:7","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 查看已经激活的单元 systemctl 或 systemctl list-units ","date":"2018-12-10","objectID":"/linuxSystemd/:1:8","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 查看激活的单元 # systemctl --state=failed ","date":"2018-12-10","objectID":"/linuxSystemd/:1:9","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 查看单元是否开机启动 # systemctl is-enabled sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:10","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 设置单元开机自动启动 # systemctl enable sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:11","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 设置单元开机自动启动并启动 # systemctl enable --now sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:12","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 取消开机启动 # systemctl disable sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:13","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 禁用一个单元 #（禁用后是不能启动的） systemctl mask sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:14","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 启用一个单元 # systemctl unmask sshd.service ","date":"2018-12-10","objectID":"/linuxSystemd/:1:15","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 重新加载systemd扫描新的或有变动的单元 # systemctl daemon-reload 电源管理及命令安装polkit后才能以普通用户身份使用电源管理。 如果是本地登录用户无需root权限但要输入root密码 ","date":"2018-12-10","objectID":"/linuxSystemd/:1:16","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 重启系统 systemctl reboot ","date":"2018-12-10","objectID":"/linuxSystemd/:2:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 退出系统并关闭电源 # ### systemctl poweroff ","date":"2018-12-10","objectID":"/linuxSystemd/:3:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 待机 # systemctl suspend ","date":"2018-12-10","objectID":"/linuxSystemd/:4:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 休眠 # systemctl hibernate ","date":"2018-12-10","objectID":"/linuxSystemd/:5:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 同时休眠到硬盘并待机 # systemctl hybrid-sleep 运行级别与运行目标systemd引入了一个和运行级别功能相似又不同的概念叫target(目标)。不像数字表示的启动级别，每个目标都有名字和独特的功能， 并且能同时启用多个。一些目标继承其他目标的服务，并启动新服务。 systemd提供了一些模仿sysvinit运行级别的目标，仍可以使用旧的telinit命令切换运行级别 。 SysV 启动级别 SysV 运行级别目标 systemd目标 说明 0 runlevel0.target poweroff.target 关机 1 runlevel1.target rescue.target 单用户模式 2 runlevel2.target multi-user.target 多用户模式，没有NFS网络 3 runlevel3.target multi-user.target 完整的多用户模式，默认运行级别 4 runlevel4.target multi-user.target 系统保留 5 runlevel5.target graphical.targe 图形化 6 runlevel6.target reboot.target 重启模式 emergency emergency.target emergency.target 急救模式 ","date":"2018-12-10","objectID":"/linuxSystemd/:6:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 运行目标相关命令 # 查看当前目标 runlevel #切换当前运行目标（临时有效） systemctl isolate runlevel3.target #验证当前的启动目标， systemctl get-default #修改开机默认启动目标，方法一：systemctl命令修改 systemctl set-default runlevel3.target 临时文件/usr/lib/tmpfiles.d/ 和 /etc/tmpfiles.d/ 中的文件描述了 systemd-tmpfiles 如何创建、清理、删除临时文件和目录，这些文件和目录通常存放在 /run 和 /tmp 中。配置文件名称为 /etc/tmpfiles.d/.conf。此处的配置能覆盖 /usr/lib/tmpfiles.d/ 目录中的同名配置。 定时器一个定时器是一个以 .timer 为结尾的单元配置文件并包含由 systemd 控制和监督的信息，可以做一些时间任务 挂载因为 systemd 也负责按 /etc/fstab 挂载目录。在系统启动和重新加载系统管理器时，systemd-fstab-generator(8) 会将 /etc/fstab 中的配置转化为 systemd 单元。 systemd 扩展了 fstab 的传统功能，提供了额外的挂载选项。例如可以确保一个挂载仅在网络已经连接时进行，或者仅当另外一个分区已挂载时再挂载。这些选项通常以 x-systemd. 开头，systemd.mount(5) 中包含了完整说明。 日志systemd提供了自己的日志系统称为journal。无需额外安装日志服务。 默认情况下（配置文件/etc/systemd/journald.conf 中Storage=auto），日志记录将被写入/var/log/journal/目录。 该目录是systemd软件包的一部分。如果被删除，systemd不会自动创建它，直到下次升级软件包时重建该目录。 如果该目录缺失，则会将日志记录写入/run/systemd/journal目录，这意味着，系统重启后日志将丢失。 注意：如果/var/log/journal/位于btrfs文件系统，应该考虑对这个目录禁用写入时复制 日志也有优先级和记录（0-7）类型（0-23）。Systemd日志事件提示信息的记录安装优先级和更能进行分离，符合经典的BSD syslog协议风格 默认日志最大限制为所在文件系统容量的 10%，即：如果 /var/log/journal 储存在 50GiB 的根分区中，那么日志最多存储 5GiB 数据 #读取日志的命令 journalctl #显示本次启动的日志 journalctl -b -0 #显示上一次启动的日志 journalctl -b -1 #显示错误、冲突、警告日志 journalctl -p err..alert #显示从指定日期开始的日志 journalctl --since=\"2018-10-6 18:17:16\" #显示指定时间开始的日志 journalctl --since \"20 min ago\" #显示最日志 journalctl -f #显示特定程序的所有日志 journalctl /usr/lib/systemd/systemd #显示特定进程所有日志 journalctl _PID=1577 #显示指定单元的日志 journalctl -u service #显示内存缓存的日志 journalctl -k #查看指定进程的错误日志 journalctl -b _PID=15630 配置文件配置文件在：/usr/lib/systemd/system/ 配置选项说明：https://www.freedesktop.org/software/systemd/man/systemd.directives.html 新的配置文件生成后需要使用systemctl daemon-reload重新载入 ","date":"2018-12-10","objectID":"/linuxSystemd/:7:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 单元属性 # 说明文档：https://www.freedesktop.org/software/systemd/man/systemd.unit.html [Unit] ... ","date":"2018-12-10","objectID":"/linuxSystemd/:8:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" Before与After # https://www.freedesktop.org/software/systemd/man/systemd.unit.html#Before= # 单元启动顺序，多个单元以空格分开 # Before：如果这些单元也在启动中，则当前单元优先启动 # 示例表示 bar.service 与当前单元同时启动时，当前单元启动之后在启动 bar.service Before=bar.service # After：如果这些单元也在启动中，则当前单元最后启动 # 示例表示：如果这些也在启动中，则等它们启动后再启动当前单元 After=network.target remote-fs.target nss-lookup.target ","date":"2018-12-10","objectID":"/linuxSystemd/:8:1","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" Description # https://www.freedesktop.org/software/systemd/man/systemd.unit.html#Description= # Description：添加描述说明 Description=The nginx HTTP and reverse proxy server ","date":"2018-12-10","objectID":"/linuxSystemd/:8:2","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 安装信息 # https://www.freedesktop.org/software/systemd/man/systemd.unit.html # 其中包含该单元的安装信息 [Install] ... ","date":"2018-12-10","objectID":"/linuxSystemd/:9:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" WantedBy与RequiredBy # https://www.freedesktop.org/software/systemd/man/systemd.unit.html#WantedBy= # 该选项可以多次使用，或者可以给出以空格分隔的单元名称列表 # 在给定的运行目标中设置单元开机启动 # - 示例：执行命令 systemctl enable ... 后链接到 multi-user.target 级别 # 如果开机启动级别为 multi-user.target ，则会自动启动当前单元 WantedBy=multi-user.target 示例： # nginx服务单元设置开机启动链接的运行目标 [root@localhost ~]# grep \"WantedBy\" /usr/lib/systemd/system/nginx.service WantedBy=multi-user.target # multi-user.target运行目标的开机启动单元目录： # /etc/systemd/system/multi-user.target.wants/ # 开机启动方式是创建软链接 [root@localhost ~]# systemctl enable nginx.service Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service. # 取消删除软链接 [root@localhost ~]# systemctl disable nginx.service Removed /etc/systemd/system/multi-user.target.wants/nginx.service. ","date":"2018-12-10","objectID":"/linuxSystemd/:9:1","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 单元终止过程进程终止过程： 使用信号SIGTERM（除非要发送的信号通过KillSignal=或更改RestartKillSignal=） 可选地，这后面紧跟一个SIGHUP（如果启用了 SendSIGHUP=）。 如果在单元的主进程退出后进程仍然存在或通过 TimeoutStopSec= 配置的延迟已经过去，则使用 SIGKILL 信号或通过 FinalKillSignal= 指定的信号重复终止请求（除非通过 SendSIGKILL= 选项禁用此功能 ","date":"2018-12-10","objectID":"/linuxSystemd/:10:0","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" KillMode # 终止单元的进程方式，有以下值 # - control-group：单元的控制组中的所有剩余进程将在单元停止时被杀死 # - process：则仅杀死主进程本身 # - none: 单元停止时只会执行停止命令，否则不会杀死任何进程。 # 停止后仍处于活动状态的进程将留在其控制组中，并且控制组在停止后继续存在， # 除非为空 # - mixed，则 SIGTERM信号被发送到主进程，而后续 SIGKILL信号被发送到单元控制组 # 的所有剩余进程 ","date":"2018-12-10","objectID":"/linuxSystemd/:10:1","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" KillSignal # 停止时使用的信号，默认为SIGTERM # https://www.freedesktop.org/software/systemd/man/systemd.kill.html# # 在发送此设置中指定的信号后，systemd 将始终发送 SIGCONT，以确保即使挂起的任务也可以干净地终止。 ","date":"2018-12-10","objectID":"/linuxSystemd/:10:2","tags":["systemctl"],"title":"超级守护进程 systemd","uri":"/linuxSystemd/"},{"categories":["linux"],"content":" 运行环境： centos:7 命令历史 登陆 shell 时会读取命令历史文件（~/.bash_history）中记录的命令。~/.bash_history 只会在首个打开终端时才会被读取 登陆 shell 后执行的命令会保存在缓存中 退出 shell 后缓存中的命令会追加到文件（~/.bash_history）中 查看使用过的命令查看最近3条历史命令 [root@vps ~]# history 3 4 history --help 5 history 6 history 3 调用历史中的命令调用历史中的第6条命令 [root@vps ~]# !6 history 3 4 history --help 5 history 6 history 3 调用上一条命令最后的参数 [root@vps ~]# ls -al || ls !$ ls -al || ls -l total 44 dr-xr-x---. 3 root root 4096 Oct 14 12:02 . drwxr-xr-x. 17 root root 4096 Oct 14 15:08 .. 调用最近以h开头的命令 [root@vps ~]# !h 调用上一条命令 [root@vps ~]# !! 修改配置 记录方式在 HISTCONTROL 变量中，有以下值： ignoredups: 忽略连续的重复命令 ignorespace: 忽略以空白开头的命令 ignoreboth: 包含以上2个 记录格式由 HISTTIMEFORMAT 变量指定 记录文件大小由 HISTFILESIZE 变量指定 记录数量由 HISTSIZE 变量指定 记录文件由 HISTFILE 变量指定 设置记录记录文件大小 [root@yh ~]# export HISTFILESIZE=1450 设置历史记录条数 [root@yh ~]# export HISTSIZE=1500 设置所有终端命令历史都保存在同一个文件 [root@yh ~]# export HISTFILE=~/.bash_history 可以将所有设置写入/etc/bashrc中下次启动生效，也可以执行文件立即生效 [root@yh ~]# tail -4 /etc/bashrc # vim:ts=4:sw=4 export HISTTIMEFORMAT=\"%F %T \" export HISTCONTROL=\"ignoreboth\" [root@yh ~]# source /etc/bashrc 查看记录历史的方式 [root@vps ~]# echo $HISTCONTROL ignoredups 修改当前记录历史的方式 [root@vps ~]# export HISTCONTROL=\"ignoreboth\" 显示时间戳 [root@yh ~]# export HISTTIMEFORMAT='%F %T ' [root@yh ~]# history 2 89 2018-12-19 10:25:47 export HISTTIMEFORMAT='%F %T ' 90 2018-12-19 10:25:49 history 2 [root@yh ~]# export HISTTIMEFORMAT=\"%Y-%m-%d \" [root@yh ~]# history 2 91 2018-12-19 export HISTTIMEFORMAT=\"%Y-%m-%d \" 92 2018-12-19 history 2 删除历史命令删除命令历史中第32条命令 [root@vps ~]# history -d 32 清空命令历史 [root@vps ~]# history -c 手动把缓存的命令追加到文件（~/.bash_history）中 [root@vps ~]# history -a ","date":"2018-12-10","objectID":"/history/:0:0","tags":["命令","history 命令"],"title":"使用命令记录","uri":"/history/"},{"categories":["linux"],"content":" 运行环境： centos:7 grep: 3.1 内容来自以下文档： sed帮助手册 grepgrep 在标准输入文件中搜索包含模式匹配的文本行，默认情况下只打印 grep 匹配的行；如果没有指定文件，则 grep 搜索当前目录 grep 有以下四种搜索模式 基本正则表达式，默认使用的模式 扩展正则表达式，繁衍出变种命令 egrep 固定字符串，繁衍出变种命令 fgrep 兼容 Perl 正则表达式 退出状态码： 0 : 表示有匹配当行，但如果是使用 -q, --quiet, - 发送错误退出状态码也是 0 1 : 表示没有匹配到行 2 : 表示 sed 错误，但如果是使用 -q, --quiet, - 发送错误退出状态码也是 0 使用方式： grep [OPTIONS] PATTERN [FILE...] grep [OPTIONS] [-e PATTERN | -f FILE] [FILE...] PATTERN：匹配条件 Regexp selection and interpretation: -E, --extended-regexp PATTERN is an extended regular expression (ERE) -F, --fixed-strings PATTERN is a set of newline-separated fixed strings -G, --basic-regexp PATTERN is a basic regular expression (BRE) -P, --perl-regexp # PCRE 兼容 perl 正则 -e, --regexp=PATTERN use PATTERN for matching -f, --file=FILE obtain PATTERN from FILE -i, --ignore-case ignore case distinctions -w, --word-regexp force PATTERN to match only whole words -x, --line-regexp force PATTERN to match only whole lines -z, --null-data a data line ends in 0 byte, not newline Miscellaneous: -s, --no-messages suppress error messages -v, --invert-match select non-matching lines -V, --version display version information and exit --help display this help text and exit Output control: -m, --max-count=NUM stop after NUM matches -b, --byte-offset print the byte offset with output lines -n, --line-number print line number with output lines --line-buffered flush output on every line -H, --with-filename print the file name for each match -h, --no-filename # 不显示文件名 --label=LABEL use LABEL as the standard input file name prefix -o, --only-matching show only the part of a line matching PATTERN -q, --quiet, --silent suppress all normal output --binary-files=TYPE assume that binary files are TYPE; TYPE is 'binary', 'text', or 'without-match' -a, --text equivalent to --binary-files=text -I equivalent to --binary-files=without-match -d, --directories=ACTION how to handle directories; ACTION is 'read', 'recurse', or 'skip' -D, --devices=ACTION how to handle devices, FIFOs and sockets; ACTION is 'read' or 'skip' -r, --recursive # 递归目录，等效 --directories=recurse 选项 -R, --dereference-recursive likewise, but follow all symlinks --include=FILE_PATTERN search only files that match FILE_PATTERN --exclude=FILE_PATTERN skip files and directories matching FILE_PATTERN --exclude-from=FILE skip files matching any file pattern from FILE --exclude-dir=PATTERN directories that match PATTERN will be skipped. -L, --files-without-match print only names of FILEs containing no match -l, --files-with-matches print only names of FILEs containing matches -c, --count print only a count of matching lines per FILE -T, --initial-tab make tabs line up (if needed) -Z, --null print 0 byte after FILE name Context control: -B, --before-context=NUM print NUM lines of leading context -A, --after-context=NUM print NUM lines of trailing context -C, --context=NUM print NUM lines of output context -NUM same as --context=NUM --group-separator=SEP use SEP as a group separator --no-group-separator use empty string as a group separator --color[=WHEN], --colour[=WHEN] use markers to highlight the matching strings; WHEN is 'always', 'never', or 'auto' -U, --binary do not strip CR characters at EOL (MSDOS/Windows) -u, --unix-byte-offsets report offsets as if CRs were not there (MSDOS/Windows) 常用选项: -E, --extended-regexp 使用扩展正则表达式，等效 `egrep` 命令 -G, --basic-regexp 使用基础正则表达式，是默认选项 -F, --fixed-strings 只匹配字符串 -P, --perl-regexp 使用与 Perl 兼容的正则 --color=auto 显示颜色 -v 反选 -i 忽略大小写 -o 仅显示过滤文本 -q 不输出任何信息 -c 显示匹配文件的行数 -n 输出行号 -An 显示匹配文本的下n行 -Bn 显示匹配文本的上n行 -Cn 显示匹配文本的上下n行 -w 匹配单词 -R 递归搜索 -E 使用扩展表达式 -P 使用Perl正则表达式 -V 显示版本 -q 取消显示，只返回退出状态码（0：有匹配行，1：无匹配行，2：表示文件不存在） 设置别名 alias \"grep=grep --color=auto\" 实例 截取.ss前面的的字符 [root@vps ~]# grep -Po '[\\w+]+?(?=.ss)' ss asfs fdsfafsf wrw fss fdjlfskjfgd qr132 [root@vps ~]# cat ss asfs.ss fdsfafsf.ss wrwfss.ss fdjlfskjfgd.ss qr132.ss 只保留汉字 [root@master ~]# grep -Po '\\p{Han}+' file 获取外网ip和广播地址 ip addr | egrep -o '[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}' | e","date":"2018-12-10","objectID":"/linuxCmdGrep/:0:0","tags":["grep","linux","命令"],"title":"grep - 打印与正则表达示匹配的行","uri":"/linuxCmdGrep/"},{"categories":["linux"],"content":" 运行环境： centos: 7 简介nfs：网络文件系统。能在Linux之间实现数据共享 软件：nfs-utils, rpcbind 配置文件：/etc/sysconfig/nfs 目录导出文件：/etc/exports NFS 就是 Network FileSystem 的缩写，最早之前是由sun 这家公司所发展出来的。 它最大的功能就是可以透过网络，让不同的机器、不同的操作系统、可以彼此分享个别的档案 (share files)。所以，你也可以简单的将他看做是一个文件服务器 (file server) ！这个 NFS 服务器可以让你的 PC 来将网络远程的 NFS 服务器分享的目录，挂载到本地端的机器当中， 在本地端的机器看起来，那个远程主机的目录就好像是自己的一个磁盘分区槽一样 (partition)！使用上面相当的便利！ 因为 NFS 支持的功能相当的多，而不同的功能都会使用不同的程序来启动， 每启动一个功能就会启用一些端口来传输数据，因此， NFS 的功能所对应的端口才没有固定住， 而是随机取用一些未被使用的小于 1024 的埠口来作为传输之用。但如此一来又造成客户端想要连上服务器时的困扰， 因为客户端得要知道服务器端的相关埠口才能够联机吧！ 此时我们就得需要远程过程调用 (RPC) 的服务啦！RPC 最主要的功能就是在指定每个 NFS 功能所对应的 port number ，并且回报给客户端，让客户端可以连结到正确的埠口上去。 那 RPC 又是如何知道每个 NFS 的埠口呢？这是因为当服务器在启动 NFS 时会随机取用数个埠口，并主动的向 RPC 注册，因此 RPC 可以知道每个埠口对应的 NFS 功能，然后 RPC 又是固定使用 port 111 来监听客户端的需求并回报客户端正确的埠口， 所以当然可以让 NFS 的启动更为轻松愉快了！ 所以你要注意，要启动 NFS 之前，RPC 就要先启动了，否则 NFS 会无法向 RPC 注册。 另外，RPC 若重新启动时，原本注册的数据会不见，因此 RPC 重新启动后，它管理的所有服务都需要重新启动来重新向 RPC 注册。 当客户端有 NFS 档案存取需求时，他会如何向服务器端要求数据呢？ 客户端会向服务器端的 RPC (port 111) 发出 NFS 档案存取功能的询问要求； 服务器端找到对应的已注册的 NFS daemon 埠口后，会回报给客户端； 客户端了解正确的埠口后，就可以直接与 NFS daemon 来联机。 由于 NFS 的各项功能都必须要向 RPC 来注册，如此一来 RPC 才能了解 NFS 这个服务的各项功能之 port number, PID, NFS 在服务器所监听的 IP 等等，而客户端才能够透过 RPC 的询问找到正确对应的埠口。 也就是说，NFS 必须要有 RPC 存在时才能成功的提供服务，因此我们称 NFS 为 RPC server 的一种。事实上，有很多这样的服务器都是向 RPC 注册的，举例来说，NIS (Network Information Service) 也是 RPC server 的一种呢 #安装软件 [root@yh ~]# yum install -y rpcbind [root@yh ~]# yum install -y nfs-utils #编辑目录导出文件。多个客户端用空格隔开 [root@yh ~]# vim /etc/exports #格式：目录名称 客户端地址(权限) #客户地址：ip、网段、* #权限：ro：只读，rw：读写，sync：同步(CPU和硬盘)，async：异步(CPU到内存再到硬盘) #其他权限：all_squash 客户端上所有用户传的文件所属为nfsnobody #其他权限：root_squash 客户端roo用户上传的文件所属为nfsnobody #其他权限：no_root_squash 客户端root用户上传的文件所属为root #其他权限：anonuid=指定用户ID，anongid=指定用户组ID #以只读方式挂载 /nfs/ro 192.168.157.130(ro) #以读写方式挂载,文件组ID为1000，root用户上传的文件指定为nfsnobody /nfs/rw 192.168.157.130(rw,root_squash,anongid=1000) #重启服务，有顺序的启动 [root@yh ~]# systemctl restart rpcbind [root@yh ~]# systemctl restart nfs-server #重新加载目录导出文件 [root@yh ~]# exportfs -rav exporting 192.168.157.130:/nfs/rw exporting 192.168.157.130:/nfs/ro #验证 [root@yh ~]# showmount -e localhost Export list for localhost: /nfs/rw 192.168.157.130 /nfs/ro 192.168.157.130 #在客户端安装软件 [root@ma ~]# yum install -y rpcbind [root@ma ~]# yum install -y nfs-utils [root@ma ~]# systemctl restart rpcbind [root@ma ~]# systemctl restart nfs-server #验证是否能连接服务端 [root@ma ~]# showmount -e 192.168.157.131 #在客户端挂载 [root@ma ~]# mount 192.168.157.131:/nfs/ro /nfs/ro [root@ma ~]# mount 192.168.157.131:/nfs/rw /nfs/rw #验证在客户端是否能写入文件到/nfs/ro [root@ma ~]# touch /nfs/ro/tsa touch: cannot touch ‘/nfs/ro/tsa’: Read-only file system #验证在客户端是否能写入文件到/nfs/rw [root@yh ~]# chmod o+w /nfs/rw [root@ma ~]# touch /nfs/rw/tsa #在服务端查看上传文件属性 [root@yh ~]# ll /nfs/rw/tsa -rw-r--r-- 1 nfsnobody ua 0 Aug 11 22:23 /nfs/rw/tsa ","date":"2018-12-10","objectID":"/nfs/:0:0","tags":[null],"title":"nfs","uri":"/nfs/"},{"categories":["linux"],"content":" 运行环境： centos: 7 vsftpd: 3.0 内容来自以下文档： 官网 版本变化 常见问题 vsftpdvsftpd 是用于 UNIX 系统（包括Linux）的 GPL 许可 FTP 服务 ","date":"2018-12-10","objectID":"/ftp/:0:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" 安装 yum 安装 # 检查使用的 yum 源中安装包使用有 vsftpd [root@localhost ~]# yum list | grep vsftpd vsftpd.x86_64 3.0.2-27.el7 base vsftpd-sysvinit.x86_64 3.0.2-27.el7 base # 安装 vsftpd ，-y 选项确定安装 [root@localhost ~]# yum install -y vsftpd ... Resolving Dependencies --\u003e Running transaction check ---\u003e Package vsftpd.x86_64 0:3.0.2-27.el7 will be installed --\u003e Finished Dependency Resolution ... Running transaction Installing : vsftpd-3.0.2-27.el7.x86_64 1/1 Verifying : vsftpd-3.0.2-27.el7.x86_64 1/1 Installed: vsftpd.x86_64 0:3.0.2-27.el7 Complete! ","date":"2018-12-10","objectID":"/ftp/:1:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" 相关文件 [root@localhost ~]# rpm -ql vsftpd # 日志配置文件 /etc/logrotate.d/vsftpd # PAM 认证配置文件 /etc/pam.d/vsftpd # 黑名单用户列表文件 /etc/vsftpd/ftpusers # 黑名单和白名单用户列表 /etc/vsftpd/user_list # vsftpd 服务配置文件 /etc/vsftpd/vsftpd.conf # 迁移 vsftpd 脚本 /etc/vsftpd/vsftpd_conf_migrate.sh # vsftpd 系统单元生成器文件 /usr/lib/systemd/system-generators/vsftpd-generator # vsftpd 系统服务文件 /usr/lib/systemd/system/vsftpd.service # 系统单元文件 /usr/lib/systemd/system/vsftpd.target /usr/lib/systemd/system/vsftpd@.service # 二进制文件，也就是命令 /usr/sbin/vsftpd ... # 配置文件帮助手册信息 /usr/share/man/man5/vsftpd.conf.5.gz # vsftpd 帮助信息 /usr/share/man/man8/vsftpd.8.gz # 匿名用户家目录 /var/ftp # 匿名用户下载目录 /var/ftp/pub ","date":"2018-12-10","objectID":"/ftp/:2:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" 日志配置文件 [root@localhost ~]# cat /etc/logrotate.d/vsftpd /var/log/vsftpd.log { # ftpd doesn't handle SIGHUP properly # 不压缩文件 nocompress # 日志轮循期间，任何错误将被忽略 missingok } /var/log/xferlog { # ftpd doesn't handle SIGHUP properly nocompress missingok } ","date":"2018-12-10","objectID":"/ftp/:3:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" vsftpd 服务配置文件vsftpd.conf 可用于控制 vsftpd 行为的各个方面，默认情况下在/etc/vsftpd.conf 可以通过 vsftpd 命令覆盖某些功能 以 # 开头表示注释 配置和值之间用等号连接，且等号左右两边不能有空格 每个配置都有默认值 ","date":"2018-12-10","objectID":"/ftp/:4:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" 配置文件说明 以下内容来自官方文档–vsftpd.config说明 ###################################################################################### # 匿名用户相关配置 anonymous_enable 是否允许使用匿名用户，如果开启，ftp 和 anonymous 用户都视为匿名用户 可选值： - YES（默认值） - NO anon_mkdir_write_enable 是否允许匿名用户在某些条件下创建新目录，有以下条件： - 必须开启 write_enable - 匿名用户必须在父目录有写入权限 可选值： - YES - NO（默认值） anon_other_write_enable 是否允许许匿名用户执行除上载和创建目录之外的写操作（如：删除和重命名） 可选值： - YES - NO（默认值） anon_upload_enable 是否允许匿名用户在某些条件下上传文件，有以下条件： - 必须开启 write_enable - 匿名用户必须对上传文件的目录具有写权限 可选值： - YES - NO （默认值） anon_world_visible_only 是否开启匿名用户只能下载可读文件(即：匿名用户对文件拥有读取选项则可以下载该文件) 可选值： - YES - NO（默认值） chown_upload_mode 匿名用户上传文件的权限：（在v2.0.6中添加），默认值为 0600 chown_uploads 所有匿名上传的文件所有权都改为 chown_username 配置指定的用户 可选值： - YES - NO（默认值） chown_username 匿名用户上传的所有文件拥有着，默认为 root deny_email_enable 是否提供匿名密码邮箱响应列表，开启会导致某些情况拒绝登陆，默认列表记录在文件 /etc/vsftpd.banned_emails 中 有以下情况 - banned_email_file 选项配置会覆盖默认文件 可选值： - YES - NO（默认值） no_anon_password 是否启动匿名用户直接登陆，（不需要咨询密码） 可选值： - YES - NO（默认值） anon_max_rate 匿名用户最大传输速率，单位为字节每秒 可取值： - n (n 为正整数) - 0（默认值，表示不限制） anon_umask 用于匿名用户的用于文件创建的 umask 设置的值，默认值为：077 可取值： - n（n 为正整数，以 0 开头：表示八进制，其他情况视为十进制） anon_root 匿名用户家目录，匿名登录后尝试将其更改为该目录，失败则忽略 取值：路径，默认值没有设置 ftp_username 匿名用户，默认值为 ftp allow_anon_ssl 是否允许匿名用户使用 SSL 连接,，仅在 ssl_enable 开启时使用 可选值： - YES - NO （默认值） # ###################################################################################### ###################################################################################### # 本地用户相关设置 local_enable 是否允许本地用户登陆，必须开启此选项才能让非匿名用户正常工作；如果开启，则使用 /etc/passwd 文件或 PAM 配置指定的文件中的普通用户登陆 可选值： - YES - NO（默认值） chroot_local_user 是否限制用户在家目录 可选值： - YES - NO（默认值） passwd_chroot_enable 限制每个用户在 /etc/passwd/ 中指定的家目录，有下先决条件： - 必须启用 chroot_local_user 配置 可选值： - YES - NO（默认值） chroot_list_enable 是否开启限制例外的用户名单 有以下特殊情况： - 如果 chroot_local_user=YES，则文件中的用户不受限制，相当于白名单列表 - 如果 chroot_local_user=NO，则文件中的用户受到限制，相当于黑名单列表 - chroot_list_file 选项指定存储用户名单列表的文件 可选值： - YES - NO （默认值） chroot_list_file 例外本地用户名单，默认值为 /etc/vsftpd.chroot_list，有一下先决条件 - chroot_list_enable 配置开启才有效 local_root 本地用户家目录，本地用户登陆后，会尝试切换到指定目录，失败则忽略。默认是没有设置的 use_localtime 是否显示目录列表和当地时间，认为显示GMT；MDTM FTP命令返回的时间也受此选项的影响 可选值： - YES - NO（默认值） local_max_rate 本地用户最大的传输速率，单位多少字节每秒 可取值： - n (n 为正整数) - 0（默认值，表示不限制） local_umask 用于本地用户的用于文件创建的 umask 设置的值， 可取值： - n（n 为正整数，以 0 开头：表示八进制，其他情况视为十进制） check_shell 是否开启检查本地用户 shell，如果开启，用户 shell 不在 `/etc/shells` 中则会拒绝登陆ftp 有以下特殊情况: - 没有使用 PAM 建立连接的才有效 可选值： - YES（默认值） - NO # ###################################################################################### ###################################################################################### # 虚拟户相关设置 local_enable 是否允许本地用户登陆，必须开启此选项才能让非匿名用户正常工作；如果开启，则使用 /etc/passwd 文件或 PAM 配置指定的文件中的普通用户登陆 可选值： - YES - NO（默认值） virtual_use_local_privs 是否启用虚拟用户将使用与本地用户相同的特权，默认情况下，虚拟用户与匿名用户相同的特权 可选值： - YES - NO（默认值） user_sub_token 基于模板为每个虚拟用户自动生成家目录 # ###################################################################################### ###################################################################################### # 权限设置 write_enable 是否有写入权限，即（STOR，DELE，RNFR，RNTO，MKD，RMD，APPESITE 这些命令） 可选值： - YES - NO（默认值） nopriv_user 这是vsftpd想要完全没有特权时使用的用户名，默认没有设置 download_enable 是否允许下载文件，如果为 NO ，则拒绝所有下载请求 可选值： - YES（默认值） - NO file_open_mode 设置上传文件的权限，默认值 0666 # ###################################################################################### ###################################################################################### # 日志设置 dual_log_enable 是否启用以下两种日志记录方式 - wu-ftpd样式，由 xferlog_file 配置指定记录位置 - vsftpd样式：由 vsftpd_log_file 配置指定记录位置 可选值： - YES - NO（默认值） log_ftp_protocol 是否记录所有FTP请求和响应，对于调试很有帮助，有以下先决条件： - 启用选项 xferlog_std_format 可选值： - YES - NO（默认值） xferlog_enable 是否开启日志记录 可选值： - YES（配置文件示例中已经启用） - NO（默认值） vsftpd_log_file vsftp 样式日志记录文件位置，默认值为：/var/log/vsftpd.log xferlog_std_format 是否启用 xferlog 样式记录日志 可选值： - YES - NO（默认值） xferlog_file wu-ftpd样式日志记录文件位置，默认值：/var/log/xferlog syslog_enable 是否把日志信息记录到系统日志中，如果开启此选项，/var/log/vsftpd.log 文件不会在受到日志信息 可选值： - YES - NO（默认值） no_log_lock 关闭锁定日志文件 可选","date":"2018-12-10","objectID":"/ftp/:5:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" 匿名用户匿名用户也是本地用户的一种，是一个通用的本地用户，不需要使用密码就能使用登陆 ftp 修改 ftp 服务配置文件,（按照需求选择修改，默认配置只允许匿名用户下载） # 备份默认配置文件 [root@localhost ~]# cp /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.1.bak # 查看是否开启允许使用匿名用户 [root@centos7 ~]# grep \"anonymous_enable\" /etc/vsftpd/vsftpd.conf anonymous_enable=YES # 查看是否允许匿名上传文件 [root@centos7 ~]# grep \"anon_upload_enable\" /etc/vsftpd/vsftpd.conf #anon_upload_enable=YES # 取消配置文件中的 anon_upload_enable 注释，允许匿名用户上传文件 [root@centos7 ~]# sed -i '/^#anon_upload_enable/s/#//' /etc/vsftpd/vsftpd.conf # 查看匿名用户是否允许创建目录 [root@centos7 ~]# grep \"anon_mkdir_write_enable\" /etc/vsftpd/vsftpd.conf #anon_mkdir_write_enable=YES # 取消配置文件中的 anon_mkdir_write_enable 注释，允许匿名用户创建目录 [root@centos7 ~]# sed -i '/^#anon_mkdir_write_enable/s/#//' /etc/vsftpd/vsftpd.conf 启动服务 # 临时关闭 selinux 立即生效 [root@centos7 ~]# setenforce 0 # 永久关闭 selinux 重启生效 [root@centos7 ~]# sed -i '/^SELINUX=/c\\SELINUX=disabled' /etc/selinux/config # 启动服务 [root@centos7 ~]# systemctl restart vsftpd # 查看服务状态 [root@centos7 ~]# systemctl status vsftpd ● vsftpd.service - Vsftpd ftp daemon Loaded: loaded (/usr/lib/systemd/system/vsftpd.service; disabled; vendor preset: disabled) Active: active (running) since Tue 2020-07-07 06:49:35 CST; 5s ago Process: 1903 ExecStart=/usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf (code=exited, status=0/SUCCESS) Main PID: 1904 (vsftpd) Tasks: 1 Memory: 576.0K CGroup: /system.slice/vsftpd.service └─1904 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf Jul 07 06:49:35 centos7 systemd[1]: Starting Vsftpd ftp daemon... Jul 07 06:49:35 centos7 systemd[1]: Started Vsftpd ftp daemon. # 开机自动启动 [root@centos7 ~]# systemctl enable vsftpd Created symlink from /etc/systemd/system/multi-user.target.wants/vsftpd.service to /usr/lib/systemd/system/vsftpd.service. # 查看是否有监听端口 [root@centos7 ~]# ss -naltp | grep vsftpd LISTEN 0 32 [::]:21 [::]:* users:((\"vsftpd\",pid=1904,fd=4)) 报错处理","date":"2018-12-10","objectID":"/ftp/:6:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" 500 OOPS 错误信息 500 OOPS: vsftpd: refusing to run with writable root inside chroot () 解决方法 错误原因：从2.3.5之后，vsftpd 增强了安全检查，如果用户被限定在了其家目录下，则该用户的家目录不能再具有写权限了！如果检查发现还有写权限，就会报该错误。 ftp 文件传输协议响应状态码： 1**：信息 2**：成功类 3**：提示需要进一步提供补充信息 4**：客户端错误 5**：服务端错误 ","date":"2018-12-10","objectID":"/ftp/:7:0","tags":["命令","vsftp 命令"],"title":"ftp 协议及其应用","uri":"/ftp/"},{"categories":["linux"],"content":" 内容来自以下文档： GNU Findutils 4.9.0 find 用于查找文件语法：find [选项] [路径] [条件] [处理] 注意：find 文件查找的结果会一次性传递给后面的命令，如果命令不能完全接受，可能会执行失败。解决方法：find 查找 | xargs 命令 缺省值 路径：当前目录 处理：-print，标准输出至显示屏 按文件名称查找 -name：区分大小写，支持通配符 -iname：不区分大小写 -regex：按正则表达式匹配文件路径字符串 按文件属性查找 -user：按文件属主查找 -group：按文件属组查找 -uid：按UID查找 -gid：按GID查找 -nouser：查找没有属主的文件 -nogroup：查找没有属组的文件 按文件类型查找 -type 选项 ： -type f：普通文件 -type d：目录文件 -type b：块设备文件 -type c：字符设备文件 -type l：符号链接文件 -type p：管道文件 -type s：套接字文件 按文件大小查找: -size [+|-] n单位：常用单位：G，M，K。缺省范围：n-1到数值之间 -n的匹配范围：0到n-1之间 +n的匹配范围：n到无穷大之间 按文件时间戳查找 -atime [+|-] n ：按访问戳查找，单位：（天）不带+-，n的范围：n到n+1之间 +n的范围：n+1到无穷大之间 -n的范围：0到n之间 -mtime [+|-] n：按修改戳查找，单位：（天），单位（天） -ctime [+|-] n：按状态修改时间戳查找，单位（天） -amin [+|-] n：按访问戳查找，单位：（天） -mmin [+|-] n：按修改戳查找，单位：（天） -cmin [+|-] n：按状态修改时间戳查找，单位：（天） 按文件权限查找 -perm 权限：精确查找 -perm +权限：(u,g,o)中任何一个拥有指定权限 -perm -权限：(u,g,o)同时拥有指定权限 条件组合 与：-a 或：-o 非：-not，！ 处理操作： -print：打印至显示屏（默认） -ls：结果与ll一样 -delete：删除 -fls file ：所有文件的长格式信息保存在指定文件 -ok 命令 {} \\;：对每个文件执行命令之前要求确认，{}表示引用文件名 -exec 命令 {} \\;：与-ok相反 按名称查找 [root@localhost ~]# find ./ -name \".bash*\" 查找当前路径下的.bash开头的文件 按大小查找 find /etc/ -size +300k #大于300k的文件 find /etc/ -size -300k #小于300k的文件 按修改时间查找 [root@localhost ~]# find /root/ -mtime +7 #7天前修改的文件 [root@localhost ~]# find /root/ -mtime -7 #7天以内修改的文件 按文件类型查找 [root@localhost ~]# find /etc/ -type l #查找链接文件 复合查找 find / -name \"an*\" -a -size -200k #an开头和下于200k的文件 示例 删除 page 以外的所有目录 [root@localhost posts]# ll total 64 drwxr-xr-x. 5 root root 4096 Jan 28 15:26 aws drwxr-xr-x. 2 root root 44 Jan 28 15:26 git drwxr-xr-x. 2 root root 4096 Jan 28 15:26 golang drwxr-xr-x. 2 root root 4096 Jan 28 15:26 hugo -rw-r--r--. 1 root root 18044 Jan 28 15:26 index.html -rw-r--r--. 1 root root 3198 Jan 28 15:26 index.xml drwxr-xr-x. 2 root root 4096 Jan 28 15:26 k8s drwxr-xr-x. 2 root root 4096 Jan 28 15:26 linux drwxr-xr-x. 2 root root 78 Jan 28 15:26 nginx drwxr-xr-x. 9 root root 62 Jan 28 15:26 page drwxr-xr-x. 2 root root 23 Jan 28 15:26 README drwxr-xr-x. 2 root root 4096 Jan 28 15:26 redis drwxr-xr-x. 3 root root 54 Jan 28 15:26 vim drwxr-xr-x. 2 root root 4096 Jan 28 15:26 windows drwxr-xr-x. 2 root root 4096 Jan 28 15:26 五笔 drwxr-xr-x. 2 root root 54 Jan 28 15:26 其它 -rw-r--r--. 1 root root 3384 Jan 28 15:26 新建 文本文档.txt drwxr-xr-x. 2 root root 4096 Jan 28 15:26 游戏 drwxr-xr-x. 2 root root 32 Jan 28 15:26 网络通信 drwxr-xr-x. 2 root root 38 Jan 28 15:26 观测 [root@localhost posts]# find /usr/local/nginx/note/posts/ -mindepth 1 -maxdepth 1 -type d -a -not -name 'page' -exec rm -rf {} \\; [root@localhost posts]# ll total 28 -rw-r--r--. 1 root root 18044 Jan 28 15:26 index.html -rw-r--r--. 1 root root 3198 Jan 28 15:26 index.xml drwxr-xr-x. 9 root root 62 Jan 28 15:26 page -rw-r--r--. 1 root root 3384 Jan 28 15:26 新建 文本文档.txt ","date":"2018-12-10","objectID":"/linux-%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE/:0:0","tags":["命令","linux","find 命令"],"title":"linux 文件查找","uri":"/linux-%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： [dnf 官方文档][dnf 官方文档] [rpm 官方文档][rpm 官方文档] yum 官方文档 yumyum：RPM包管理的前端管理工具 作用：解决RPM包的依赖 配置文件： 公共配置文件： /etc/yum.conf rpm包配置： /etc/yum/version-groups.conf /etc/yum.repos.d/ /etc/yum/pluginconf.d/ /var/cache/yum/ yum命令语法格式：yum [options] [command] [package ...] 常用选项： -y：确认 -q：静默模式 --disablerepo=repoidglob：临时禁用指定的源 --enablerepo=repoidglo：临时启用指定的源 --noplugins：临时禁用所有的差异 --disableexcludes： --downloaddir: 指定下载目录，默认为缓存目录 --downloadonly : 只下载rpm包，不安装 列出可用的yum仓库 [root@yh ~]# yum repolist 列出所有的软件包 [root@yh ~]# yum list all 列出所有软件包版本 --showduplicates 列出可用的升级包 [root@yh ~]# yum check-update 安装软件包（默认安装最新版本，可以指定版本） [root@yh ~]# yum install -y package1 [package2] [...] 重新安装软件包 [root@yh ~]# yum reinstall -y package1 [package2] [...] 升级软件包 [root@yh ~]# yum update -y [package1] [package2] [...] 降级软件包 [root@yh ~]# yum downgrade -y package1 [package2] [...] 卸载软件包 [root@yh ~]# yum remove -y | erase package1 [package2] [...] 查看软件包信息 [root@yh ~]# yum info [...] 查看指定特性（可以是文件）是有哪些软件包提供 [root@yh ~]# yum provides | whatprovides feature1 [feature2] [...] 清理缓存 [root@yh ~]# yum clean [ packages | metadata | expire-cache | rpmdb | plugins | all ] 手动生成缓存 [root@yh ~]# yum makecache [fast] 指定关键字模糊搜索安装包 [root@yh ~]# yum search string1 [string2] [...] 查看软件包依赖关系 [root@yh ~]# yum deplist package1 [package2] [...] 查看历史事务（安装和卸载） [root@yh ~]# yum history [info|list|stats] 查找命令相关的软件包 [root@vps ~]# yum search command 查看软件包组 [root@yh ~]# yum grouplist 安装软包组（也会安装相关依赖） [root@yh ~]# yum group install -y packages 安装软件包组（也会安装相关依赖） [root@yh ~]# yum group update packages 卸载软包组（也会安装相关依赖） [root@yh ~]# yum group remove packages 查看软包组信息 [root@yh ~]# yum group info packages /etc/yum.conf配置文件简介 [main] #ID 必须具有唯一性 cachedir=/var/cache/yum/$basearch/$releasever keepcache=0 debuglevel=2 logfile=/var/log/yum.log exactarch=1 obsoletes=1 gpgcheck=1 plugins=1 installonly_limit=5 bugtracker_url= distroverpkg=centos-release yum仓库使用帮助：man yum.conf 自定义yum源： 在配置文件/etc/yum.repos.d/以.repo结尾都可以 [yun id] name=描述 baseurl=仓库URL gpgcheck=检查来源是否完整和合法，0 表示关闭，1表示开启 enabled= 是否启动0表示关闭，1表示开启（此行没有则默认为1） gpgkey=密钥URL 配置文件中可用的变量 系统发行主版本号：$releasever CPU架构：$arch CPU基础架构：$basearch 自定义变量：$YUM0到$YUM9 自定义YUM仓库： 安装软件 [root@yh ~]# yum install -y createrepo 创建目录作为软件包存放位置，并下载软件包到此目录 [root@yh erpo]# mkdir /erpo [root@yh media]# cp Packages/zip-3.0-11.el7.x86_64.rpm /erpo/ 生成yum仓库，配置yum源即可使用 [root@yh erpo]# createrepo /erpo/ Spawning worker 0 with 1 pkgs Spawning worker 1 with 0 pkgs Workers Finished Saving Primary metadata Saving file lists metadata Saving other metadata Generating sqlite DBs Sqlite DBs complete 查看信息 [root@yh ~]# ls /erpo/repodata/ createrepo命令的其他选项 缓存缓存在一般来说，在 CentOS 7 中，下载的 RPM 包会被保存在类似 /var/cache/yum/x86_64/7/base/packages 这样的路径中，其中 x86_64 是系统的架构，7 是 CentOS 版本，base 是仓库名称，packages 是存放 RPM 包的目录。 源码安装通常命令方式 名称-版本号.tar.gz 获取帮助：configure –help，或者insert文件 第一步 ：./configure#运行这个脚本 进行软件安装的环境测试，可加软件安装路径与模块选项，用于定制软件功能 第二步：make #进行软件编译 第三步：make install #进行安装 安装后 （1）导出二进制文件(bin)到变量中并让其开机执行 [root@m1 ~]#echo \"export PATH=PATH1 PATH2\" \u003e /etc/profile.d/name.sh （2）导出库文件(lib)路径 [root@m1 ~]# echo \"库文件目录\" \u003e /etc/ld.so.conf.d/name.conf （3）导出头文件(include) ln s 目录 目录 （4）导出帮助手册 /etc/man_db.conf MANPATH 目录 repos","date":"2018-12-10","objectID":"/yum/:0:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/yum/"},{"categories":["linux"],"content":" repl地址 # CentOS 7 yum install epel-release -y # CentOS Linux 8, AlmaLinux 8, Rocky Linux 8 dnf install epel-release -y \u0026\u0026 dnf config-manager --set-enabled powertools error","date":"2018-12-10","objectID":"/yum/:1:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/yum/"},{"categories":["linux"],"content":" No more mirrors to try 详情：安装包时报错 Error downloading packages: kubelet-1.17.2-0.x86_64: [Errno 256] No more mirrors to try. 解决：刷新 yum 缓存 [root@master ~]# yum clean all Loaded plugins: fastestmirror Cleaning repos: base docker-ce-stable epel extras kubernetes updates Cleaning up list of fastest mirrors [root@master ~]# yum makecache Loaded plugins: fastestmirror Determining fastest mirrors ","date":"2018-12-10","objectID":"/yum/:2:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/yum/"},{"categories":["linux"],"content":" Error: Failed to download metadata for repo ‘appstream’: Cannot prepare internal mirrorlist: No URLs in mirrorlist # https://stackoverflow.com/questions/70926799/centos-through-vm-no-urls-in-mirrorlist # https://mirrors.tuna.tsinghua.edu.cn/help/centos-vault/ # centos 8 不在维护，镜像已经迁移 # vault.centos.org是提供不在维护的centos版本yum源 sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-* sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-* ","date":"2018-12-10","objectID":"/yum/:3:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/yum/"},{"categories":["linux"],"content":" Error: rpmdb open failed [root@US01-C6220-DS050-03 lib]# yum clean all error: db5 error(11) from dbenv-\u003eopen: Resource temporarily unavailable error: cannot open Packages index using db5 - Resource temporarily unavailable (11) error: cannot open Packages database in /var/lib/rpm CRITICAL:yum.main: Error: rpmdb open failed ","date":"2018-12-10","objectID":"/yum/:4:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/yum/"},{"categories":["linux"],"content":" Insufficient space in download directory Error downloading packages: gitlab-jh-16.2.4-jh.0.el7.x86_64: Insufficient space in download directory /var/cache/yum/x86_64/7/gitlab-jh/packages * free 748 M * needed 1.4 G 缓存空间不够，要清理空间或扩容 # 清理 yum 缓存 [root@localhost ~]# yum clean all ","date":"2018-12-10","objectID":"/yum/:5:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/yum/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： dnf 官方文档 rpm 官方文档 yum 官方文档 安装包cnetos 下的安装包称为rpm包，通常是 .rpm 的RPM包和 src.rpm 的SRPM包以及源码包 .rpm 包可以直接使用 rpm 命令安装 srpm 包含有编译时的源码文件和编译的参数，所以在使用的时候要重新编译 除了上述方式，可以使用源码包编译安装 通常 RPM 包的命令方式：名称-版本号-发行号.系统.CPU架构.rpm（noarch 表示所有 CPU 架构通用） RPM 包之间存在依赖关系。如：安装 a 包的前提要安装 b 包，否则失败 ldd 命令可以查看二进制文件共享库的依赖关系 ldd `which sshd` 查看缓存的所有可用库文件 ldconfig -lp 配置文件： /etc/ld.so.conf /etc/ld.so.conf.d/* 缓存文件：/etc/ld.so.cache 重新加载配置文件： ldconfig 获取RPM包方式 系统镜像 官方下载 第三方组织：fedora-epel 搜索引擎：pkgs 下载的文件或安装包需要检查来源合法性和文件完整性 rpmrpm 命令是 rpm 包管理工具 ","date":"2018-12-10","objectID":"/rpm/:0:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 安装软件rpm -ivh name.rpm (软件包的位置可以是本地、ftp 地址、http 地址) --text ：测试安装（非真正的安装） --notriggers：忽略依赖包（有可能无法正常使用） --replacepkgs：重新安装（原配置可能被覆盖） --nodigest：不检查完整性 --nosignature：不检查来源合法性 --noscript：不执行安装包脚本 --nopre ：安装前的脚本 --nopost ：安装后的脚本 --nopreun ：卸载前脚本 --nopostun：卸载后脚本 ","date":"2018-12-10","objectID":"/rpm/:1:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 升级软件不要直接对内核升级。可以直接安装新版本的内核。升级后，如果原配置文件发生变化，则新的配置文件以.rpmnew为后缀 rpm -Uvh name.rpm -F：只升级但不安装 --oldpackage：降级 --force：强行升级 ","date":"2018-12-10","objectID":"/rpm/:2:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 卸载软件rpm -e name.rpm ","date":"2018-12-10","objectID":"/rpm/:3:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 查询软件的描述rpm -qpi name.rpm，其他附加选项：（必须加 -q ） -a：所有包。 -f：查看文件由哪个程序包提供（可以接 which 命令） --whatprovides：查看指定功能有哪里包提供 --whatrequires：查看指定功能有哪些包依赖 --changelog：查看RPM包的更新日志 -c：查看安装包生成的配置文件 --conflicts：查看与之冲突的软件包 -d：查看安装包的帮助文档 -l：查看安装包后生成的文件 --scripts：查看脚本 --provides：查看软件提供的功能 -R：查看软件依赖的功能 校验软件：rpm -V name.rpm S：文件大小是否改变 M：模式是否改变（包括权限和文件类型） 5：以前的MD5总和是否改变 D：设备主要/次要编号不匹配 L：路径不匹配 U：用户所有权是否改变 G：用户组所有权是否改变 T ：mTime是否改变 P ：caPabilities是否改变 校验软件是否完整性和安全性 导入公钥：rpm --import GPGkeyfile rpm -K name.rpm rpm的库路径：/var/lib/rpm/* rpm库重建：rpm --rebuilddb dnfdnf 全称 “Dandified Yum”，是 yum 的下一代 rpm 包管理工具，在 centos 8 中，已经是默认 rpm 包管理工具，yum 命令也只是 dnf 的软链接 [root@c8 ~]# ll $(which yum) lrwxrwxrwx. 1 root root 5 Apr 25 03:57 /usr/bin/yum -\u003e dnf-3 dnf 命令使用上和 yum 方式一样，使用方式：dnf [Option] [Command] 相关文件： 主配置文件：/etc/dnf/dnf.conf 仓库文件： /etc/yum.repos.d/ 缓存目录：/var/cache/dnf/ 获取帮助： dnf -h ：获取帮助信息 man dnf ：获取帮助信息 官方文档：dnf官方文档 子命令及其选项 alias 列出或创建命令别名 autoremove 删除所有原先因为依赖关系安装的不需要的软件包 check 在包数据库中寻找问题 check-update 检查是否有软件包升级 clean 删除已缓存的数据 deplist 列出软件包的依赖关系和提供这些软件包的源 distro-sync 同步已经安装的软件包到最新可用版本 downgrade 降级包 group 显示或使用组信息 help 显示一个有帮助的用法信息 history 显示或使用事务历史 info 显示关于软件包或软件包组的详细信息 install 向系统中安装一个或多个软件包 list 列出一个或一组软件包 makecache 创建元数据缓存 mark 在已安装的软件包中标记或者取消标记由用户安装的软件包。 module 与模块交互 provides 查找提供指定命令由哪个软件包提供 reinstall 重装一个包 remove 从系统中移除一个或多个软件包 repolist 显示已配置的软件仓库 repoquery 搜索匹配关键字的软件包 repository-packages 对指定仓库中的所有软件包运行命令 search 在软件包详细信息中搜索指定字符串 shell 运行交互式的 DNF 终端 swap 运行交互式的 DNF 终端以删除或者安装 spec 描述文件 updateinfo 显示软件包的参考建议 upgrade 升级系统中的一个或多个软件包 upgrade-minimal 升级，但只有“最新”的软件包已修复可能影响你的系统的问题 config-manager --enable 启用某个库 config-manager -disable 禁用某个库 ","date":"2018-12-10","objectID":"/rpm/:4:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 安装包dnf install 命令可以安装一个或多个包、包组、模块 ","date":"2018-12-10","objectID":"/rpm/:5:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 重新安装包yum reinstall 命令 ","date":"2018-12-10","objectID":"/rpm/:6:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 卸载已安装的包dnf remove 命令可以 Remove command-specific options: --duplicates remove duplicated packages --oldinstallonly remove installonly packages over the limit PACKAGE Package to remove ","date":"2018-12-10","objectID":"/rpm/:7:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 检查本地包文件库的问题dnf [options] check [--dependencies] [--duplicates] [--obsoleted] [--provides] --all # 显示所有问题，默认值 --dependencies # 显示依赖问题 --duplicates # 显示重复的问题 --obsoleted # 显示过时的包 --provides show problems with provides ","date":"2018-12-10","objectID":"/rpm/:8:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 查看信息dnf [options] info [\u003cpackage-file-spec\u003e...] --all # 显示所有包信息，默认值 --available show only available packages --installed show only installed packages --extras show only extras packages --updates show only upgrades packages --upgrades show only upgrades packages --autoremove show only autoremove packages --recent show only recently changed packages 查看 acl 包的信息 [root@localhost ~]# dnf info acl Last metadata expiration check: 1:35:30 ago on Fri 09 Sep 2022 02:47:07 PM CST. Installed Packages Name : acl Version : 2.2.53 Release : 1.el8.1 Architecture : x86_64 Size : 194 k Source : acl-2.2.53-1.el8.1.src.rpm Repository : @System From repo : anaconda Summary : Access control list utilities URL : https://savannah.nongnu.org/projects/acl License : GPLv2+ Description : This package contains the getfacl and setfacl utilities needed for : manipulating access control lists. ","date":"2018-12-10","objectID":"/rpm/:9:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 历史记录 [root@localhost ~]# dnf history --help ... --reverse display history list output reversed -o OUTPUT, --output OUTPUT For the store command, file path to store the transaction to --ignore-installed For the replay command, don't check for installed packages matching those in transaction --ignore-extras For the replay command, don't check for extra packages pulled into the transaction --skip-unavailable For the replay command, skip packages that are not available or have missing dependencies COMMAND # 子命令，有以下值： # - list: 查看列表 # - info: 查看信息 # redo # replay, rollback, store, undo, userinstalled TRANSACTION For commands working with history transactions, Transaction ID (\u003cnumber\u003e, 'last' or 'last-\u003cnumber\u003e' for one transaction, \u003ctransaction-id\u003e..\u003ctransaction- id\u003e for a range) TRANSACTION_FILE For the replay command, path to the stored transaction file to replay ","date":"2018-12-10","objectID":"/rpm/:10:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 历史列表dnf history list History command-specific options: --reverse # 反转 -o OUTPUT, --output OUTPUT For the store command, file path to store the transaction to --ignore-installed For the replay command, don't check for installed packages matching those in transaction --ignore-extras For the replay command, don't check for extra packages pulled into the transaction --skip-unavailable For the replay command, skip packages that are not available or have missing dependencies COMMAND Available commands: list (default), info, redo, replay, rollback, store, undo, userinstalled TRANSACTION For commands working with history transactions, Transaction ID (\u003cnumber\u003e, 'last' or 'last-\u003cnumber\u003e' for one transaction, \u003ctransaction-id\u003e..\u003ctransaction- id\u003e for a range) TRANSACTION_FILE For the replay command, path to the stored transaction file to replay 查看命令历史记录 [root@localhost ~]# dnf history list ID | Command line | Date and time | Action(s) | Altered ---------------------------------------------------------------------------------------------- 3 | install -y jq | 2022-09-08 14:27 | Install | 2 2 | update -y | 2022-09-08 13:45 | I, U | 204 1 | | 2022-09-08 11:18 | Install | 351 EE 查看已启用的仓库 [root@c8 ~]# dnf repolist repo id repo name AppStream CentOS-8 - AppStream BaseOS CentOS-8 - Base docker-ce-stable Docker CE Stable - x86_64 extras CentOS-8 - Extras 查看所有仓库 [root@c8 ~]# dnf repolist all repo id repo name status AppStream CentOS-8 - AppStream enabled AppStream-source CentOS-8 - AppStream Sources disabled BaseOS CentOS-8 - Base enabled BaseOS-source CentOS-8 - BaseOS Sources disabled Devel CentOS-8 - Devel WARNING! FOR BUILDROOT USE ONLY! disabled ... 查看所有软件包 [root@c8 ~]# dnf list | head -n 10 Last metadata expiration check: 2:10:06 ago on Mon 29 Jun 2020 12:48:36 PM CST. Installed Packages NetworkManager.x86_64 1:1.22.8-4.el8 @BaseOS NetworkManager-libnm.x86_64 1:1.22.8-4.el8 @BaseOS NetworkManager-team.x86_64 1:1.22.8-4.el8 @BaseOS NetworkManager-tui.x86_64 1:1.22.8-4.el8 @BaseOS acl.x86_64 2.2.53-1.el8 @anaconda adobe-mappings-cmap.noarch 20171205-3.el8 @AppStream adobe-mappings-cmap-deprecated.noarch 20171205-3.el8 @AppStream adobe-mappings-pdf.noarch 20180407-1.el8 @AppStream 查看仓库中是否有 docker [root@c8 ~]# dnf list | grep docker docker-ce.x86_64 3:19.03.12-3.el7 @docker-ce-stable docker-ce-cli.x86_64 1:19.03.12-3.el7 @docker-ce-stable docker-ce-selinux.noarch 17.03.3.ce-1.el7 docker-ce-stable pcp-pmda-docker.x86_64 5.0.2-5.el8 AppStream podman-docker.noarch 1.6.4-10.module_el8.2.0+305+5e198a41 AppStream 查看已经安装的软件包 [root@c8 ~]# dnf list installed Installed Packages NetworkManager.x86_64 1:1.22.8-4.el8 @BaseOS NetworkManager-libnm.x86_64 1:1.22.8-4.el8 @BaseOS NetworkManager-team.x86_64 1:1.22.8-4.el8 @BaseOS NetworkManager-tui.x86_64 1:1.22.8-4.el8 @BaseOS 搜索有 docker 描述相关的软件包 [root@c8 ~]# dnf search docker Last metadata expiration check: 2:12:56 ago on Mon 29 Jun 2020 12:48:36 PM CST. ==================================================== Name \u0026 Summary Matched: docker ==================================================== podman-docker.noarch : Emulate Docker CLI using podman pcp-pmda-docker.x86_64 : Performance Co-Pilot (PCP) metrics from the Docker daemon ========================================================= Name Matched: docker ========================================================= docker-ce.x86_64 : The open-source application container engine docker-ce-cli.x86_64 : The open-source application container engine docker-ce-selinux.noarch : SELinux Policies for the open-source application container engine 查看该文件是哪个安装包提供 [root@c8 ~]# dnf provides /bin/docker Last metadata expiration check: 2:14:32 ago on Mon 29 Jun 2020 12:48:36 PM CST. docker-ce-17.03.0.ce-1.el7.centos.x86_64 : The open-source application container engine Repo : docker-ce-stable Matched from: Filename : /usr/bin/docker 查看软件包详细信息 [root@c8 ~]# dnf info docker-ce Last metadata expiration check: 2:16:06 ago on Mon 29 Jun 2020 12:48:36 PM CST. Installed Packages Name : docker-ce","date":"2018-12-10","objectID":"/rpm/:10:1","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" repl地址 # CentOS 7 yum install epel-release -y # CentOS Linux 8, AlmaLinux 8, Rocky Linux 8 dnf install epel-release -y \u0026\u0026 dnf config-manager --set-enabled powertools error","date":"2018-12-10","objectID":"/rpm/:11:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" No more mirrors to try 详情：安装包时报错 Error downloading packages: kubelet-1.17.2-0.x86_64: [Errno 256] No more mirrors to try. 解决：刷新 yum 缓存 [root@master ~]# yum clean all Loaded plugins: fastestmirror Cleaning repos: base docker-ce-stable epel extras kubernetes updates Cleaning up list of fastest mirrors [root@master ~]# yum makecache Loaded plugins: fastestmirror Determining fastest mirrors ","date":"2018-12-10","objectID":"/rpm/:12:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" Error: Failed to download metadata for repo ‘appstream’: Cannot prepare internal mirrorlist: No URLs in mirrorlist # https://stackoverflow.com/questions/70926799/centos-through-vm-no-urls-in-mirrorlist # https://mirrors.tuna.tsinghua.edu.cn/help/centos-vault/ # centos 8 不在维护，镜像已经迁移 # vault.centos.org是提供不在维护的centos版本yum源 sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-* sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-* ","date":"2018-12-10","objectID":"/rpm/:13:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" Error: rpmdb open failed [root@US01-C6220-DS050-03 lib]# yum clean all error: db5 error(11) from dbenv-\u003eopen: Resource temporarily unavailable error: cannot open Packages index using db5 - Resource temporarily unavailable (11) error: cannot open Packages database in /var/lib/rpm CRITICAL:yum.main: Error: rpmdb open failed ","date":"2018-12-10","objectID":"/rpm/:14:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" Insufficient space in download directory Error downloading packages: gitlab-jh-16.2.4-jh.0.el7.x86_64: Insufficient space in download directory /var/cache/yum/x86_64/7/gitlab-jh/packages * free 748 M * needed 1.4 G 缓存空间不够，要清理空间或扩容 # 清理 yum 缓存 [root@localhost ~]# yum clean all ","date":"2018-12-10","objectID":"/rpm/:15:0","tags":["rpm","yum","dnf"],"title":"yum","uri":"/rpm/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： [name][url] [url]: 一次性计划任务 #确定at服务已经启动 [root@yh ~]# systemctl status atd.service ● atd.service - Job spooling tools Loaded: loaded (/usr/lib/systemd/system/atd.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2018-08-09 10:24:07 CST; 1min 50s ago Main PID: 779 (atd) CGroup: /system.slice/atd.service └─779 /usr/sbin/atd -f Aug 09 10:24:07 yh.localdomain systemd[1]: Started Job spooling tools. Aug 09 10:24:07 yh.localdomain systemd[1]: Starting Job spooling tools… #执行结果会发送到任务创建着的系统邮箱 #系统时间12：00关机，Ctrl +D 保存任务 [root@yh ~]# at 12:00 at\u003e poweroff at\u003e \u003cEOT\u003e #Ctrl +D job 2 at Thu Aug 9 12:00:00 2018 #一天后重启 [root@yh ~]# at now +1 day at\u003e reboot at\u003e \u003cEOT\u003e #Ctrl +D job 5 at Fri Aug 10 10:34:00 2018 其他指定时间方式 HH:MM,YYYY-MM-DD -c：查看作业具体任务 -q：队列 -l：查看等待运行的作业 -t：删除指定作业 -f：指定文件为作业内容 系统邮箱： centos6：mail centos7：mailx 语法：mailx -s \"标题\" 收件人 直接输入正文或者管道 、重定向都可以 Ctrl +D 发送退出 让系统自行选择空闲时间执行任务：batch 使用 crond 实现周期性计划任务安装相关安装包 [root@localhost logs]# yum install -y cronie crontabs cronie-* ... 安装后生成以下命令： crond: 执行任务的守护进程 crontab: 编写任务的客户端，编写的任务都会保存在 var/spool/cron/$user 查看 crond 状态 [root@yh ~]# systemctl status crond ● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2018-08-09 10:24:07 CST; 12min ago Main PID: 777 (crond) CGroup: /system.slice/crond.service └─777 /usr/sbin/crond -n Aug 09 10:24:07 yh.localdomain systemd[1]: Started Command Scheduler. Aug 09 10:24:07 yh.localdomain systemd[1]: Starting Command Scheduler... Aug 09 10:24:07 yh.localdomain crond[777]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 57% if used.) Aug 09 10:24:08 yh.localdomain crond[777]: (CRON) INFO (running with inotify support) Hint: Some lines were ellipsized, use -l to show in full. 定时任务格式 [root@localhost logs]# cat /etc/crontab SHELL=/bin/bash # 执行使用的 shell PATH=/sbin:/bin:/usr/sbin:/usr/bin # path 变量，用于查找执行命令位置 MAILTO=root # 执行用户的身份 # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed #分 时 天 月 周 执行用户名 命令 # 时间有以下值： # - * 号表示任意值 # - */n 表示 * 时间内每隔 n 执行一次, 当时间无法整除时可使用 sleep 命令延迟执行 # - a-b 表示从 a 到 b 之间的值 # - a,b 表示 a 或 b 为当前用户建立周期性任务（保存在/var/spool/cron/$user） [root@yh ~]# crontab -e 0 0 * * 0 yum update #每周日的零点更新 0 21 * * 1,3,5 ntp1.aliyun.com #每周1、周3、周5 同步时间 0 0 10-20/3 * * bash /root/atd.sh #在每月第10天至20天中每隔3天执行atd.sh脚本 10 23 * 1-3 * systemctl restart atd #1-3月每天23:10重启at服务 # 用sleep命令延迟了59秒实现每天23:59:59执行脚本 59 23 * * * root sleep 59; bash /data/download/nginx_logs_day.sh ","date":"2018-12-10","objectID":"/%E6%97%B6%E9%97%B4%E4%BB%BB%E5%8A%A1/:0:0","tags":["命令","at 命令","crontab 命令","一次性时间任务","周期性时间任务"],"title":"时间任务","uri":"/%E6%97%B6%E9%97%B4%E4%BB%BB%E5%8A%A1/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： [name][url] [url]: 硬件时间 查看当前硬件时间，以下2条命令同效 [root@yh ~]# clock [root@yh ~]# hwclock 系统时间同步硬件时间 [root@yh ~]# hwclock -s 硬件时间同步系统时间 [root@yh ~]# hwclock -w 设置硬件时间为24小时制 [root@yh ~]# export LANG= 使用 date 命令修改或查看系统时间date 命令用于修改或按指定样式查看系统时间，使用 date --help、info date、man date 都可以查看帮助信息 SYNOPSIS date [OPTION]... [+FORMAT] date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]] OPTION -d, --date=STRING # 指定字符串显示时间 -r, --reference=FIL # 查看文件最后修改的时间 -R, --rfc-2822 # 使用 RFC-2822 样式显示时间 -s, --set=STRING # 设置时间 -u, --utc, --universal # 以 UTC 样式设置或显示时间，缺省时使用 CST FORMAT %% # 字符串 % %a # %a # 工作日英语缩写 (e.g., Sun) %A # 工作日英语 (e.g., Sunday) %b # locale's abbreviated month name (e.g., Jan) %B # locale's full month name (e.g., January) %c # locale's date and time (e.g., Thu Mar 3 23:05:25 2005) %C # century; like %Y, except omit last two digits (e.g., 20) %d # 日，(e.g., 01) %D # date; same as %m/%d/%y %e # day of month, space padded; same as %_d %F # full date; same as %Y-%m-%d %g # last two digits of year of ISO week number (see %G) %G # year of ISO week number (see %V); normally useful only with %V %h # same as %b %H # 时，24小时制 (00..23) %I # 时，12小时制 (01..12) %j # day of year (001..366) %k # hour, space padded ( 0..23); same as %_H %l # hour, space padded ( 1..12); same as %_I %m # 月，数字 (01..12) %M # 分，数字 (00..59) %n # a newline %N # 纳秒 (000000000..999999999) %p # 显示 AM (上午) 或 PM (下午); 未知则为空 %P # like %p, but lower case %r # 时:分:秒，12小时制 (e.g., 11:11:04 PM) %R # 时:分 24小时制; same as %H:%M %s # 从 1970-01-01 00:00:00 UTC 到现在的秒 %S # 秒 (00..60) %t # a tab %T # 时:分:秒，24小时制，等效： %H:%M:%S %u # day of week (1..7); 1 is Monday %U # week number of year, with Sunday as first day of week (00..53) %V # ISO week number, with Monday as first day of week (01..53) %w # day of week (0..6); 0 is Sunday %W # week number of year, with Monday as first day of week (00..53) %x # 月/日/年 (e.g., 12/31/99) %X # 时:分:秒 12小时制 (e.g., 23:13:48) %y # last two digits of year (00..99) %Y # 年 %z # 时区 (e.g., -0400) %:z # +hh:mm numeric time zone (e.g., -04:00) %::z # +hh:mm:ss numeric time zone (e.g., -04:00:00) %:::z # numeric time zone with : to necessary precision (e.g., -04, +05:30) %Z # 时区单词缩写 查看当前系统时间 [root@localhost ~]# date Fri Aug 12 13:34:53 CST 2022 [root@localhost ~]# date \"+%Y-%m-%d %H:%M:%S %Z%:z\" 2022-08-12 13:36:11 CST+08:00 修改时区 方法1：将时区信息文件复制到本地时区文件。 [root@yh ~]cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 使用 ntpd 服务同步时间 ntp ：网络时间协议 软件：ntp 服务：ntpd 端口：123/udp 配置文件： /etc/ntp.conf 安装软件 [root@yh ~]# yum install -y ntp 编辑配置文件 [root@yh ~]# vim /etc/ntp.conf # 用于同步本机时间 server 互联网时间服务器 iburst #或 server 127.127.1.0 iburst 同步硬件时间 # 这台服务器在整个时间服务器的级别 fudge 127.127.1.0 stratum 10 # 允许这个网段向我同步时间 但不能修改我的时间 restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap 使用 timedatectl 查看或修改时间timedatectl 命令是超级守护进程 systemd 的一部分 [root@localhost ~]# timedatectl --help timedatectl [OPTIONS...] COMMAND ... Query or change system time and date settings. -h --help # 查看帮助 --version Show package version --no-pager Do not pipe output into a pager --no-ask-password Do not prompt for password -H --host=[USER@]HOST # 在远程主机上操作 -M --machine=CONTAINER # 在本地容器上操作 --adjust-system-clock Adjust system clock when changing local RTC mode Commands: status # 查看时间信息 set-time TIME # 设置系统时间 set-timezone ZONE # 设置系统时区 list-timezones # 查看支持的时区 set-local-rtc BOOL # 是否使用 RTC 时钟作为本地时间 set-ntp BOOL # 是否启用 ntp 服务 查看当前时间 [root@yh ~]# timedatectl centos7 设置时间 timedatectl set-time \"YYYY-MM-DD HH:MM:SS\" timedatectl set-time \"YYYY-MM-DD\" timedatectl set-time \"HH:MM:SS\" centos7 查看可用时区 [root@yh ~]# timedatectl list-timezones 设置时区为亚洲上海 [root@yh ~]# timedatectl set-timezone Asia/Shanghai centos7启动自动同步时间 [root@yh ~]# timedatectl set-ntp yes centos7查看chrony时间同步源 [root@yh ~]# chronyc sources -v 使用 chrony 同步时间chrony 的优势包括: 更快的同步只需要数分钟而非数小时时间，从而最大程度的减少时间和频率误差，这对于并非全天运行的台式计算机或系统而言非常有用。 能够更好的响应时间频率的快速变化，这对于具备不稳定时钟的虚拟机或导致时钟频率反生变化的节能技术而言非常有用。 在初始同步后，它并不会停止时钟，以防对需要系统时间保持单调的程序造成影响。 在应对临时非对称延迟时，（例如，大规模下载造成链接饱和时）提供了更好的稳定性。 无需对服务","date":"2018-12-10","objectID":"/%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4/:0:0","tags":["硬件时间","系统时间","时间服务","时区","命令","date 命令","timedatectl 命令","clock 命令","hwclock 命令","chronyc 命令"],"title":"系统时间","uri":"/%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4/"},{"categories":["linux"],"content":" chronyccronyc 是chrony的命令行界面。常用命令： accheck 检查NTP访问是否对特定主机可用 activity 该命令会显示有多少NTP源在线/离线 add server 手动添加一台新的NTP服务器 clients 在客户端报告已访问到服务器 delete 手动移除NTP服务器或对等服务器 settime 手动设置守护进程时间 tracking 显示系统时间信息 进入chronyc控制界面，并查看有多少NTP源在线 [root@yh ~]# chronyc chronyc\u003e activity 公共时间服务器 阿里云提供时间服务器 ntp1.aliyun.com-ntp7.aliyun.com ","date":"2018-12-10","objectID":"/%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4/:1:0","tags":["硬件时间","系统时间","时间服务","时区","命令","date 命令","timedatectl 命令","clock 命令","hwclock 命令","chronyc 命令"],"title":"系统时间","uri":"/%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： name TCP_Wrappers是基于tcp协议开发并提供的应用程序的一层访问控制工具， 守护进程：tcpd 基于库调用实现的功能 库：libwrap 查看sshd服务是否支持，有相应的模块则表示支持 ldd `which sshd` |grep wrap libwrap.so.0 =\u003e /lib64/libwrap.so.0 (0x00007f2a17c70000) 如果是动态编译则使用strings命令查看程文件，输出中有`hosts_access`则表示支持 [root@localhost ~]# strings $(which sshd) |grep hosts_access hosts_access TCP_Wrappers的使用主要是依靠两个配置文件/etc/hosts.allow, /etc/hosts.deny，用于拒绝和接受具有TCP_Wrappers控制全的程序 拒绝：/etc/hosts.deny 允许：/etc/hosts.allow 帮助：man man hosts.allow ，man hosts.deny 原理：TCP_Wrappers有一个TCP的守护进程叫作tcpd。以ssh为例，每当有ssh的连接请求时，tcpd即会截获请求，先读取系统管理员所设置的访问控制文件，符合要求，则会把这次连接原封不动的转给真正的ssh进程，由ssh完成后续工作；如果这次连接发起的ip不符合访问控制文件中的设置，则会中断连接请求，拒绝提供ssh服务 流程 （1）客户端请求服务 （2）TCP_Wrapper：tcpd进程 （3）/etc/hosts.allow：如果允许则跳过/etc/hosts.deny （4）/etc/hosts.deny：如果拒绝则拒绝请求 （5）服务接收请求 配置文件语法：daemon_list : client_list [option1] [ :option2… ] daemon_list：进程名，多个进程用逗号分割。 client_list： 主机名：www.ba.com，.ba.com IP：192.168.2.2 完整的网络地址：192.18.32.0/255.255.255.0 简短的网络地址：192.18.32. centos7网络地址：192.168.32.0/24 ALL：表示所有 LOCAL：本地主机 KNOWN：主机名可解析成ip的 UNKNOWN：主机名无法解析成IP的 PARANOID：正向解析与反向解析不对应的主机 option1： EXCEPT：排除 opthon2: deny：拒绝，通常在/etc/hosts.allow中实现拒绝 allow：允许，通常在/etc/hosts.deny中实现允许 spawn：启动其他程序 扩展：可能会混淆shell的％expansions中的字符将被替换为下划线。 ％a（％A）：客户端（服务器）主机地址。 ％c：客户端信息：user @ host，user @ address，主机名或只是一个地址，取决于可用的信息量。 ％d：守护程序进程名称（argv [0]值）。 ％h（％H）：客户端（服务器）主机名或地址（如果主机名是）不可用。 ％n（％N）：客户端（服务器）主机名（或“未知”或“偏执”）。 ％p：守护进程id ％s：服务器信息：daemon @ host，daemon @ address或dae-名字，取决于可用的信息量。 ％u：客户端用户名（或“未知”）。 %%：扩展为单个'％'字符。 举例： 仅运行192.168.12.2访问sshd服务 ）vim /etc/hosts.allow sshd:192.168.12.2 ）vim /etc/hosts.deny sshd:ALL 允许192.168.IP段访问排除192.168.12.这个IP段但允许192.168.12.3访问 ）vim /etc/hosts.allow sshd:192.168. EXCEPT 192.168.12. EXCEPT 192.168.12.3 只允许192.12.23.12访问 ）vim /etc/hosts.deny sshd:ALL EXCEPT 192.12.23.12 拒绝192.239.23.12访问 ）vim /etc/hosts.allow sshd:192.239.23.12 :deny 允许192.239.23.122访问 ）vim /etc/hosts.deny sshd:192.239.23.12 :allow 拒绝192.54.IP段访问并相关记录 ）vim /etc/hosts.deny sshd:192.54. :spawn /bin/echo \" `date` %a %c %d \" \u003e\u003e/var/log/sshd.hosts.deny #记录允许的客户端信息 sshd:192.54. :spawn /bin/echo \" `date` %a %c %d \" \u003e\u003e/var/log/sshd.hosts.allow ","date":"2018-12-10","objectID":"/tcp-wrappers/:0:0","tags":["传输层的安全控制工具"],"title":"TCP_Wrappers","uri":"/tcp-wrappers/"},{"categories":["linux"],"content":" 1、命令历史 登陆shell时会读取命令历史文件（~/.bash_history）中记录的命令 登陆shell后执行的命令会保存在换成缓存中 退出shell后缓存中的命令会追加到文件（~/.bash_history）中 2、TAB键补全 bash更据环境变量定义的路径从左往右搜索文件 命令补全：输入bash命令时可以使用tab键补全后续的命令。 路径补全：输入文件路径时可以使用tab键补全后续的文件和文件名 3、命令行展开 ~：当前用户家目录 ~user1：user1家目录 4、管道与重定向 索引：文件描述符 Linux系统将每个对象当作文件处理。这包括输入和输出进程。Linux用文件描述符（filedescriptor）来标识每个文件对象。文件描述符是一个非负整数，可以唯一标识会话中打开的文件。每个进程一次最多可以有九个文件描述符。出于特殊目的，bash shell保留了前三个文件描述符（0、1和2）， losf命令可以使用-d选项查看文件描述符 标准输入：0 标准输出：1 标准错误输入：2 所有标准输出：\u0026 重定向或追加的目标可以是文件，也可以是文件描述符 重定向：\u003e 追加：\u003e\u003e 所有标准输出追加：\u0026\u003e 或 命令 \u003e file 2\u003e\u00261 不同输出到不同文件：命令 \u003ea 2\u003eb \u0026\u003ec 将错误输出到文件，从文件读取错误输出（读写错误输出）：2\u003c\u003efile 管道(上一条的命令输出作为下一条命令的输入且最后一个命令当前shell的子shell执行的)：| ","date":"2018-12-10","objectID":"/bash1/:0:0","tags":["linux"],"title":"bash 特性","uri":"/bash1/"},{"categories":["linux"],"content":" 运行环境： centos: 7 用户 Linux有2种类型：普通用户和root管理员，管理员拥有所有的权限，普通用户只有自己的权限 Linux按照UID区分用户类型 所有用户都有一个唯一的ID称为UID，0是管理员专属ID，1-499是守护进程的，500-65535是登陆用户 所有的组都有一个唯一的ID称为GID，0是管理组专属ID，1-499是系统组，500-65535普通组 centos7 进程UID和GID是从1-999，普通用户UID和GID是从1000-65535 相关文件：/etc/shadow的配置优先级高于 /etc/login.defs 用户配置：/etc/passwd 组配置：/etc/group 用户密码配置：/etc/shadow 组密码配置：/etc/gshadow 用户限制配置：etc/login.defs 新用户配置文件：/etc/skel/* 系统邮箱位置：/var/spool/mail/$USER #用户信息以冒号为分隔符 #用户:密码占位符:UID:GID:描述:家目录:shell [root@vps ~]# cat /etc/passwd root:x:0:0:root:/root:/bin/bash #组信息以冒号为分隔符，组员用逗号分割 #用户:密码:GID:用户成员 [root@vps ~]# cat /etc/group root:x:0: #用户密码信息以冒号为分隔符 #第二段：密码以$为分隔符，第一段表示算法，第二段表示杂质，第三段是密文 #算法：1表示MDS算法，2a表示Blowfish，5表示SHA-256，6表示：SHA-512 [root@vps ~]# cat /etc/shadow |grep bin bin:*:16231:0:99999:7::: 第1段：用户名 对应着/etc/passwd中的用户名 第2段：加密密码 如果值是*则帐户被锁定，并且不允许用户登录。如果值为！以前从未设置过密码，没有密码将无法登录 第3段：密码最后更改时间 记算方式：自1970年1月1日以来的最后一次更改密码的天数 第4段：可更改密码之前的天数(在更改密码之前必须经过的最少天数,0表示随时可以修改时间) 第5段：密码有效的天数(必须更改密码之前必须经过的天数)99999表示永久 第6段：密码更改之前的警告天数(密码到期前的天数，在此期间警告用户即将到期) 第7段：密码到期之后的宽限天数(帐户停用之前密码到期后的天数) 第8段：自帐户被停用后的日期,自用户帐户被停用以来的日期 记算方式：自1970年1月1日以来被停用的天数 第9段：保留 #添加用户 #-u指定UID，-g指定GID，-G指定附加组，-c指定备注，-d指定家目录，-s指定shell，-r创建系统用户 [root@vps ~]# useradd -u 1112 -g 1004 -c \"user成员\" -d /home/user -s /bin/bash user3 useradd: warning: the home directory already exists. Not copying any file from skel directory into it. #修改用户属性 #-u指定UID，-g指定GID，-c指定备注，-s指定shell，-l 修改用户名 #-G覆盖附加组 -a添加附加组，-d指定家目录 -m 家目录下的文件也移动到新的家目录， [root@vps ~]# usermod #删除用户 #-r删除家目录 [root@vps ~]# userdel -r userx #修改用户密码 [root@vps ~]# passwd user [root@vps ~]# echo \"passwd\" | passwd --stdin user #查看有效用户 #-u只查看UID，-g只查看GID，-G只查看组员，-n显示名称 [root@vps ~]# id userx uid=1001(userx) gid=1001(userx) groups=1001(userx) #切换用户 # -表示完全读取用户配置文件，缺省则不读取用户配置文件 # -c 以其他用户执行命令 [root@vps ~]# su userx [userx@vps root]$ #添加组 #-g 指定GID，-r 创建进程组 [root@vps ~]# groupadd grou #修改组属性 #-g修改新GID，-n指定名称 root@vps ~]# groupmod grou #组删除 [root@vps ~]# groupdel grou #组密码 #-a添加指定用户到本组，-d与-a相反，-A指定有管理权限的用户 #临时切换组 [root@vps ~]# newgrp #检查密码文件完整性 [root@vps ~]# pwck 权限 ll命令可以查看文件或权限 [root@vps ~]# ll /usr/bin/ls -rwxr-xr-x. 1 root root 117616 Jun 9 2014 /usr/bin/ls ）第一个字符表示文件类型 ）第2-4表示文件所属主的权限 ）第5-7表示文件所属组的权限 ）第7-10表示其他用户的权限 权限 写入：可以修改文件内容；可以创建或删除文件和目录 读取：可以查看文件内容；可以查看目录内容 执行：可以执行文件；可以进入目录或查看列表 SUID：特殊权限 UGID：特殊权限 Sticky：特殊权限 权限可以用二进制或八进制表示 没有权限：---， 二进制：000，八进制：0 读取权限：r--， 二进制：000，八进制：4 写入权限：-w-，二进制：010，八进制：2 执行权限：--x， 二进制：001，八进制：1 #修改权限 #-R 递归修改权限，u表示用户，g表示组，o表示其他用户，a表示ugo root@vps ~]# chmod -R 777 a [root@vps ~]# chmod -R u+rx,go=x a #修改b文件权限与a文件一样 [root@vps ~]# chmod -R --reference=a b #修改文件所属 #root.yuhai 表示属主.属组，如果属主或属组缺省表示不修改 #-R表示递归，逗号可以换成冒号 [root@vps ~]# chown -R root.yuhai a #修改b文件所属主和组与a文件一样 [root@vps ~]# chown -R --reference=a b 文件和目录创建的遮罩码：umask 文件默认：666-umask 目录默认：777-umask 如果文件的666-umask中用户权限存在x权限则+1 安全上下文： 当一个进程启动之后，进程的属主为启动进程的用户，属组为进程主的用户组。 当文件的属主与进程的属主相同，则使用文件属主的权限 当文件的属组也是进程的属组，则使用文件属组的权限 SUID：（u+s，8进制：4） 进程启动之后，进程的所属主为原程序的所属主 UID权限仅对二进制程序有效 执行该程序的过程中有效 SGID：（g+s，进制：2） 任何用户在目录下创建的目录或文档的组与父目录相同 Sticky：(0+t，8进制：1) 当用户在目录下建立文件或目录时，仅有自己与 root才有权力删除。 #添加所有特殊权限，当文件有执行权限时特殊权限为小写；没有执行权限时，特殊权限大写 [root@vps ~]# chmod 7111 file [root@vps ~]# ll file ---s--s--t. 1 root root 1330 Oct 18 06:24 file [root@vps ~]# chmod 7000 file [root@vps ~]# ll file ---S--S--T. 1 root root 1330 Oct 18 06:24 file 权限 把用户加入到另一个组 [root@localhost ~]# usermod -a -G gitlab-www nginx [root@localhost ~]# [root@localhost ~]# id nginx uid=1000(nginx) gid=1000(nginx) groups=1000(nginx),991(gitlab-www) ","date":"2018-12-10","objectID":"/user/:0:0","tags":["linux 用户权限"],"title":"用户与权限","uri":"/user/"},{"categories":["linux"],"content":"sed 是流编辑器","date":"2018-12-10","objectID":"/linuxCmdSed/","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" 运行环境： sed：4.2.2 centos：7 以下内容来自： Go_Home-awk \u0026\u0026 sed　练习题 kgduu-sed 命令 n，N，d，D，p，P，h，H，g，G，x解析 sed 官方文档 高级 Bash 脚本编程指南-sed sedsed 是字节流编辑器，可以更据命令来处理数据流中的数据，这些命令通常在命令行中输入或文本中读取 工作模式sed 有2个数据缓冲区，活动模式空间（active pattern space）和辅助保持空间（auxiliary hold space），通常称为模式空间和保持空间 sed 标准工作流程（标准行为可以被选项或命令修改，但大致行为没发生变化）： sed 从输入流中读取一行文本并删除文本结尾的换行符，再放入模式空间中 在模式空间中先验证等操作命令生效的范围（文本行），如果验证成功则在模式空间中执行命令，否则跳过该命令 文本结尾添加被删除的换行符，再把将模式空间的内容打印到输出流中 读取下一行，重复上述操作直到读取完所有输入流 保持空间是特殊的，可以理解为 sed 的剪切板，有以相关命令： h：把模式空间中的内容覆盖保持空间 H：把模式空间中的内容前面添加换行符之后追加到保持空间 g：把保持空间中的内容覆盖模式空间 G：把保持空间中的内容前面添加换行符之后追加到模式空间 x：把保持空间和模式空间的内容互换 数据缓冲区的换行符把文本加载到缓冲区之前，会删除文本尾部的换行符，单纯的加载文本是不会产生换行符的，有部分操作命令会添加换行符 \\n ，该换行符并不会把文本分成多行，而是以上一行内容\\n下一行内容的一行形式存在，无论是模式空间还是保持空间都是这样 当输出时，除了 l 命令会把 \\n 当成文本输出，其余情况会当成换行符输出 当匹配时，只能由正则表达式 \\n 匹配，无法被文本自身换行符 \\n 所匹配（读取之前就被删除） 如果文本中含义文本 \\n 在模式空间是文本 \\\\n；输出时会转换为文本 \\n 示例：l 命令 # N 命令是把下一行内容前面添加换行符并追加模式空间 [root@localhost ~]# echo -e 'aa\\n\\\\n\\ncc' | sed -n '1N;l' aa\\n\\\\n$ cc$ 命令行选项更多帮助信息可以使用 info sed 命令查看 使用方式：sed [options] {sed-commands} {input-file} 常见选项： -n 不自动打印模式空间内容 -e 后面接sed命令，可以有多个-e -f 指定sed脚本文件 -i[SUFFIX], --in-place[=SUFFIX] 默认写入文件，如果指定扩展名称，则写入（”文件名称.扩展名“）结构的文件 -l N, --line-length=N 指定 sed命令 `l` 换行长度 -q 退出命令 -r sed脚本中使用扩展正则表达式 -c 保持文件属主 -l 配合sed命令l（小写L）使用 --follow-symlinks 适用软连接，不使用该选项直接修改软连接时原文件没变，且断开链接 --posix 关闭所有 GNU 扩展 -r, --regexp-extended 在脚本中使用扩展正则表达式 -s, --separate 将输入文件视为各个独立的文件而不是一个长的连续输入 -u, --unbuffered 从输入文件读取最少的数据，更频繁的刷新输出 --help 打印帮助并退出 --version 输出版本信息并退出 -a 新增行， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行) -c 替换行， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ -s 替换字符，可以配合正规表达式 -d 删除 -i 插入行， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行) -p 查看，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起使用 sed 命令 # 把注释扩展到下一个换行符之前 = 打印当前输入行行号，并在之后添加换行符 : label 指定标签 \"label\"，用于 b， t，T 命令跳转 a 在一行之后附加文本，等效 `-a` 选项 b label 无条件分支到标签，如果标签 \"label\" 不存在则跳过后续的命令 c 替换模式空间中的内容，等效 `-c` 选项 d 删除模式空间内容，立即进入下一个周期，等效 `-d` 选项 D 删除模式空间开头到第一个换行符内容，之后用模式空间内容进入下一个周期。默认空间么有换行符时，等效 d 命令 e [command] 如果指定命令，则执行并将其发送到输出流，最后一行以反斜杠结尾；如果没有指定命令，则从模式空间中寻找命令；尾随换行符会被取消 F 打印当前输入文件的文件名，以换行符结尾 g 用保持空间的内容覆盖模式空间内容 G 在模式空间尾部添加换行符，再用保持空间的内容追加到模式空间 h 用模式空间内容的内容覆盖保持空间 H 在保持空间尾部添加换行符，再用模式空间的内容追加到保持空间 i （小写i）在模式空间之前插入内容，结尾时自动添加换行符，等效 `-i` 选项 l （小写的L）以明确的形式打印模式空间内容 n 读取下一个输入行，用下一个命令处理新的行而不是当前行，旧的行会被输出，如果没有更多输入，则退出 sed N 追加下一行输入到模式空间后面并二者之间嵌入一个换行符，如果没有更多输入，则退出 sed p 打印模式空间的内容 P 打印模式空间开头到第一个换行符的内容 q [n] 退出 sed，可以指定退出状态码 Q [n] 退出 sed，可以指定退出状态码；不打印模式空间内容 r filename 从 file 中读行 R filename 在当前循环结束时或在读取下一个输入行时，将要读取的文件内容行排队并插入到输出流中 t label 当读取最后一条输入行或前面命令 s 命令替换成功时，跳转到指定分支，如果没有指定分支，则进入下一个周期 T label 当读取最后一条输入行或前面命令 s 命令替换失败时，跳转到指定分支，如果没有指定分支，则进入下一个周期 v [version] 不执行任何操作，但指定的版本号 \"version\" 不可用或不支持 GUN 扩展则会报错 w file 把模式空间的内容写入指定文件中，如果文件存在则覆盖 W file 把模式空间的内容到第一个换行符，如果文件存在则覆盖 x 交互模式空间和保持空间的内容 y/src/dst/ 字符替换，一对一字符替换，s 替换为 d ; r 替换为 s; c 替换为 t z 清除模式空间内容 s 替换 语法：sed '[start|end] s/original/replacement/[substitute]' start：匹配范围其实位置，忽略则表示从第一行开始 end：匹配范围结束位置，忽略则表示最后一行结束 //：分界符，可以使用其他字符替换，如：##、^^等等 original：替换前的字符 replacement：替换后的字符 \u0026：表示 original 匹配到的文本 \\n：与正则表达式一样，`（`分组起始，`)`分组结束，需要使用转义符`\\`。sed最多能处理9个分组 substitute：修饰词，可以多个联合使用 g：表示全局。（默认只替换每行的第一个匹配项） p：显示替换后的行 n：0\u003cn\u003c512的正整数，表示第n次出匹配之后才替换 w：写入文件 i：忽略匹配项大小写 p：打印替换后的内容 e：将模式空间中的内容当成shell命令执行（GUN sed 才能使用） y：替换，不能用于正则表达式，只是单纯的字符替换 几个GNU sed 特有的替换标志： \\l：（小写的L）紧跟着后面字符替换为小写，用于替换后的字符处前 \\L：将后面的所有字符都替换为大写，用于替换后的字符处前 \\u：（小写的U）紧跟着后面字符替换为小写，用于替换后的字符处前 \\U：紧跟着后面所有字符替换为大写，用于替换后的字符处前 \\E：与\\L或\\U一起使用，将关闭\\U或\\L的功能，用于替换后的字符后 选取地址该地址是文本行地址，也就是说无论是行号，还是表达式都是表示文本行位置。有以下几种方式指定文本范围： n: n 是行号 $: 表示文本最后一行 /regexp/[IM]: regexp 是正则表达示。I 修饰符表示不区分大小写，M 修饰符表示多行模式下匹配正则表达式 \\%regexp%[IM]: regexp 是扩展正则表达。I 修饰符表示不区分大小写，M 修饰符表示多行模式下匹配正则表达式示，有以下特殊情况： 修饰符 ^ 和 $ 除了匹配开始和结束还匹配换行符之后的空字符串和换行符之前的空字符串 有特殊的字符序列始终与缓冲区的开头或结尾匹配 在多行模式下，句点字符（ . ）与换行符不匹配 x~y: x 与 y 都表示行号，~ 表示间距。如 1~3 表示匹配（行）1 4 7... x,y: x 与 y 都表示行号，从第 x 行到 y 行，x \u003e y x,x+y: x 与 y 都表示行号，从第 x 行到 x+y 行 0,/regexp/: 从文档开头到第一次成功匹配正则表达示的行 x,/regexp/: x 表示行号，从 x 行到之后第一次成功匹配正则表达示的行 x,~y: x 表示行号或正则表达示，y 表示行号的倍数（可以是一倍）。如 2,~2 表示第2行到第4行（ 4 是 2 的 2 倍） !： 在地址后面表示取反 读取到指定文本行就会触发命令对模式空间内容操作；很多命令看起来像是对指定文本行操作，实际上是执行操作时模式空间只有该行文本 [root@loc","date":"2018-12-10","objectID":"/linuxCmdSed/:0:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" 基础正则表达式 下表是 sed 中使用的基础正则表达式 元字符 说明 \\ 转义符，用于区分字符本身和元字符，\\\\ 表示一个 \\ 字符 字符串 可以是任意字符或任意字符串 * 前面的正则表达式匹配一系列零个或多个匹配实例 . 单个字符，包括换行符 ^ 模式空间中行开头部分 $ 模式空间中行结尾部分 [] 方括号内的单个字符，有以下特殊情况： - $, *, ., [, \\ 这些字符串表示字符串本身 - ] 字符表示结束列表，要匹配字符本身必须放在首位 - - 字符表示把起始到结束的范围 - ^ 字符放在首位表示取反，如果要匹配 ^ 字符本身不能放在首位 - [..] 排序类，这是特殊的格式，如 [.ch.] - [::] 字符类，这是特殊的格式，如 [:space:] - [==] 等价类，这是特殊的格式，如 [=a=] \\+ 一个或多个字符 \\? 前面字符出现零次或一次。如 a\\?b 匹配 b 或 ab \\{i\\} 前面的表达式出现的次数，i 为10进制正整数 \\{i,j\\} 前面的表达式出现的最低次数和最高次数，i和 j 都是10进制正整数且 i \u003c j \\{i,\\} 前面的表达式出现最低次数，i 为10进制正整数 \\(regexp\\) 把表达式分组分组 \\digit 引用前面从左往右第 digit 个 \\(regexp\\)实例 regexp1|regexp2 从左往右匹配，选择第一个匹配的表达式，该表达式还可以在[]中使用，如：`a-[b \\n 匹配换行符或产生换行符 \\a 匹配 BEL字符，即产生警告 \\f 产生换页符或匹配换页符 \\r 产生回车符或匹配回车符 \\t 产生水平制表符或匹配水平制表符（\u003cTab\u003e 键） \\v 产生垂直制表符或匹配垂直制表符 \\cx 产生或匹配快捷键。c 表示 \u003cCtrl\u003e; x 是字符，可以是任意字符 \\xx 产生或匹十六进制字符（ ASCII 码），x 表示字符 \\dx 产生或匹配十进制字符（ ASCII 码），x 表示字符 \\ox 产生或匹配八进制字符（ ASCII 码），x 表示字符 以下是特殊命名类的正则表达式 元字符 说明 [:alnum:] 单个字母或数字，等效 [0-aA-Za-z] [:alpha:] 单个字母，等效 [A-Za-z] [:blank:] 空格或制表符 [:cntrl:] 控制字符。在 ASCII 中，这些字符的八进制代码为000至037，以及177（DEL） [:digit:] 单个数字，等效 [0-9] [:graph:] 可见字符 [:lower:] 单个小写字母，等效 [a-z] [:print:] 单个可打印字符（所有大小写字母、数字、标点字符），包括空格 [:punct:] 单个标点字符：! \" # $ % \u0026 ' ( ) * + , - . / : ; \u003c = \u003e ? @ [ \\ ] ^ _ { [:space:] 空格字符 [:upper:] 单个大写字母，等效 [A-Z] [:xdigit:] 16进制，等效 [0-6A-Fa-f] ","date":"2018-12-10","objectID":"/linuxCmdSed/:1:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" 扩展正则表达式扩展正则表达式和基本正则表达式区别在于以下元字符使用转义符情况，其他都一样，如下表格 元字符 BRE ERE 注释 ? \\? ? 如果想匹配 ? 字符本身，BRE 去掉 \\；ERE 添加 \\ + \\+ + 如果想匹配 + 字符本身，BRE 去掉 \\；ERE 添加 \\ () \\(\\) () 如果想匹配 () 字符本身，BRE 去掉 \\；ERE 添加 \\ {} \\{\\} {} 如果想匹配 {} 字符本身，BRE 去掉 \\；ERE 添加 \\ ` ` 无 | ","date":"2018-12-10","objectID":"/linuxCmdSed/:2:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" 用于地址选址和 s 命令的表达式这些基本正则表达式只能用于地址选址或 s 命令中 元字符 说明 \\w 单词，可以是任意字符数字或下划线组成 \\W 非单词 \\b 单词边界，即单词左边或单词右边都不是单词，示例 `echo “abc %-= def.” \\B 字符边界，即机房或单词左右两边都是非单词或字符，示例 `echo “abc %-= def.” \\s 空白字符，包含制表符和换行符 \\S 非空白字符 \\\u003c 匹配单词开头 \\\u003e 匹配单词结尾 \\` 只匹配模式空间中的开头 示例：``` echo -e “a\\nb\\nc\\n” \\' 只匹配模式空间中的结尾 sed 命令sed 命令是 sed 自带的函数，单个命令格式：{匹配项}[sed命令] ","date":"2018-12-10","objectID":"/linuxCmdSed/:3:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" a: 下一行插入行 a\\ 或 a 在最后一行插入文本 [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 # 等效 sed '$a\\这是第6行' txt [root@localhost ~]# sed '$a 这是第6行' txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 这是第6行 # 使用 a\\ 方式时不会忽略后面的空格，会认为是转义 [root@localhost ~]# sed '$a\\ 这是第6行' txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 这是第6行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:4:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" b: 无条件分支b 命令始终跳至标签，跳过或重复其他命令，而无需重新启动新循环。结合地址，可以在匹配的行上有条件地执行分支 示例： # bx 跳转到标签 x，执行 x 标签后续的命令 # :x 创建标签 x [root@localhost ~]# printf '%s\\n' a1 a2 a3 | sed -E 'bx; s/3/z/ ;:x ; y/123/456/' a4 a5 a6 示例 # 读取第一行 a1 到模式空间 ，满足 bx 跳转到标签 x ，跳过 s 命令，执行 y 命令 # 读取第二行 a2 到模式空间 ，不满足 bx 跳转标签条件，依次执行 s 与 y 命令 # 第三行同第二行 [root@localhost ~]# printf '%s\\n' a1 a2 a3 | sed -E '/1/bx; s/[13]/z/ ;:x ; y/123/456/' a4 a5 az ","date":"2018-12-10","objectID":"/linuxCmdSed/:5:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" c: 替换行 [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 [root@localhost ~]# sed '1c\\----' txt ---- 这是第2行 这是第3行 这是第4行 这是第5行 [root@localhost ~]# sed '$c----' txt 这是第1行 这是第2行 这是第3行 这是第4行 ---- ","date":"2018-12-10","objectID":"/linuxCmdSed/:6:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" d: 删除行d 命令是删除当前模式空间内容（不在传至标准输出），并放弃之后的命令，不打印模式空间内容，重新读取下一行继续循环 [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 # 第一行以被删除，后续的 p 命令被忽略 [root@localhost ~]# sed '1d; 1p' txt 这是第2行 这是第3行 这是第4行 这是第5行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:7:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" D: 删除模式空间到换行符的内容D 命令是删除当前模式空间开头到第一个 \\n的内容，保留余下内容执行后续的命令 示例：保留最后一行 [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 # 删除第一行到倒数第二行 [root@localhost ~]# sed 'N;D' txt 这是第5行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:8:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" e: 把 shell 命令通过管道符传递到模式空间e [shell command] 命令（ GUN 版本才有）允许将来自 shell 命令的输入通过管道传递到模式空间。如果命令中需执行空字符，结果不是可预料的 指定了命令，e 命令会将其解释为命令，并将其输出发送到输出流。该命令可以跨多行运行，除了最后一行以外都以反斜杠结尾 不带参数的e命令将执行在模式空间中找到的命令，并用输出替换模式空间。尾随换行符被取消 ","date":"2018-12-10","objectID":"/linuxCmdSed/:9:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" F: 查看文件名称F 命令（GUN 版本才有）打印出当前输入文件的文件名（带有换行符） [root@localhost ~]# sed 'F' txt txt 这是第1行 txt 这是第2行 txt 这是第3行 txt 这是第4行 txt 这是第5行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:10:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" g: 将当前保持空间中内容覆盖至模式空间g 命令是将当前保持空间中内容覆盖至模式空间 ","date":"2018-12-10","objectID":"/linuxCmdSed/:11:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" G: 将当前保持空间中的内容追加至模式空间G 命令是在当前模式空间追加换行符，再把保持空间内容追加到模式空间。形如：“模式空间内容 \\n 保持空间内容” ","date":"2018-12-10","objectID":"/linuxCmdSed/:12:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" h: 将当前模式空间中内容覆盖至保持空间h 命令是将当前模式空间中内容覆盖至保持空间 ","date":"2018-12-10","objectID":"/linuxCmdSed/:13:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" H: 将当前模式空间中的内容追加至保持空间H 命令是在保留空间中追加换行符，再把模式空间内容追加到保持空间。形如：“保持空间内容 \\n 模式空间内容“ ","date":"2018-12-10","objectID":"/linuxCmdSed/:14:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" i: 上一行插入行 [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 [root@localhost ~]# sed '1i ---' txt --- 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 [root@localhost ~]# sed '1i\\ ---' txt --- 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:15:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" l: 明确方式打印模式空间l n 命令指定模式空间中的长度，超过长度的行被 \\ 字符分割；每行的结尾都标有$。如果为 0 则永不换行，缺省，则使用文本自身的换行符 该命令还有一个妙用就是可以查看模式空间呈现方式 示例 # 字符本身占 1 个位置；换行符占用 1 个位置；分割符 \\ 也占用1个位置 [root@c8 ~]# echo {1..6} | sed -n 'l7' 1 2 3 \\ 4 5 6$ 示例 [root@c8 ~]# echo {1..6} | sed -n 'l4' 1 2\\ 3 \\ 4 5\\ 6$ 查看模式空间内容 [root@localhost ~]# seq 5 | sed -n 'N; l; D' 1\\n2$ 2\\n3$ 3\\n4$ 4\\n5$ ","date":"2018-12-10","objectID":"/linuxCmdSed/:16:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" n: 读取下一行覆盖当前行n 函数会提前读取下一行文本，覆盖当前模式空间中的行；旧的行会被直接输出，不会被后续命令处理；新的行也不会被前面的命令处理 示例： [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 # 读取第 3 行触发 n 命令，把当前模式空间内容输出，直接读取行第 4 行 # 因此，第 4 行没有触发 d 命令，第 4 行没有触发 s 命令 [root@localhost ~]# sed 's/$/。/; 3n; 3d' txt 这是第1行。 这是第2行。 这是第3行。 这是第4行 这是第5行。 ","date":"2018-12-10","objectID":"/linuxCmdSed/:17:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" N: 当前行追加到下一行之前N 命令会在模式空间中添加一行换行符再把下一行追加到当前模式空间，形如：”当前行内容\\n下一行内容“ 的样式。如果没有更多的输入，则输出模式空间内容后退出 sed 命令，不处理其它命令 示例：第二行和第三行连接起来 [root@localhost ~]# cat file hello hel lo hello [root@localhost ~]# sed '2{N;s/\\n//;}' file hello hello hello 示例 [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 # 读取第一行触发 N 命令，读取第二行。 # 模式空间内容为：这是第1行\\n这是第2行 # 之后触发 d 命令，删除模式空间内容 # 读取第三行触发 N 命令，读取第四行，因此跳过 s 命令 [root@localhost ~]# sed 's/$/。/; N; 2d' txt 这是第3行。 这是第4行 这是第5行。 示例： [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 # 触发 N 命令时没有读取到内容，直接输出模式空间内容，退出 sed [root@localhost ~]# sed '$N; d' txt 这是第5行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:18:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" p: 打印模式空间匹配项的内容p 命令是打印模式空间匹配项的内容，追加到默认输入之后，通常和 sed -n 选项一起使用 查看奇数行 sed -n '1~2p' file 查看偶数行 [root@localhost ~]# cat txt 这是第1行 这是第2行 这是第3行 这是第4行 这是第5行 # 等效：sed -n '2~2p' txt [root@localhost ~]# sed -n 'n;p' txt 这是第2行 这是第4行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:19:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" P: 打印模式空间匹配项的内容P 命令是打印当前模式空间匹配项开端到\\n（换行符）的内容，并追加到默认输出之前，通常和 sed -n 选项一起使用 显示/etc/passwd文件中以bash结尾的行 sed -n '/bash$/p' /etc/passwd ","date":"2018-12-10","objectID":"/linuxCmdSed/:20:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" q: 输出并退出q 命令会输出模式空间内容再退出 sed ，不再读取下一行 示例：找到第一个 2 字符之后退出sed [root@c8 ~]# seq 3 | sed '/2/ q' 1 2 指定退出状态码为 42 [root@c8 ~]# echo | sed '142' ; echo $? 42 ","date":"2018-12-10","objectID":"/linuxCmdSed/:21:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" Q: 退出 sedQ [退出状态码] 命令（GUN 版本才有），退出 sed ，但不会显示模式空间内容，仅接受一个地址 指定退出状态码为 42 [root@c8 ~]# echo | sed 'Q42' ; echo $? 42 ","date":"2018-12-10","objectID":"/linuxCmdSed/:22:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" r: 读取其他文件内容 读取 who 文件内容追加到带有 at 行的下面 [root@localhost ~]# sed '/at/ r who' a.out sed-tbt sed-at 199671d343 sed-att 199671d343 ","date":"2018-12-10","objectID":"/linuxCmdSed/:23:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" R: 读取文件R filename 命令（GUN 版本才有）在当前循环结束时或在读取下一个输入行时，将要读取的文件名行排队并插入到输出流中。如果无法读取文件名或到达文件名末尾，则不添加任何行，而不会显示任何错误 与r命令一样，特殊的文件 （/ dev / stdin 之类的），该文件名从标准输入中读取一行 ","date":"2018-12-10","objectID":"/linuxCmdSed/:24:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" s: 替换字符 语法：sed '[start|end] s/original/replacement/[substitute]' start：匹配范围其实位置，忽略则表示从第一行开始 end：匹配范围结束位置，忽略则表示最后一行结束 //：分界符，可以使用其他字符替换，如：##、^^等等 original：替换前的字符 replacement：替换后的字符 \u0026：表示 original 匹配到的文本 \\n：与正则表达式一样，`（`分组起始，`)`分组结束，需要使用转义符`\\`。sed最多能处理9个分组 substitute：修饰词，可以多个联合使用 g：表示全局。（默认只替换每行的第一个匹配项） n：0\u003cn\u003c512的正整数，表示只替换第n次出匹配 w：写入文件 i：忽略匹配项大小写 p：打印替换后的内容 e：将模式空间中的内容当成shell命令执行（GUN sed 才能使用） 几个GNU sed 特有的替换标志： \\l：（小写的L）紧跟着后面字符替换为小写，用于替换后的字符处前 \\L：将后面的所有字符都替换为大写，用于替换后的字符处前 \\u：（小写的U）紧跟着后面字符替换为小写，用于替换后的字符处前 \\U：紧跟着后面所有字符替换为大写，用于替换后的字符处前 \\E：与\\L或\\U一起使用，将关闭\\U或\\L的功能，用于替换后的字符后 数字日期转换 [root@c8 ~]# echo 20200701|sed 's/\\(....\\)\\(..\\)\\(..\\)/\\1年\\2月\\3日/' 2020年07月01日 替换第三个匹配 [root@c8 ~]# cat file.txt 2020/06/04 07:21:02 udp.go:135: listening UDP on :8488 2020/06/04 07:21:02 tcp.go:101: listening TCP on :8488 2020/06/04 07:21:09 tcp.go:128: proxy 113.116.236.181:28059 \u003c-\u003e 111.13.141.211:443 2020/06/04 07:21:10 tcp.go:128: proxy 113.116.236.181:28061 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:10 tcp.go:128: proxy 113.116.236.181:28062 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:10 tcp.go:128: proxy 113.116.236.181:28063 \u003c-\u003e 216.58.197.100:443 2020/06/04 07:21:11 tcp.go:128: proxy 113.116.236.181:28071 \u003c-\u003e 14.215.138.67:14000 2020/06/04 07:21:14 tcp.go:128: proxy 113.116.236.181:28075 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:14 tcp.go:128: proxy 113.116.236.181:28076 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:14 tcp.go:128: proxy 113.116.236.181:28077 \u003c-\u003e 8.8.8.8:53 [root@c8 ~]# sed 's/1/一/3' file.txt 2020/06/04 07:21:02 udp.go:135: listening UDP on :8488 2020/06/04 07:21:02 tcp.go:10一: listening TCP on :8488 2020/06/04 07:21:09 tcp.go:128: proxy 一13.116.236.181:28059 \u003c-\u003e 111.13.141.211:443 2020/06/04 07:21:10 tcp.go:一28: proxy 113.116.236.181:28061 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:10 tcp.go:一28: proxy 113.116.236.181:28062 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:10 tcp.go:一28: proxy 113.116.236.181:28063 \u003c-\u003e 216.58.197.100:443 2020/06/04 07:21:1一 tcp.go:128: proxy 113.116.236.181:28071 \u003c-\u003e 14.215.138.67:14000 2020/06/04 07:21:14 tcp.go:一28: proxy 113.116.236.181:28075 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:14 tcp.go:一28: proxy 113.116.236.181:28076 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:14 tcp.go:一28: proxy 113.116.236.181:28077 \u003c-\u003e 8.8.8.8:53 以 voiceId 字符串为行开头 # \\n 表示换行符 # \u0026 表示前面匹配的 voiceId # 2g 表示从第二个匹配开始之后的所有匹配 [root@c8 gawk]# sed 's/voiceId/\\n\u0026/2g' file3 voiceId RQIVOICE_3d923f1b-178f-4703-ae41-6a70942b2657 quality_rt_quality 1594792296863 voiceId RQIVOICE_3d923f1b-178f-4703-ae41-6a7094211111 quality_rt_quality 1594792297409 voiceId RQIVOICE_3d923f1b-178f-4703-ae41-6a70333337 knowledge 1594792295712 repNo 10089 [root@c8 gawk]# cat file3 voiceId RQIVOICE_3d923f1b-178f-4703-ae41-6a70942b2657 quality_rt_quality 1594792296863 voiceId RQIVOICE_3d923f1b-178f-4703-ae41-6a7094211111 quality_rt_quality 1594792297409 voiceId RQIVOICE_3d923f1b-178f-4703-ae41-6a70333337 knowledge 1594792295712 repNo 10089 将SELINUX=开头的enforcing修改为disabled sed -i '/^SELINUX=/ s/enforcing/disabled/g' /etc/selinux/config 将1至5行的第一个NSA替换成nsa，并把替换的行输出到屏幕 sed '1,5 s/NSA/nsa/ p' file 从第3个nas开始替换 sed 's/nas/NAS/2' file 将匹配到original行的nass替换成NASS sed -n '/original/ s/nass/NASS/g' file 将nas替换成NAS写入到file2 sed 's/nas/NAS/g w file2' file 将NAS（不区分大小写）替换成NAS sed 's/NAS/NAS/i' file 将文件中的行首添加echo 并当初shell执行 sed 's/^/echo /e' file 将NAS替换成original在将含original的行打印 sed '{ s/NAS/original/g /original/ p }' file 将5至7行行首加入 \u003c，行尾加入\u003e；\u0026 获取匹配 sed '5,7 s/^.*/\u003c\u0026\u003e/g' file sed获取目录，等效 dirname 命令 [root@centos7 shell]# echo '/root/file' | sed -r 's#(/[^/]+)/[^/]+/?$#\\1#g' /root sed获取文件名称，等效 basename 命令 [root@centos7 shell]# echo '/root/file.txt' | sed -r 's#/.*/([^/]+)/?$#\\1#g' file.txt 获取用户名 sed 's/\\([^:]*\\).*/\\1/' /etc/passwd 获取用户名和shell sed -nr 's/^(.*:)(.*):(.*):(.*):(.*):(.*):(.*)/\\1\\7/p' /etc/passwd 把 server 0.centos.pool.ntp.org iburst换成server ntp1.aliyun.com iburst sed 's/\\(^server \\)\\(0.*\\)\\( iburst\\)$/\\1ntp1.aliyun.com\\3/' /etc/chrony.conf 获取URL： [root@localhost ~]# cat url \"url\":\"http://openapi.fjsdn.com/swan/cdn/cn.log.gz\" # 方法1 [root@localhost ~]# sed 's/.\\+\":\"\\","date":"2018-12-10","objectID":"/linuxCmdSed/:25:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" t: 有条件分支t 如果最后一次输入的最后一个 s 子命令执行成功,跳转到标签（label）,如果没有指定标签（label）,则跳转到命令的结尾 示例： # 前面 s 命令执行成功的会跳转到结尾 [root@localhost ~]# echo -e \"AA\\nBC\\nAA\\nCB\\nCC\\nAA\" | sed '/^A/ s/$/：YES/; t; s/$/：NO/' AA：YES BC：NO AA：YES CB：NO CC：NO AA：YES 示例：千分位 等效：echo \"1234\"|sed -r ':1 s/(.*\\B)(\\w{3})/\\1,\\2/;t1' [root@localhost ~]# echo \"1234\"|sed ':1 s/\\B\\w\\{3\\}\\b/,\u0026/;t1' 1,234 示例 [root@localhost ~]# echo \"01/02/03/t1.txt\" | sed ':1 s#^\\([^,]\\+\\)/\\(.*\\)#\\1,\\1/\\2#;t1' 01,01/02,01/02/03,01/02/03/t1.txt ","date":"2018-12-10","objectID":"/linuxCmdSed/:26:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" T: 有条件分支T 命令仅在自读取最后一条输入行以来没有成功替换的情况下分支。和 t 相反 ","date":"2018-12-10","objectID":"/linuxCmdSed/:27:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" v: 查看是否支持 GUN 扩展该命令不执行任何操作，如果 sed 不支持 GNU 扩展，则使该命令失败。此外，可以指定 sed脚本所需的版本，例如4.0.5。缺省是 4.0因为这是实现此命令的第一个版本。即使POSIXLY_CORRECT在环境中设置了此命令，也会启用所有 GNU` 扩展 ","date":"2018-12-10","objectID":"/linuxCmdSed/:28:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" w: 写入其他文件 将file的内容写入file2，file2可以是绝对路径，如果file2存在则覆盖 sed -n 'w file2' file 将file的第二行写入file2 sed -n ' 2 w file2' file 将file的奇数行写入file2 sed -n '1~2 w file2 ' file 将file的1-4行写入file2 sed -n '1,4 w file2' file 将file的第3行至最后一行写入file2 sed -n '2,$ w file2' file 将第一次匹配operate的行到第8行写入file2，如果前8行没有匹配到operate，则从第8行开始直到匹配为止 sed -n ' /operate/,8 w file2 ' file 将匹配asd和行到匹配lkj的行写入file2 sed -n '/asd/,/lkj/ w file2 ' file 将匹配operate的行以及后4行写入file2 (不能将匹配模式和步长共用) sed -n '/operate/,+2 w file2' file ","date":"2018-12-10","objectID":"/linuxCmdSed/:29:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" W: 写入文文件W file （GUN 版本才有）命令将模式空间开头到第一个换行符部分写入给定文件名 ","date":"2018-12-10","objectID":"/linuxCmdSed/:30:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" x: 将当前保持空间和模式空间内容互换x 命令是将当前保持空间和模式空间内容互换 示例 [root@c8 ~]# cat ddd This is a and a is 1 This is b and b is 2 This is c and c is 3 This is d and d is 4 This is e and e is 5 [root@c8 ~]# sed 'h;{s/.*is \\(.*\\) and .*/\\1/;y/abcde/ABCDE/;G;s/\\(.*\\)\\n\\(.*is \\).*\\(and \\).*\\(is \\)\\(.*\\)/\\2\\5 \\3\\5 \\4\\1/}' ddd This is 1 and 1 is A This is 2 and 2 is B This is 3 and 3 is C This is 4 and 4 is D This is 5 and 5 is E ","date":"2018-12-10","objectID":"/linuxCmdSed/:31:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" y: 转换字符替换为对应的字符，并非替换字符串 把 字符 t 替换为 T; 字符c替换为C；p 替换为 P [root@c8 ~]# sed 'y/tcp/TCP/' file.txt 2020/06/04 07:21:17 TCP.go:128: Proxy 113.116.236.181:28138 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:17 TCP.go:128: Proxy 113.116.236.181:28139 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:17 TCP.go:128: Proxy 113.116.236.181:28140 \u003c-\u003e 8.8.8.8:53 2020/06/04 07:21:18 TCP.go:128: Proxy 113.116.236.181:28137 \u003c-\u003e 157.185.128.213:80 2020/06/04 07:21:18 TCP.go:128: Proxy 113.116.236.181:28141 \u003c-\u003e 119.147.46.68:80 把字符 2替换为1；字符P 替换为 p [root@c8 ~]# sed 'y/2P/1p/' file.txt 1010/06/04 07:11:17 tcp.go:118: proxy 113.116.136.181:18138 \u003c-\u003e 8.8.8.8:53 1010/06/04 07:11:17 tcp.go:118: proxy 113.116.136.181:18139 \u003c-\u003e 8.8.8.8:53 1010/06/04 07:11:17 tcp.go:118: proxy 113.116.136.181:18140 \u003c-\u003e 8.8.8.8:53 ","date":"2018-12-10","objectID":"/linuxCmdSed/:32:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" =: 统计行 [root@yh ~]# sed -n '$=' fd 10 ","date":"2018-12-10","objectID":"/linuxCmdSed/:33:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" z: 清空模式空间的内容z ( GUN 版本才有) 该命令清空模式空间的内容。等效 s /.*//，但效率更高 ","date":"2018-12-10","objectID":"/linuxCmdSed/:34:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" #: 注释# 命令在添加注释信息，通常在脚本中。如果sed脚本的前两个字符为#n，则 sed -n（无自动打印）选项是强制的。想在脚本的第一行中添加注释，可以使用 #N 或在之前保留一个空格 #n ","date":"2018-12-10","objectID":"/linuxCmdSed/:35:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" 同时执行多个sed命令方法 # 使用 `-e` 选项 sed -n -e '/^root/ p' -e '/^nobody/ p' /etc/passwd # 使用`{ }`分组执行，这种可以把相同地址且连续的操作放入大跨号内， sed -n '2{ /^root/ p /^nobody/ p }' /etc/passwd # 使用 ;分割 sed -n 'n;p' file.txt 分支的循环标签: 以冒号 : 定义，后面可以是一个或多个字母数字，如 :1 表示标签为 1 如果 sed 命令中没有标签时，则分支命令（t, T, b）重新启动循环 跳转到标签和循环 重新启动循环时，sed首先打印模式空间的当前内容，然后将下一个输入行读入模式空间 跳转到标签（即使它位于程序的开头）也不会打模式空间，也不会读取下一个输入行。 sed脚本在文本文件中，每一行记录一个sed命令操作，多个sed命令操作组合而成 sed脚本流程 读取文件第一行内容到空间模式 依次执行sed脚本中的操作 读取文件第二行到空间空间模式，依次类推，直到遍历整个文件 将多个sed执行命令写入一个文件中组成一个sed脚本文件 在sed脚本中#开头的行表示注释。但有2种特殊情况： 第一行如果sed命令则表示默认值，如#-n（不自动打印模式空间内容）方法：sed -f sed脚本文件 文档文件 第一行如果是#!/bin/sed -f 则作为默认解释器。方法：加执行权限，./sed脚本文件 文档文件 更据env的内容去修改fd文件 。-f 表示用指定文档（sed命令）内容 去修改文件。 [root@yh ~]# cat env /^name/ c\\name=copr 2 i ggom 4d [root@yh ~]# sed -i -f env fd [root@yh ~]# cat fd [librehat-shadowsocks] ggom name=copr repo_gpgcheck=0 enabled=0 enabled_metadata=0 退出状态码sed 退出状态码有以下固定信息： 0：成功 1：无效命令（语法、正则表达式、选项等） 2：无法打开在命令行上指定的一个或多个输入文件（例如，如果找不到文件或拒绝了读取权限）。其他文件继续处理 4：I/O 错误或运行时严重的处理错误，GNU sed立即中止 退出状态码可以在 q 或 Q 中指定 指定退出状态码为 42 [root@c8 ~]# echo | sed 'Q42' ; echo $? 42 ","date":"2018-12-10","objectID":"/linuxCmdSed/:36:0","tags":["sed","文本处理","linux"],"title":"sed","uri":"/linuxCmdSed/"},{"categories":["linux"],"content":" 运行环境： centos: 7 内容来自以下文档： 程磊: 深入理解Linux进程管理 程磊: 深入理解Linux进程调度 小一！: Linux中进程的六种状态 进程基本概念进程是计算机里面最重要的概念之一。操作系统的目的就是为了运行进程。进程是程序执行的过程，执行期间是在内存中进行的。进程是操作系统管理系统资源的基本单位 对于内核来说，内存是有虚拟内存和物理内存之分的。但是对于进程来说，这些都是不可见的，进程只需要知道自己独占一个用户空间的内存就可以了，它不知道也不需要知道自己是否运行在虚拟内存上。如果非要说进程知道物理内存和虚拟内存，那么进程也只能分配和管理虚拟内存，它没法分配管理物理内存，因为物理内存对它来说是不可见的。内核在合适的时候会为进程分配相应的物理内存，保证进程在访问内存的时候一定会有对应的物理内存，但是进程对此毫不知情，也管不了。 进程与内核在同一个虚拟地址空间中，但是在不同的子空间，进程是在用户空间，内核是在内核空间。整个系统只有一个内核空间，但是却有很多用户空间，不过对于一个CPU来说，当前用户空间永远只有一个。虽然内核空间和用户空间在同一个空间中，但是它们的权限并不相同。内核空间处于特权模式，用户空间处于非特权模式。内核可以随意访问和操作用户空间，但是用户空间对内核空间却是看得见摸不着。内核空间可以做很多特权操作，用户空间没有权限做，但是有些时候又需要做，所以内核为用户空间开了一个口子，就是系统调用，用户空间可以通过系统调用来请求内核的服务。总的来说： 进程是工作在用户空间的 一颗内核一次只能调用一个进程 进程基本概念进程是计算机里面最重要的概念之一。操作系统的目的就是为了运行进程。进程是程序执行的过程，执行期间是在内存中进行的。进程是操作系统管理系统资源的基本单位 按照标准的操作系统理论，进程是资源分配的单位，线程是程序执行的单位，内核里用进程控制块(PCB Process Control Block)来管理进程，用线程控制块(TCB Thread Control Block)来管理线程。由于 linux 最开始的时候是不支持多线程的，最初时候 task_struct(内核代码中的结构体名)既代表进程又代表线程，但是后来 linux 也要支持多线程。linux 选择的是在内核实现。为了最大限度地利用已有的代码，尽量不对代码做大的改动，Linux内核并不是按照标准的操作系统理论来实现进程，选择让 task_struct 既是线程又是进程的代理(不是进程本身)。把同一个进程下的所有线程(task_struct)都指向相同的资源实现了线程。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:0:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 进程与线程在早期时，进程是程序执行的最小单位，现在线程是程序执行的基本单位，代表一个执行流，进程可以有多个执行流。在 linux 中线程与进程没有进行严格区分，当一个进程就只有一个执行流，也就是主线程，此时进程就是线程，线程就是进程。同理，多个线程共享一个进程资源，它就是线程。 创建一个新进程是一个很耗费资源的事情，而且多个进程之间还要进行进程间通信也很费事。于是人们便想到了开发进程内并发机制，也就是在一个进程内能同时存在多个执行流(线程)。不同的人设计的进程内并发机制并不相同。按照线程的管理是否实现在内核里，进程内并发机制可以分为两大类： 内核级线程(内核级线程也被叫做轻量级进程)： 内核线程：运行主体在内核空间 用户线程：运行主体在用户空间 用户级线程： 协程或纤程：运行主体在用户空间 这两种实现多线程的方法各有优缺点。在用户空间实现的话，优点是简单，不用改内核，只需要实现一个库就行了，创建线程开销小，缺点是线程之间做不到真并发，一个线程阻塞就会阻塞同一进程的所有其它线程。在内核空间实现的话，缺点是麻烦，需要改内核，创建线程开销大，但是优点是能做到真并发，一个进程的多个线程可以同时在多个CPU上运行，能充分利用CPU。当然这两者并不是对立的，它们可以同时实现，一个进程可以有多个内核级线程，一个内核级线程又可以有多个用户级线程，编程者可以灵活选择使用哪种多线程方式。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:1:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 进程与内核进程与内核在同一个虚拟地址空间中，但是在不同的子空间，进程是在用户空间，内核是在内核空间。整个系统只有一个内核空间，但是却有很多用户空间，不过对于一个CPU来说，当前用户空间永远只有一个。虽然内核空间和用户空间在同一个空间中，但是它们的权限并不相同。内核空间处于特权模式，用户空间处于非特权模式。内核可以随意访问和操作用户空间，但是用户空间对内核空间却是看得见摸不着。内核空间可以做很多特权操作，用户空间没有权限做，但是有些时候又需要做，所以内核为用户空间开了一个口子，就是系统调用，用户空间可以通过系统调用来请求内核的服务。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:2:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 进程与内存对于内核来说，内存是有虚拟内存和物理内存之分的。但是对于进程来说，这些都是不可见的，进程只需要知道自己独占一个用户空间的内存就可以了，它不知道也不需要知道自己是否运行在虚拟内存上。如果非要说进程知道物理内存和虚拟内存，那么进程也只能分配和管理虚拟内存，它没法分配管理物理内存，因为物理内存对它来说是不可见的。内核在合适的时候会为进程分配相应的物理内存，保证进程在访问内存的时候一定会有对应的物理内存，但是进程对此毫不知情，也管不了。 进程需要内存的时候可以通过系统调用 brk、sbrk、mmap 来向内核申请分配虚拟内存。但是直接使用系统调用来分配管理内存显然很麻烦效率也低，为此 libc 向进程提供了 malloc 库， malloc 提供了 malloc、free 等几个接口供进程使用。这样进程需要内存的时候就可以直接使用 malloc 去分配内存，使用完了就用 free 去释放内存，不用考虑分配效率、内存碎片等问题了。目前比较流行的 malloc 库有 ptmalloc、jemalloc、scudo等。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:3:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 进程运行状态进程刚创建之后处于新建态，但是新建态不是持久状态，它会立马转变为就绪状态。然后进程就会一直处于就绪、执行、阻塞三态的循环之中。就绪态会由于进程调度而转为执行态；执行态会由于时间片耗尽而转为就绪态，也会由于等待某个事件而转为阻塞态；阻塞态会由于某个事件的发生而转为就绪态。最后进程可能会由于主动退出或者发生异常而死亡。死亡态也不是一个持久态，进程死亡之后就不存在了。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:4:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 进程树所有进程都通过父子关系连接而构成一颗亲缘树，这颗树的树根是 init 进程，进程号为 1，ini 进程是第一个用户空间进程，所有的用户空间进程都是它的子孙进程。init 进程的父进程是零号进程，零号进程是在代码中通过硬编码创建的，其它所有的进程都是通过 fork 函数创建的。这里为什么叫做零号进程呢？因为零号进程的职责发生过变化，在系统刚启动的时候，零号进程是 BSP(bootstrap process), start_kernel 函数就是在零号进程中运行的。当系统初始化完成的时候，零号进程退化为了 idle 进程。当我们只强调零号进程的身份而不关心它的职责的时候，就叫它零号进程。当后面我们强调它的 idle 职责的时候，就叫它 idle 进程 零号进程有两个亲儿子，除了 init 之外，还有一个是 kthreadd 进程号为 2，Kthreadd 是一个内核线程，它是所有其它内核线程的父进程。内核线程比较特殊的点在于它只运行在内核空间，所以所有的内核线程都可以看做是同一个进程下的线程，因为内核空间只有一个。但是每个内核线程在逻辑意义上又是一个独立的进程，它们执行独立的任务，有着独立的进程人格。所以当我们说一个内核线程的时候，心里也要明白它是一个单独的进程，是一个只有主线程的单线程进程。 进程除了父子关系外还存在着会话组与进程组，每个用户都有自己的用户id，一个用户运行的所有的程序构成了一个会话组。有了会话组的概念，就可以方便我们把一个用户运行的所有进程作为一个整体进行管理。进程组的产生来源于命令行操作的作业管理。什么是作业管理呢？就是把一行命令的执行整体作为一个作业。一行命令的执行不一定只有一个进程，比如命令 ps -ef | grep bash，就有两个进程，我们需要有个概念把这两个进程作为一个整体来处理，这个概念就是进程组。 一个进程诞生的时候默认继承父进程的会话组和进程组，但是进程可以通过系统调用（如 setsid，setpgrp）创建新的会话组或者进程组。会话组的第一个进程叫做这个会话组的组长，进程组的第一个进程叫做这个进程组的组长，会话组的 id 等于会话组组长的 pid ；进程组的 id 等于进程组组长的 pid。一个进程只有当它不是某个进程组组长的时候，它才可以调用 setpgrp 创建新的进程组，同时它也成为了这个新建的进程组的组长。同理，只有不是会话组组长的进程才能通过setsid创建新的会话组，并成为这个会话组组长。而且在这个新的会话组里也不能没有进程组啊，于是还会创建一个进程组，这个会话组组长还会成为这个新建的进程组的组长，这也要求了这个进程之前不能是进程组组长。所以只有既不是进程组组长又不是会话组组长的进程才能创建新的会话组。 一个会话组的所有进程肯定都是其会话组组长的子孙进程，一个进程组的所有进程一般情况下都是其进程组组长的子孙进程。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:5:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 进程标识符在 task_struct 结构体里面有两个重要的字段：pid、tgid。用户空间的 tid 是内核空间 pid，用户空间的 pid 是内核空间的 tgid，内核空间的 tgid 是内核里主线程的 pid。也就是进程的第一个线程创建时，会为 task_struct 分配一个 pid，就是主线程的 tgid，然后进程的 pid（也就是 tfid 字段）会被赋值为主线程的 tid。此后再创建的线程都会继承父线程的 tgid，所以在每个线程中都能直接获取进程的 pid。 Linux里面虽然没有进程结构体，但是所有 tgid 相同、虚拟内存等资源相同的线程构成一个虚拟的进程结构体。创建进程的第一个线程(task_struct)就是同时在创建进程，其对应的系统资源都会被创建出来。创建进程的第二个线程那就是纯粹地创建线程了。 进程调度调度是 CPU 资源管理器。操作系统的作用之一就是系统资源管理器。 CPU 是计算机系统中最重要的资源，当然也要管理。所有进程的运行都需要 CPU ，对 CPU 该如何管理呢？对于直接共享型的事物，我们有两种管理方法：一种是时间分割管理，另一种是空间分割管理。由于 CPU 自身的特性，没有空间分割相似性，只有时间分割相似性，所以我们只能对 CPU 进行时间分割管理。对 CPU 进行时间分割管理的具体做法就叫做进程调度。 对线程的调度可以有两种方式：一种是直接调度线程，不考虑它们所属的进程，这种方式叫做直接调度或者一级调度；另一种是先调度进程，再在进程内部调度线程，这种方式叫做间接调度或者二级调度。POSIX 规定，操作系统可以选择这两种方式中的任何一种都行。linux 选择的是一级调度，这主要是为了提高进程的并发性，充分利用多 CPU 核心的优势。 最早的计算机是没有调度的，程序只能一个一个地运行，一个进程死亡之后才能去运行下一个进程。后来随着计算机的普及，以及计算机的使用者和程序员这两个角色的分离，我们需要强制性多任务，也就是抢占式多任务。抢占式多任务使得每个进程都可以相对公平地平分 CPU 时间，如果一个进程运行了过长的时间就会被强制性地调度出去，不管这个进程是否愿意。 抢占又分为用户抢占和内核抢占。由于抢占对进程来说是异步的，进程被抢占时不一定运行在什么地方，有可能运行在用户空间，也有可能运行在内核空间(进程通过系统调用进入内核空间)。如果抢占点是在用户空间，那么抢占就是安全的，如果在内核空间就不一定安全，这因为对于用户空间来说，如果抢占会导致线程同步问题，那么用户空间有责任使用线程同步机制来保护临界区，只要用户空间做好同步就不会出问题。如果内核也做好了同步措施，内核抢占也不会出问题，但是内核最初的设计就没有考虑内核抢占问题，所以刚开始的时候内核是不能抢占的。后来内核开发者对内核进行了完善，把内核所有的临界区都加上了同步措施，然后内核就是可抢占的了。内核能抢占了不代表内核一定会抢占，内核会不会抢占由config选项控制，可以开启也可以关闭，因为内核抢占还会影响系统的响应性和性能。开启内核抢占会提高系统的响应性但是会降低一点性能，关闭内核抢占会降低系统的响应性但是会提高一点性能。因此把内核抢占做成配置项，可以让大家灵活配置。服务器系统一般不需要与用户交互，所以会关闭内核抢占来提高性能，桌面系统会开启内核抢占来提高系统的响应性，来增加用户体验。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:6:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 调度方式我们把协作式多任务叫做主动调度，抢占式多任务叫做被动调度。对于主动调度，调度是进程主动触发的，对于被动调度，在图灵机模型中是做不到的，因为图灵机是一条线性一直往前走的，进程在执行时，进程要是不主动，是不可能跳到其它进程来执行的。被动调度能做到的原因关键就在于中断机制，因为中断是强行在正常的执行流中插入了一段代码，它能改变后续代码的走向。有了中断机制，我们就可以创建一个定时器中断，以固定的时间间隔比如每10ms来触发中断，检测进程是否运行时间过长，如果过长就触发调度。这样任何进程都不可能霸占CPU，所以进程都能公平地共享CPU时间。 主动调度又可以分为自愿性主动调度和非自愿性主动调度： 自愿性主动调度是指进程主动调用sched_yield让出CPU，进程本身还会回到运行队列中去等待下次调度。如果运行队列中没有其它进程的话，此进程还会继续运行。 非自愿性主动调度是指进程运行时遇到了无法继续运行的情况(加锁失败、要读的文件现在不在内存中、进程死亡等)，只能进行调度让其它进程运行。 对于主动调度，触发调度和执行调度是同步的、一体的，触发即执行。主动调度发生的时机有IO等待、加锁失败等各种阻塞操作以及用户空间主动调用(sched_yield) 避免进程自己不主动让出CPU，强行长时间霸占CPU。内核还提供了被动调度，强制进行进程调度。被动调度的过程分为两步： 触发调度。触发调度仅仅是做个标记，告诉系统需要调度了。有以下触发调度点： 定时器中断 唤醒进程时 迁移进程时 改变进程优先级时 执行调度是系统会在某些特定的点去检查调度标记，如果被设置的话就执行调度。执行调度的点有： 从系统调用返回用户空间 从中断返回用户空间 从中断返回内核 禁用抢占临界区结束 禁用软中断临界区结束 cond_resched调用点 对于被动调度，触发调度和执行调度是异步的、分离的，触发调度并不会立马执行调度，而是做个需要调度的标记，然后在之后的某个合适的地方会检测这个标记，如果被设置就进行调度。触发调度的点有： 在定时器中断中发现当前进程超时 在唤醒进程时发现新进程需要抢占当前进程 在迁移进程时发现新进程需要抢占当前进程 在改变进程优先级时发现新进程需要抢占当前进程 其中第一个触发点是当前进程需要被抢占，它是用来保证公平调度，防止进程霸占CPU的，后三个触发点是新进程需要抢占当前进程，它是用来提高系统响应性的。执行调度的点有： 系统调用完成之后即将返回用户空间 中断完成之后即将返回用户空间 如果开启了内核抢占的话则还有,中断完成之后即将返回内核 如果中断发生在禁止抢占临界区中，那么中断完成之后返回内核是不会执行调度的，而是会在临界区结束的时候执行调度 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:7:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 调度时机首先调度算法只能从Runnable的进程中进行选择，不能选择Blocked进程，因为选择了也没有意义。其次算法还要区分进程类型，比如普通进程与实时进程，肯定要优先选择实时进程，在同一类型的进程中还要有具体的算法来决定到底选择哪个进程。在Linux中一共把进程分为了5类，每一类都有一个具体的算法。类之间的关系是优先选择高类的进程，只有当高类没有Runnable进程时才会去选择低类进程。 进程选择好了之后就要切换进程，切换进程分两步：第一步是切换用户空间，第二步是切换执行栈(线程栈)。如果要切换的两个线程属于同一个进程就不需要切换用户空间了。切换用户空间是一个CPU架构相关的事情，不同CPU架构有所不同。此时切换的执行栈是线程的内核栈，执行栈代表的是当前线程的执行情况，切换执行栈就是切换线程。线程的用户栈信息都在内核栈里保存着。切换完内核栈之后，线程继续执行就会返回用户空间，由于此时用户空间已经切换完成，内核栈上也保存着用户栈的信息，所以线程能返回到正确的用户空间线程上去。 对于一个CPU来说，永远只有一个当前进程在运行，当执行进程调度时，需要从其它进程中选择一个进程并指向它。对于多个CPU来说，每个CPU也是这样的逻辑。但避免系统上的多个CPU忙的忙死闲的闲死，因此多个CPU之间会进行调度均衡。调度均衡可以分为个体均衡和总体均衡： 个体均衡是从进程的角度出发选择到一个相对清闲的CPU上去运行。个体均衡的触发点有以下三个： 新进程刚创建时 进程要执行新程序时 进程被唤醒时 总体均衡是从CPU的角度出发如何从别的CPU上拉取一些进程到自己这来执行，使得所有CPU的工作量尽量平均。总体均衡的触发点有以下三个： CPU即将idle前会去找到最忙的CPU然后拉取一些任务过来 定时器中断的周期性检测，会检查是否所有的CPU都一样忙，如果忙闲差别太大就会进行进程迁移，使得所有CPU忙闲程度接近 在idle进程中如果CPU发现自己太忙而有的CPU在idle就会唤醒那个CPU进行负载均衡 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:8:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 调度算法内核中有调度类、调度策略、调度算法的概念： 调度类代表的是进程对调度器的需求，主要是对调度紧迫性的需求。 调度策略是调度类的子类，是对调度类的细分，是在同一个调度需求下的细微区别。 调度算法是对调度类的实现，一个调度类一个调度算法。同一个调度类的调度策略是有很强的相似性的，所以在同一个算法中实现，对于它们不同的部分，算法再去进行区分。 Linux中一共有五个调度类，它们的调度紧迫性从上到下，依次降低： stop(禁令调度类) deadline(限时调度类) realtime(实时调度类) time-share(分时调度类) idle(闲时调度类) 实时调度类属于软实时，适用于那些只要可运行就希望立马能执行的进程，比如音视频的解码进程。实时调度类又分为两个调度策略：SCHED_FIFO和SCHED_RR。实时调度类的内部逻辑是让实时优先级大的进程先运行，只要有实时优先级大的进程可运行，就不会去调度实时优先级小的进程。当两个实时进程的优先级相同时，SCHED_RR和SCHED_FIFO这两个策略就有区别： SCHED_FIFO策略：进程如果抢占了CPU，它就会一直占着CPU，不会给同优先级的实时进程让CPU SCHED_RR策略：进程会在运行了一定的时间片之后主动让给同优先级的实时进程。 分时调度类是给广大的普通进程来用的，大家共同分享CPU。根据优先级的不同，可能有的进程分的多有的进程分的少，但是不会出现一个进程霸占CPU的情况。分时调度类下面有三个调度策略，它们的基本思想都是分时，但是略有不同： SCHED_BATCH进程希望减少调度次数，每次调度能执行的时间长一点 SCHED_IDLE是优先级特别低的进程，其分到的CPU时间的比例非常低，但是也总是能保证分到。分时调度类现在的算法叫做CFS(完全公平调度)，所以分时调度类也叫做公平调度类。 Linux上的分时调度算法叫CFS(Completely Fair Scheduler)完全公平调度。它是内核核心开发者Ingo Molnar基于SD调度器和RSDL调度器的公平调度思想而开发的一款调度器，在版本2.6.23中合入内核。CFS只负责调度普通进程，包括三个调度策略NORMAL、BATCH、IDLE。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:9:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 进程优先级只有实时调度类和分时调度类会用到进程优先级。由于历史原因，实时进程和普通进程的优先级并不是一个简单的数值，而是有好几个数值体系和变换规则， 在用户空间的时候，实时进程和普通进程(分时进程)共享同一个优先级数轴，叫静态优先级，范围是0-99，值越大优先级越高，实时进程占用1-99，普通进程占用0。普通进程自己又新开了一个数轴，叫动态优先级，也叫nice值，范围是 -20 - 19，值越低优先级越高。 到了内核空间的时候，实时进程有一个实时优先级，直接复制用户空间的静态优先级，普通进程有一个静态优先级，它是用户空间的nice值转换过来的，转换规则是nice+120。然后内核又定义了规范优先级，把它们都统一到同一个数轴上来。普通进程的规范优先级是直接复制其静态优先级，实时进程的规范优先级等于99减去它的实时优先级。在规范优先级的数轴上，所有进程都可以直接比较优先级了，值越小优先级越大。实时进程的规范优先级范围是0-99，但是由于它是从用户空间的优先级计算而来的，所以99这个值就用不到。 最后是动态优先级，对进程所有的处理都以动态优先级为准，动态优先级默认等于其规范优先级。以前的时候调度算法会去调整进程的动态优先级，现在不会再调了。现在只有使用了优先级继承锁的时候才会去调整进程的动态优先级。 对于禁令调度类、限时调度类和闲时调度类，它们用不到进程优先级，但是系统在规范优先级数轴上为它们提供了象征值，其动态优先级是对规范优先级的复制，也只有象征意义。有一个特殊的情况是分时调度类里面的SCHED_IDLE调度策略的进程，它的优先级无法在规范优先级数轴上体现出来，它的优先级是在CFS算法专门处理的，直接设置的调度权重，相当于是nice 26。 ps 命令中显示的优先级 [root@localhost ~]# ps -o pid,cls,nice,pri,rtprio,cmd PID CLS NI PRI RTPRIO CMD 6001 TS 0 19 - -bash 20613 TS 0 19 - ps -o pid,cls,nice,pri,rtprio,cmd cls 字段是调度策略，含义如下： TS: SCHED_OTHER/SCHED_NORMAL FF: SCHED_FIFO RR: SCHED_RR b: SCHED_BATCH IDL: SCHED_IDLE DLN: SCHED_DEADLINE NI 字段是 nice 值，优先级范围从大到小是 -20~19。只有在 SCHED_NORMAL 策略与 SCHED_BATCH 有意义 RTPRIO 字段代表的实时进程的用户空间优先级，范围从小到大是 1~99。只有在 SCHED_FIFO 和 SCHED_RR 策略有意义 PRI: 值越大优先级越大，普通进程范围是 0~39，计算方式为：pri = 19 - nice，实时进程范围是 41~139，计算方式为：pri = 40 + rtprio top 命令中显示的优先级 [root@localhost ~]# top top - 10:37:19 up 10 days, 9:29, 1 user, load average: 0.03, 0.03, 0.05 Tasks: 152 total, 1 running, 151 sleeping, 0 stopped, 0 zombie %Cpu(s): 1.3 us, 6.3 sy, 0.0 ni, 92.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 4094632 total, 2200272 free, 399812 used, 1494548 buff/cache KiB Swap: 0 total, 0 free, 0 used. 3449524 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 672 root 20 0 543788 8840 6744 S 5.6 0.2 282:57.06 NetworkManager 6870 root 20 0 162104 2208 1532 R 5.6 0.1 0:00.05 top ... NI 列表示 nice 值，只对普通进程有效 PR 列表示进程优先级，值越小优先级越大。普通进程计算方式为：pr = 20 + nice，实时进程计算方式为：pr = -1 - rt。如果为 -100 时显示为 rt ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:10:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 优先级与权重优先级会转化为进程的权重，权重高的占用更长 CPU 时间片。nice值的范围是-20到19，是等差数列，转化之后的权重是等比数列，以nice 0作为权重1024，公比为0.8。之前的调度算法都是把nice值转化为等差数列的时间片或者多段等差数列的时间片。公比为何是0.8呢？这是为了让两个nice值只相差1的进程获得的CPU时间比例差为10%。把nice 0 作为权重1024来进行转换呢？这是为了二进制运算方便。内核里并不是每次优先级转权重都进行运算，而是提前运算好了放在数组，每次用的时候查一下就可以了。反权重的值也提前计算好了放在了数组里。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:11:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 基本分时调度Linux上的分时调度算法叫CFS(Completely Fair Scheduler)完全公平调度。它是内核核心开发者Ingo Molnar基于SD调度器和RSDL调度器的公平调度思想而开发的一款调度器，在版本2.6.23中合入内核。CFS只负责调度普通进程，包括三个调度策略NORMAL、BATCH、IDLE。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:12:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 单个CPU上的调度内核文档对CFS的定义是：CFS在真实的硬件上基本模拟了完全理想的多任务处理器。完全理想的多任务处理器是指，如果把CPU的执行能力看成是100%，则N个进程可以同时并行执行，每个进程获得了1/N的CPU执行能力。例如有2个进程在2GHz的CPU上执行了20ms，则每个进程都以1GHz的速度执行了20ms。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:12:1","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 调度周期与粒度在CFS调度模型中，没有时间片递减的逻辑。CFS的调度周期也和传统的调度周期不一样，CFS的调度周期仅仅是一个计算量。调度周期的计算又和调度粒度有关。调度粒度是指进程在CPU上至少要运行多少时间才能被抢占。调度粒度指的是被动调度中进程一次运行最少的时间，如果进程阻塞发生主动调度，不受这个限制。时间片的计算依赖调度周期，调度周期的计算依赖调度粒度。 ps -o 命令可以指定查看内容 进程优先级： 0-99：实时优先级（数值越大优先级越高） 100-199：用户调整优先级（数值越小优先级越高） nice值：-20，19（只能降低优先级） Linux进程相关的信息保存在/proc/PID目录下 [root@m1 ~]# ls /proc/ 查看内存相关信息 [root@m1 ~]# cat /proc/meminfo 查看指定进程与内存的映射 [root@m1 ~]# cat /proc/1/maps #查看当前终端 [root@localhost ~]# ps m在进程后面显示线程 #a显示与当前终端相关的进程；u显示启动进程的用户；x显示与当前终端无关的进程，Z：安全上下文 [root@localhost ~]# ps auxmZ USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND #ps aux 每段解释 USER：进程数组 PID ：进程号 %CPU：CPU占用时间比 %MEM：内存占用时间比 VSZ：虚拟内存级(物理内存+虚拟内存) RSS：常驻内存集（不能放在交换分区的） TTY：终端类型，？号表示与终端无关 STAT：状态（ D:不可中断的睡眠；S:可中断的睡眠；R:运行或就绪；T:停止；Z:僵死；\u003c:高优先级进程； N:低优先级进程；+:前台进程组中的进程；l:多线程进程；s:会话进程首进程，某一个连接的父进程) START ：启动时间 TIME：执行时间 COMMAND：命令名称 中括号内的是线程 #-e显示所有进程，-f显示完整格式，m在进程后面显示线程 [root@localhost ~]# ps -elfm F S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD #ps -el 每段解释 PPID：父进程号 C：CPU编号 PR：进程优先级 NI：进程优先级调整值，数值越低，优先级越高。调整范围：；普通用户只能调高 S：进程状态 #top查看进程，键退出 [root@localhost ~]# top top - 11:08:58 up 34 min, 1 user, load average: 0.00, 0.01, 0.04 Tasks: 173 total, 1 running, 172 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.1 sy, 0.0 ni, 99.9 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 4158416 total, 3833740 free, 166036 used, 158640 buff/cache KiB Swap: 4194300 total, 4194300 free, 0 used. 3771184 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND #解释 top -系统当前时间 up 运行时长，当前在线用户，CPU负载均衡：平均1分钟，平均5分钟，平均15分钟 任务进程：总进程，运行进程，进程睡眠，停止进程，僵死进程 CPU平均使用率：用户进程，系统进程，调整优先级的进程，当前空闲率，等待磁盘IO完成进程时间，硬见中断，软中断，CPU处理时间 物理内存：总大小，空闲大小，使用大小，缓冲大小 交换分区：总大小，空闲大小，使用情况， #top每段解释 PR：同PRI，进程的优先级 NI：nice值 VIRT：同VSZ RES：物理内存 SHR：共享内存 #top快捷键使用 当前CPU百分比排序：P 查看CPU核心使用：1 查看cou信息：t 按内存使用率排序：M 关闭或开启第一行：l 按进程执行时间排序：T 修改刷新时间间隔：s（秒） 终止指定进程：k 其他选项 -d：指定刷新时间间隔 #安装软件 [root@m1 ~]# yum install -y htop s：更踪选的进程的系统调用 l：更踪选定经常的文件列表 #查看虚拟内存,x表示刷新频率秒，y表示刷新次数，-s显示统计 [root@m1 ~]# vmstat [x] [y] procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 1979928 2108 533296 0 0 5 4 37 52 0 0 100 0 0 procs r：等待运行进程的数量 b：阻塞进程数量（不可中断的睡眠进程） memory swpd：虚拟（交换）内存使用总量 free：物理内存空闲总量 buff：用于buff的内存总量 cache：用于cache的内存总量 swap si：数据进入swap中的数据速率(kb/s) so：数据离开swap中的数据速率(kb/s) io bi：从快设备读入数据到内存的速率(kb/s) bo：保存数据到块设备的速率(kb/s) system in：中断速率 cs：进程切换速率 cpu sy：内核空间占用CPU比例 us：用户空间占用CPU比例 wa： st： #查看进程的内存映射 #查看帮助 [root@m1 ~]# man pmap pmap [options] pid [...] -x：以扩展格式显示 #基于curses的跨平台系统监控 [root@m1 ~]# yum install -y glances #查看帮助，或者运行时按h键 [root@m1 ~]# man glances 运行： [root@m1 ~]# glances Rx/s：接收数据包的速率 Tx/s：发送数据表的速率 在C/S模式下运行（不建议在外网使用） （1）启用服务模式（本机IP） [root@m1 ~]# glances -s -B 192.168.150.128 （2）客户端模式（客户端IP） [root@m1 ~]# glances -C 103.106.245.110 #生成系统资源统计的多功能工具 语法：dstat [-afv] [options..] [delay [count]] [root@m1 ~]# dstat -avf 1 10 --top-tcp：CPU占用最高的进程 --top-io：io占用最高的进程 --top-men：内存占用最高的进程 #查看进程树，u:UTF8，u:PID yum install -y psmisc [root@localhost ~]# pstree -up #调整进程nice值(普通用户只能降低优先级) 调整范围：-20到19（数字越小，优先级越高） 语法：nice [OPTION] [COMMAND [ARG]...] #指定htop的nice值为9运行（-n 指定nice值） [root@yh ~]# nice -n 9 htop #修改运行htop的nice值 #语法：renice -n naice值 PID [root@yh ~]# renice -n 12 8877 8877 (process ID) old priority 9, new priority 12 #终止进程 ， -l查看支持的信号。信号名 等效 信号编号 [root@localhost ~]# kill -l 常用信号编号： 1）终止进程 2）中止正在运行的进程 9）暴力杀死正在运行的进程 15）终止关闭在运行的进程 18）手动继续运行进程 19）暂停进程运行 #指定信号的语法： kill [-s signal|-p] [-q sigval] [-a] [--] pid... #信号编号 [root@localhost ~]# kill -9 2308 #简写信号名称 [root@localhost ~]# kill -KILL 2308 #完整的信号名称 [root@localhost ~]# kill -SIGKILL 2308 #杀死所有sshd进程 [root@localhost ~]# killall sshd #前台作业：占用终端 #后台作业：没有占有终端，但是进程继续运行 后台进程虽然没有占有终端，但是还是依然与终端有关联，除非使用nohup COMMAID \u0026 #控制命令在后台进行，Ctrl +z 把正在运行的进程放入后台并暂停 [root@localhost ~]# top \u0026 [1] 3775 #查看后台运行的进程 [root@yh ~]# jobs [1] Stopped htop [2]- Stopped dstat [3]+ Stopped vi sfds #将后台的进程调到前台，（如果不指定作业号 默认是+加号） [root@localhost ~]# fg %1 #让送往后台的作业继续运行（没有剥离终端任然输出到前台） root@yh","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:12:2","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" pstree 命令查看用户空间进程树pstree 命令可以查看用户进程树 # 安装软件包 [root@localhost ~]# yum install -y psmisc # 查看帮助 [root@localhost ~]# pstree --help pstree: unrecognized option '--help' Usage: pstree [ -a ] [ -c ] [ -h | -H PID ] [ -l ] [ -n ] [ -p ] [ -g ] [ -u ] [ -A | -G | -U ] [ PID | USER ] pstree -V Display a tree of processes. -a, --arguments show command line arguments -A, --ascii use ASCII line drawing characters -c, --compact don't compact identical subtrees -h, --highlight-all highlight current process and its ancestors -H PID, --highlight-pid=PID highlight this process and its ancestors -g, --show-pgids show process group ids; implies -c -G, --vt100 use VT100 line drawing characters -l, --long don't truncate long lines -n, --numeric-sort sort output by PID -N type, --ns-sort=type sort by namespace type (ipc, mnt, net, pid, user, uts) -p, --show-pids show PIDs; implies -c -s, --show-parents show parents of the selected process -S, --ns-changes show namespace transitions -u, --uid-changes show uid transitions -U, --unicode use UTF-8 (Unicode) line drawing characters -V, --version display version information -Z, --security-context show SELinux security contexts PID start at this PID; default is 1 (init) USER show only trees rooted at processes of this user 查看当前系统进程树 # -p 显示进程号 [root@localhost ~]# pstree -p systemd(1)─┬─NetworkManager(672)─┬─{NetworkManager}(678) │ └─{NetworkManager}(681) ├─agetty(662) ├─agetty(664) ... ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:13:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 使用 ps 命令查看进程组、会话组 [root@localhost ~]# ps j PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 1 662 662 662 tty1 662 Ss+ 0 0:00 /sbin/agetty --noclear tty1 linux 1 664 664 664 hvc0 664 Ss+ 0 0:00 /sbin/agetty --keep-baud 115200,38400,9600 hvc0 vt220 18311 18317 18317 18317 pts/0 21616 Ss 0 0:00 -bash 18317 21616 21616 18317 pts/0 21616 R+ 0 0:00 ps j 进程优先级最早的计算机是没有调度的，程序只能一个一个地运行，一个进程死亡之后才能去运行下一个进程。后来随着计算机的普及，以及计算机的使用者和程序员这两个角色的分离，我们需要强制性多任务，也就是抢占式多任务。抢占式多任务使得每个进程都可以相对公平地平分 CPU 时间，如果一个进程运行了过长的时间就会被强制性地调度出去，不管这个进程是否愿意。 进程优先级别越高，表示越先被 cpu 调用执行，同时占用 cpu 的时间片越长。由于历史原因，linux 进程优先级并不是一个简单的数值，而是有好几个数值体系和变换规则，下图是进程优先级转换 在用户空间中，实时进程和普通进程(分时进程)共享同一个优先级数轴，叫静态优先级，范围是0-99，值越大优先级越高： 实时进程占用1-99 普通进程占用0。普通进程自己又新开了一个数轴，叫动态优先级，也叫nice值，范围是 -20 - 19，值越低优先级越高。 在内核空间中分为实时优先级、规范优先级、动态优先级： 实时优先级是直接复制用户空间的实时进程优先级 静态优先级是用户空间的分时进程转换的，方式为：nice+120 规范优先级是把内核空间的实时优先级与静态优先级统一到同一个数轴上来。计算方式： 实时进程的规范优先级等于99减去它的实时优先级 普通进程的规范优先级是直接复制其静态优先级 对进程所有的处理都以动态优先级为准，现在动态优先级默认等于其规范优先级。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:14:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" ps 命令中显示的优先级 [root@localhost ~]# ps -o pid,cls,nice,pri,rtprio,cmd PID CLS NI PRI RTPRIO CMD 6001 TS 0 19 - -bash 20613 TS 0 19 - ps -o pid,cls,nice,pri,rtprio,cmd cls 字段是调度策略算法，含义如下： TS: SCHED_OTHER/SCHED_NORMAL FF: SCHED_FIFO RR: SCHED_RR b: SCHED_BATCH IDL: SCHED_IDLE DLN: SCHED_DEADLINE NI 字段是 nice 值，优先级范围从大到小是 -20~19。只有在 SCHED_NORMAL 策略与 SCHED_BATCH 有意义 RTPRIO 字段代表的实时进程的用户空间优先级，范围从小到大是 1~99。只有在 SCHED_FIFO 和 SCHED_RR 策略有意义 PRI: 值越大优先级越大，普通进程范围是 0~39，计算方式为：pri = 19 - nice，实时进程范围是 41~139，计算方式为：pri = 40 + rtprio ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:15:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" top 命令中显示的优先级 [root@localhost ~]# top top - 10:37:19 up 10 days, 9:29, 1 user, load average: 0.03, 0.03, 0.05 Tasks: 152 total, 1 running, 151 sleeping, 0 stopped, 0 zombie %Cpu(s): 1.3 us, 6.3 sy, 0.0 ni, 92.4 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 4094632 total, 2200272 free, 399812 used, 1494548 buff/cache KiB Swap: 0 total, 0 free, 0 used. 3449524 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 672 root 20 0 543788 8840 6744 S 5.6 0.2 282:57.06 NetworkManager 6870 root 20 0 162104 2208 1532 R 5.6 0.1 0:00.05 top ... NI 列表示 nice 值，只对普通进程有效 PR 列表示进程优先级，值越小优先级越大。普通进程计算方式为：pr = 20 + nice，实时进程计算方式为：pr = -1 - rt。如果为 -100 时显示为 rt ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:16:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 运行进程时使用 nice 命令指定用户空间的冬天优先级nice NICE CMD ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:17:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 使用 renice 命令调整用户空间的动态优先级renice NICE PID ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:18:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 使用 chrt 命令指定进行的动态优先级 进程状态linux 中进程有以下状态： 运行：运行中或在运行队列中 睡眠：中断状态，等待被某种条件就绪，唤醒后进入运行状态 不可中断睡眠：正在与磁盘交互，不可被杀死 停止：人为暂停进程，可让进程继续运行 僵死：当子进程退出并且父进程没有读取到子进程退出的返回代码时，就会处于僵死进程 死亡：这个状态只是一个返回状态，当父进程读取子进程的返回结果时，子进程立刻释放资源。 孤儿进程：当一个进程的父进程结束时，但是它自己还没有结束，那么这个进程将会成为孤儿进程。 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:19:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 使用 ps 命令查看进程状态 [root@localhost ~]# ps -axo pid,stat,cmd PID STAT CMD ... 22797 R+ ps -axo pid,stat,cmd 28945 S nginx: worker process 28946 S nginx: worker process 28947 S nginx: worker process 28948 S nginx: worker process 29414 Ss nginx: master process nginx ... STAT 列表示进程状态，有以下值： R+：运行中 S: 睡眠 s: 有子进程 Z: 僵死 D: 不可中断 T: 中止，进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行 P: W: X: 死亡进程 \u003c: 优先级较高的进程 N: 优先级较低的进程 l: 多进程的 进程运行方式运行进程有以下方式： 前台作业：直接在终端执行，适用于一次性任务，会占用终端 后台作业：直接在终端执行，适用于一次性任务，没有占有终端，但是还是依然与终端有关联 守护进程：所为服务端长时间运行的进程 ","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:20:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" 后台运行在命令行后加 \u0026 符号可以使命令以后台方式运行。后台进程虽然没有占有终端，但是还是依然与终端有关联，可以使用 nohup 命令 向进程发送信号","date":"2018-12-10","objectID":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/:21:0","tags":["linux"],"title":"进程管理","uri":"/linux%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"categories":["linux"],"content":" linux 命令","date":"2018-12-10","objectID":"/man/:0:0","tags":["man"],"title":"linux 命令使用帮助","uri":"/man/"},{"categories":["linux"],"content":" 内置命令和外置命令Linux 命令分为内部命令和外部命令 内部命令：shell自带的命令，执行时不需要创建子进程执行 外部命令：非shell自带命令，执行时，会创建出一个子进程。（父进程发送外部命令时会创建出一个子进程执行这个命令） type 命令可以查看一个命令是否为内置命令 [root@localhost ~]# type type type is a shell builtin 非内置的命令查询结果是显示二进制文件路径 [root@localhost ~]# type wget wget is /usr/bin/wget 其他选项 常见选项 -a 显示一个名字的所有可能 -t 判断一个名字当前是否是alias、keyword、function、builtin、file -p 查看一个外部命令的执行路径 -P 查看内部命令路径 命令二进制执行文件当执行一个命令时，会根据PATH变量从左往右查找相关二进制文件，如找到则执行，找不到则报错。如果命令（可执行文件）不在PATH环境变量中，可以修改环境变量或把可执行文件复制到PATH变量指定的目录 查看文件命令执行文件位置 [root@vps ~]# which cd /usr/bin/cd 查看 PATH 变量值 [root@localhost ~]# echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin shell 执行过的外部命令二进制文件路径会缓存在键值对存储中，当再次执行时，优先查找 hash 记录，因此，如果 PATH 路径改变，再次命令执行会报错，这时需要执行 hash -d 删除相关缓存或 hash -r清除所有缓存 查看当前缓存外部命令 [root@localhost ~]# hash hits command 2 /usr/bin/man 1 /usr/bin/info [root@localhost ~]# hash -l builtin hash -p /usr/bin/man man builtin hash -p /usr/bin/info info 清除 hash 记录 [root@localhost ~]# hash -r [root@localhost ~]# type man man is /usr/bin/man whereis 命令可以查找命令的二进制文件，源文件和帮助手册文件 [root@localhost ~]# whereis -u whereis whereis: /usr/bin/whereis /usr/share/man/man1/whereis.1.gz 其他选项 -b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件的路径 -S 指定搜索源代码文件的路径 man 命令man 手册可以查看大量的命令帮助信息，还可以查看文件帮助。如：man /etc/ssh/sshd_config 安装man手册 yum install -y man man-pages 查看 man 命令的 man 手册 [root@localhost ~]# man man 其他常见选项 -C, --config-file=文件 使用该用户设置文件 -d, --debug 输出调试信息 -D, --default 将所有选项都重置为默认值 --warnings[=警告] 开启 groff 的警告 -f, --whatis 等同于 whatis 命令 -k, --apropos 等同于 apropos 命令 -l, --local-file 把“手册页”参数当成本地文件名来解读 -L, --locale=区域 定义本次手册页搜索所采用的区域设置 -m, --systems=系统 指定其他操作系统 -M, --manpath=路径 设置搜索手册页的路径为“路径” -i, --ignore-case 查找手册页时不区分大小写字母 (默认) -I, --match-case 查找手册页时区分大小写字母 -t 输出到标准输出 ","date":"2018-12-10","objectID":"/man/:1:0","tags":["man"],"title":"linux 命令使用帮助","uri":"/man/"},{"categories":["linux"],"content":" man 手册章节man 被分为 9 个章节： man1：用户命令 man2：系统调用 man3：C库调用 man4：设备及特殊文件 man5：配置文件格式 man6：游戏相关 man7：杂项 man8：管理类命令 man9：内核 mann：Tcl/Tk和新文档 通常某个命令的帮助文档会在某章节中，也有少数命令会在多个章节中都有帮助文档。当命令帮助手册有多个章节时，默认优先级（whatis 命令结果）从上而下 查看 man 手册位置 [root@localhost ~]# man -w /usr/local/man:/usr/local/share/man:/usr/share/man 查看命令在man手册哪些章节 # 等效 man -f cd [root@vps ~]# whatis cd cd (1) - bash built-in commands, see bash(1) cd (n) - Change working directory 修改命令帮助文档位置 在配置文件中：MANPATH 可以指定帮助文档位置 man -M 设置帮助文档位置 whatis 命令其他常见选项 -w 使用通配符 -r 使用正则表达式 ","date":"2018-12-10","objectID":"/man/:2:0","tags":["man"],"title":"linux 命令使用帮助","uri":"/man/"},{"categories":["linux"],"content":" man 区域除了第一行信息：MAN(1)：手册页 Manual pager utils ：说明 MAN(1)：手册页 以外手册通常会把帮助信息分类，可以理解为某段信息的标题。可以使用 man -L 指定区域，以下是常见区域： NAME：命令名称和基本功能 SYNOPSIS：语法格式 DESCRIPTION：详细功能 EXAMPLES：使用示例 OPTIONS：选项和参数 ","date":"2018-12-10","objectID":"/man/:3:0","tags":["man"],"title":"linux 命令使用帮助","uri":"/man/"},{"categories":["linux"],"content":" man 手册操作命令绝大多数情况下，man 手册使用 less 命令打开的帮助手册信息，因此 less 命令操作同样在 man 手册中使用 /字符串 正向搜索字符串 ?字符串 反向搜索字符串 n 正向搜索下一个字符串 N 反向搜索下一个字符串 d 正向滚动半页 u 反向滚动半页 回车 正向滚动一行 y 反向滚动一行 空格 正向滚动一页 b 反向滚动一页 h 显示帮助 q 退出 help 命令通常 shell 内置命令都可以使用 help 命令查看帮助信息，无法查看外部命令帮助信息 使用 help 命令查看 help 命令的帮助信息 [root@vps ~]# help help help: help [-dms] [pattern ...] Display information about builtin commands. Displays brief summaries of builtin commands. If PATTERN is specified, gives detailed help on all commands matching PATTERN, otherwise the list of help topics is printed. Options: -d output short description for each topic -m display usage in pseudo-manpage format -s output only a short usage synopsis for each topic matching PATTERN Arguments: PATTERN Pattern specifiying a help topic ... info 命令info 命令也是一个 man 手册阅读器，包含大量的 GUN 项目帮助信息 示例： 查看 info 帮助信息 [root@localhost ~]# info info 常见选项 常见选项： -k, --apropos=STRING 在所有手册页的索引中查找 STRING。 -d, --directory=DIR 将 DIR 添加至 INFOPATH。 --dribble=FILENAME 将用户的击键条目在 FILENAME 中。 -f, --file=FILENAME 指定想浏览的 Info 文件。 -h, --help 显示此帮助并退出。 --index-search=STRING 跳转至索引条目 STRING 所指的节点。 -n, --node=NODENAME 在首个浏览过的 Info 文件中指定节点。 -o, --output=FILENAME 将选中的节点全输出至 FILENAME。 -R, --raw-escapes 输出“原始”的 ANSI 转义符(默认)。 --no-raw-escapes 将转义符输出为普通文本。 --restore=FILENAME 从 FILENAME 中读取初始击键条目。 -O, --show-options, --usage 跳转至命令行选项节点。 --subnodes 递归输出菜单项。 --vi-keys 使用类似于 vi 和 less 的按键绑定。 --version 显示版本信息并退出。 -w, --where, --location 打印 Info 文件在系统中的位置 常用快捷键 ? 查看info的常用快捷键。 N 显示（相对于本节点的）下一节点的文档内容。 P 显示（相对于本节点的）前一节点的文档内容。 U 进入当前命令所在的主题。 M 敲M键后输入命令的名称就可以查看该命令的帮助文档了。 G 敲G键后输入主题名称，进入该主题。 L 回到上一个访问的页面。 SPACE 向前滚动一页。 BACKUP或DEL键 向后滚动一页。 Q 退出info。 ？ 显示帮助窗口，在帮助窗口中有以下操作： Ctrl-x 0 闭帮助窗口 Ctrl-x Ctrl-c 关闭整个 Info q 退出 info n 打开与本 Node 关联的下一个 Node p 打开与本 Node 关联的前一个 Node u 打开与本 Node 关联的上一个 Node l 回到上一次访问的 Node m或g 选择一个菜单项（Node 的名字）输入指定菜单的名字后按回车，打开指定菜单项关联的 Node 空格键 下一页（PageDown 也可以，下一页从当前页的最后两行开始算起）下一个 Node （若当前页在 Node 文档的末尾） Del 键 上一页（PageUp 也可以，上一页从当前页的开始两行开始算起）上一个 Node （若当前页 Node 文档的开始） b 或 t 或 Home 文档的开始（b 是 begining 的意思） e 或 End 文档的末尾（b 是 ending 的意思） Ctrl-l 刷新当前页，若当前文档显示情况有问题时 Ctrl-g 取消所键入的指令 -h 或 –help 选项基本上所有命令或脚本都会有 -h 或 --help 选项查看简短的帮助信息或完整的帮助信息 查看 man 命令简短帮助信息 [root@localhost ~]# man -h Usage: man [OPTION...] [SECTION] PAGE... 软件包地址部分命令可以通过软件包信息中获取官方地址，如 vsftpd , firewalld 等，有的则是软件包下载地址 [root@centos7 yum.repos.d]# yum info $(rpm -qf $(which firewalld)) | grep URL URL : http://www.firewalld.org error","date":"2018-12-10","objectID":"/man/:4:0","tags":["man"],"title":"linux 命令使用帮助","uri":"/man/"},{"categories":["linux"],"content":" No manual entry for proc报错信息： [root@localhost hugo]# man proc No manual entry for proc 出现原因：manpage 不够完整 解决方法：安装 man-pages [root@localhost hugo]# yum install -y man-pages Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile epel/x86_64/metalink ... Installed: man-pages.noarch 0:3.53-5.el7 Complete! ","date":"2018-12-10","objectID":"/man/:5:0","tags":["man"],"title":"linux 命令使用帮助","uri":"/man/"},{"categories":["linux"],"content":"linux 中的通配符： *: 任意字符（0个或多个） ?: 任意单个字符 []: 方括号内的任意单个字符 [:digit:]: 所有数字 [:alpha:]: 所有字母 [:space:]: 所有空白字符 [:punct:]: 所有标点符号 [:lower:]: 所有小写字母 [:upper:]: 所有大写字母 [:alnum:]: 所有数字和字母 [:print:]: 所有非空白字符（包括空格） [^]: 非方括号内的任意单个字符 ","date":"2018-12-10","objectID":"/%E9%80%9A%E9%85%8D%E7%AC%A6/:0:0","tags":["通配符"],"title":"linux中的通配符","uri":"/%E9%80%9A%E9%85%8D%E7%AC%A6/"}]